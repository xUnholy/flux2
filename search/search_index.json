{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Flux v2 \u00b6 Flux is a tool for keeping Kubernetes clusters in sync with sources of configuration (like Git repositories), and automating updates to configuration when there is new code to deploy. Flux version 2 (\"Flux v2\") is built from the ground up to use Kubernetes' API extension system, and to integrate with Prometheus and other core components of the Kubernetes ecosystem. In version 2, Flux supports multi-tenancy and support for syncing an arbitrary number of Git repositories, among other long-requested features. Flux v2 is constructed with the GitOps Toolkit , a set of composable APIs and specialized tools for building Continuous Delivery on top of Kubernetes. Who is Flux for? \u00b6 Flux helps cluster operators who automate provision and configuration of clusters; platform engineers who build continuous delivery for developer teams; app developers who rely on continuous delivery to get their code live. The GitOps Toolkit is for platform engineers who want to make their own continuous delivery system, and have requirements not covered by Flux. What can I do with Flux? \u00b6 Flux is based on a set of Kubernetes API extensions (\"custom resources\"), which control how git repositories and other sources of configuration are applied into the cluster (\"synced\"). For example, you create a GitRepository object to mirror configuration from a Git repository, then a Kustomization object to sync that configuration. Flux works with Kubernetes' role-based access control (RBAC), so you can lock down what any particular sync can change. It can send notifications to Slack and other like systems when configuration is synced and ready, and receive webhooks to tell it when to sync. The flux command-line tool is a convenient way to bootstrap the system in a cluster, and to access the custom resources that make up the API. Where do I start? \u00b6 Get started with Flux v2! Following this guide will just take a couple of minutes to complete: After installing the flux CLI and running a couple of very simple commands, you will have a GitOps workflow setup which involves a staging and a production cluster. If you should need help, please refer to our Support page . More detail on what's in Flux \u00b6 Features: Source configuration from Git and Helm repositories, and S3-compatible buckets (e.g., Minio) Kustomize and Helm support Event-triggered and periodic reconciliation Integration with Kubernetes RBAC Health assessment (clusters and workloads) Dependency management (infrastructure and workloads) Alerting to external systems (webhook senders) External events handling (webhook receivers) Automated container image updates to Git (image scanning and patching) Policy-driven validation (OPA, Kyverno, admission controllers) Seamless integration with Git providers (GitHub, GitLab, Bitbucket) Interoperability with workflow providers (GitHub Actions, Tekton, Argo) Interoperability with Cluster API (CAPI) providers Community \u00b6 Need help or want to contribute? Please see the links below. The Flux project is always looking for new contributors and there are a multitude of ways to get involved. Getting Started? Look at our Get Started guide and give us feedback Need help? First: Ask questions on our GH Discussions page Second: Talk to us in the #flux channel on CNCF Slack Please follow our Support Guidelines (in short: be nice, be respectful of volunteers' time, understand that maintainers and contributors cannot respond to all DMs, and keep discussions in the public #flux channel as much as possible). Have feature proposals or want to contribute? Propose features on our GH Discussions page Join our upcoming dev meetings ( meeting access and agenda ) Join the flux-dev mailing list . Check out how to contribute to the project Events \u00b6 Check out our events calendar , both with upcoming talks you can attend or past events videos you can watch. We look forward to seeing you with us!","title":"Introduction"},{"location":"#flux-v2","text":"Flux is a tool for keeping Kubernetes clusters in sync with sources of configuration (like Git repositories), and automating updates to configuration when there is new code to deploy. Flux version 2 (\"Flux v2\") is built from the ground up to use Kubernetes' API extension system, and to integrate with Prometheus and other core components of the Kubernetes ecosystem. In version 2, Flux supports multi-tenancy and support for syncing an arbitrary number of Git repositories, among other long-requested features. Flux v2 is constructed with the GitOps Toolkit , a set of composable APIs and specialized tools for building Continuous Delivery on top of Kubernetes.","title":"Flux v2"},{"location":"#who-is-flux-for","text":"Flux helps cluster operators who automate provision and configuration of clusters; platform engineers who build continuous delivery for developer teams; app developers who rely on continuous delivery to get their code live. The GitOps Toolkit is for platform engineers who want to make their own continuous delivery system, and have requirements not covered by Flux.","title":"Who is Flux for?"},{"location":"#what-can-i-do-with-flux","text":"Flux is based on a set of Kubernetes API extensions (\"custom resources\"), which control how git repositories and other sources of configuration are applied into the cluster (\"synced\"). For example, you create a GitRepository object to mirror configuration from a Git repository, then a Kustomization object to sync that configuration. Flux works with Kubernetes' role-based access control (RBAC), so you can lock down what any particular sync can change. It can send notifications to Slack and other like systems when configuration is synced and ready, and receive webhooks to tell it when to sync. The flux command-line tool is a convenient way to bootstrap the system in a cluster, and to access the custom resources that make up the API.","title":"What can I do with Flux?"},{"location":"#where-do-i-start","text":"Get started with Flux v2! Following this guide will just take a couple of minutes to complete: After installing the flux CLI and running a couple of very simple commands, you will have a GitOps workflow setup which involves a staging and a production cluster. If you should need help, please refer to our Support page .","title":"Where do I start?"},{"location":"#more-detail-on-whats-in-flux","text":"Features: Source configuration from Git and Helm repositories, and S3-compatible buckets (e.g., Minio) Kustomize and Helm support Event-triggered and periodic reconciliation Integration with Kubernetes RBAC Health assessment (clusters and workloads) Dependency management (infrastructure and workloads) Alerting to external systems (webhook senders) External events handling (webhook receivers) Automated container image updates to Git (image scanning and patching) Policy-driven validation (OPA, Kyverno, admission controllers) Seamless integration with Git providers (GitHub, GitLab, Bitbucket) Interoperability with workflow providers (GitHub Actions, Tekton, Argo) Interoperability with Cluster API (CAPI) providers","title":"More detail on what's in Flux"},{"location":"#community","text":"Need help or want to contribute? Please see the links below. The Flux project is always looking for new contributors and there are a multitude of ways to get involved. Getting Started? Look at our Get Started guide and give us feedback Need help? First: Ask questions on our GH Discussions page Second: Talk to us in the #flux channel on CNCF Slack Please follow our Support Guidelines (in short: be nice, be respectful of volunteers' time, understand that maintainers and contributors cannot respond to all DMs, and keep discussions in the public #flux channel as much as possible). Have feature proposals or want to contribute? Propose features on our GH Discussions page Join our upcoming dev meetings ( meeting access and agenda ) Join the flux-dev mailing list . Check out how to contribute to the project","title":"Community"},{"location":"#events","text":"Check out our events calendar , both with upcoming talks you can attend or past events videos you can watch. We look forward to seeing you with us!","title":"Events"},{"location":"cmd/flux/","text":"flux \u00b6 Command line utility for assembling Kubernetes CD pipelines Synopsis \u00b6 Command line utility for assembling Kubernetes CD pipelines the GitOps way. Examples \u00b6 # Check prerequisites flux check --pre # Install the latest version of Flux flux install --version=master # Create a source from a public Git repository flux create source git webapp-latest \\ --url=https://github.com/stefanprodan/podinfo \\ --branch=master \\ --interval=3m # List GitRepository sources and their status flux get sources git # Trigger a GitRepository source reconciliation flux reconcile source git flux-system # Export GitRepository sources in YAML format flux export source git --all > sources.yaml # Create a Kustomization for deploying a series of microservices flux create kustomization webapp-dev \\ --source=webapp-latest \\ --path=\"./deploy/webapp/\" \\ --prune=true \\ --interval=5m \\ --validation=client \\ --health-check=\"Deployment/backend.webapp\" \\ --health-check=\"Deployment/frontend.webapp\" \\ --health-check-timeout=2m # Trigger a git sync of the Kustomization's source and apply changes flux reconcile kustomization webapp-dev --with-source # Suspend a Kustomization reconciliation flux suspend kustomization webapp-dev # Export Kustomizations in YAML format flux export kustomization --all > kustomizations.yaml # Resume a Kustomization reconciliation flux resume kustomization webapp-dev # Delete a Kustomization flux delete kustomization webapp-dev # Delete a GitRepository source flux delete source git webapp-latest # Uninstall Flux and delete CRDs flux uninstall Options \u00b6 --context string kubernetes context to use -h, --help help for flux --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux bootstrap - Bootstrap toolkit components flux check - Check requirements and installation flux completion - Generates completion scripts for various shells flux create - Create or update sources and resources flux delete - Delete sources and resources flux export - Export resources in YAML format flux get - Get sources and resources flux install - Install or upgrade Flux flux reconcile - Reconcile sources and resources flux resume - Resume suspended resources flux suspend - Suspend resources flux uninstall - Uninstall Flux and its custom resource definitions","title":"Overview"},{"location":"cmd/flux/#flux","text":"Command line utility for assembling Kubernetes CD pipelines","title":"flux"},{"location":"cmd/flux/#synopsis","text":"Command line utility for assembling Kubernetes CD pipelines the GitOps way.","title":"Synopsis"},{"location":"cmd/flux/#examples","text":"# Check prerequisites flux check --pre # Install the latest version of Flux flux install --version=master # Create a source from a public Git repository flux create source git webapp-latest \\ --url=https://github.com/stefanprodan/podinfo \\ --branch=master \\ --interval=3m # List GitRepository sources and their status flux get sources git # Trigger a GitRepository source reconciliation flux reconcile source git flux-system # Export GitRepository sources in YAML format flux export source git --all > sources.yaml # Create a Kustomization for deploying a series of microservices flux create kustomization webapp-dev \\ --source=webapp-latest \\ --path=\"./deploy/webapp/\" \\ --prune=true \\ --interval=5m \\ --validation=client \\ --health-check=\"Deployment/backend.webapp\" \\ --health-check=\"Deployment/frontend.webapp\" \\ --health-check-timeout=2m # Trigger a git sync of the Kustomization's source and apply changes flux reconcile kustomization webapp-dev --with-source # Suspend a Kustomization reconciliation flux suspend kustomization webapp-dev # Export Kustomizations in YAML format flux export kustomization --all > kustomizations.yaml # Resume a Kustomization reconciliation flux resume kustomization webapp-dev # Delete a Kustomization flux delete kustomization webapp-dev # Delete a GitRepository source flux delete source git webapp-latest # Uninstall Flux and delete CRDs flux uninstall","title":"Examples"},{"location":"cmd/flux/#options","text":"--context string kubernetes context to use -h, --help help for flux --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options"},{"location":"cmd/flux/#see-also","text":"flux bootstrap - Bootstrap toolkit components flux check - Check requirements and installation flux completion - Generates completion scripts for various shells flux create - Create or update sources and resources flux delete - Delete sources and resources flux export - Export resources in YAML format flux get - Get sources and resources flux install - Install or upgrade Flux flux reconcile - Reconcile sources and resources flux resume - Resume suspended resources flux suspend - Suspend resources flux uninstall - Uninstall Flux and its custom resource definitions","title":"SEE ALSO"},{"location":"cmd/flux_bootstrap/","text":"flux bootstrap \u00b6 Bootstrap toolkit components Synopsis \u00b6 The bootstrap sub-commands bootstrap the toolkit components on the targeted Git provider. Options \u00b6 --branch string default branch (for GitHub this must match the default branch setting for the organization) (default \"main\") --cluster-domain string internal cluster domain (default \"cluster.local\") --components strings list of components, accepts comma-separated values (default [source-controller,kustomize-controller,helm-controller,notification-controller]) --components-extra strings list of components in addition to those supplied or defaulted, accepts comma-separated values -h, --help help for bootstrap --image-pull-secret string Kubernetes secret name used for pulling the toolkit images from a private registry --log-level logLevel log level, available options are: (debug, info, error) (default info) --network-policy deny ingress access to the toolkit controllers from other namespaces using network policies (default true) --registry string container registry where the toolkit images are published (default \"ghcr.io/fluxcd\") --token-auth when enabled, the personal access token will be used instead of SSH deploy key --toleration-keys strings list of toleration keys used to schedule the components pods onto nodes with matching taints -v, --version string toolkit version, when specified the manifests are downloaded from https://github.com/fluxcd/flux2/releases --watch-all-namespaces watch for custom resources in all namespaces, if set to false it will only watch the namespace where the toolkit is installed (default true) Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux - Command line utility for assembling Kubernetes CD pipelines flux bootstrap github - Bootstrap toolkit components in a GitHub repository flux bootstrap gitlab - Bootstrap toolkit components in a GitLab repository","title":"Bootstrap"},{"location":"cmd/flux_bootstrap/#flux-bootstrap","text":"Bootstrap toolkit components","title":"flux bootstrap"},{"location":"cmd/flux_bootstrap/#synopsis","text":"The bootstrap sub-commands bootstrap the toolkit components on the targeted Git provider.","title":"Synopsis"},{"location":"cmd/flux_bootstrap/#options","text":"--branch string default branch (for GitHub this must match the default branch setting for the organization) (default \"main\") --cluster-domain string internal cluster domain (default \"cluster.local\") --components strings list of components, accepts comma-separated values (default [source-controller,kustomize-controller,helm-controller,notification-controller]) --components-extra strings list of components in addition to those supplied or defaulted, accepts comma-separated values -h, --help help for bootstrap --image-pull-secret string Kubernetes secret name used for pulling the toolkit images from a private registry --log-level logLevel log level, available options are: (debug, info, error) (default info) --network-policy deny ingress access to the toolkit controllers from other namespaces using network policies (default true) --registry string container registry where the toolkit images are published (default \"ghcr.io/fluxcd\") --token-auth when enabled, the personal access token will be used instead of SSH deploy key --toleration-keys strings list of toleration keys used to schedule the components pods onto nodes with matching taints -v, --version string toolkit version, when specified the manifests are downloaded from https://github.com/fluxcd/flux2/releases --watch-all-namespaces watch for custom resources in all namespaces, if set to false it will only watch the namespace where the toolkit is installed (default true)","title":"Options"},{"location":"cmd/flux_bootstrap/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_bootstrap/#see-also","text":"flux - Command line utility for assembling Kubernetes CD pipelines flux bootstrap github - Bootstrap toolkit components in a GitHub repository flux bootstrap gitlab - Bootstrap toolkit components in a GitLab repository","title":"SEE ALSO"},{"location":"cmd/flux_bootstrap_github/","text":"flux bootstrap github \u00b6 Bootstrap toolkit components in a GitHub repository Synopsis \u00b6 The bootstrap github command creates the GitHub repository if it doesn't exists and commits the toolkit components manifests to the main branch. Then it configures the target cluster to synchronize with the repository. If the toolkit components are present on the cluster, the bootstrap command will perform an upgrade if needed. flux bootstrap github [flags] Examples \u00b6 # Create a GitHub personal access token and export it as an env var export GITHUB_TOKEN=<my-token> # Run bootstrap for a private repo owned by a GitHub organization flux bootstrap github --owner=<organization> --repository=<repo name> # Run bootstrap for a private repo and assign organization teams to it flux bootstrap github --owner=<organization> --repository=<repo name> --team=<team1 slug> --team=<team2 slug> # Run bootstrap for a repository path flux bootstrap github --owner=<organization> --repository=<repo name> --path=dev-cluster # Run bootstrap for a public repository on a personal account flux bootstrap github --owner=<user> --repository=<repo name> --private=false --personal=true # Run bootstrap for a private repo hosted on GitHub Enterprise using SSH auth flux bootstrap github --owner=<organization> --repository=<repo name> --hostname=<domain> --ssh-hostname=<domain> # Run bootstrap for a private repo hosted on GitHub Enterprise using HTTPS auth flux bootstrap github --owner=<organization> --repository=<repo name> --hostname=<domain> --token-auth # Run bootstrap for a an existing repository with a branch named main flux bootstrap github --owner=<organization> --repository=<repo name> --branch=main Options \u00b6 -h, --help help for github --hostname string GitHub hostname (default \"github.com\") --interval duration sync interval (default 1m0s) --owner string GitHub user or organization name --path safeRelativePath path relative to the repository root, when specified the cluster sync will be scoped to this path --personal if true, the owner is assumed to be a GitHub user; otherwise an org --private if true, the repository is assumed to be private (default true) --repository string GitHub repository name --ssh-hostname string GitHub SSH hostname, to be used when the SSH host differs from the HTTPS one --team stringArray GitHub team to be given maintainer access Options inherited from parent commands \u00b6 --branch string default branch (for GitHub this must match the default branch setting for the organization) (default \"main\") --cluster-domain string internal cluster domain (default \"cluster.local\") --components strings list of components, accepts comma-separated values (default [source-controller,kustomize-controller,helm-controller,notification-controller]) --components-extra strings list of components in addition to those supplied or defaulted, accepts comma-separated values --context string kubernetes context to use --image-pull-secret string Kubernetes secret name used for pulling the toolkit images from a private registry --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --log-level logLevel log level, available options are: (debug, info, error) (default info) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --network-policy deny ingress access to the toolkit controllers from other namespaces using network policies (default true) --registry string container registry where the toolkit images are published (default \"ghcr.io/fluxcd\") --timeout duration timeout for this operation (default 5m0s) --token-auth when enabled, the personal access token will be used instead of SSH deploy key --toleration-keys strings list of toleration keys used to schedule the components pods onto nodes with matching taints --verbose print generated objects -v, --version string toolkit version, when specified the manifests are downloaded from https://github.com/fluxcd/flux2/releases --watch-all-namespaces watch for custom resources in all namespaces, if set to false it will only watch the namespace where the toolkit is installed (default true) SEE ALSO \u00b6 flux bootstrap - Bootstrap toolkit components","title":"Bootstrap github"},{"location":"cmd/flux_bootstrap_github/#flux-bootstrap-github","text":"Bootstrap toolkit components in a GitHub repository","title":"flux bootstrap github"},{"location":"cmd/flux_bootstrap_github/#synopsis","text":"The bootstrap github command creates the GitHub repository if it doesn't exists and commits the toolkit components manifests to the main branch. Then it configures the target cluster to synchronize with the repository. If the toolkit components are present on the cluster, the bootstrap command will perform an upgrade if needed. flux bootstrap github [flags]","title":"Synopsis"},{"location":"cmd/flux_bootstrap_github/#examples","text":"# Create a GitHub personal access token and export it as an env var export GITHUB_TOKEN=<my-token> # Run bootstrap for a private repo owned by a GitHub organization flux bootstrap github --owner=<organization> --repository=<repo name> # Run bootstrap for a private repo and assign organization teams to it flux bootstrap github --owner=<organization> --repository=<repo name> --team=<team1 slug> --team=<team2 slug> # Run bootstrap for a repository path flux bootstrap github --owner=<organization> --repository=<repo name> --path=dev-cluster # Run bootstrap for a public repository on a personal account flux bootstrap github --owner=<user> --repository=<repo name> --private=false --personal=true # Run bootstrap for a private repo hosted on GitHub Enterprise using SSH auth flux bootstrap github --owner=<organization> --repository=<repo name> --hostname=<domain> --ssh-hostname=<domain> # Run bootstrap for a private repo hosted on GitHub Enterprise using HTTPS auth flux bootstrap github --owner=<organization> --repository=<repo name> --hostname=<domain> --token-auth # Run bootstrap for a an existing repository with a branch named main flux bootstrap github --owner=<organization> --repository=<repo name> --branch=main","title":"Examples"},{"location":"cmd/flux_bootstrap_github/#options","text":"-h, --help help for github --hostname string GitHub hostname (default \"github.com\") --interval duration sync interval (default 1m0s) --owner string GitHub user or organization name --path safeRelativePath path relative to the repository root, when specified the cluster sync will be scoped to this path --personal if true, the owner is assumed to be a GitHub user; otherwise an org --private if true, the repository is assumed to be private (default true) --repository string GitHub repository name --ssh-hostname string GitHub SSH hostname, to be used when the SSH host differs from the HTTPS one --team stringArray GitHub team to be given maintainer access","title":"Options"},{"location":"cmd/flux_bootstrap_github/#options-inherited-from-parent-commands","text":"--branch string default branch (for GitHub this must match the default branch setting for the organization) (default \"main\") --cluster-domain string internal cluster domain (default \"cluster.local\") --components strings list of components, accepts comma-separated values (default [source-controller,kustomize-controller,helm-controller,notification-controller]) --components-extra strings list of components in addition to those supplied or defaulted, accepts comma-separated values --context string kubernetes context to use --image-pull-secret string Kubernetes secret name used for pulling the toolkit images from a private registry --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --log-level logLevel log level, available options are: (debug, info, error) (default info) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --network-policy deny ingress access to the toolkit controllers from other namespaces using network policies (default true) --registry string container registry where the toolkit images are published (default \"ghcr.io/fluxcd\") --timeout duration timeout for this operation (default 5m0s) --token-auth when enabled, the personal access token will be used instead of SSH deploy key --toleration-keys strings list of toleration keys used to schedule the components pods onto nodes with matching taints --verbose print generated objects -v, --version string toolkit version, when specified the manifests are downloaded from https://github.com/fluxcd/flux2/releases --watch-all-namespaces watch for custom resources in all namespaces, if set to false it will only watch the namespace where the toolkit is installed (default true)","title":"Options inherited from parent commands"},{"location":"cmd/flux_bootstrap_github/#see-also","text":"flux bootstrap - Bootstrap toolkit components","title":"SEE ALSO"},{"location":"cmd/flux_bootstrap_gitlab/","text":"flux bootstrap gitlab \u00b6 Bootstrap toolkit components in a GitLab repository Synopsis \u00b6 The bootstrap gitlab command creates the GitLab repository if it doesn't exists and commits the toolkit components manifests to the master branch. Then it configures the target cluster to synchronize with the repository. If the toolkit components are present on the cluster, the bootstrap command will perform an upgrade if needed. flux bootstrap gitlab [flags] Examples \u00b6 # Create a GitLab API token and export it as an env var export GITLAB_TOKEN=<my-token> # Run bootstrap for a private repo using HTTPS token authentication flux bootstrap gitlab --owner=<group> --repository=<repo name> --token-auth # Run bootstrap for a private repo using SSH authentication flux bootstrap gitlab --owner=<group> --repository=<repo name> # Run bootstrap for a repository path flux bootstrap gitlab --owner=<group> --repository=<repo name> --path=dev-cluster # Run bootstrap for a public repository on a personal account flux bootstrap gitlab --owner=<user> --repository=<repo name> --private=false --personal --token-auth # Run bootstrap for a private repo hosted on a GitLab server flux bootstrap gitlab --owner=<group> --repository=<repo name> --hostname=<domain> --token-auth # Run bootstrap for a an existing repository with a branch named main flux bootstrap gitlab --owner=<organization> --repository=<repo name> --branch=main --token-auth Options \u00b6 -h, --help help for gitlab --hostname string GitLab hostname (default \"gitlab.com\") --interval duration sync interval (default 1m0s) --owner string GitLab user or group name --path safeRelativePath path relative to the repository root, when specified the cluster sync will be scoped to this path --personal if true, the owner is assumed to be a GitLab user; otherwise a group --private if true, the repository is assumed to be private (default true) --repository string GitLab repository name --ssh-hostname string GitLab SSH hostname, to be used when the SSH host differs from the HTTPS one Options inherited from parent commands \u00b6 --branch string default branch (for GitHub this must match the default branch setting for the organization) (default \"main\") --cluster-domain string internal cluster domain (default \"cluster.local\") --components strings list of components, accepts comma-separated values (default [source-controller,kustomize-controller,helm-controller,notification-controller]) --components-extra strings list of components in addition to those supplied or defaulted, accepts comma-separated values --context string kubernetes context to use --image-pull-secret string Kubernetes secret name used for pulling the toolkit images from a private registry --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --log-level logLevel log level, available options are: (debug, info, error) (default info) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --network-policy deny ingress access to the toolkit controllers from other namespaces using network policies (default true) --registry string container registry where the toolkit images are published (default \"ghcr.io/fluxcd\") --timeout duration timeout for this operation (default 5m0s) --token-auth when enabled, the personal access token will be used instead of SSH deploy key --toleration-keys strings list of toleration keys used to schedule the components pods onto nodes with matching taints --verbose print generated objects -v, --version string toolkit version, when specified the manifests are downloaded from https://github.com/fluxcd/flux2/releases --watch-all-namespaces watch for custom resources in all namespaces, if set to false it will only watch the namespace where the toolkit is installed (default true) SEE ALSO \u00b6 flux bootstrap - Bootstrap toolkit components","title":"Bootstrap gitlab"},{"location":"cmd/flux_bootstrap_gitlab/#flux-bootstrap-gitlab","text":"Bootstrap toolkit components in a GitLab repository","title":"flux bootstrap gitlab"},{"location":"cmd/flux_bootstrap_gitlab/#synopsis","text":"The bootstrap gitlab command creates the GitLab repository if it doesn't exists and commits the toolkit components manifests to the master branch. Then it configures the target cluster to synchronize with the repository. If the toolkit components are present on the cluster, the bootstrap command will perform an upgrade if needed. flux bootstrap gitlab [flags]","title":"Synopsis"},{"location":"cmd/flux_bootstrap_gitlab/#examples","text":"# Create a GitLab API token and export it as an env var export GITLAB_TOKEN=<my-token> # Run bootstrap for a private repo using HTTPS token authentication flux bootstrap gitlab --owner=<group> --repository=<repo name> --token-auth # Run bootstrap for a private repo using SSH authentication flux bootstrap gitlab --owner=<group> --repository=<repo name> # Run bootstrap for a repository path flux bootstrap gitlab --owner=<group> --repository=<repo name> --path=dev-cluster # Run bootstrap for a public repository on a personal account flux bootstrap gitlab --owner=<user> --repository=<repo name> --private=false --personal --token-auth # Run bootstrap for a private repo hosted on a GitLab server flux bootstrap gitlab --owner=<group> --repository=<repo name> --hostname=<domain> --token-auth # Run bootstrap for a an existing repository with a branch named main flux bootstrap gitlab --owner=<organization> --repository=<repo name> --branch=main --token-auth","title":"Examples"},{"location":"cmd/flux_bootstrap_gitlab/#options","text":"-h, --help help for gitlab --hostname string GitLab hostname (default \"gitlab.com\") --interval duration sync interval (default 1m0s) --owner string GitLab user or group name --path safeRelativePath path relative to the repository root, when specified the cluster sync will be scoped to this path --personal if true, the owner is assumed to be a GitLab user; otherwise a group --private if true, the repository is assumed to be private (default true) --repository string GitLab repository name --ssh-hostname string GitLab SSH hostname, to be used when the SSH host differs from the HTTPS one","title":"Options"},{"location":"cmd/flux_bootstrap_gitlab/#options-inherited-from-parent-commands","text":"--branch string default branch (for GitHub this must match the default branch setting for the organization) (default \"main\") --cluster-domain string internal cluster domain (default \"cluster.local\") --components strings list of components, accepts comma-separated values (default [source-controller,kustomize-controller,helm-controller,notification-controller]) --components-extra strings list of components in addition to those supplied or defaulted, accepts comma-separated values --context string kubernetes context to use --image-pull-secret string Kubernetes secret name used for pulling the toolkit images from a private registry --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --log-level logLevel log level, available options are: (debug, info, error) (default info) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --network-policy deny ingress access to the toolkit controllers from other namespaces using network policies (default true) --registry string container registry where the toolkit images are published (default \"ghcr.io/fluxcd\") --timeout duration timeout for this operation (default 5m0s) --token-auth when enabled, the personal access token will be used instead of SSH deploy key --toleration-keys strings list of toleration keys used to schedule the components pods onto nodes with matching taints --verbose print generated objects -v, --version string toolkit version, when specified the manifests are downloaded from https://github.com/fluxcd/flux2/releases --watch-all-namespaces watch for custom resources in all namespaces, if set to false it will only watch the namespace where the toolkit is installed (default true)","title":"Options inherited from parent commands"},{"location":"cmd/flux_bootstrap_gitlab/#see-also","text":"flux bootstrap - Bootstrap toolkit components","title":"SEE ALSO"},{"location":"cmd/flux_check/","text":"flux check \u00b6 Check requirements and installation Synopsis \u00b6 The check command will perform a series of checks to validate that the local environment is configured correctly and if the installed components are healthy. flux check [flags] Examples \u00b6 # Run pre-installation checks flux check --pre # Run installation checks flux check Options \u00b6 --components strings list of components, accepts comma-separated values (default [source-controller,kustomize-controller,helm-controller,notification-controller]) --components-extra strings list of components in addition to those supplied or defaulted, accepts comma-separated values -h, --help help for check --pre only run pre-installation checks Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux - Command line utility for assembling Kubernetes CD pipelines","title":"Check"},{"location":"cmd/flux_check/#flux-check","text":"Check requirements and installation","title":"flux check"},{"location":"cmd/flux_check/#synopsis","text":"The check command will perform a series of checks to validate that the local environment is configured correctly and if the installed components are healthy. flux check [flags]","title":"Synopsis"},{"location":"cmd/flux_check/#examples","text":"# Run pre-installation checks flux check --pre # Run installation checks flux check","title":"Examples"},{"location":"cmd/flux_check/#options","text":"--components strings list of components, accepts comma-separated values (default [source-controller,kustomize-controller,helm-controller,notification-controller]) --components-extra strings list of components in addition to those supplied or defaulted, accepts comma-separated values -h, --help help for check --pre only run pre-installation checks","title":"Options"},{"location":"cmd/flux_check/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_check/#see-also","text":"flux - Command line utility for assembling Kubernetes CD pipelines","title":"SEE ALSO"},{"location":"cmd/flux_completion/","text":"flux completion \u00b6 Generates completion scripts for various shells Synopsis \u00b6 The completion sub-command generates completion scripts for various shells Options \u00b6 -h, --help help for completion Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux - Command line utility for assembling Kubernetes CD pipelines flux completion bash - Generates bash completion scripts flux completion fish - Generates fish completion scripts flux completion powershell - Generates powershell completion scripts flux completion zsh - Generates zsh completion scripts","title":"Flux completion"},{"location":"cmd/flux_completion/#flux-completion","text":"Generates completion scripts for various shells","title":"flux completion"},{"location":"cmd/flux_completion/#synopsis","text":"The completion sub-command generates completion scripts for various shells","title":"Synopsis"},{"location":"cmd/flux_completion/#options","text":"-h, --help help for completion","title":"Options"},{"location":"cmd/flux_completion/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_completion/#see-also","text":"flux - Command line utility for assembling Kubernetes CD pipelines flux completion bash - Generates bash completion scripts flux completion fish - Generates fish completion scripts flux completion powershell - Generates powershell completion scripts flux completion zsh - Generates zsh completion scripts","title":"SEE ALSO"},{"location":"cmd/flux_completion_bash/","text":"flux completion bash \u00b6 Generates bash completion scripts flux completion bash [flags] Examples \u00b6 To load completion run . <(flux completion bash) To configure your bash shell to load completions for each session add to your bashrc # ~/.bashrc or ~/.profile command -v flux >/dev/null && . <(flux completion bash) Options \u00b6 -h, --help help for bash Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux completion - Generates completion scripts for various shells","title":"Flux completion bash"},{"location":"cmd/flux_completion_bash/#flux-completion-bash","text":"Generates bash completion scripts flux completion bash [flags]","title":"flux completion bash"},{"location":"cmd/flux_completion_bash/#examples","text":"To load completion run . <(flux completion bash) To configure your bash shell to load completions for each session add to your bashrc # ~/.bashrc or ~/.profile command -v flux >/dev/null && . <(flux completion bash)","title":"Examples"},{"location":"cmd/flux_completion_bash/#options","text":"-h, --help help for bash","title":"Options"},{"location":"cmd/flux_completion_bash/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_completion_bash/#see-also","text":"flux completion - Generates completion scripts for various shells","title":"SEE ALSO"},{"location":"cmd/flux_completion_fish/","text":"flux completion fish \u00b6 Generates fish completion scripts flux completion fish [flags] Examples \u00b6 To configure your fish shell to load completions for each session write this script to your completions dir: flux completion fish > ~/.config/fish/completions/flux.fish See http://fishshell.com/docs/current/index.html#completion-own for more details Options \u00b6 -h, --help help for fish Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux completion - Generates completion scripts for various shells","title":"Flux completion fish"},{"location":"cmd/flux_completion_fish/#flux-completion-fish","text":"Generates fish completion scripts flux completion fish [flags]","title":"flux completion fish"},{"location":"cmd/flux_completion_fish/#examples","text":"To configure your fish shell to load completions for each session write this script to your completions dir: flux completion fish > ~/.config/fish/completions/flux.fish See http://fishshell.com/docs/current/index.html#completion-own for more details","title":"Examples"},{"location":"cmd/flux_completion_fish/#options","text":"-h, --help help for fish","title":"Options"},{"location":"cmd/flux_completion_fish/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_completion_fish/#see-also","text":"flux completion - Generates completion scripts for various shells","title":"SEE ALSO"},{"location":"cmd/flux_completion_powershell/","text":"flux completion powershell \u00b6 Generates powershell completion scripts flux completion powershell [flags] Examples \u00b6 To load completion run . <(flux completion powershell) To configure your powershell shell to load completions for each session add to your powershell profile Windows: cd \"$env:USERPROFILE\\Documents\\WindowsPowerShell\\Modules\" flux completion >> flux-completion.ps1 Linux: cd \"${XDG_CONFIG_HOME:-\"$HOME/.config/\"}/powershell/modules\" flux completion >> flux-completions.ps1 Options \u00b6 -h, --help help for powershell Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux completion - Generates completion scripts for various shells","title":"Flux completion powershell"},{"location":"cmd/flux_completion_powershell/#flux-completion-powershell","text":"Generates powershell completion scripts flux completion powershell [flags]","title":"flux completion powershell"},{"location":"cmd/flux_completion_powershell/#examples","text":"To load completion run . <(flux completion powershell) To configure your powershell shell to load completions for each session add to your powershell profile Windows: cd \"$env:USERPROFILE\\Documents\\WindowsPowerShell\\Modules\" flux completion >> flux-completion.ps1 Linux: cd \"${XDG_CONFIG_HOME:-\"$HOME/.config/\"}/powershell/modules\" flux completion >> flux-completions.ps1","title":"Examples"},{"location":"cmd/flux_completion_powershell/#options","text":"-h, --help help for powershell","title":"Options"},{"location":"cmd/flux_completion_powershell/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_completion_powershell/#see-also","text":"flux completion - Generates completion scripts for various shells","title":"SEE ALSO"},{"location":"cmd/flux_completion_zsh/","text":"flux completion zsh \u00b6 Generates zsh completion scripts flux completion zsh [flags] Examples \u00b6 To load completion run . <(flux completion zsh) && compdef _flux flux To configure your zsh shell to load completions for each session add to your zshrc # ~/.zshrc or ~/.profile command -v flux >/dev/null && . <(flux completion zsh) && compdef _flux flux or write a cached file in one of the completion directories in your ${fpath}: echo \"${fpath// /\\n}\" | grep -i completion flux completion zsh > _flux mv _flux ~/.oh-my-zsh/completions # oh-my-zsh mv _flux ~/.zprezto/modules/completion/external/src/ # zprezto Options \u00b6 -h, --help help for zsh Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux completion - Generates completion scripts for various shells","title":"Flux completion zsh"},{"location":"cmd/flux_completion_zsh/#flux-completion-zsh","text":"Generates zsh completion scripts flux completion zsh [flags]","title":"flux completion zsh"},{"location":"cmd/flux_completion_zsh/#examples","text":"To load completion run . <(flux completion zsh) && compdef _flux flux To configure your zsh shell to load completions for each session add to your zshrc # ~/.zshrc or ~/.profile command -v flux >/dev/null && . <(flux completion zsh) && compdef _flux flux or write a cached file in one of the completion directories in your ${fpath}: echo \"${fpath// /\\n}\" | grep -i completion flux completion zsh > _flux mv _flux ~/.oh-my-zsh/completions # oh-my-zsh mv _flux ~/.zprezto/modules/completion/external/src/ # zprezto","title":"Examples"},{"location":"cmd/flux_completion_zsh/#options","text":"-h, --help help for zsh","title":"Options"},{"location":"cmd/flux_completion_zsh/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_completion_zsh/#see-also","text":"flux completion - Generates completion scripts for various shells","title":"SEE ALSO"},{"location":"cmd/flux_create/","text":"flux create \u00b6 Create or update sources and resources Synopsis \u00b6 The create sub-commands generate sources and resources. Options \u00b6 --export export in YAML format to stdout -h, --help help for create --interval duration source sync interval (default 1m0s) --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux - Command line utility for assembling Kubernetes CD pipelines flux create alert - Create or update a Alert resource flux create alert-provider - Create or update a Provider resource flux create helmrelease - Create or update a HelmRelease resource flux create image - Create or update resources dealing with image automation flux create kustomization - Create or update a Kustomization resource flux create receiver - Create or update a Receiver resource flux create secret - Create or update Kubernetes secrets flux create source - Create or update sources flux create tenant - Create or update a tenant","title":"Create"},{"location":"cmd/flux_create/#flux-create","text":"Create or update sources and resources","title":"flux create"},{"location":"cmd/flux_create/#synopsis","text":"The create sub-commands generate sources and resources.","title":"Synopsis"},{"location":"cmd/flux_create/#options","text":"--export export in YAML format to stdout -h, --help help for create --interval duration source sync interval (default 1m0s) --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2)","title":"Options"},{"location":"cmd/flux_create/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create/#see-also","text":"flux - Command line utility for assembling Kubernetes CD pipelines flux create alert - Create or update a Alert resource flux create alert-provider - Create or update a Provider resource flux create helmrelease - Create or update a HelmRelease resource flux create image - Create or update resources dealing with image automation flux create kustomization - Create or update a Kustomization resource flux create receiver - Create or update a Receiver resource flux create secret - Create or update Kubernetes secrets flux create source - Create or update sources flux create tenant - Create or update a tenant","title":"SEE ALSO"},{"location":"cmd/flux_create_alert-provider/","text":"flux create alert-provider \u00b6 Create or update a Provider resource Synopsis \u00b6 The create alert-provider command generates a Provider resource. flux create alert-provider [name] [flags] Examples \u00b6 # Create a Provider for a Slack channel flux create alert-provider slack \\ --type slack \\ --channel general \\ --address https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK \\ --secret-ref webhook-url # Create a Provider for a Github repository flux create alert-provider github-podinfo \\ --type github \\ --address https://github.com/stefanprodan/podinfo \\ --secret-ref github-token Options \u00b6 --address string path to either the git repository, chat provider or webhook --channel string channel to send messages to in the case of a chat provider -h, --help help for alert-provider --secret-ref string name of secret containing authentication token --type string type of provider --username string bot username used by the provider Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create - Create or update sources and resources","title":"Create alert provider"},{"location":"cmd/flux_create_alert-provider/#flux-create-alert-provider","text":"Create or update a Provider resource","title":"flux create alert-provider"},{"location":"cmd/flux_create_alert-provider/#synopsis","text":"The create alert-provider command generates a Provider resource. flux create alert-provider [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_create_alert-provider/#examples","text":"# Create a Provider for a Slack channel flux create alert-provider slack \\ --type slack \\ --channel general \\ --address https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK \\ --secret-ref webhook-url # Create a Provider for a Github repository flux create alert-provider github-podinfo \\ --type github \\ --address https://github.com/stefanprodan/podinfo \\ --secret-ref github-token","title":"Examples"},{"location":"cmd/flux_create_alert-provider/#options","text":"--address string path to either the git repository, chat provider or webhook --channel string channel to send messages to in the case of a chat provider -h, --help help for alert-provider --secret-ref string name of secret containing authentication token --type string type of provider --username string bot username used by the provider","title":"Options"},{"location":"cmd/flux_create_alert-provider/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_alert-provider/#see-also","text":"flux create - Create or update sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_create_alert/","text":"flux create alert \u00b6 Create or update a Alert resource Synopsis \u00b6 The create alert command generates a Alert resource. flux create alert [name] [flags] Examples \u00b6 # Create an Alert for kustomization events flux create alert \\ --event-severity info \\ --event-source Kustomization/flux-system \\ --provider-ref slack \\ flux-system Options \u00b6 --event-severity string severity of events to send alerts for --event-source stringArray sources that should generate alerts (<kind>/<name>) -h, --help help for alert --provider-ref string reference to provider Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create - Create or update sources and resources","title":"Create alert"},{"location":"cmd/flux_create_alert/#flux-create-alert","text":"Create or update a Alert resource","title":"flux create alert"},{"location":"cmd/flux_create_alert/#synopsis","text":"The create alert command generates a Alert resource. flux create alert [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_create_alert/#examples","text":"# Create an Alert for kustomization events flux create alert \\ --event-severity info \\ --event-source Kustomization/flux-system \\ --provider-ref slack \\ flux-system","title":"Examples"},{"location":"cmd/flux_create_alert/#options","text":"--event-severity string severity of events to send alerts for --event-source stringArray sources that should generate alerts (<kind>/<name>) -h, --help help for alert --provider-ref string reference to provider","title":"Options"},{"location":"cmd/flux_create_alert/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_alert/#see-also","text":"flux create - Create or update sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_create_helmrelease/","text":"flux create helmrelease \u00b6 Create or update a HelmRelease resource Synopsis \u00b6 The helmrelease create command generates a HelmRelease resource for a given HelmRepository source. flux create helmrelease [name] [flags] Examples \u00b6 # Create a HelmRelease with a chart from a HelmRepository source flux create hr podinfo \\ --interval=10m \\ --source=HelmRepository/podinfo \\ --chart=podinfo \\ --chart-version=\">4.0.0\" # Create a HelmRelease with a chart from a GitRepository source flux create hr podinfo \\ --interval=10m \\ --source=GitRepository/podinfo \\ --chart=./charts/podinfo # Create a HelmRelease with a chart from a Bucket source flux create hr podinfo \\ --interval=10m \\ --source=Bucket/podinfo \\ --chart=./charts/podinfo # Create a HelmRelease with values from local YAML files flux create hr podinfo \\ --source=HelmRepository/podinfo \\ --chart=podinfo \\ --values=./my-values1.yaml \\ --values=./my-values2.yaml # Create a HelmRelease with values from a Kubernetes secret kubectl -n app create secret generic my-secret-values \\ --from-file=values.yaml=/path/to/my-secret-values.yaml flux -n app create hr podinfo \\ --source=HelmRepository/podinfo \\ --chart=podinfo \\ --values-from=Secret/my-secret-values # Create a HelmRelease with a custom release name flux create hr podinfo \\ --release-name=podinfo-dev --source=HelmRepository/podinfo \\ --chart=podinfo \\ # Create a HelmRelease targeting another namespace than the resource flux create hr podinfo \\ --target-namespace=default \\ --source=HelmRepository/podinfo \\ --chart=podinfo # Create a HelmRelease definition on disk without applying it on the cluster flux create hr podinfo \\ --source=HelmRepository/podinfo \\ --chart=podinfo \\ --values=./values.yaml \\ --export > podinfo-release.yaml Options \u00b6 --chart string Helm chart name or path --chart-version string Helm chart version, accepts a semver range (ignored for charts from GitRepository sources) --depends-on stringArray HelmReleases that must be ready before this release can be installed, supported formats '<name>' and '<namespace>/<name>' -h, --help help for helmrelease --release-name string name used for the Helm release, defaults to a composition of '[<target-namespace>-]<HelmRelease-name>' --service-account string the name of the service account to impersonate when reconciling this HelmRelease --source helmChartSource source that contains the chart in the format '<kind>/<name>', where kind must be one of: (HelmRepository, GitRepository, Bucket) --target-namespace string namespace to install this release, defaults to the HelmRelease namespace --values stringArray local path to values.yaml files --values-from helmReleaseValuesFrom Kubernetes object reference that contains the values.yaml data key in the format '<kind>/<name>', where kind must be one of: (Secret, ConfigMap) Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create - Create or update sources and resources","title":"Create helmrelease"},{"location":"cmd/flux_create_helmrelease/#flux-create-helmrelease","text":"Create or update a HelmRelease resource","title":"flux create helmrelease"},{"location":"cmd/flux_create_helmrelease/#synopsis","text":"The helmrelease create command generates a HelmRelease resource for a given HelmRepository source. flux create helmrelease [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_create_helmrelease/#examples","text":"# Create a HelmRelease with a chart from a HelmRepository source flux create hr podinfo \\ --interval=10m \\ --source=HelmRepository/podinfo \\ --chart=podinfo \\ --chart-version=\">4.0.0\" # Create a HelmRelease with a chart from a GitRepository source flux create hr podinfo \\ --interval=10m \\ --source=GitRepository/podinfo \\ --chart=./charts/podinfo # Create a HelmRelease with a chart from a Bucket source flux create hr podinfo \\ --interval=10m \\ --source=Bucket/podinfo \\ --chart=./charts/podinfo # Create a HelmRelease with values from local YAML files flux create hr podinfo \\ --source=HelmRepository/podinfo \\ --chart=podinfo \\ --values=./my-values1.yaml \\ --values=./my-values2.yaml # Create a HelmRelease with values from a Kubernetes secret kubectl -n app create secret generic my-secret-values \\ --from-file=values.yaml=/path/to/my-secret-values.yaml flux -n app create hr podinfo \\ --source=HelmRepository/podinfo \\ --chart=podinfo \\ --values-from=Secret/my-secret-values # Create a HelmRelease with a custom release name flux create hr podinfo \\ --release-name=podinfo-dev --source=HelmRepository/podinfo \\ --chart=podinfo \\ # Create a HelmRelease targeting another namespace than the resource flux create hr podinfo \\ --target-namespace=default \\ --source=HelmRepository/podinfo \\ --chart=podinfo # Create a HelmRelease definition on disk without applying it on the cluster flux create hr podinfo \\ --source=HelmRepository/podinfo \\ --chart=podinfo \\ --values=./values.yaml \\ --export > podinfo-release.yaml","title":"Examples"},{"location":"cmd/flux_create_helmrelease/#options","text":"--chart string Helm chart name or path --chart-version string Helm chart version, accepts a semver range (ignored for charts from GitRepository sources) --depends-on stringArray HelmReleases that must be ready before this release can be installed, supported formats '<name>' and '<namespace>/<name>' -h, --help help for helmrelease --release-name string name used for the Helm release, defaults to a composition of '[<target-namespace>-]<HelmRelease-name>' --service-account string the name of the service account to impersonate when reconciling this HelmRelease --source helmChartSource source that contains the chart in the format '<kind>/<name>', where kind must be one of: (HelmRepository, GitRepository, Bucket) --target-namespace string namespace to install this release, defaults to the HelmRelease namespace --values stringArray local path to values.yaml files --values-from helmReleaseValuesFrom Kubernetes object reference that contains the values.yaml data key in the format '<kind>/<name>', where kind must be one of: (Secret, ConfigMap)","title":"Options"},{"location":"cmd/flux_create_helmrelease/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_helmrelease/#see-also","text":"flux create - Create or update sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_create_image/","text":"flux create image \u00b6 Create or update resources dealing with image automation Synopsis \u00b6 The create image sub-commands work with image automation objects; that is, object controlling updates to git based on e.g., new container images being available. Options \u00b6 -h, --help help for image Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create - Create or update sources and resources flux create image policy - Create or update an ImagePolicy object flux create image repository - Create or update an ImageRepository object flux create image update - Create or update an ImageUpdateAutomation object","title":"Create image"},{"location":"cmd/flux_create_image/#flux-create-image","text":"Create or update resources dealing with image automation","title":"flux create image"},{"location":"cmd/flux_create_image/#synopsis","text":"The create image sub-commands work with image automation objects; that is, object controlling updates to git based on e.g., new container images being available.","title":"Synopsis"},{"location":"cmd/flux_create_image/#options","text":"-h, --help help for image","title":"Options"},{"location":"cmd/flux_create_image/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_image/#see-also","text":"flux create - Create or update sources and resources flux create image policy - Create or update an ImagePolicy object flux create image repository - Create or update an ImageRepository object flux create image update - Create or update an ImageUpdateAutomation object","title":"SEE ALSO"},{"location":"cmd/flux_create_image_policy/","text":"flux create image policy \u00b6 Create or update an ImagePolicy object Synopsis \u00b6 The create image policy command generates an ImagePolicy resource. An ImagePolicy object calculates a \"latest image\" given an image repository and a policy, e.g., semver. The image that sorts highest according to the policy is recorded in the status of the object. flux create image policy <name> [flags] Options \u00b6 --filter-extract string replacement pattern (using capture groups from --filter-regex) to use for sorting --filter-regex string regular expression pattern used to filter the image tags -h, --help help for policy --image-ref string the name of an image repository object --select-alpha string use alphabetical sorting to select image; either \"asc\" meaning select the last, or \"desc\" meaning select the first --select-numeric string use numeric sorting to select image; either \"asc\" meaning select the last, or \"desc\" meaning select the first --select-semver string a semver range to apply to tags; e.g., '1.x' Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create image - Create or update resources dealing with image automation","title":"Create image policy"},{"location":"cmd/flux_create_image_policy/#flux-create-image-policy","text":"Create or update an ImagePolicy object","title":"flux create image policy"},{"location":"cmd/flux_create_image_policy/#synopsis","text":"The create image policy command generates an ImagePolicy resource. An ImagePolicy object calculates a \"latest image\" given an image repository and a policy, e.g., semver. The image that sorts highest according to the policy is recorded in the status of the object. flux create image policy <name> [flags]","title":"Synopsis"},{"location":"cmd/flux_create_image_policy/#options","text":"--filter-extract string replacement pattern (using capture groups from --filter-regex) to use for sorting --filter-regex string regular expression pattern used to filter the image tags -h, --help help for policy --image-ref string the name of an image repository object --select-alpha string use alphabetical sorting to select image; either \"asc\" meaning select the last, or \"desc\" meaning select the first --select-numeric string use numeric sorting to select image; either \"asc\" meaning select the last, or \"desc\" meaning select the first --select-semver string a semver range to apply to tags; e.g., '1.x'","title":"Options"},{"location":"cmd/flux_create_image_policy/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_image_policy/#see-also","text":"flux create image - Create or update resources dealing with image automation","title":"SEE ALSO"},{"location":"cmd/flux_create_image_repository/","text":"flux create image repository \u00b6 Create or update an ImageRepository object Synopsis \u00b6 The create image repository command generates an ImageRepository resource. An ImageRepository object specifies an image repository to scan. flux create image repository <name> [flags] Examples \u00b6 # Create an ImageRepository object to scan the alpine image repository: flux create image repository alpine-repo --image alpine --interval 20m # Create an image repository that uses an image pull secret (assumed to # have been created already): flux create image repository myapp-repo \\ --secret-ref image-pull \\ --image ghcr.io/example.com/myapp --interval 5m # Create a TLS secret for a local image registry using a self-signed # host certificate, and use it to scan an image. ca.pem is a file # containing the CA certificate used to sign the host certificate. flux create secret tls local-registry-cert --ca-file ./ca.pem flux create image repository app-repo \\ --cert-secret-ref local-registry-cert \\ --image local-registry:5000/app --interval 5m # Create a TLS secret with a client certificate and key, and use it # to scan a private image registry. flux create secret tls client-cert \\ --cert-file client.crt --key-file client.key flux create image repository app-repo \\ --cert-secret-ref client-cert \\ --image registry.example.com/private/app --interval 5m Options \u00b6 --cert-ref string the name of a secret to use for TLS certificates -h, --help help for repository --image string the image repository to scan; e.g., library/alpine --scan-timeout duration a timeout for scanning; this defaults to the interval if not set --secret-ref string the name of a docker-registry secret to use for credentials Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create image - Create or update resources dealing with image automation","title":"Create image repository"},{"location":"cmd/flux_create_image_repository/#flux-create-image-repository","text":"Create or update an ImageRepository object","title":"flux create image repository"},{"location":"cmd/flux_create_image_repository/#synopsis","text":"The create image repository command generates an ImageRepository resource. An ImageRepository object specifies an image repository to scan. flux create image repository <name> [flags]","title":"Synopsis"},{"location":"cmd/flux_create_image_repository/#examples","text":"# Create an ImageRepository object to scan the alpine image repository: flux create image repository alpine-repo --image alpine --interval 20m # Create an image repository that uses an image pull secret (assumed to # have been created already): flux create image repository myapp-repo \\ --secret-ref image-pull \\ --image ghcr.io/example.com/myapp --interval 5m # Create a TLS secret for a local image registry using a self-signed # host certificate, and use it to scan an image. ca.pem is a file # containing the CA certificate used to sign the host certificate. flux create secret tls local-registry-cert --ca-file ./ca.pem flux create image repository app-repo \\ --cert-secret-ref local-registry-cert \\ --image local-registry:5000/app --interval 5m # Create a TLS secret with a client certificate and key, and use it # to scan a private image registry. flux create secret tls client-cert \\ --cert-file client.crt --key-file client.key flux create image repository app-repo \\ --cert-secret-ref client-cert \\ --image registry.example.com/private/app --interval 5m","title":"Examples"},{"location":"cmd/flux_create_image_repository/#options","text":"--cert-ref string the name of a secret to use for TLS certificates -h, --help help for repository --image string the image repository to scan; e.g., library/alpine --scan-timeout duration a timeout for scanning; this defaults to the interval if not set --secret-ref string the name of a docker-registry secret to use for credentials","title":"Options"},{"location":"cmd/flux_create_image_repository/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_image_repository/#see-also","text":"flux create image - Create or update resources dealing with image automation","title":"SEE ALSO"},{"location":"cmd/flux_create_image_update/","text":"flux create image update \u00b6 Create or update an ImageUpdateAutomation object Synopsis \u00b6 The create image update command generates an ImageUpdateAutomation resource. An ImageUpdateAutomation object specifies an automated update to images mentioned in YAMLs in a git repository. flux create image update <name> [flags] Options \u00b6 --author-email string the email to use for commit author --author-name string the name to use for commit author --branch string the branch to checkout and push commits to --commit-template string a template for commit messages --git-repo-ref string the name of a GitRepository resource with details of the upstream git repository -h, --help help for update Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create image - Create or update resources dealing with image automation","title":"Create image update"},{"location":"cmd/flux_create_image_update/#flux-create-image-update","text":"Create or update an ImageUpdateAutomation object","title":"flux create image update"},{"location":"cmd/flux_create_image_update/#synopsis","text":"The create image update command generates an ImageUpdateAutomation resource. An ImageUpdateAutomation object specifies an automated update to images mentioned in YAMLs in a git repository. flux create image update <name> [flags]","title":"Synopsis"},{"location":"cmd/flux_create_image_update/#options","text":"--author-email string the email to use for commit author --author-name string the name to use for commit author --branch string the branch to checkout and push commits to --commit-template string a template for commit messages --git-repo-ref string the name of a GitRepository resource with details of the upstream git repository -h, --help help for update","title":"Options"},{"location":"cmd/flux_create_image_update/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_image_update/#see-also","text":"flux create image - Create or update resources dealing with image automation","title":"SEE ALSO"},{"location":"cmd/flux_create_kustomization/","text":"flux create kustomization \u00b6 Create or update a Kustomization resource Synopsis \u00b6 The kustomization source create command generates a Kustomize resource for a given source. flux create kustomization [name] [flags] Examples \u00b6 # Create a Kustomization resource from a source at a given path flux create kustomization contour \\ --source=contour \\ --path=\"./examples/contour/\" \\ --prune=true \\ --interval=10m \\ --validation=client \\ --health-check=\"Deployment/contour.projectcontour\" \\ --health-check=\"DaemonSet/envoy.projectcontour\" \\ --health-check-timeout=3m # Create a Kustomization resource that depends on the previous one flux create kustomization webapp \\ --depends-on=contour \\ --source=webapp \\ --path=\"./deploy/overlays/dev\" \\ --prune=true \\ --interval=5m \\ --validation=client # Create a Kustomization resource that references a Bucket flux create kustomization secrets \\ --source=Bucket/secrets \\ --prune=true \\ --interval=5m Options \u00b6 --decryption-provider decryptionProvider decryption provider, available options are: (sops) --decryption-secret string set the Kubernetes secret name that contains the OpenPGP private keys used for sops decryption --depends-on stringArray Kustomization that must be ready before this Kustomization can be applied, supported formats '<name>' and '<namespace>/<name>' --health-check stringArray workload to be included in the health assessment, in the format '<kind>/<name>.<namespace>' --health-check-timeout duration timeout of health checking operations (default 2m0s) -h, --help help for kustomization --path safeRelativePath path to the directory containing a kustomization.yaml file (default ./) --prune enable garbage collection --service-account string the name of the service account to impersonate when reconciling this Kustomization --source kustomizationSource source that contains the Kubernetes manifests in the format '[<kind>/]<name>', where kind must be one of: (GitRepository, Bucket), if kind is not specified it defaults to GitRepository --target-namespace string overrides the namespace of all Kustomization objects reconciled by this Kustomization --validation string validate the manifests before applying them on the cluster, can be 'client' or 'server' Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create - Create or update sources and resources","title":"Create kustomization"},{"location":"cmd/flux_create_kustomization/#flux-create-kustomization","text":"Create or update a Kustomization resource","title":"flux create kustomization"},{"location":"cmd/flux_create_kustomization/#synopsis","text":"The kustomization source create command generates a Kustomize resource for a given source. flux create kustomization [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_create_kustomization/#examples","text":"# Create a Kustomization resource from a source at a given path flux create kustomization contour \\ --source=contour \\ --path=\"./examples/contour/\" \\ --prune=true \\ --interval=10m \\ --validation=client \\ --health-check=\"Deployment/contour.projectcontour\" \\ --health-check=\"DaemonSet/envoy.projectcontour\" \\ --health-check-timeout=3m # Create a Kustomization resource that depends on the previous one flux create kustomization webapp \\ --depends-on=contour \\ --source=webapp \\ --path=\"./deploy/overlays/dev\" \\ --prune=true \\ --interval=5m \\ --validation=client # Create a Kustomization resource that references a Bucket flux create kustomization secrets \\ --source=Bucket/secrets \\ --prune=true \\ --interval=5m","title":"Examples"},{"location":"cmd/flux_create_kustomization/#options","text":"--decryption-provider decryptionProvider decryption provider, available options are: (sops) --decryption-secret string set the Kubernetes secret name that contains the OpenPGP private keys used for sops decryption --depends-on stringArray Kustomization that must be ready before this Kustomization can be applied, supported formats '<name>' and '<namespace>/<name>' --health-check stringArray workload to be included in the health assessment, in the format '<kind>/<name>.<namespace>' --health-check-timeout duration timeout of health checking operations (default 2m0s) -h, --help help for kustomization --path safeRelativePath path to the directory containing a kustomization.yaml file (default ./) --prune enable garbage collection --service-account string the name of the service account to impersonate when reconciling this Kustomization --source kustomizationSource source that contains the Kubernetes manifests in the format '[<kind>/]<name>', where kind must be one of: (GitRepository, Bucket), if kind is not specified it defaults to GitRepository --target-namespace string overrides the namespace of all Kustomization objects reconciled by this Kustomization --validation string validate the manifests before applying them on the cluster, can be 'client' or 'server'","title":"Options"},{"location":"cmd/flux_create_kustomization/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_kustomization/#see-also","text":"flux create - Create or update sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_create_receiver/","text":"flux create receiver \u00b6 Create or update a Receiver resource Synopsis \u00b6 The create receiver command generates a Receiver resource. flux create receiver [name] [flags] Examples \u00b6 # Create a Receiver flux create receiver github-receiver \\ --type github \\ --event ping \\ --event push \\ --secret-ref webhook-token \\ --resource GitRepository/webapp \\ --resource HelmRepository/webapp Options \u00b6 --event stringArray -h, --help help for receiver --resource stringArray --secret-ref string --type string Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create - Create or update sources and resources","title":"Create receiver"},{"location":"cmd/flux_create_receiver/#flux-create-receiver","text":"Create or update a Receiver resource","title":"flux create receiver"},{"location":"cmd/flux_create_receiver/#synopsis","text":"The create receiver command generates a Receiver resource. flux create receiver [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_create_receiver/#examples","text":"# Create a Receiver flux create receiver github-receiver \\ --type github \\ --event ping \\ --event push \\ --secret-ref webhook-token \\ --resource GitRepository/webapp \\ --resource HelmRepository/webapp","title":"Examples"},{"location":"cmd/flux_create_receiver/#options","text":"--event stringArray -h, --help help for receiver --resource stringArray --secret-ref string --type string","title":"Options"},{"location":"cmd/flux_create_receiver/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_receiver/#see-also","text":"flux create - Create or update sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_create_secret/","text":"flux create secret \u00b6 Create or update Kubernetes secrets Synopsis \u00b6 The create source sub-commands generate Kubernetes secrets specific to Flux. Options \u00b6 -h, --help help for secret Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create - Create or update sources and resources flux create secret git - Create or update a Kubernetes secret for Git authentication flux create secret helm - Create or update a Kubernetes secret for Helm repository authentication flux create secret tls - Create or update a Kubernetes secret with TLS certificates","title":"Create secret"},{"location":"cmd/flux_create_secret/#flux-create-secret","text":"Create or update Kubernetes secrets","title":"flux create secret"},{"location":"cmd/flux_create_secret/#synopsis","text":"The create source sub-commands generate Kubernetes secrets specific to Flux.","title":"Synopsis"},{"location":"cmd/flux_create_secret/#options","text":"-h, --help help for secret","title":"Options"},{"location":"cmd/flux_create_secret/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_secret/#see-also","text":"flux create - Create or update sources and resources flux create secret git - Create or update a Kubernetes secret for Git authentication flux create secret helm - Create or update a Kubernetes secret for Helm repository authentication flux create secret tls - Create or update a Kubernetes secret with TLS certificates","title":"SEE ALSO"},{"location":"cmd/flux_create_secret_git/","text":"flux create secret git \u00b6 Create or update a Kubernetes secret for Git authentication Synopsis \u00b6 The create secret git command generates a Kubernetes secret with Git credentials. For Git over SSH, the host and SSH keys are automatically generated and stored in the secret. For Git over HTTP/S, the provided basic authentication credentials are stored in the secret. flux create secret git [name] [flags] Examples \u00b6 # Create a Git SSH authentication secret using an ECDSA P-521 curve public key flux create secret git podinfo-auth \\ --url=ssh://git@github.com/stefanprodan/podinfo \\ --ssh-key-algorithm=ecdsa \\ --ssh-ecdsa-curve=p521 # Create a secret for a Git repository using basic authentication flux create secret git podinfo-auth \\ --url=https://github.com/stefanprodan/podinfo \\ --username=username \\ --password=password # Create a Git SSH secret on disk and print the deploy key flux create secret git podinfo-auth \\ --url=ssh://git@github.com/stefanprodan/podinfo \\ --export > podinfo-auth.yaml yq read podinfo-auth.yaml 'data.\"identity.pub\"' | base64 --decode # Create a Git SSH secret on disk and encrypt it with Mozilla SOPS flux create secret git podinfo-auth \\ --namespace=apps \\ --url=ssh://git@github.com/stefanprodan/podinfo \\ --export > podinfo-auth.yaml sops --encrypt --encrypted-regex '^(data|stringData)$' \\ --in-place podinfo-auth.yaml Options \u00b6 --ca-file string path to TLS CA file used for validating self-signed certificates -h, --help help for git -p, --password string basic authentication password --ssh-ecdsa-curve ecdsaCurve SSH ECDSA public key curve (p256, p384, p521) (default p384) --ssh-key-algorithm publicKeyAlgorithm SSH public key algorithm (rsa, ecdsa, ed25519) (default rsa) --ssh-rsa-bits rsaKeyBits SSH RSA public key bit size (multiplies of 8) (default 2048) --url string git address, e.g. ssh://git@host/org/repository -u, --username string basic authentication username Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create secret - Create or update Kubernetes secrets","title":"Create secret git"},{"location":"cmd/flux_create_secret_git/#flux-create-secret-git","text":"Create or update a Kubernetes secret for Git authentication","title":"flux create secret git"},{"location":"cmd/flux_create_secret_git/#synopsis","text":"The create secret git command generates a Kubernetes secret with Git credentials. For Git over SSH, the host and SSH keys are automatically generated and stored in the secret. For Git over HTTP/S, the provided basic authentication credentials are stored in the secret. flux create secret git [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_create_secret_git/#examples","text":"# Create a Git SSH authentication secret using an ECDSA P-521 curve public key flux create secret git podinfo-auth \\ --url=ssh://git@github.com/stefanprodan/podinfo \\ --ssh-key-algorithm=ecdsa \\ --ssh-ecdsa-curve=p521 # Create a secret for a Git repository using basic authentication flux create secret git podinfo-auth \\ --url=https://github.com/stefanprodan/podinfo \\ --username=username \\ --password=password # Create a Git SSH secret on disk and print the deploy key flux create secret git podinfo-auth \\ --url=ssh://git@github.com/stefanprodan/podinfo \\ --export > podinfo-auth.yaml yq read podinfo-auth.yaml 'data.\"identity.pub\"' | base64 --decode # Create a Git SSH secret on disk and encrypt it with Mozilla SOPS flux create secret git podinfo-auth \\ --namespace=apps \\ --url=ssh://git@github.com/stefanprodan/podinfo \\ --export > podinfo-auth.yaml sops --encrypt --encrypted-regex '^(data|stringData)$' \\ --in-place podinfo-auth.yaml","title":"Examples"},{"location":"cmd/flux_create_secret_git/#options","text":"--ca-file string path to TLS CA file used for validating self-signed certificates -h, --help help for git -p, --password string basic authentication password --ssh-ecdsa-curve ecdsaCurve SSH ECDSA public key curve (p256, p384, p521) (default p384) --ssh-key-algorithm publicKeyAlgorithm SSH public key algorithm (rsa, ecdsa, ed25519) (default rsa) --ssh-rsa-bits rsaKeyBits SSH RSA public key bit size (multiplies of 8) (default 2048) --url string git address, e.g. ssh://git@host/org/repository -u, --username string basic authentication username","title":"Options"},{"location":"cmd/flux_create_secret_git/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_secret_git/#see-also","text":"flux create secret - Create or update Kubernetes secrets","title":"SEE ALSO"},{"location":"cmd/flux_create_secret_helm/","text":"flux create secret helm \u00b6 Create or update a Kubernetes secret for Helm repository authentication Synopsis \u00b6 The create secret helm command generates a Kubernetes secret with basic authentication credentials. flux create secret helm [name] [flags] Examples \u00b6 # Create a Helm authentication secret on disk and encrypt it with Mozilla SOPS flux create secret helm repo-auth \\ --namespace=my-namespace \\ --username=my-username \\ --password=my-password \\ --export > repo-auth.yaml sops --encrypt --encrypted-regex '^(data|stringData)$' \\ --in-place repo-auth.yaml # Create an authentication secret using a custom TLS cert flux create secret helm repo-auth \\ --username=username \\ --password=password \\ --cert-file=./cert.crt \\ --key-file=./key.crt \\ --ca-file=./ca.crt Options \u00b6 --ca-file string TLS authentication CA file path --cert-file string TLS authentication cert file path -h, --help help for helm --key-file string TLS authentication key file path -p, --password string basic authentication password -u, --username string basic authentication username Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create secret - Create or update Kubernetes secrets","title":"Create secret helm"},{"location":"cmd/flux_create_secret_helm/#flux-create-secret-helm","text":"Create or update a Kubernetes secret for Helm repository authentication","title":"flux create secret helm"},{"location":"cmd/flux_create_secret_helm/#synopsis","text":"The create secret helm command generates a Kubernetes secret with basic authentication credentials. flux create secret helm [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_create_secret_helm/#examples","text":"# Create a Helm authentication secret on disk and encrypt it with Mozilla SOPS flux create secret helm repo-auth \\ --namespace=my-namespace \\ --username=my-username \\ --password=my-password \\ --export > repo-auth.yaml sops --encrypt --encrypted-regex '^(data|stringData)$' \\ --in-place repo-auth.yaml # Create an authentication secret using a custom TLS cert flux create secret helm repo-auth \\ --username=username \\ --password=password \\ --cert-file=./cert.crt \\ --key-file=./key.crt \\ --ca-file=./ca.crt","title":"Examples"},{"location":"cmd/flux_create_secret_helm/#options","text":"--ca-file string TLS authentication CA file path --cert-file string TLS authentication cert file path -h, --help help for helm --key-file string TLS authentication key file path -p, --password string basic authentication password -u, --username string basic authentication username","title":"Options"},{"location":"cmd/flux_create_secret_helm/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_secret_helm/#see-also","text":"flux create secret - Create or update Kubernetes secrets","title":"SEE ALSO"},{"location":"cmd/flux_create_secret_tls/","text":"flux create secret tls \u00b6 Create or update a Kubernetes secret with TLS certificates Synopsis \u00b6 The create secret tls command generates a Kubernetes secret with certificates for use with TLS. flux create secret tls [name] [flags] Examples \u00b6 # Create a TLS secret on disk and encrypt it with Mozilla SOPS. # Files are expected to be PEM-encoded. flux create secret tls certs \\ --namespace=my-namespace \\ --cert-file=./client.crt \\ --key-file=./client.key \\ --export > certs.yaml sops --encrypt --encrypted-regex '^(data|stringData)$' \\ --in-place certs.yaml Options \u00b6 --ca-file string TLS authentication CA file path --cert-file string TLS authentication cert file path -h, --help help for tls --key-file string TLS authentication key file path Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create secret - Create or update Kubernetes secrets","title":"Create secret tls"},{"location":"cmd/flux_create_secret_tls/#flux-create-secret-tls","text":"Create or update a Kubernetes secret with TLS certificates","title":"flux create secret tls"},{"location":"cmd/flux_create_secret_tls/#synopsis","text":"The create secret tls command generates a Kubernetes secret with certificates for use with TLS. flux create secret tls [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_create_secret_tls/#examples","text":"# Create a TLS secret on disk and encrypt it with Mozilla SOPS. # Files are expected to be PEM-encoded. flux create secret tls certs \\ --namespace=my-namespace \\ --cert-file=./client.crt \\ --key-file=./client.key \\ --export > certs.yaml sops --encrypt --encrypted-regex '^(data|stringData)$' \\ --in-place certs.yaml","title":"Examples"},{"location":"cmd/flux_create_secret_tls/#options","text":"--ca-file string TLS authentication CA file path --cert-file string TLS authentication cert file path -h, --help help for tls --key-file string TLS authentication key file path","title":"Options"},{"location":"cmd/flux_create_secret_tls/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_secret_tls/#see-also","text":"flux create secret - Create or update Kubernetes secrets","title":"SEE ALSO"},{"location":"cmd/flux_create_source/","text":"flux create source \u00b6 Create or update sources Synopsis \u00b6 The create source sub-commands generate sources. Options \u00b6 -h, --help help for source Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create - Create or update sources and resources flux create source bucket - Create or update a Bucket source flux create source git - Create or update a GitRepository source flux create source helm - Create or update a HelmRepository source","title":"Create source"},{"location":"cmd/flux_create_source/#flux-create-source","text":"Create or update sources","title":"flux create source"},{"location":"cmd/flux_create_source/#synopsis","text":"The create source sub-commands generate sources.","title":"Synopsis"},{"location":"cmd/flux_create_source/#options","text":"-h, --help help for source","title":"Options"},{"location":"cmd/flux_create_source/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_source/#see-also","text":"flux create - Create or update sources and resources flux create source bucket - Create or update a Bucket source flux create source git - Create or update a GitRepository source flux create source helm - Create or update a HelmRepository source","title":"SEE ALSO"},{"location":"cmd/flux_create_source_bucket/","text":"flux create source bucket \u00b6 Create or update a Bucket source Synopsis \u00b6 The create source bucket command generates a Bucket resource and waits for it to be downloaded. For Buckets with static authentication, the credentials are stored in a Kubernetes secret. flux create source bucket [name] [flags] Examples \u00b6 # Create a source from a Buckets using static authentication flux create source bucket podinfo \\ --bucket-name=podinfo \\ --endpoint=minio.minio.svc.cluster.local:9000 \\ --insecure=true \\ --access-key=myaccesskey \\ --secret-key=mysecretkey \\ --interval=10m # Create a source from an Amazon S3 Bucket using IAM authentication flux create source bucket podinfo \\ --bucket-name=podinfo \\ --provider=aws \\ --endpoint=s3.amazonaws.com \\ --region=us-east-1 \\ --interval=10m Options \u00b6 --access-key string the bucket access key --bucket-name string the bucket name --endpoint string the bucket endpoint address -h, --help help for bucket --insecure for when connecting to a non-TLS S3 HTTP endpoint --provider sourceBucketProvider the S3 compatible storage provider name, available options are: (generic, aws) (default generic) --region string the bucket region --secret-key string the bucket secret key --secret-ref string the name of an existing secret containing credentials Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create source - Create or update sources","title":"Create source bucket"},{"location":"cmd/flux_create_source_bucket/#flux-create-source-bucket","text":"Create or update a Bucket source","title":"flux create source bucket"},{"location":"cmd/flux_create_source_bucket/#synopsis","text":"The create source bucket command generates a Bucket resource and waits for it to be downloaded. For Buckets with static authentication, the credentials are stored in a Kubernetes secret. flux create source bucket [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_create_source_bucket/#examples","text":"# Create a source from a Buckets using static authentication flux create source bucket podinfo \\ --bucket-name=podinfo \\ --endpoint=minio.minio.svc.cluster.local:9000 \\ --insecure=true \\ --access-key=myaccesskey \\ --secret-key=mysecretkey \\ --interval=10m # Create a source from an Amazon S3 Bucket using IAM authentication flux create source bucket podinfo \\ --bucket-name=podinfo \\ --provider=aws \\ --endpoint=s3.amazonaws.com \\ --region=us-east-1 \\ --interval=10m","title":"Examples"},{"location":"cmd/flux_create_source_bucket/#options","text":"--access-key string the bucket access key --bucket-name string the bucket name --endpoint string the bucket endpoint address -h, --help help for bucket --insecure for when connecting to a non-TLS S3 HTTP endpoint --provider sourceBucketProvider the S3 compatible storage provider name, available options are: (generic, aws) (default generic) --region string the bucket region --secret-key string the bucket secret key --secret-ref string the name of an existing secret containing credentials","title":"Options"},{"location":"cmd/flux_create_source_bucket/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_source_bucket/#see-also","text":"flux create source - Create or update sources","title":"SEE ALSO"},{"location":"cmd/flux_create_source_git/","text":"flux create source git \u00b6 Create or update a GitRepository source Synopsis \u00b6 The create source git command generates a GitRepository resource and waits for it to sync. For Git over SSH, host and SSH keys are automatically generated and stored in a Kubernetes secret. For private Git repositories, the basic authentication credentials are stored in a Kubernetes secret. flux create source git [name] [flags] Examples \u00b6 # Create a source from a public Git repository master branch flux create source git podinfo \\ --url=https://github.com/stefanprodan/podinfo \\ --branch=master # Create a source from a Git repository pinned to specific git tag flux create source git podinfo \\ --url=https://github.com/stefanprodan/podinfo \\ --tag=\"3.2.3\" # Create a source from a public Git repository tag that matches a semver range flux create source git podinfo \\ --url=https://github.com/stefanprodan/podinfo \\ --tag-semver=\">=3.2.0 <3.3.0\" # Create a source from a Git repository using SSH authentication flux create source git podinfo \\ --url=ssh://git@github.com/stefanprodan/podinfo \\ --branch=master # Create a source from a Git repository using SSH authentication and an # ECDSA P-521 curve public key flux create source git podinfo \\ --url=ssh://git@github.com/stefanprodan/podinfo \\ --branch=master \\ --ssh-key-algorithm=ecdsa \\ --ssh-ecdsa-curve=p521 # Create a source from a Git repository using basic authentication flux create source git podinfo \\ --url=https://github.com/stefanprodan/podinfo \\ --username=username \\ --password=password Options \u00b6 --branch string git branch (default \"master\") --ca-file string path to TLS CA file used for validating self-signed certificates, requires libgit2 --git-implementation gitImplementation the Git implementation to use, available options are: (go-git, libgit2) -h, --help help for git -p, --password string basic authentication password --secret-ref string the name of an existing secret containing SSH or basic credentials --ssh-ecdsa-curve ecdsaCurve SSH ECDSA public key curve (p256, p384, p521) (default p384) --ssh-key-algorithm publicKeyAlgorithm SSH public key algorithm (rsa, ecdsa, ed25519) --ssh-rsa-bits rsaKeyBits SSH RSA public key bit size (multiplies of 8) (default 2048) --tag string git tag --tag-semver string git tag semver range --url string git address, e.g. ssh://git@host/org/repository -u, --username string basic authentication username Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create source - Create or update sources","title":"Create source git"},{"location":"cmd/flux_create_source_git/#flux-create-source-git","text":"Create or update a GitRepository source","title":"flux create source git"},{"location":"cmd/flux_create_source_git/#synopsis","text":"The create source git command generates a GitRepository resource and waits for it to sync. For Git over SSH, host and SSH keys are automatically generated and stored in a Kubernetes secret. For private Git repositories, the basic authentication credentials are stored in a Kubernetes secret. flux create source git [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_create_source_git/#examples","text":"# Create a source from a public Git repository master branch flux create source git podinfo \\ --url=https://github.com/stefanprodan/podinfo \\ --branch=master # Create a source from a Git repository pinned to specific git tag flux create source git podinfo \\ --url=https://github.com/stefanprodan/podinfo \\ --tag=\"3.2.3\" # Create a source from a public Git repository tag that matches a semver range flux create source git podinfo \\ --url=https://github.com/stefanprodan/podinfo \\ --tag-semver=\">=3.2.0 <3.3.0\" # Create a source from a Git repository using SSH authentication flux create source git podinfo \\ --url=ssh://git@github.com/stefanprodan/podinfo \\ --branch=master # Create a source from a Git repository using SSH authentication and an # ECDSA P-521 curve public key flux create source git podinfo \\ --url=ssh://git@github.com/stefanprodan/podinfo \\ --branch=master \\ --ssh-key-algorithm=ecdsa \\ --ssh-ecdsa-curve=p521 # Create a source from a Git repository using basic authentication flux create source git podinfo \\ --url=https://github.com/stefanprodan/podinfo \\ --username=username \\ --password=password","title":"Examples"},{"location":"cmd/flux_create_source_git/#options","text":"--branch string git branch (default \"master\") --ca-file string path to TLS CA file used for validating self-signed certificates, requires libgit2 --git-implementation gitImplementation the Git implementation to use, available options are: (go-git, libgit2) -h, --help help for git -p, --password string basic authentication password --secret-ref string the name of an existing secret containing SSH or basic credentials --ssh-ecdsa-curve ecdsaCurve SSH ECDSA public key curve (p256, p384, p521) (default p384) --ssh-key-algorithm publicKeyAlgorithm SSH public key algorithm (rsa, ecdsa, ed25519) --ssh-rsa-bits rsaKeyBits SSH RSA public key bit size (multiplies of 8) (default 2048) --tag string git tag --tag-semver string git tag semver range --url string git address, e.g. ssh://git@host/org/repository -u, --username string basic authentication username","title":"Options"},{"location":"cmd/flux_create_source_git/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_source_git/#see-also","text":"flux create source - Create or update sources","title":"SEE ALSO"},{"location":"cmd/flux_create_source_helm/","text":"flux create source helm \u00b6 Create or update a HelmRepository source Synopsis \u00b6 The create source helm command generates a HelmRepository resource and waits for it to fetch the index. For private Helm repositories, the basic authentication credentials are stored in a Kubernetes secret. flux create source helm [name] [flags] Examples \u00b6 # Create a source from a public Helm repository flux create source helm podinfo \\ --url=https://stefanprodan.github.io/podinfo \\ --interval=10m # Create a source from a Helm repository using basic authentication flux create source helm podinfo \\ --url=https://stefanprodan.github.io/podinfo \\ --username=username \\ --password=password # Create a source from a Helm repository using TLS authentication flux create source helm podinfo \\ --url=https://stefanprodan.github.io/podinfo \\ --cert-file=./cert.crt \\ --key-file=./key.crt \\ --ca-file=./ca.crt Options \u00b6 --ca-file string TLS authentication CA file path --cert-file string TLS authentication cert file path -h, --help help for helm --key-file string TLS authentication key file path -p, --password string basic authentication password --secret-ref string the name of an existing secret containing TLS or basic auth credentials --url string Helm repository address -u, --username string basic authentication username Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create source - Create or update sources","title":"Create source helm"},{"location":"cmd/flux_create_source_helm/#flux-create-source-helm","text":"Create or update a HelmRepository source","title":"flux create source helm"},{"location":"cmd/flux_create_source_helm/#synopsis","text":"The create source helm command generates a HelmRepository resource and waits for it to fetch the index. For private Helm repositories, the basic authentication credentials are stored in a Kubernetes secret. flux create source helm [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_create_source_helm/#examples","text":"# Create a source from a public Helm repository flux create source helm podinfo \\ --url=https://stefanprodan.github.io/podinfo \\ --interval=10m # Create a source from a Helm repository using basic authentication flux create source helm podinfo \\ --url=https://stefanprodan.github.io/podinfo \\ --username=username \\ --password=password # Create a source from a Helm repository using TLS authentication flux create source helm podinfo \\ --url=https://stefanprodan.github.io/podinfo \\ --cert-file=./cert.crt \\ --key-file=./key.crt \\ --ca-file=./ca.crt","title":"Examples"},{"location":"cmd/flux_create_source_helm/#options","text":"--ca-file string TLS authentication CA file path --cert-file string TLS authentication cert file path -h, --help help for helm --key-file string TLS authentication key file path -p, --password string basic authentication password --secret-ref string the name of an existing secret containing TLS or basic auth credentials --url string Helm repository address -u, --username string basic authentication username","title":"Options"},{"location":"cmd/flux_create_source_helm/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_source_helm/#see-also","text":"flux create source - Create or update sources","title":"SEE ALSO"},{"location":"cmd/flux_create_tenant/","text":"flux create tenant \u00b6 Create or update a tenant Synopsis \u00b6 The create tenant command generates namespaces, service accounts and role bindings to limit the reconcilers scope to the tenant namespaces. flux create tenant [flags] Examples \u00b6 # Create a tenant with access to a namespace flux create tenant dev-team \\ --with-namespace=frontend \\ --label=environment=dev # Generate tenant namespaces and role bindings in YAML format flux create tenant dev-team \\ --with-namespace=frontend \\ --with-namespace=backend \\ --export > dev-team.yaml Options \u00b6 --cluster-role string cluster role of the tenant role binding (default \"cluster-admin\") -h, --help help for tenant --with-namespace strings namespace belonging to this tenant Options inherited from parent commands \u00b6 --context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux create - Create or update sources and resources","title":"Create tenant"},{"location":"cmd/flux_create_tenant/#flux-create-tenant","text":"Create or update a tenant","title":"flux create tenant"},{"location":"cmd/flux_create_tenant/#synopsis","text":"The create tenant command generates namespaces, service accounts and role bindings to limit the reconcilers scope to the tenant namespaces. flux create tenant [flags]","title":"Synopsis"},{"location":"cmd/flux_create_tenant/#examples","text":"# Create a tenant with access to a namespace flux create tenant dev-team \\ --with-namespace=frontend \\ --label=environment=dev # Generate tenant namespaces and role bindings in YAML format flux create tenant dev-team \\ --with-namespace=frontend \\ --with-namespace=backend \\ --export > dev-team.yaml","title":"Examples"},{"location":"cmd/flux_create_tenant/#options","text":"--cluster-role string cluster role of the tenant role binding (default \"cluster-admin\") -h, --help help for tenant --with-namespace strings namespace belonging to this tenant","title":"Options"},{"location":"cmd/flux_create_tenant/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --export export in YAML format to stdout --interval duration source sync interval (default 1m0s) --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") --label strings set labels on the resource (can specify multiple labels with commas: label1=value1,label2=value2) -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_create_tenant/#see-also","text":"flux create - Create or update sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_delete/","text":"flux delete \u00b6 Delete sources and resources Synopsis \u00b6 The delete sub-commands delete sources and resources. Options \u00b6 -h, --help help for delete -s, --silent delete resource without asking for confirmation Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux - Command line utility for assembling Kubernetes CD pipelines flux delete alert - Delete a Alert resource flux delete alert-provider - Delete a Provider resource flux delete helmrelease - Delete a HelmRelease resource flux delete image - Delete image automation objects flux delete kustomization - Delete a Kustomization resource flux delete receiver - Delete a Receiver resource flux delete source - Delete sources","title":"Delete"},{"location":"cmd/flux_delete/#flux-delete","text":"Delete sources and resources","title":"flux delete"},{"location":"cmd/flux_delete/#synopsis","text":"The delete sub-commands delete sources and resources.","title":"Synopsis"},{"location":"cmd/flux_delete/#options","text":"-h, --help help for delete -s, --silent delete resource without asking for confirmation","title":"Options"},{"location":"cmd/flux_delete/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete/#see-also","text":"flux - Command line utility for assembling Kubernetes CD pipelines flux delete alert - Delete a Alert resource flux delete alert-provider - Delete a Provider resource flux delete helmrelease - Delete a HelmRelease resource flux delete image - Delete image automation objects flux delete kustomization - Delete a Kustomization resource flux delete receiver - Delete a Receiver resource flux delete source - Delete sources","title":"SEE ALSO"},{"location":"cmd/flux_delete_alert-provider/","text":"flux delete alert-provider \u00b6 Delete a Provider resource Synopsis \u00b6 The delete alert-provider command removes the given Provider from the cluster. flux delete alert-provider [name] [flags] Examples \u00b6 # Delete a Provider and the Kubernetes resources created by it flux delete alert-provider slack Options \u00b6 -h, --help help for alert-provider Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete - Delete sources and resources","title":"Flux delete alert provider"},{"location":"cmd/flux_delete_alert-provider/#flux-delete-alert-provider","text":"Delete a Provider resource","title":"flux delete alert-provider"},{"location":"cmd/flux_delete_alert-provider/#synopsis","text":"The delete alert-provider command removes the given Provider from the cluster. flux delete alert-provider [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_delete_alert-provider/#examples","text":"# Delete a Provider and the Kubernetes resources created by it flux delete alert-provider slack","title":"Examples"},{"location":"cmd/flux_delete_alert-provider/#options","text":"-h, --help help for alert-provider","title":"Options"},{"location":"cmd/flux_delete_alert-provider/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_alert-provider/#see-also","text":"flux delete - Delete sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_delete_alert/","text":"flux delete alert \u00b6 Delete a Alert resource Synopsis \u00b6 The delete alert command removes the given Alert from the cluster. flux delete alert [name] [flags] Examples \u00b6 # Delete an Alert and the Kubernetes resources created by it flux delete alert main Options \u00b6 -h, --help help for alert Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete - Delete sources and resources","title":"Flux delete alert"},{"location":"cmd/flux_delete_alert/#flux-delete-alert","text":"Delete a Alert resource","title":"flux delete alert"},{"location":"cmd/flux_delete_alert/#synopsis","text":"The delete alert command removes the given Alert from the cluster. flux delete alert [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_delete_alert/#examples","text":"# Delete an Alert and the Kubernetes resources created by it flux delete alert main","title":"Examples"},{"location":"cmd/flux_delete_alert/#options","text":"-h, --help help for alert","title":"Options"},{"location":"cmd/flux_delete_alert/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_alert/#see-also","text":"flux delete - Delete sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_delete_helmrelease/","text":"flux delete helmrelease \u00b6 Delete a HelmRelease resource Synopsis \u00b6 The delete helmrelease command removes the given HelmRelease from the cluster. flux delete helmrelease [name] [flags] Examples \u00b6 # Delete a Helm release and the Kubernetes resources created by it flux delete hr podinfo Options \u00b6 -h, --help help for helmrelease Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete - Delete sources and resources","title":"Delete helmrelease"},{"location":"cmd/flux_delete_helmrelease/#flux-delete-helmrelease","text":"Delete a HelmRelease resource","title":"flux delete helmrelease"},{"location":"cmd/flux_delete_helmrelease/#synopsis","text":"The delete helmrelease command removes the given HelmRelease from the cluster. flux delete helmrelease [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_delete_helmrelease/#examples","text":"# Delete a Helm release and the Kubernetes resources created by it flux delete hr podinfo","title":"Examples"},{"location":"cmd/flux_delete_helmrelease/#options","text":"-h, --help help for helmrelease","title":"Options"},{"location":"cmd/flux_delete_helmrelease/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_helmrelease/#see-also","text":"flux delete - Delete sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_delete_image/","text":"flux delete image \u00b6 Delete image automation objects Synopsis \u00b6 The delete image sub-commands delete image automation objects. Options \u00b6 -h, --help help for image Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete - Delete sources and resources flux delete image policy - Delete an ImagePolicy object flux delete image repository - Delete an ImageRepository object flux delete image update - Delete an ImageUpdateAutomation object","title":"Delete image"},{"location":"cmd/flux_delete_image/#flux-delete-image","text":"Delete image automation objects","title":"flux delete image"},{"location":"cmd/flux_delete_image/#synopsis","text":"The delete image sub-commands delete image automation objects.","title":"Synopsis"},{"location":"cmd/flux_delete_image/#options","text":"-h, --help help for image","title":"Options"},{"location":"cmd/flux_delete_image/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_image/#see-also","text":"flux delete - Delete sources and resources flux delete image policy - Delete an ImagePolicy object flux delete image repository - Delete an ImageRepository object flux delete image update - Delete an ImageUpdateAutomation object","title":"SEE ALSO"},{"location":"cmd/flux_delete_image_policy/","text":"flux delete image policy \u00b6 Delete an ImagePolicy object Synopsis \u00b6 The delete image policy command deletes the given ImagePolicy from the cluster. flux delete image policy [name] [flags] Examples \u00b6 # Delete an image policy flux delete image policy alpine3.x Options \u00b6 -h, --help help for policy Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete image - Delete image automation objects","title":"Delete image policy"},{"location":"cmd/flux_delete_image_policy/#flux-delete-image-policy","text":"Delete an ImagePolicy object","title":"flux delete image policy"},{"location":"cmd/flux_delete_image_policy/#synopsis","text":"The delete image policy command deletes the given ImagePolicy from the cluster. flux delete image policy [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_delete_image_policy/#examples","text":"# Delete an image policy flux delete image policy alpine3.x","title":"Examples"},{"location":"cmd/flux_delete_image_policy/#options","text":"-h, --help help for policy","title":"Options"},{"location":"cmd/flux_delete_image_policy/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_image_policy/#see-also","text":"flux delete image - Delete image automation objects","title":"SEE ALSO"},{"location":"cmd/flux_delete_image_repository/","text":"flux delete image repository \u00b6 Delete an ImageRepository object Synopsis \u00b6 The delete image repository command deletes the given ImageRepository from the cluster. flux delete image repository [name] [flags] Examples \u00b6 # Delete an image repository flux delete image repository alpine Options \u00b6 -h, --help help for repository Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete image - Delete image automation objects","title":"Delete image repository"},{"location":"cmd/flux_delete_image_repository/#flux-delete-image-repository","text":"Delete an ImageRepository object","title":"flux delete image repository"},{"location":"cmd/flux_delete_image_repository/#synopsis","text":"The delete image repository command deletes the given ImageRepository from the cluster. flux delete image repository [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_delete_image_repository/#examples","text":"# Delete an image repository flux delete image repository alpine","title":"Examples"},{"location":"cmd/flux_delete_image_repository/#options","text":"-h, --help help for repository","title":"Options"},{"location":"cmd/flux_delete_image_repository/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_image_repository/#see-also","text":"flux delete image - Delete image automation objects","title":"SEE ALSO"},{"location":"cmd/flux_delete_image_update/","text":"flux delete image update \u00b6 Delete an ImageUpdateAutomation object Synopsis \u00b6 The delete image update command deletes the given ImageUpdateAutomation from the cluster. flux delete image update [name] [flags] Examples \u00b6 # Delete an image update automation flux delete image update latest-images Options \u00b6 -h, --help help for update Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete image - Delete image automation objects","title":"Delete image update"},{"location":"cmd/flux_delete_image_update/#flux-delete-image-update","text":"Delete an ImageUpdateAutomation object","title":"flux delete image update"},{"location":"cmd/flux_delete_image_update/#synopsis","text":"The delete image update command deletes the given ImageUpdateAutomation from the cluster. flux delete image update [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_delete_image_update/#examples","text":"# Delete an image update automation flux delete image update latest-images","title":"Examples"},{"location":"cmd/flux_delete_image_update/#options","text":"-h, --help help for update","title":"Options"},{"location":"cmd/flux_delete_image_update/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_image_update/#see-also","text":"flux delete image - Delete image automation objects","title":"SEE ALSO"},{"location":"cmd/flux_delete_kustomization/","text":"flux delete kustomization \u00b6 Delete a Kustomization resource Synopsis \u00b6 The delete kustomization command deletes the given Kustomization from the cluster. flux delete kustomization [name] [flags] Examples \u00b6 # Delete a kustomization and the Kubernetes resources created by it flux delete kustomization podinfo Options \u00b6 -h, --help help for kustomization Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete - Delete sources and resources","title":"Delete kustomization"},{"location":"cmd/flux_delete_kustomization/#flux-delete-kustomization","text":"Delete a Kustomization resource","title":"flux delete kustomization"},{"location":"cmd/flux_delete_kustomization/#synopsis","text":"The delete kustomization command deletes the given Kustomization from the cluster. flux delete kustomization [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_delete_kustomization/#examples","text":"# Delete a kustomization and the Kubernetes resources created by it flux delete kustomization podinfo","title":"Examples"},{"location":"cmd/flux_delete_kustomization/#options","text":"-h, --help help for kustomization","title":"Options"},{"location":"cmd/flux_delete_kustomization/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_kustomization/#see-also","text":"flux delete - Delete sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_delete_receiver/","text":"flux delete receiver \u00b6 Delete a Receiver resource Synopsis \u00b6 The delete receiver command removes the given Receiver from the cluster. flux delete receiver [name] [flags] Examples \u00b6 # Delete an Receiver and the Kubernetes resources created by it flux delete receiver main Options \u00b6 -h, --help help for receiver Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete - Delete sources and resources","title":"Flux delete receiver"},{"location":"cmd/flux_delete_receiver/#flux-delete-receiver","text":"Delete a Receiver resource","title":"flux delete receiver"},{"location":"cmd/flux_delete_receiver/#synopsis","text":"The delete receiver command removes the given Receiver from the cluster. flux delete receiver [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_delete_receiver/#examples","text":"# Delete an Receiver and the Kubernetes resources created by it flux delete receiver main","title":"Examples"},{"location":"cmd/flux_delete_receiver/#options","text":"-h, --help help for receiver","title":"Options"},{"location":"cmd/flux_delete_receiver/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_receiver/#see-also","text":"flux delete - Delete sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_delete_source/","text":"flux delete source \u00b6 Delete sources Synopsis \u00b6 The delete source sub-commands delete sources. Options \u00b6 -h, --help help for source Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete - Delete sources and resources flux delete source bucket - Delete a Bucket source flux delete source git - Delete a GitRepository source flux delete source helm - Delete a HelmRepository source","title":"Delete source"},{"location":"cmd/flux_delete_source/#flux-delete-source","text":"Delete sources","title":"flux delete source"},{"location":"cmd/flux_delete_source/#synopsis","text":"The delete source sub-commands delete sources.","title":"Synopsis"},{"location":"cmd/flux_delete_source/#options","text":"-h, --help help for source","title":"Options"},{"location":"cmd/flux_delete_source/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_source/#see-also","text":"flux delete - Delete sources and resources flux delete source bucket - Delete a Bucket source flux delete source git - Delete a GitRepository source flux delete source helm - Delete a HelmRepository source","title":"SEE ALSO"},{"location":"cmd/flux_delete_source_bucket/","text":"flux delete source bucket \u00b6 Delete a Bucket source Synopsis \u00b6 The delete source bucket command deletes the given Bucket from the cluster. flux delete source bucket [name] [flags] Examples \u00b6 # Delete a Bucket source flux delete source bucket podinfo Options \u00b6 -h, --help help for bucket Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete source - Delete sources","title":"Delete source bucket"},{"location":"cmd/flux_delete_source_bucket/#flux-delete-source-bucket","text":"Delete a Bucket source","title":"flux delete source bucket"},{"location":"cmd/flux_delete_source_bucket/#synopsis","text":"The delete source bucket command deletes the given Bucket from the cluster. flux delete source bucket [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_delete_source_bucket/#examples","text":"# Delete a Bucket source flux delete source bucket podinfo","title":"Examples"},{"location":"cmd/flux_delete_source_bucket/#options","text":"-h, --help help for bucket","title":"Options"},{"location":"cmd/flux_delete_source_bucket/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_source_bucket/#see-also","text":"flux delete source - Delete sources","title":"SEE ALSO"},{"location":"cmd/flux_delete_source_git/","text":"flux delete source git \u00b6 Delete a GitRepository source Synopsis \u00b6 The delete source git command deletes the given GitRepository from the cluster. flux delete source git [name] [flags] Examples \u00b6 # Delete a Git repository flux delete source git podinfo Options \u00b6 -h, --help help for git Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete source - Delete sources","title":"Delete source git"},{"location":"cmd/flux_delete_source_git/#flux-delete-source-git","text":"Delete a GitRepository source","title":"flux delete source git"},{"location":"cmd/flux_delete_source_git/#synopsis","text":"The delete source git command deletes the given GitRepository from the cluster. flux delete source git [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_delete_source_git/#examples","text":"# Delete a Git repository flux delete source git podinfo","title":"Examples"},{"location":"cmd/flux_delete_source_git/#options","text":"-h, --help help for git","title":"Options"},{"location":"cmd/flux_delete_source_git/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_source_git/#see-also","text":"flux delete source - Delete sources","title":"SEE ALSO"},{"location":"cmd/flux_delete_source_helm/","text":"flux delete source helm \u00b6 Delete a HelmRepository source Synopsis \u00b6 The delete source helm command deletes the given HelmRepository from the cluster. flux delete source helm [name] [flags] Examples \u00b6 # Delete a Helm repository flux delete source helm podinfo Options \u00b6 -h, --help help for helm Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux delete source - Delete sources","title":"Delete source helm"},{"location":"cmd/flux_delete_source_helm/#flux-delete-source-helm","text":"Delete a HelmRepository source","title":"flux delete source helm"},{"location":"cmd/flux_delete_source_helm/#synopsis","text":"The delete source helm command deletes the given HelmRepository from the cluster. flux delete source helm [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_delete_source_helm/#examples","text":"# Delete a Helm repository flux delete source helm podinfo","title":"Examples"},{"location":"cmd/flux_delete_source_helm/#options","text":"-h, --help help for helm","title":"Options"},{"location":"cmd/flux_delete_source_helm/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") -s, --silent delete resource without asking for confirmation --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_delete_source_helm/#see-also","text":"flux delete source - Delete sources","title":"SEE ALSO"},{"location":"cmd/flux_export/","text":"flux export \u00b6 Export resources in YAML format Synopsis \u00b6 The export sub-commands export resources in YAML format. Options \u00b6 --all select all resources -h, --help help for export Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux - Command line utility for assembling Kubernetes CD pipelines flux export alert - Export Alert resources in YAML format flux export alert-provider - Export Provider resources in YAML format flux export helmrelease - Export HelmRelease resources in YAML format flux export image - Export image automation objects flux export kustomization - Export Kustomization resources in YAML format flux export receiver - Export Receiver resources in YAML format flux export source - Export sources","title":"Export"},{"location":"cmd/flux_export/#flux-export","text":"Export resources in YAML format","title":"flux export"},{"location":"cmd/flux_export/#synopsis","text":"The export sub-commands export resources in YAML format.","title":"Synopsis"},{"location":"cmd/flux_export/#options","text":"--all select all resources -h, --help help for export","title":"Options"},{"location":"cmd/flux_export/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_export/#see-also","text":"flux - Command line utility for assembling Kubernetes CD pipelines flux export alert - Export Alert resources in YAML format flux export alert-provider - Export Provider resources in YAML format flux export helmrelease - Export HelmRelease resources in YAML format flux export image - Export image automation objects flux export kustomization - Export Kustomization resources in YAML format flux export receiver - Export Receiver resources in YAML format flux export source - Export sources","title":"SEE ALSO"},{"location":"cmd/flux_export_alert-provider/","text":"flux export alert-provider \u00b6 Export Provider resources in YAML format Synopsis \u00b6 The export alert-provider command exports one or all Provider resources in YAML format. flux export alert-provider [name] [flags] Examples \u00b6 # Export all Provider resources flux export alert-provider --all > alert-providers.yaml # Export a Provider flux export alert-provider slack > slack.yaml Options \u00b6 -h, --help help for alert-provider Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux export - Export resources in YAML format","title":"Export alert provider"},{"location":"cmd/flux_export_alert-provider/#flux-export-alert-provider","text":"Export Provider resources in YAML format","title":"flux export alert-provider"},{"location":"cmd/flux_export_alert-provider/#synopsis","text":"The export alert-provider command exports one or all Provider resources in YAML format. flux export alert-provider [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_export_alert-provider/#examples","text":"# Export all Provider resources flux export alert-provider --all > alert-providers.yaml # Export a Provider flux export alert-provider slack > slack.yaml","title":"Examples"},{"location":"cmd/flux_export_alert-provider/#options","text":"-h, --help help for alert-provider","title":"Options"},{"location":"cmd/flux_export_alert-provider/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_alert-provider/#see-also","text":"flux export - Export resources in YAML format","title":"SEE ALSO"},{"location":"cmd/flux_export_alert/","text":"flux export alert \u00b6 Export Alert resources in YAML format Synopsis \u00b6 The export alert command exports one or all Alert resources in YAML format. flux export alert [name] [flags] Examples \u00b6 # Export all Alert resources flux export alert --all > alerts.yaml # Export a Alert flux export alert main > main.yaml Options \u00b6 -h, --help help for alert Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux export - Export resources in YAML format","title":"Export alert"},{"location":"cmd/flux_export_alert/#flux-export-alert","text":"Export Alert resources in YAML format","title":"flux export alert"},{"location":"cmd/flux_export_alert/#synopsis","text":"The export alert command exports one or all Alert resources in YAML format. flux export alert [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_export_alert/#examples","text":"# Export all Alert resources flux export alert --all > alerts.yaml # Export a Alert flux export alert main > main.yaml","title":"Examples"},{"location":"cmd/flux_export_alert/#options","text":"-h, --help help for alert","title":"Options"},{"location":"cmd/flux_export_alert/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_alert/#see-also","text":"flux export - Export resources in YAML format","title":"SEE ALSO"},{"location":"cmd/flux_export_helmrelease/","text":"flux export helmrelease \u00b6 Export HelmRelease resources in YAML format Synopsis \u00b6 The export helmrelease command exports one or all HelmRelease resources in YAML format. flux export helmrelease [name] [flags] Examples \u00b6 # Export all HelmRelease resources flux export helmrelease --all > kustomizations.yaml # Export a HelmRelease flux export hr my-app > app-release.yaml Options \u00b6 -h, --help help for helmrelease Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux export - Export resources in YAML format","title":"Export helmrelease"},{"location":"cmd/flux_export_helmrelease/#flux-export-helmrelease","text":"Export HelmRelease resources in YAML format","title":"flux export helmrelease"},{"location":"cmd/flux_export_helmrelease/#synopsis","text":"The export helmrelease command exports one or all HelmRelease resources in YAML format. flux export helmrelease [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_export_helmrelease/#examples","text":"# Export all HelmRelease resources flux export helmrelease --all > kustomizations.yaml # Export a HelmRelease flux export hr my-app > app-release.yaml","title":"Examples"},{"location":"cmd/flux_export_helmrelease/#options","text":"-h, --help help for helmrelease","title":"Options"},{"location":"cmd/flux_export_helmrelease/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_helmrelease/#see-also","text":"flux export - Export resources in YAML format","title":"SEE ALSO"},{"location":"cmd/flux_export_image/","text":"flux export image \u00b6 Export image automation objects Synopsis \u00b6 The export image sub-commands export image automation objects in YAML format. Options \u00b6 -h, --help help for image Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux export - Export resources in YAML format flux export image policy - Export ImagePolicy resources in YAML format flux export image repository - Export ImageRepository resources in YAML format flux export image update - Export ImageUpdateAutomation resources in YAML format","title":"Export image"},{"location":"cmd/flux_export_image/#flux-export-image","text":"Export image automation objects","title":"flux export image"},{"location":"cmd/flux_export_image/#synopsis","text":"The export image sub-commands export image automation objects in YAML format.","title":"Synopsis"},{"location":"cmd/flux_export_image/#options","text":"-h, --help help for image","title":"Options"},{"location":"cmd/flux_export_image/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_image/#see-also","text":"flux export - Export resources in YAML format flux export image policy - Export ImagePolicy resources in YAML format flux export image repository - Export ImageRepository resources in YAML format flux export image update - Export ImageUpdateAutomation resources in YAML format","title":"SEE ALSO"},{"location":"cmd/flux_export_image_policy/","text":"flux export image policy \u00b6 Export ImagePolicy resources in YAML format Synopsis \u00b6 The export image policy command exports one or all ImagePolicy resources in YAML format. flux export image policy [name] [flags] Examples \u00b6 # Export all ImagePolicy resources flux export image policy --all > image-policies.yaml # Export a specific policy flux export image policy alpine1x > alpine1x.yaml Options \u00b6 -h, --help help for policy Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux export image - Export image automation objects","title":"Export image policy"},{"location":"cmd/flux_export_image_policy/#flux-export-image-policy","text":"Export ImagePolicy resources in YAML format","title":"flux export image policy"},{"location":"cmd/flux_export_image_policy/#synopsis","text":"The export image policy command exports one or all ImagePolicy resources in YAML format. flux export image policy [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_export_image_policy/#examples","text":"# Export all ImagePolicy resources flux export image policy --all > image-policies.yaml # Export a specific policy flux export image policy alpine1x > alpine1x.yaml","title":"Examples"},{"location":"cmd/flux_export_image_policy/#options","text":"-h, --help help for policy","title":"Options"},{"location":"cmd/flux_export_image_policy/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_image_policy/#see-also","text":"flux export image - Export image automation objects","title":"SEE ALSO"},{"location":"cmd/flux_export_image_repository/","text":"flux export image repository \u00b6 Export ImageRepository resources in YAML format Synopsis \u00b6 The export image repository command exports one or all ImageRepository resources in YAML format. flux export image repository [name] [flags] Examples \u00b6 # Export all ImageRepository resources flux export image repository --all > image-repositories.yaml # Export a specific ImageRepository resource flux export image repository alpine > alpine.yaml Options \u00b6 -h, --help help for repository Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux export image - Export image automation objects","title":"Export image repository"},{"location":"cmd/flux_export_image_repository/#flux-export-image-repository","text":"Export ImageRepository resources in YAML format","title":"flux export image repository"},{"location":"cmd/flux_export_image_repository/#synopsis","text":"The export image repository command exports one or all ImageRepository resources in YAML format. flux export image repository [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_export_image_repository/#examples","text":"# Export all ImageRepository resources flux export image repository --all > image-repositories.yaml # Export a specific ImageRepository resource flux export image repository alpine > alpine.yaml","title":"Examples"},{"location":"cmd/flux_export_image_repository/#options","text":"-h, --help help for repository","title":"Options"},{"location":"cmd/flux_export_image_repository/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_image_repository/#see-also","text":"flux export image - Export image automation objects","title":"SEE ALSO"},{"location":"cmd/flux_export_image_update/","text":"flux export image update \u00b6 Export ImageUpdateAutomation resources in YAML format Synopsis \u00b6 The export image update command exports one or all ImageUpdateAutomation resources in YAML format. flux export image update [name] [flags] Examples \u00b6 # Export all ImageUpdateAutomation resources flux export image update --all > updates.yaml # Export a specific automation flux export image update latest-images > latest.yaml Options \u00b6 -h, --help help for update Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux export image - Export image automation objects","title":"Export image update"},{"location":"cmd/flux_export_image_update/#flux-export-image-update","text":"Export ImageUpdateAutomation resources in YAML format","title":"flux export image update"},{"location":"cmd/flux_export_image_update/#synopsis","text":"The export image update command exports one or all ImageUpdateAutomation resources in YAML format. flux export image update [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_export_image_update/#examples","text":"# Export all ImageUpdateAutomation resources flux export image update --all > updates.yaml # Export a specific automation flux export image update latest-images > latest.yaml","title":"Examples"},{"location":"cmd/flux_export_image_update/#options","text":"-h, --help help for update","title":"Options"},{"location":"cmd/flux_export_image_update/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_image_update/#see-also","text":"flux export image - Export image automation objects","title":"SEE ALSO"},{"location":"cmd/flux_export_kustomization/","text":"flux export kustomization \u00b6 Export Kustomization resources in YAML format Synopsis \u00b6 The export kustomization command exports one or all Kustomization resources in YAML format. flux export kustomization [name] [flags] Examples \u00b6 # Export all Kustomization resources flux export kustomization --all > kustomizations.yaml # Export a Kustomization flux export kustomization my-app > kustomization.yaml Options \u00b6 -h, --help help for kustomization Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux export - Export resources in YAML format","title":"Export kustomization"},{"location":"cmd/flux_export_kustomization/#flux-export-kustomization","text":"Export Kustomization resources in YAML format","title":"flux export kustomization"},{"location":"cmd/flux_export_kustomization/#synopsis","text":"The export kustomization command exports one or all Kustomization resources in YAML format. flux export kustomization [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_export_kustomization/#examples","text":"# Export all Kustomization resources flux export kustomization --all > kustomizations.yaml # Export a Kustomization flux export kustomization my-app > kustomization.yaml","title":"Examples"},{"location":"cmd/flux_export_kustomization/#options","text":"-h, --help help for kustomization","title":"Options"},{"location":"cmd/flux_export_kustomization/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_kustomization/#see-also","text":"flux export - Export resources in YAML format","title":"SEE ALSO"},{"location":"cmd/flux_export_receiver/","text":"flux export receiver \u00b6 Export Receiver resources in YAML format Synopsis \u00b6 The export receiver command exports one or all Receiver resources in YAML format. flux export receiver [name] [flags] Examples \u00b6 # Export all Receiver resources flux export receiver --all > receivers.yaml # Export a Receiver flux export receiver main > main.yaml Options \u00b6 -h, --help help for receiver Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux export - Export resources in YAML format","title":"Export receiver"},{"location":"cmd/flux_export_receiver/#flux-export-receiver","text":"Export Receiver resources in YAML format","title":"flux export receiver"},{"location":"cmd/flux_export_receiver/#synopsis","text":"The export receiver command exports one or all Receiver resources in YAML format. flux export receiver [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_export_receiver/#examples","text":"# Export all Receiver resources flux export receiver --all > receivers.yaml # Export a Receiver flux export receiver main > main.yaml","title":"Examples"},{"location":"cmd/flux_export_receiver/#options","text":"-h, --help help for receiver","title":"Options"},{"location":"cmd/flux_export_receiver/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_receiver/#see-also","text":"flux export - Export resources in YAML format","title":"SEE ALSO"},{"location":"cmd/flux_export_source/","text":"flux export source \u00b6 Export sources Synopsis \u00b6 The export source sub-commands export sources in YAML format. Options \u00b6 -h, --help help for source --with-credentials include credential secrets Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux export - Export resources in YAML format flux export source bucket - Export Bucket sources in YAML format flux export source git - Export GitRepository sources in YAML format flux export source helm - Export HelmRepository sources in YAML format","title":"Export source"},{"location":"cmd/flux_export_source/#flux-export-source","text":"Export sources","title":"flux export source"},{"location":"cmd/flux_export_source/#synopsis","text":"The export source sub-commands export sources in YAML format.","title":"Synopsis"},{"location":"cmd/flux_export_source/#options","text":"-h, --help help for source --with-credentials include credential secrets","title":"Options"},{"location":"cmd/flux_export_source/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_source/#see-also","text":"flux export - Export resources in YAML format flux export source bucket - Export Bucket sources in YAML format flux export source git - Export GitRepository sources in YAML format flux export source helm - Export HelmRepository sources in YAML format","title":"SEE ALSO"},{"location":"cmd/flux_export_source_bucket/","text":"flux export source bucket \u00b6 Export Bucket sources in YAML format Synopsis \u00b6 The export source git command exports on or all Bucket sources in YAML format. flux export source bucket [name] [flags] Examples \u00b6 # Export all Bucket sources flux export source bucket --all > sources.yaml # Export a Bucket source including the static credentials flux export source bucket my-bucket --with-credentials > source.yaml Options \u00b6 -h, --help help for bucket Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects --with-credentials include credential secrets SEE ALSO \u00b6 flux export source - Export sources","title":"Export source bucket"},{"location":"cmd/flux_export_source_bucket/#flux-export-source-bucket","text":"Export Bucket sources in YAML format","title":"flux export source bucket"},{"location":"cmd/flux_export_source_bucket/#synopsis","text":"The export source git command exports on or all Bucket sources in YAML format. flux export source bucket [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_export_source_bucket/#examples","text":"# Export all Bucket sources flux export source bucket --all > sources.yaml # Export a Bucket source including the static credentials flux export source bucket my-bucket --with-credentials > source.yaml","title":"Examples"},{"location":"cmd/flux_export_source_bucket/#options","text":"-h, --help help for bucket","title":"Options"},{"location":"cmd/flux_export_source_bucket/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects --with-credentials include credential secrets","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_source_bucket/#see-also","text":"flux export source - Export sources","title":"SEE ALSO"},{"location":"cmd/flux_export_source_git/","text":"flux export source git \u00b6 Export GitRepository sources in YAML format Synopsis \u00b6 The export source git command exports on or all GitRepository sources in YAML format. flux export source git [name] [flags] Examples \u00b6 # Export all GitRepository sources flux export source git --all > sources.yaml # Export a GitRepository source including the SSH key pair or basic auth credentials flux export source git my-private-repo --with-credentials > source.yaml Options \u00b6 -h, --help help for git Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects --with-credentials include credential secrets SEE ALSO \u00b6 flux export source - Export sources","title":"Export source git"},{"location":"cmd/flux_export_source_git/#flux-export-source-git","text":"Export GitRepository sources in YAML format","title":"flux export source git"},{"location":"cmd/flux_export_source_git/#synopsis","text":"The export source git command exports on or all GitRepository sources in YAML format. flux export source git [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_export_source_git/#examples","text":"# Export all GitRepository sources flux export source git --all > sources.yaml # Export a GitRepository source including the SSH key pair or basic auth credentials flux export source git my-private-repo --with-credentials > source.yaml","title":"Examples"},{"location":"cmd/flux_export_source_git/#options","text":"-h, --help help for git","title":"Options"},{"location":"cmd/flux_export_source_git/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects --with-credentials include credential secrets","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_source_git/#see-also","text":"flux export source - Export sources","title":"SEE ALSO"},{"location":"cmd/flux_export_source_helm/","text":"flux export source helm \u00b6 Export HelmRepository sources in YAML format Synopsis \u00b6 The export source git command exports on or all HelmRepository sources in YAML format. flux export source helm [name] [flags] Examples \u00b6 # Export all HelmRepository sources flux export source helm --all > sources.yaml # Export a HelmRepository source including the basic auth credentials flux export source helm my-private-repo --with-credentials > source.yaml Options \u00b6 -h, --help help for helm Options inherited from parent commands \u00b6 --all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects --with-credentials include credential secrets SEE ALSO \u00b6 flux export source - Export sources","title":"Export source helm"},{"location":"cmd/flux_export_source_helm/#flux-export-source-helm","text":"Export HelmRepository sources in YAML format","title":"flux export source helm"},{"location":"cmd/flux_export_source_helm/#synopsis","text":"The export source git command exports on or all HelmRepository sources in YAML format. flux export source helm [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_export_source_helm/#examples","text":"# Export all HelmRepository sources flux export source helm --all > sources.yaml # Export a HelmRepository source including the basic auth credentials flux export source helm my-private-repo --with-credentials > source.yaml","title":"Examples"},{"location":"cmd/flux_export_source_helm/#options","text":"-h, --help help for helm","title":"Options"},{"location":"cmd/flux_export_source_helm/#options-inherited-from-parent-commands","text":"--all select all resources --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects --with-credentials include credential secrets","title":"Options inherited from parent commands"},{"location":"cmd/flux_export_source_helm/#see-also","text":"flux export source - Export sources","title":"SEE ALSO"},{"location":"cmd/flux_get/","text":"flux get \u00b6 Get sources and resources Synopsis \u00b6 The get sub-commands print the statuses of sources and resources. Options \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces -h, --help help for get Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux - Command line utility for assembling Kubernetes CD pipelines flux get alert-providers - Get Provider statuses flux get alerts - Get Alert statuses flux get helmreleases - Get HelmRelease statuses flux get images - Get image automation object status flux get kustomizations - Get Kustomization statuses flux get receivers - Get Receiver statuses flux get sources - Get source statuses","title":"Get"},{"location":"cmd/flux_get/#flux-get","text":"Get sources and resources","title":"flux get"},{"location":"cmd/flux_get/#synopsis","text":"The get sub-commands print the statuses of sources and resources.","title":"Synopsis"},{"location":"cmd/flux_get/#options","text":"-A, --all-namespaces list the requested object(s) across all namespaces -h, --help help for get","title":"Options"},{"location":"cmd/flux_get/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get/#see-also","text":"flux - Command line utility for assembling Kubernetes CD pipelines flux get alert-providers - Get Provider statuses flux get alerts - Get Alert statuses flux get helmreleases - Get HelmRelease statuses flux get images - Get image automation object status flux get kustomizations - Get Kustomization statuses flux get receivers - Get Receiver statuses flux get sources - Get source statuses","title":"SEE ALSO"},{"location":"cmd/flux_get_alert-providers/","text":"flux get alert-providers \u00b6 Get Provider statuses Synopsis \u00b6 The get alert-provider command prints the statuses of the resources. flux get alert-providers [flags] Examples \u00b6 # List all Providers and their status flux get alert-providers Options \u00b6 -h, --help help for alert-providers Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get - Get sources and resources","title":"Get alert providers"},{"location":"cmd/flux_get_alert-providers/#flux-get-alert-providers","text":"Get Provider statuses","title":"flux get alert-providers"},{"location":"cmd/flux_get_alert-providers/#synopsis","text":"The get alert-provider command prints the statuses of the resources. flux get alert-providers [flags]","title":"Synopsis"},{"location":"cmd/flux_get_alert-providers/#examples","text":"# List all Providers and their status flux get alert-providers","title":"Examples"},{"location":"cmd/flux_get_alert-providers/#options","text":"-h, --help help for alert-providers","title":"Options"},{"location":"cmd/flux_get_alert-providers/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_alert-providers/#see-also","text":"flux get - Get sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_get_alerts/","text":"flux get alerts \u00b6 Get Alert statuses Synopsis \u00b6 The get alert command prints the statuses of the resources. flux get alerts [flags] Examples \u00b6 # List all Alerts and their status flux get alerts Options \u00b6 -h, --help help for alerts Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get - Get sources and resources","title":"Get alerts"},{"location":"cmd/flux_get_alerts/#flux-get-alerts","text":"Get Alert statuses","title":"flux get alerts"},{"location":"cmd/flux_get_alerts/#synopsis","text":"The get alert command prints the statuses of the resources. flux get alerts [flags]","title":"Synopsis"},{"location":"cmd/flux_get_alerts/#examples","text":"# List all Alerts and their status flux get alerts","title":"Examples"},{"location":"cmd/flux_get_alerts/#options","text":"-h, --help help for alerts","title":"Options"},{"location":"cmd/flux_get_alerts/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_alerts/#see-also","text":"flux get - Get sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_get_helmreleases/","text":"flux get helmreleases \u00b6 Get HelmRelease statuses Synopsis \u00b6 The get helmreleases command prints the statuses of the resources. flux get helmreleases [flags] Examples \u00b6 # List all Helm releases and their status flux get helmreleases Options \u00b6 -h, --help help for helmreleases Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get - Get sources and resources","title":"Get helmreleases"},{"location":"cmd/flux_get_helmreleases/#flux-get-helmreleases","text":"Get HelmRelease statuses","title":"flux get helmreleases"},{"location":"cmd/flux_get_helmreleases/#synopsis","text":"The get helmreleases command prints the statuses of the resources. flux get helmreleases [flags]","title":"Synopsis"},{"location":"cmd/flux_get_helmreleases/#examples","text":"# List all Helm releases and their status flux get helmreleases","title":"Examples"},{"location":"cmd/flux_get_helmreleases/#options","text":"-h, --help help for helmreleases","title":"Options"},{"location":"cmd/flux_get_helmreleases/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_helmreleases/#see-also","text":"flux get - Get sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_get_images/","text":"flux get images \u00b6 Get image automation object status Synopsis \u00b6 The get image sub-commands print the status of image automation objects. Options \u00b6 -h, --help help for images Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get - Get sources and resources flux get images policy - Get ImagePolicy status flux get images repository - Get ImageRepository status flux get images update - Get ImageUpdateAutomation status","title":"Get images"},{"location":"cmd/flux_get_images/#flux-get-images","text":"Get image automation object status","title":"flux get images"},{"location":"cmd/flux_get_images/#synopsis","text":"The get image sub-commands print the status of image automation objects.","title":"Synopsis"},{"location":"cmd/flux_get_images/#options","text":"-h, --help help for images","title":"Options"},{"location":"cmd/flux_get_images/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_images/#see-also","text":"flux get - Get sources and resources flux get images policy - Get ImagePolicy status flux get images repository - Get ImageRepository status flux get images update - Get ImageUpdateAutomation status","title":"SEE ALSO"},{"location":"cmd/flux_get_images_policy/","text":"flux get images policy \u00b6 Get ImagePolicy status Synopsis \u00b6 The get image policy command prints the status of ImagePolicy objects. flux get images policy [flags] Examples \u00b6 # List all image policies and their status flux get image policy # List image policies from all namespaces flux get image policy --all-namespaces Options \u00b6 -h, --help help for policy Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get images - Get image automation object status","title":"Get images policy"},{"location":"cmd/flux_get_images_policy/#flux-get-images-policy","text":"Get ImagePolicy status","title":"flux get images policy"},{"location":"cmd/flux_get_images_policy/#synopsis","text":"The get image policy command prints the status of ImagePolicy objects. flux get images policy [flags]","title":"Synopsis"},{"location":"cmd/flux_get_images_policy/#examples","text":"# List all image policies and their status flux get image policy # List image policies from all namespaces flux get image policy --all-namespaces","title":"Examples"},{"location":"cmd/flux_get_images_policy/#options","text":"-h, --help help for policy","title":"Options"},{"location":"cmd/flux_get_images_policy/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_images_policy/#see-also","text":"flux get images - Get image automation object status","title":"SEE ALSO"},{"location":"cmd/flux_get_images_repository/","text":"flux get images repository \u00b6 Get ImageRepository status Synopsis \u00b6 The get image repository command prints the status of ImageRepository objects. flux get images repository [flags] Examples \u00b6 # List all image repositories and their status flux get image repository # List image repositories from all namespaces flux get image repository --all-namespaces Options \u00b6 -h, --help help for repository Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get images - Get image automation object status","title":"Get images repository"},{"location":"cmd/flux_get_images_repository/#flux-get-images-repository","text":"Get ImageRepository status","title":"flux get images repository"},{"location":"cmd/flux_get_images_repository/#synopsis","text":"The get image repository command prints the status of ImageRepository objects. flux get images repository [flags]","title":"Synopsis"},{"location":"cmd/flux_get_images_repository/#examples","text":"# List all image repositories and their status flux get image repository # List image repositories from all namespaces flux get image repository --all-namespaces","title":"Examples"},{"location":"cmd/flux_get_images_repository/#options","text":"-h, --help help for repository","title":"Options"},{"location":"cmd/flux_get_images_repository/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_images_repository/#see-also","text":"flux get images - Get image automation object status","title":"SEE ALSO"},{"location":"cmd/flux_get_images_update/","text":"flux get images update \u00b6 Get ImageUpdateAutomation status Synopsis \u00b6 The get image update command prints the status of ImageUpdateAutomation objects. flux get images update [flags] Examples \u00b6 # List all image update automation object and their status flux get image update # List image update automations from all namespaces flux get image update --all-namespaces Options \u00b6 -h, --help help for update Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get images - Get image automation object status","title":"Get images update"},{"location":"cmd/flux_get_images_update/#flux-get-images-update","text":"Get ImageUpdateAutomation status","title":"flux get images update"},{"location":"cmd/flux_get_images_update/#synopsis","text":"The get image update command prints the status of ImageUpdateAutomation objects. flux get images update [flags]","title":"Synopsis"},{"location":"cmd/flux_get_images_update/#examples","text":"# List all image update automation object and their status flux get image update # List image update automations from all namespaces flux get image update --all-namespaces","title":"Examples"},{"location":"cmd/flux_get_images_update/#options","text":"-h, --help help for update","title":"Options"},{"location":"cmd/flux_get_images_update/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_images_update/#see-also","text":"flux get images - Get image automation object status","title":"SEE ALSO"},{"location":"cmd/flux_get_kustomizations/","text":"flux get kustomizations \u00b6 Get Kustomization statuses Synopsis \u00b6 The get kustomizations command prints the statuses of the resources. flux get kustomizations [flags] Examples \u00b6 # List all kustomizations and their status flux get kustomizations Options \u00b6 -h, --help help for kustomizations Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get - Get sources and resources","title":"Get kustomizations"},{"location":"cmd/flux_get_kustomizations/#flux-get-kustomizations","text":"Get Kustomization statuses","title":"flux get kustomizations"},{"location":"cmd/flux_get_kustomizations/#synopsis","text":"The get kustomizations command prints the statuses of the resources. flux get kustomizations [flags]","title":"Synopsis"},{"location":"cmd/flux_get_kustomizations/#examples","text":"# List all kustomizations and their status flux get kustomizations","title":"Examples"},{"location":"cmd/flux_get_kustomizations/#options","text":"-h, --help help for kustomizations","title":"Options"},{"location":"cmd/flux_get_kustomizations/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_kustomizations/#see-also","text":"flux get - Get sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_get_receivers/","text":"flux get receivers \u00b6 Get Receiver statuses Synopsis \u00b6 The get receiver command prints the statuses of the resources. flux get receivers [flags] Examples \u00b6 # List all Receiver and their status flux get receivers Options \u00b6 -h, --help help for receivers Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get - Get sources and resources","title":"Get receivers"},{"location":"cmd/flux_get_receivers/#flux-get-receivers","text":"Get Receiver statuses","title":"flux get receivers"},{"location":"cmd/flux_get_receivers/#synopsis","text":"The get receiver command prints the statuses of the resources. flux get receivers [flags]","title":"Synopsis"},{"location":"cmd/flux_get_receivers/#examples","text":"# List all Receiver and their status flux get receivers","title":"Examples"},{"location":"cmd/flux_get_receivers/#options","text":"-h, --help help for receivers","title":"Options"},{"location":"cmd/flux_get_receivers/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_receivers/#see-also","text":"flux get - Get sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_get_sources/","text":"flux get sources \u00b6 Get source statuses Synopsis \u00b6 The get source sub-commands print the statuses of the sources. Options \u00b6 -h, --help help for sources Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get - Get sources and resources flux get sources bucket - Get Bucket source statuses flux get sources chart - Get HelmChart statuses flux get sources git - Get GitRepository source statuses flux get sources helm - Get HelmRepository source statuses","title":"Get sources"},{"location":"cmd/flux_get_sources/#flux-get-sources","text":"Get source statuses","title":"flux get sources"},{"location":"cmd/flux_get_sources/#synopsis","text":"The get source sub-commands print the statuses of the sources.","title":"Synopsis"},{"location":"cmd/flux_get_sources/#options","text":"-h, --help help for sources","title":"Options"},{"location":"cmd/flux_get_sources/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_sources/#see-also","text":"flux get - Get sources and resources flux get sources bucket - Get Bucket source statuses flux get sources chart - Get HelmChart statuses flux get sources git - Get GitRepository source statuses flux get sources helm - Get HelmRepository source statuses","title":"SEE ALSO"},{"location":"cmd/flux_get_sources_bucket/","text":"flux get sources bucket \u00b6 Get Bucket source statuses Synopsis \u00b6 The get sources bucket command prints the status of the Bucket sources. flux get sources bucket [flags] Examples \u00b6 # List all Buckets and their status flux get sources bucket # List buckets from all namespaces flux get sources helm --all-namespaces Options \u00b6 -h, --help help for bucket Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get sources - Get source statuses","title":"Get sources bucket"},{"location":"cmd/flux_get_sources_bucket/#flux-get-sources-bucket","text":"Get Bucket source statuses","title":"flux get sources bucket"},{"location":"cmd/flux_get_sources_bucket/#synopsis","text":"The get sources bucket command prints the status of the Bucket sources. flux get sources bucket [flags]","title":"Synopsis"},{"location":"cmd/flux_get_sources_bucket/#examples","text":"# List all Buckets and their status flux get sources bucket # List buckets from all namespaces flux get sources helm --all-namespaces","title":"Examples"},{"location":"cmd/flux_get_sources_bucket/#options","text":"-h, --help help for bucket","title":"Options"},{"location":"cmd/flux_get_sources_bucket/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_sources_bucket/#see-also","text":"flux get sources - Get source statuses","title":"SEE ALSO"},{"location":"cmd/flux_get_sources_chart/","text":"flux get sources chart \u00b6 Get HelmChart statuses Synopsis \u00b6 The get sources chart command prints the status of the HelmCharts. flux get sources chart [flags] Examples \u00b6 # List all Helm charts and their status flux get sources chart # List Helm charts from all namespaces flux get sources chart --all-namespaces Options \u00b6 -h, --help help for chart Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get sources - Get source statuses","title":"Get sources chart"},{"location":"cmd/flux_get_sources_chart/#flux-get-sources-chart","text":"Get HelmChart statuses","title":"flux get sources chart"},{"location":"cmd/flux_get_sources_chart/#synopsis","text":"The get sources chart command prints the status of the HelmCharts. flux get sources chart [flags]","title":"Synopsis"},{"location":"cmd/flux_get_sources_chart/#examples","text":"# List all Helm charts and their status flux get sources chart # List Helm charts from all namespaces flux get sources chart --all-namespaces","title":"Examples"},{"location":"cmd/flux_get_sources_chart/#options","text":"-h, --help help for chart","title":"Options"},{"location":"cmd/flux_get_sources_chart/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_sources_chart/#see-also","text":"flux get sources - Get source statuses","title":"SEE ALSO"},{"location":"cmd/flux_get_sources_git/","text":"flux get sources git \u00b6 Get GitRepository source statuses Synopsis \u00b6 The get sources git command prints the status of the GitRepository sources. flux get sources git [flags] Examples \u00b6 # List all Git repositories and their status flux get sources git # List Git repositories from all namespaces flux get sources git --all-namespaces Options \u00b6 -h, --help help for git Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get sources - Get source statuses","title":"Get sources git"},{"location":"cmd/flux_get_sources_git/#flux-get-sources-git","text":"Get GitRepository source statuses","title":"flux get sources git"},{"location":"cmd/flux_get_sources_git/#synopsis","text":"The get sources git command prints the status of the GitRepository sources. flux get sources git [flags]","title":"Synopsis"},{"location":"cmd/flux_get_sources_git/#examples","text":"# List all Git repositories and their status flux get sources git # List Git repositories from all namespaces flux get sources git --all-namespaces","title":"Examples"},{"location":"cmd/flux_get_sources_git/#options","text":"-h, --help help for git","title":"Options"},{"location":"cmd/flux_get_sources_git/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_sources_git/#see-also","text":"flux get sources - Get source statuses","title":"SEE ALSO"},{"location":"cmd/flux_get_sources_helm/","text":"flux get sources helm \u00b6 Get HelmRepository source statuses Synopsis \u00b6 The get sources helm command prints the status of the HelmRepository sources. flux get sources helm [flags] Examples \u00b6 # List all Helm repositories and their status flux get sources helm # List Helm repositories from all namespaces flux get sources helm --all-namespaces Options \u00b6 -h, --help help for helm Options inherited from parent commands \u00b6 -A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux get sources - Get source statuses","title":"Get sources helm"},{"location":"cmd/flux_get_sources_helm/#flux-get-sources-helm","text":"Get HelmRepository source statuses","title":"flux get sources helm"},{"location":"cmd/flux_get_sources_helm/#synopsis","text":"The get sources helm command prints the status of the HelmRepository sources. flux get sources helm [flags]","title":"Synopsis"},{"location":"cmd/flux_get_sources_helm/#examples","text":"# List all Helm repositories and their status flux get sources helm # List Helm repositories from all namespaces flux get sources helm --all-namespaces","title":"Examples"},{"location":"cmd/flux_get_sources_helm/#options","text":"-h, --help help for helm","title":"Options"},{"location":"cmd/flux_get_sources_helm/#options-inherited-from-parent-commands","text":"-A, --all-namespaces list the requested object(s) across all namespaces --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_get_sources_helm/#see-also","text":"flux get sources - Get source statuses","title":"SEE ALSO"},{"location":"cmd/flux_install/","text":"flux install \u00b6 Install or upgrade Flux Synopsis \u00b6 The install command deploys Flux in the specified namespace. If a previous version is installed, then an in-place upgrade will be performed. flux install [flags] Examples \u00b6 # Install the latest version in the flux-system namespace flux install --version=latest --namespace=flux-system # Install a specific version and a series of components flux install --dry-run --version=v0.0.7 --components=\"source-controller,kustomize-controller\" # Install Flux onto tainted Kubernetes nodes flux install --toleration-keys=node.kubernetes.io/dedicated-to-flux # Dry-run install with manifests preview flux install --dry-run --verbose # Write install manifests to file flux install --export > flux-system.yaml Options \u00b6 --cluster-domain string internal cluster domain (default \"cluster.local\") --components strings list of components, accepts comma-separated values (default [source-controller,kustomize-controller,helm-controller,notification-controller]) --components-extra strings list of components in addition to those supplied or defaulted, accepts comma-separated values --dry-run only print the object that would be applied --export write the install manifests to stdout and exit -h, --help help for install --image-pull-secret string Kubernetes secret name used for pulling the toolkit images from a private registry --log-level logLevel log level, available options are: (debug, info, error) (default info) --network-policy deny ingress access to the toolkit controllers from other namespaces using network policies (default true) --registry string container registry where the toolkit images are published (default \"ghcr.io/fluxcd\") --toleration-keys strings list of toleration keys used to schedule the components pods onto nodes with matching taints -v, --version string toolkit version, when specified the manifests are downloaded from https://github.com/fluxcd/flux2/releases --watch-all-namespaces watch for custom resources in all namespaces, if set to false it will only watch the namespace where the toolkit is installed (default true) Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux - Command line utility for assembling Kubernetes CD pipelines","title":"Install"},{"location":"cmd/flux_install/#flux-install","text":"Install or upgrade Flux","title":"flux install"},{"location":"cmd/flux_install/#synopsis","text":"The install command deploys Flux in the specified namespace. If a previous version is installed, then an in-place upgrade will be performed. flux install [flags]","title":"Synopsis"},{"location":"cmd/flux_install/#examples","text":"# Install the latest version in the flux-system namespace flux install --version=latest --namespace=flux-system # Install a specific version and a series of components flux install --dry-run --version=v0.0.7 --components=\"source-controller,kustomize-controller\" # Install Flux onto tainted Kubernetes nodes flux install --toleration-keys=node.kubernetes.io/dedicated-to-flux # Dry-run install with manifests preview flux install --dry-run --verbose # Write install manifests to file flux install --export > flux-system.yaml","title":"Examples"},{"location":"cmd/flux_install/#options","text":"--cluster-domain string internal cluster domain (default \"cluster.local\") --components strings list of components, accepts comma-separated values (default [source-controller,kustomize-controller,helm-controller,notification-controller]) --components-extra strings list of components in addition to those supplied or defaulted, accepts comma-separated values --dry-run only print the object that would be applied --export write the install manifests to stdout and exit -h, --help help for install --image-pull-secret string Kubernetes secret name used for pulling the toolkit images from a private registry --log-level logLevel log level, available options are: (debug, info, error) (default info) --network-policy deny ingress access to the toolkit controllers from other namespaces using network policies (default true) --registry string container registry where the toolkit images are published (default \"ghcr.io/fluxcd\") --toleration-keys strings list of toleration keys used to schedule the components pods onto nodes with matching taints -v, --version string toolkit version, when specified the manifests are downloaded from https://github.com/fluxcd/flux2/releases --watch-all-namespaces watch for custom resources in all namespaces, if set to false it will only watch the namespace where the toolkit is installed (default true)","title":"Options"},{"location":"cmd/flux_install/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_install/#see-also","text":"flux - Command line utility for assembling Kubernetes CD pipelines","title":"SEE ALSO"},{"location":"cmd/flux_reconcile/","text":"flux reconcile \u00b6 Reconcile sources and resources Synopsis \u00b6 The reconcile sub-commands trigger a reconciliation of sources and resources. Options \u00b6 -h, --help help for reconcile Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux - Command line utility for assembling Kubernetes CD pipelines flux reconcile alert - Reconcile an Alert flux reconcile alert-provider - Reconcile a Provider flux reconcile helmrelease - Reconcile a HelmRelease resource flux reconcile image - Reconcile image automation objects flux reconcile kustomization - Reconcile a Kustomization resource flux reconcile receiver - Reconcile a Receiver flux reconcile source - Reconcile sources","title":"Reconcile"},{"location":"cmd/flux_reconcile/#flux-reconcile","text":"Reconcile sources and resources","title":"flux reconcile"},{"location":"cmd/flux_reconcile/#synopsis","text":"The reconcile sub-commands trigger a reconciliation of sources and resources.","title":"Synopsis"},{"location":"cmd/flux_reconcile/#options","text":"-h, --help help for reconcile","title":"Options"},{"location":"cmd/flux_reconcile/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile/#see-also","text":"flux - Command line utility for assembling Kubernetes CD pipelines flux reconcile alert - Reconcile an Alert flux reconcile alert-provider - Reconcile a Provider flux reconcile helmrelease - Reconcile a HelmRelease resource flux reconcile image - Reconcile image automation objects flux reconcile kustomization - Reconcile a Kustomization resource flux reconcile receiver - Reconcile a Receiver flux reconcile source - Reconcile sources","title":"SEE ALSO"},{"location":"cmd/flux_reconcile_alert-provider/","text":"flux reconcile alert-provider \u00b6 Reconcile a Provider Synopsis \u00b6 The reconcile alert-provider command triggers a reconciliation of a Provider resource and waits for it to finish. flux reconcile alert-provider [name] [flags] Examples \u00b6 # Trigger a reconciliation for an existing provider flux reconcile alert-provider slack Options \u00b6 -h, --help help for alert-provider Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux reconcile - Reconcile sources and resources","title":"Flux reconcile alert provider"},{"location":"cmd/flux_reconcile_alert-provider/#flux-reconcile-alert-provider","text":"Reconcile a Provider","title":"flux reconcile alert-provider"},{"location":"cmd/flux_reconcile_alert-provider/#synopsis","text":"The reconcile alert-provider command triggers a reconciliation of a Provider resource and waits for it to finish. flux reconcile alert-provider [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_reconcile_alert-provider/#examples","text":"# Trigger a reconciliation for an existing provider flux reconcile alert-provider slack","title":"Examples"},{"location":"cmd/flux_reconcile_alert-provider/#options","text":"-h, --help help for alert-provider","title":"Options"},{"location":"cmd/flux_reconcile_alert-provider/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile_alert-provider/#see-also","text":"flux reconcile - Reconcile sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_reconcile_alert/","text":"flux reconcile alert \u00b6 Reconcile an Alert Synopsis \u00b6 The reconcile alert command triggers a reconciliation of an Alert resource and waits for it to finish. flux reconcile alert [name] [flags] Examples \u00b6 # Trigger a reconciliation for an existing alert flux reconcile alert main Options \u00b6 -h, --help help for alert Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux reconcile - Reconcile sources and resources","title":"Flux reconcile alert"},{"location":"cmd/flux_reconcile_alert/#flux-reconcile-alert","text":"Reconcile an Alert","title":"flux reconcile alert"},{"location":"cmd/flux_reconcile_alert/#synopsis","text":"The reconcile alert command triggers a reconciliation of an Alert resource and waits for it to finish. flux reconcile alert [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_reconcile_alert/#examples","text":"# Trigger a reconciliation for an existing alert flux reconcile alert main","title":"Examples"},{"location":"cmd/flux_reconcile_alert/#options","text":"-h, --help help for alert","title":"Options"},{"location":"cmd/flux_reconcile_alert/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile_alert/#see-also","text":"flux reconcile - Reconcile sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_reconcile_helmrelease/","text":"flux reconcile helmrelease \u00b6 Reconcile a HelmRelease resource Synopsis \u00b6 The reconcile kustomization command triggers a reconciliation of a HelmRelease resource and waits for it to finish. flux reconcile helmrelease [name] [flags] Examples \u00b6 # Trigger a HelmRelease apply outside of the reconciliation interval flux reconcile hr podinfo # Trigger a reconciliation of the HelmRelease's source and apply changes flux reconcile hr podinfo --with-source Options \u00b6 -h, --help help for helmrelease --with-source reconcile HelmRelease source Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux reconcile - Reconcile sources and resources","title":"Reconcile helmrelease"},{"location":"cmd/flux_reconcile_helmrelease/#flux-reconcile-helmrelease","text":"Reconcile a HelmRelease resource","title":"flux reconcile helmrelease"},{"location":"cmd/flux_reconcile_helmrelease/#synopsis","text":"The reconcile kustomization command triggers a reconciliation of a HelmRelease resource and waits for it to finish. flux reconcile helmrelease [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_reconcile_helmrelease/#examples","text":"# Trigger a HelmRelease apply outside of the reconciliation interval flux reconcile hr podinfo # Trigger a reconciliation of the HelmRelease's source and apply changes flux reconcile hr podinfo --with-source","title":"Examples"},{"location":"cmd/flux_reconcile_helmrelease/#options","text":"-h, --help help for helmrelease --with-source reconcile HelmRelease source","title":"Options"},{"location":"cmd/flux_reconcile_helmrelease/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile_helmrelease/#see-also","text":"flux reconcile - Reconcile sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_reconcile_image/","text":"flux reconcile image \u00b6 Reconcile image automation objects Synopsis \u00b6 The reconcile sub-commands trigger a reconciliation of image automation objects. Options \u00b6 -h, --help help for image Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux reconcile - Reconcile sources and resources flux reconcile image repository - Reconcile an ImageRepository flux reconcile image update - Reconcile an ImageUpdateAutomation","title":"Reconcile image"},{"location":"cmd/flux_reconcile_image/#flux-reconcile-image","text":"Reconcile image automation objects","title":"flux reconcile image"},{"location":"cmd/flux_reconcile_image/#synopsis","text":"The reconcile sub-commands trigger a reconciliation of image automation objects.","title":"Synopsis"},{"location":"cmd/flux_reconcile_image/#options","text":"-h, --help help for image","title":"Options"},{"location":"cmd/flux_reconcile_image/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile_image/#see-also","text":"flux reconcile - Reconcile sources and resources flux reconcile image repository - Reconcile an ImageRepository flux reconcile image update - Reconcile an ImageUpdateAutomation","title":"SEE ALSO"},{"location":"cmd/flux_reconcile_image_repository/","text":"flux reconcile image repository \u00b6 Reconcile an ImageRepository Synopsis \u00b6 The reconcile image repository command triggers a reconciliation of an ImageRepository resource and waits for it to finish. flux reconcile image repository [name] [flags] Examples \u00b6 # Trigger an scan for an existing image repository flux reconcile image repository alpine Options \u00b6 -h, --help help for repository Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux reconcile image - Reconcile image automation objects","title":"Reconcile image repository"},{"location":"cmd/flux_reconcile_image_repository/#flux-reconcile-image-repository","text":"Reconcile an ImageRepository","title":"flux reconcile image repository"},{"location":"cmd/flux_reconcile_image_repository/#synopsis","text":"The reconcile image repository command triggers a reconciliation of an ImageRepository resource and waits for it to finish. flux reconcile image repository [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_reconcile_image_repository/#examples","text":"# Trigger an scan for an existing image repository flux reconcile image repository alpine","title":"Examples"},{"location":"cmd/flux_reconcile_image_repository/#options","text":"-h, --help help for repository","title":"Options"},{"location":"cmd/flux_reconcile_image_repository/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile_image_repository/#see-also","text":"flux reconcile image - Reconcile image automation objects","title":"SEE ALSO"},{"location":"cmd/flux_reconcile_image_update/","text":"flux reconcile image update \u00b6 Reconcile an ImageUpdateAutomation Synopsis \u00b6 The reconcile image update command triggers a reconciliation of an ImageUpdateAutomation resource and waits for it to finish. flux reconcile image update [name] [flags] Examples \u00b6 # Trigger an automation run for an existing image update automation flux reconcile image update latest-images Options \u00b6 -h, --help help for update Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux reconcile image - Reconcile image automation objects","title":"Reconcile image update"},{"location":"cmd/flux_reconcile_image_update/#flux-reconcile-image-update","text":"Reconcile an ImageUpdateAutomation","title":"flux reconcile image update"},{"location":"cmd/flux_reconcile_image_update/#synopsis","text":"The reconcile image update command triggers a reconciliation of an ImageUpdateAutomation resource and waits for it to finish. flux reconcile image update [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_reconcile_image_update/#examples","text":"# Trigger an automation run for an existing image update automation flux reconcile image update latest-images","title":"Examples"},{"location":"cmd/flux_reconcile_image_update/#options","text":"-h, --help help for update","title":"Options"},{"location":"cmd/flux_reconcile_image_update/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile_image_update/#see-also","text":"flux reconcile image - Reconcile image automation objects","title":"SEE ALSO"},{"location":"cmd/flux_reconcile_kustomization/","text":"flux reconcile kustomization \u00b6 Reconcile a Kustomization resource Synopsis \u00b6 The reconcile kustomization command triggers a reconciliation of a Kustomization resource and waits for it to finish. flux reconcile kustomization [name] [flags] Examples \u00b6 # Trigger a Kustomization apply outside of the reconciliation interval flux reconcile kustomization podinfo # Trigger a sync of the Kustomization's source and apply changes flux reconcile kustomization podinfo --with-source Options \u00b6 -h, --help help for kustomization --with-source reconcile Kustomization source Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux reconcile - Reconcile sources and resources","title":"Reconcile kustomization"},{"location":"cmd/flux_reconcile_kustomization/#flux-reconcile-kustomization","text":"Reconcile a Kustomization resource","title":"flux reconcile kustomization"},{"location":"cmd/flux_reconcile_kustomization/#synopsis","text":"The reconcile kustomization command triggers a reconciliation of a Kustomization resource and waits for it to finish. flux reconcile kustomization [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_reconcile_kustomization/#examples","text":"# Trigger a Kustomization apply outside of the reconciliation interval flux reconcile kustomization podinfo # Trigger a sync of the Kustomization's source and apply changes flux reconcile kustomization podinfo --with-source","title":"Examples"},{"location":"cmd/flux_reconcile_kustomization/#options","text":"-h, --help help for kustomization --with-source reconcile Kustomization source","title":"Options"},{"location":"cmd/flux_reconcile_kustomization/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile_kustomization/#see-also","text":"flux reconcile - Reconcile sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_reconcile_receiver/","text":"flux reconcile receiver \u00b6 Reconcile a Receiver Synopsis \u00b6 The reconcile receiver command triggers a reconciliation of a Receiver resource and waits for it to finish. flux reconcile receiver [name] [flags] Examples \u00b6 # Trigger a reconciliation for an existing receiver flux reconcile receiver main Options \u00b6 -h, --help help for receiver Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux reconcile - Reconcile sources and resources","title":"Flux reconcile receiver"},{"location":"cmd/flux_reconcile_receiver/#flux-reconcile-receiver","text":"Reconcile a Receiver","title":"flux reconcile receiver"},{"location":"cmd/flux_reconcile_receiver/#synopsis","text":"The reconcile receiver command triggers a reconciliation of a Receiver resource and waits for it to finish. flux reconcile receiver [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_reconcile_receiver/#examples","text":"# Trigger a reconciliation for an existing receiver flux reconcile receiver main","title":"Examples"},{"location":"cmd/flux_reconcile_receiver/#options","text":"-h, --help help for receiver","title":"Options"},{"location":"cmd/flux_reconcile_receiver/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile_receiver/#see-also","text":"flux reconcile - Reconcile sources and resources","title":"SEE ALSO"},{"location":"cmd/flux_reconcile_source/","text":"flux reconcile source \u00b6 Reconcile sources Synopsis \u00b6 The reconcile source sub-commands trigger a reconciliation of sources. Options \u00b6 -h, --help help for source Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux reconcile - Reconcile sources and resources flux reconcile source bucket - Reconcile a Bucket source flux reconcile source git - Reconcile a GitRepository source flux reconcile source helm - Reconcile a HelmRepository source","title":"Reconcile source"},{"location":"cmd/flux_reconcile_source/#flux-reconcile-source","text":"Reconcile sources","title":"flux reconcile source"},{"location":"cmd/flux_reconcile_source/#synopsis","text":"The reconcile source sub-commands trigger a reconciliation of sources.","title":"Synopsis"},{"location":"cmd/flux_reconcile_source/#options","text":"-h, --help help for source","title":"Options"},{"location":"cmd/flux_reconcile_source/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile_source/#see-also","text":"flux reconcile - Reconcile sources and resources flux reconcile source bucket - Reconcile a Bucket source flux reconcile source git - Reconcile a GitRepository source flux reconcile source helm - Reconcile a HelmRepository source","title":"SEE ALSO"},{"location":"cmd/flux_reconcile_source_bucket/","text":"flux reconcile source bucket \u00b6 Reconcile a Bucket source Synopsis \u00b6 The reconcile source command triggers a reconciliation of a Bucket resource and waits for it to finish. flux reconcile source bucket [name] [flags] Examples \u00b6 # Trigger a reconciliation for an existing source flux reconcile source bucket podinfo Options \u00b6 -h, --help help for bucket Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux reconcile source - Reconcile sources","title":"Reconcile source bucket"},{"location":"cmd/flux_reconcile_source_bucket/#flux-reconcile-source-bucket","text":"Reconcile a Bucket source","title":"flux reconcile source bucket"},{"location":"cmd/flux_reconcile_source_bucket/#synopsis","text":"The reconcile source command triggers a reconciliation of a Bucket resource and waits for it to finish. flux reconcile source bucket [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_reconcile_source_bucket/#examples","text":"# Trigger a reconciliation for an existing source flux reconcile source bucket podinfo","title":"Examples"},{"location":"cmd/flux_reconcile_source_bucket/#options","text":"-h, --help help for bucket","title":"Options"},{"location":"cmd/flux_reconcile_source_bucket/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile_source_bucket/#see-also","text":"flux reconcile source - Reconcile sources","title":"SEE ALSO"},{"location":"cmd/flux_reconcile_source_git/","text":"flux reconcile source git \u00b6 Reconcile a GitRepository source Synopsis \u00b6 The reconcile source command triggers a reconciliation of a GitRepository resource and waits for it to finish. flux reconcile source git [name] [flags] Examples \u00b6 # Trigger a git pull for an existing source flux reconcile source git podinfo Options \u00b6 -h, --help help for git Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux reconcile source - Reconcile sources","title":"Reconcile source git"},{"location":"cmd/flux_reconcile_source_git/#flux-reconcile-source-git","text":"Reconcile a GitRepository source","title":"flux reconcile source git"},{"location":"cmd/flux_reconcile_source_git/#synopsis","text":"The reconcile source command triggers a reconciliation of a GitRepository resource and waits for it to finish. flux reconcile source git [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_reconcile_source_git/#examples","text":"# Trigger a git pull for an existing source flux reconcile source git podinfo","title":"Examples"},{"location":"cmd/flux_reconcile_source_git/#options","text":"-h, --help help for git","title":"Options"},{"location":"cmd/flux_reconcile_source_git/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile_source_git/#see-also","text":"flux reconcile source - Reconcile sources","title":"SEE ALSO"},{"location":"cmd/flux_reconcile_source_helm/","text":"flux reconcile source helm \u00b6 Reconcile a HelmRepository source Synopsis \u00b6 The reconcile source command triggers a reconciliation of a HelmRepository resource and waits for it to finish. flux reconcile source helm [name] [flags] Examples \u00b6 # Trigger a reconciliation for an existing source flux reconcile source helm podinfo Options \u00b6 -h, --help help for helm Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux reconcile source - Reconcile sources","title":"Reconcile source helm"},{"location":"cmd/flux_reconcile_source_helm/#flux-reconcile-source-helm","text":"Reconcile a HelmRepository source","title":"flux reconcile source helm"},{"location":"cmd/flux_reconcile_source_helm/#synopsis","text":"The reconcile source command triggers a reconciliation of a HelmRepository resource and waits for it to finish. flux reconcile source helm [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_reconcile_source_helm/#examples","text":"# Trigger a reconciliation for an existing source flux reconcile source helm podinfo","title":"Examples"},{"location":"cmd/flux_reconcile_source_helm/#options","text":"-h, --help help for helm","title":"Options"},{"location":"cmd/flux_reconcile_source_helm/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_reconcile_source_helm/#see-also","text":"flux reconcile source - Reconcile sources","title":"SEE ALSO"},{"location":"cmd/flux_resume/","text":"flux resume \u00b6 Resume suspended resources Synopsis \u00b6 The resume sub-commands resume a suspended resource. Options \u00b6 -h, --help help for resume Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux - Command line utility for assembling Kubernetes CD pipelines flux resume alert - Resume a suspended Alert flux resume helmrelease - Resume a suspended HelmRelease flux resume image - Resume image automation objects flux resume kustomization - Resume a suspended Kustomization flux resume receiver - Resume a suspended Receiver flux resume source - Resume sources","title":"Resume"},{"location":"cmd/flux_resume/#flux-resume","text":"Resume suspended resources","title":"flux resume"},{"location":"cmd/flux_resume/#synopsis","text":"The resume sub-commands resume a suspended resource.","title":"Synopsis"},{"location":"cmd/flux_resume/#options","text":"-h, --help help for resume","title":"Options"},{"location":"cmd/flux_resume/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume/#see-also","text":"flux - Command line utility for assembling Kubernetes CD pipelines flux resume alert - Resume a suspended Alert flux resume helmrelease - Resume a suspended HelmRelease flux resume image - Resume image automation objects flux resume kustomization - Resume a suspended Kustomization flux resume receiver - Resume a suspended Receiver flux resume source - Resume sources","title":"SEE ALSO"},{"location":"cmd/flux_resume_alert/","text":"flux resume alert \u00b6 Resume a suspended Alert Synopsis \u00b6 The resume command marks a previously suspended Alert resource for reconciliation and waits for it to finish the apply. flux resume alert [name] [flags] Examples \u00b6 # Resume reconciliation for an existing Alert flux resume alert main Options \u00b6 -h, --help help for alert Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux resume - Resume suspended resources","title":"Resume alert"},{"location":"cmd/flux_resume_alert/#flux-resume-alert","text":"Resume a suspended Alert","title":"flux resume alert"},{"location":"cmd/flux_resume_alert/#synopsis","text":"The resume command marks a previously suspended Alert resource for reconciliation and waits for it to finish the apply. flux resume alert [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_resume_alert/#examples","text":"# Resume reconciliation for an existing Alert flux resume alert main","title":"Examples"},{"location":"cmd/flux_resume_alert/#options","text":"-h, --help help for alert","title":"Options"},{"location":"cmd/flux_resume_alert/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume_alert/#see-also","text":"flux resume - Resume suspended resources","title":"SEE ALSO"},{"location":"cmd/flux_resume_helmrelease/","text":"flux resume helmrelease \u00b6 Resume a suspended HelmRelease Synopsis \u00b6 The resume command marks a previously suspended HelmRelease resource for reconciliation and waits for it to finish the apply. flux resume helmrelease [name] [flags] Examples \u00b6 # Resume reconciliation for an existing Helm release flux resume hr podinfo Options \u00b6 -h, --help help for helmrelease Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux resume - Resume suspended resources","title":"Resume helmrelease"},{"location":"cmd/flux_resume_helmrelease/#flux-resume-helmrelease","text":"Resume a suspended HelmRelease","title":"flux resume helmrelease"},{"location":"cmd/flux_resume_helmrelease/#synopsis","text":"The resume command marks a previously suspended HelmRelease resource for reconciliation and waits for it to finish the apply. flux resume helmrelease [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_resume_helmrelease/#examples","text":"# Resume reconciliation for an existing Helm release flux resume hr podinfo","title":"Examples"},{"location":"cmd/flux_resume_helmrelease/#options","text":"-h, --help help for helmrelease","title":"Options"},{"location":"cmd/flux_resume_helmrelease/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume_helmrelease/#see-also","text":"flux resume - Resume suspended resources","title":"SEE ALSO"},{"location":"cmd/flux_resume_image/","text":"flux resume image \u00b6 Resume image automation objects Synopsis \u00b6 The resume image sub-commands resume suspended image automation objects. Options \u00b6 -h, --help help for image Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux resume - Resume suspended resources flux resume image repository - Resume a suspended ImageRepository flux resume image update - Resume a suspended ImageUpdateAutomation","title":"Resume image"},{"location":"cmd/flux_resume_image/#flux-resume-image","text":"Resume image automation objects","title":"flux resume image"},{"location":"cmd/flux_resume_image/#synopsis","text":"The resume image sub-commands resume suspended image automation objects.","title":"Synopsis"},{"location":"cmd/flux_resume_image/#options","text":"-h, --help help for image","title":"Options"},{"location":"cmd/flux_resume_image/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume_image/#see-also","text":"flux resume - Resume suspended resources flux resume image repository - Resume a suspended ImageRepository flux resume image update - Resume a suspended ImageUpdateAutomation","title":"SEE ALSO"},{"location":"cmd/flux_resume_image_repository/","text":"flux resume image repository \u00b6 Resume a suspended ImageRepository Synopsis \u00b6 The resume command marks a previously suspended ImageRepository resource for reconciliation and waits for it to finish. flux resume image repository [name] [flags] Examples \u00b6 # Resume reconciliation for an existing ImageRepository flux resume image repository alpine Options \u00b6 -h, --help help for repository Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux resume image - Resume image automation objects","title":"Resume image repository"},{"location":"cmd/flux_resume_image_repository/#flux-resume-image-repository","text":"Resume a suspended ImageRepository","title":"flux resume image repository"},{"location":"cmd/flux_resume_image_repository/#synopsis","text":"The resume command marks a previously suspended ImageRepository resource for reconciliation and waits for it to finish. flux resume image repository [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_resume_image_repository/#examples","text":"# Resume reconciliation for an existing ImageRepository flux resume image repository alpine","title":"Examples"},{"location":"cmd/flux_resume_image_repository/#options","text":"-h, --help help for repository","title":"Options"},{"location":"cmd/flux_resume_image_repository/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume_image_repository/#see-also","text":"flux resume image - Resume image automation objects","title":"SEE ALSO"},{"location":"cmd/flux_resume_image_update/","text":"flux resume image update \u00b6 Resume a suspended ImageUpdateAutomation Synopsis \u00b6 The resume command marks a previously suspended ImageUpdateAutomation resource for reconciliation and waits for it to finish. flux resume image update [name] [flags] Examples \u00b6 # Resume reconciliation for an existing ImageUpdateAutomation flux resume image update latest-images Options \u00b6 -h, --help help for update Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux resume image - Resume image automation objects","title":"Resume image update"},{"location":"cmd/flux_resume_image_update/#flux-resume-image-update","text":"Resume a suspended ImageUpdateAutomation","title":"flux resume image update"},{"location":"cmd/flux_resume_image_update/#synopsis","text":"The resume command marks a previously suspended ImageUpdateAutomation resource for reconciliation and waits for it to finish. flux resume image update [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_resume_image_update/#examples","text":"# Resume reconciliation for an existing ImageUpdateAutomation flux resume image update latest-images","title":"Examples"},{"location":"cmd/flux_resume_image_update/#options","text":"-h, --help help for update","title":"Options"},{"location":"cmd/flux_resume_image_update/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume_image_update/#see-also","text":"flux resume image - Resume image automation objects","title":"SEE ALSO"},{"location":"cmd/flux_resume_kustomization/","text":"flux resume kustomization \u00b6 Resume a suspended Kustomization Synopsis \u00b6 The resume command marks a previously suspended Kustomization resource for reconciliation and waits for it to finish the apply. flux resume kustomization [name] [flags] Examples \u00b6 # Resume reconciliation for an existing Kustomization flux resume ks podinfo Options \u00b6 -h, --help help for kustomization Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux resume - Resume suspended resources","title":"Resume kustomization"},{"location":"cmd/flux_resume_kustomization/#flux-resume-kustomization","text":"Resume a suspended Kustomization","title":"flux resume kustomization"},{"location":"cmd/flux_resume_kustomization/#synopsis","text":"The resume command marks a previously suspended Kustomization resource for reconciliation and waits for it to finish the apply. flux resume kustomization [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_resume_kustomization/#examples","text":"# Resume reconciliation for an existing Kustomization flux resume ks podinfo","title":"Examples"},{"location":"cmd/flux_resume_kustomization/#options","text":"-h, --help help for kustomization","title":"Options"},{"location":"cmd/flux_resume_kustomization/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume_kustomization/#see-also","text":"flux resume - Resume suspended resources","title":"SEE ALSO"},{"location":"cmd/flux_resume_receiver/","text":"flux resume receiver \u00b6 Resume a suspended Receiver Synopsis \u00b6 The resume command marks a previously suspended Receiver resource for reconciliation and waits for it to finish the apply. flux resume receiver [name] [flags] Examples \u00b6 # Resume reconciliation for an existing Receiver flux resume receiver main Options \u00b6 -h, --help help for receiver Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux resume - Resume suspended resources","title":"Resume receiver"},{"location":"cmd/flux_resume_receiver/#flux-resume-receiver","text":"Resume a suspended Receiver","title":"flux resume receiver"},{"location":"cmd/flux_resume_receiver/#synopsis","text":"The resume command marks a previously suspended Receiver resource for reconciliation and waits for it to finish the apply. flux resume receiver [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_resume_receiver/#examples","text":"# Resume reconciliation for an existing Receiver flux resume receiver main","title":"Examples"},{"location":"cmd/flux_resume_receiver/#options","text":"-h, --help help for receiver","title":"Options"},{"location":"cmd/flux_resume_receiver/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume_receiver/#see-also","text":"flux resume - Resume suspended resources","title":"SEE ALSO"},{"location":"cmd/flux_resume_source/","text":"flux resume source \u00b6 Resume sources Synopsis \u00b6 The resume sub-commands resume a suspended source. Options \u00b6 -h, --help help for source Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux resume - Resume suspended resources flux resume source bucket - Resume a suspended Bucket flux resume source chart - Resume a suspended HelmChart flux resume source git - Resume a suspended GitRepository flux resume source helm - Resume a suspended HelmRepository","title":"Resume source"},{"location":"cmd/flux_resume_source/#flux-resume-source","text":"Resume sources","title":"flux resume source"},{"location":"cmd/flux_resume_source/#synopsis","text":"The resume sub-commands resume a suspended source.","title":"Synopsis"},{"location":"cmd/flux_resume_source/#options","text":"-h, --help help for source","title":"Options"},{"location":"cmd/flux_resume_source/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume_source/#see-also","text":"flux resume - Resume suspended resources flux resume source bucket - Resume a suspended Bucket flux resume source chart - Resume a suspended HelmChart flux resume source git - Resume a suspended GitRepository flux resume source helm - Resume a suspended HelmRepository","title":"SEE ALSO"},{"location":"cmd/flux_resume_source_bucket/","text":"flux resume source bucket \u00b6 Resume a suspended Bucket Synopsis \u00b6 The resume command marks a previously suspended Bucket resource for reconciliation and waits for it to finish. flux resume source bucket [name] [flags] Examples \u00b6 # Resume reconciliation for an existing Bucket flux resume source bucket podinfo Options \u00b6 -h, --help help for bucket Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux resume source - Resume sources","title":"Resume source bucket"},{"location":"cmd/flux_resume_source_bucket/#flux-resume-source-bucket","text":"Resume a suspended Bucket","title":"flux resume source bucket"},{"location":"cmd/flux_resume_source_bucket/#synopsis","text":"The resume command marks a previously suspended Bucket resource for reconciliation and waits for it to finish. flux resume source bucket [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_resume_source_bucket/#examples","text":"# Resume reconciliation for an existing Bucket flux resume source bucket podinfo","title":"Examples"},{"location":"cmd/flux_resume_source_bucket/#options","text":"-h, --help help for bucket","title":"Options"},{"location":"cmd/flux_resume_source_bucket/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume_source_bucket/#see-also","text":"flux resume source - Resume sources","title":"SEE ALSO"},{"location":"cmd/flux_resume_source_chart/","text":"flux resume source chart \u00b6 Resume a suspended HelmChart Synopsis \u00b6 The resume command marks a previously suspended HelmChart resource for reconciliation and waits for it to finish. flux resume source chart [name] [flags] Examples \u00b6 # Resume reconciliation for an existing HelmChart flux resume source chart podinfo Options \u00b6 -h, --help help for chart Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux resume source - Resume sources","title":"Resume source chart"},{"location":"cmd/flux_resume_source_chart/#flux-resume-source-chart","text":"Resume a suspended HelmChart","title":"flux resume source chart"},{"location":"cmd/flux_resume_source_chart/#synopsis","text":"The resume command marks a previously suspended HelmChart resource for reconciliation and waits for it to finish. flux resume source chart [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_resume_source_chart/#examples","text":"# Resume reconciliation for an existing HelmChart flux resume source chart podinfo","title":"Examples"},{"location":"cmd/flux_resume_source_chart/#options","text":"-h, --help help for chart","title":"Options"},{"location":"cmd/flux_resume_source_chart/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume_source_chart/#see-also","text":"flux resume source - Resume sources","title":"SEE ALSO"},{"location":"cmd/flux_resume_source_git/","text":"flux resume source git \u00b6 Resume a suspended GitRepository Synopsis \u00b6 The resume command marks a previously suspended GitRepository resource for reconciliation and waits for it to finish. flux resume source git [name] [flags] Examples \u00b6 # Resume reconciliation for an existing GitRepository flux resume source git podinfo Options \u00b6 -h, --help help for git Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux resume source - Resume sources","title":"Resume source git"},{"location":"cmd/flux_resume_source_git/#flux-resume-source-git","text":"Resume a suspended GitRepository","title":"flux resume source git"},{"location":"cmd/flux_resume_source_git/#synopsis","text":"The resume command marks a previously suspended GitRepository resource for reconciliation and waits for it to finish. flux resume source git [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_resume_source_git/#examples","text":"# Resume reconciliation for an existing GitRepository flux resume source git podinfo","title":"Examples"},{"location":"cmd/flux_resume_source_git/#options","text":"-h, --help help for git","title":"Options"},{"location":"cmd/flux_resume_source_git/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume_source_git/#see-also","text":"flux resume source - Resume sources","title":"SEE ALSO"},{"location":"cmd/flux_resume_source_helm/","text":"flux resume source helm \u00b6 Resume a suspended HelmRepository Synopsis \u00b6 The resume command marks a previously suspended HelmRepository resource for reconciliation and waits for it to finish. flux resume source helm [name] [flags] Examples \u00b6 # Resume reconciliation for an existing HelmRepository flux resume source helm bitnami Options \u00b6 -h, --help help for helm Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux resume source - Resume sources","title":"Resume source helm"},{"location":"cmd/flux_resume_source_helm/#flux-resume-source-helm","text":"Resume a suspended HelmRepository","title":"flux resume source helm"},{"location":"cmd/flux_resume_source_helm/#synopsis","text":"The resume command marks a previously suspended HelmRepository resource for reconciliation and waits for it to finish. flux resume source helm [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_resume_source_helm/#examples","text":"# Resume reconciliation for an existing HelmRepository flux resume source helm bitnami","title":"Examples"},{"location":"cmd/flux_resume_source_helm/#options","text":"-h, --help help for helm","title":"Options"},{"location":"cmd/flux_resume_source_helm/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_resume_source_helm/#see-also","text":"flux resume source - Resume sources","title":"SEE ALSO"},{"location":"cmd/flux_suspend/","text":"flux suspend \u00b6 Suspend resources Synopsis \u00b6 The suspend sub-commands suspend the reconciliation of a resource. Options \u00b6 -h, --help help for suspend Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux - Command line utility for assembling Kubernetes CD pipelines flux suspend alert - Suspend reconciliation of Alert flux suspend helmrelease - Suspend reconciliation of HelmRelease flux suspend image - Suspend image automation objects flux suspend kustomization - Suspend reconciliation of Kustomization flux suspend receiver - Suspend reconciliation of Receiver flux suspend source - Suspend sources","title":"Suspend"},{"location":"cmd/flux_suspend/#flux-suspend","text":"Suspend resources","title":"flux suspend"},{"location":"cmd/flux_suspend/#synopsis","text":"The suspend sub-commands suspend the reconciliation of a resource.","title":"Synopsis"},{"location":"cmd/flux_suspend/#options","text":"-h, --help help for suspend","title":"Options"},{"location":"cmd/flux_suspend/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend/#see-also","text":"flux - Command line utility for assembling Kubernetes CD pipelines flux suspend alert - Suspend reconciliation of Alert flux suspend helmrelease - Suspend reconciliation of HelmRelease flux suspend image - Suspend image automation objects flux suspend kustomization - Suspend reconciliation of Kustomization flux suspend receiver - Suspend reconciliation of Receiver flux suspend source - Suspend sources","title":"SEE ALSO"},{"location":"cmd/flux_suspend_alert/","text":"flux suspend alert \u00b6 Suspend reconciliation of Alert Synopsis \u00b6 The suspend command disables the reconciliation of a Alert resource. flux suspend alert [name] [flags] Examples \u00b6 # Suspend reconciliation for an existing Alert flux suspend alert main Options \u00b6 -h, --help help for alert Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux suspend - Suspend resources","title":"Suspend alert"},{"location":"cmd/flux_suspend_alert/#flux-suspend-alert","text":"Suspend reconciliation of Alert","title":"flux suspend alert"},{"location":"cmd/flux_suspend_alert/#synopsis","text":"The suspend command disables the reconciliation of a Alert resource. flux suspend alert [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_suspend_alert/#examples","text":"# Suspend reconciliation for an existing Alert flux suspend alert main","title":"Examples"},{"location":"cmd/flux_suspend_alert/#options","text":"-h, --help help for alert","title":"Options"},{"location":"cmd/flux_suspend_alert/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend_alert/#see-also","text":"flux suspend - Suspend resources","title":"SEE ALSO"},{"location":"cmd/flux_suspend_helmrelease/","text":"flux suspend helmrelease \u00b6 Suspend reconciliation of HelmRelease Synopsis \u00b6 The suspend command disables the reconciliation of a HelmRelease resource. flux suspend helmrelease [name] [flags] Examples \u00b6 # Suspend reconciliation for an existing Helm release flux suspend hr podinfo Options \u00b6 -h, --help help for helmrelease Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux suspend - Suspend resources","title":"Suspend helmrelease"},{"location":"cmd/flux_suspend_helmrelease/#flux-suspend-helmrelease","text":"Suspend reconciliation of HelmRelease","title":"flux suspend helmrelease"},{"location":"cmd/flux_suspend_helmrelease/#synopsis","text":"The suspend command disables the reconciliation of a HelmRelease resource. flux suspend helmrelease [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_suspend_helmrelease/#examples","text":"# Suspend reconciliation for an existing Helm release flux suspend hr podinfo","title":"Examples"},{"location":"cmd/flux_suspend_helmrelease/#options","text":"-h, --help help for helmrelease","title":"Options"},{"location":"cmd/flux_suspend_helmrelease/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend_helmrelease/#see-also","text":"flux suspend - Suspend resources","title":"SEE ALSO"},{"location":"cmd/flux_suspend_image/","text":"flux suspend image \u00b6 Suspend image automation objects Synopsis \u00b6 The suspend image sub-commands suspend the reconciliation of an image automation object. Options \u00b6 -h, --help help for image Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux suspend - Suspend resources flux suspend image repository - Suspend reconciliation of an ImageRepository flux suspend image update - Suspend reconciliation of an ImageUpdateAutomation","title":"Suspend image"},{"location":"cmd/flux_suspend_image/#flux-suspend-image","text":"Suspend image automation objects","title":"flux suspend image"},{"location":"cmd/flux_suspend_image/#synopsis","text":"The suspend image sub-commands suspend the reconciliation of an image automation object.","title":"Synopsis"},{"location":"cmd/flux_suspend_image/#options","text":"-h, --help help for image","title":"Options"},{"location":"cmd/flux_suspend_image/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend_image/#see-also","text":"flux suspend - Suspend resources flux suspend image repository - Suspend reconciliation of an ImageRepository flux suspend image update - Suspend reconciliation of an ImageUpdateAutomation","title":"SEE ALSO"},{"location":"cmd/flux_suspend_image_repository/","text":"flux suspend image repository \u00b6 Suspend reconciliation of an ImageRepository Synopsis \u00b6 The suspend image repository command disables the reconciliation of a ImageRepository resource. flux suspend image repository [name] [flags] Examples \u00b6 # Suspend reconciliation for an existing ImageRepository flux suspend image repository alpine Options \u00b6 -h, --help help for repository Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux suspend image - Suspend image automation objects","title":"Suspend image repository"},{"location":"cmd/flux_suspend_image_repository/#flux-suspend-image-repository","text":"Suspend reconciliation of an ImageRepository","title":"flux suspend image repository"},{"location":"cmd/flux_suspend_image_repository/#synopsis","text":"The suspend image repository command disables the reconciliation of a ImageRepository resource. flux suspend image repository [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_suspend_image_repository/#examples","text":"# Suspend reconciliation for an existing ImageRepository flux suspend image repository alpine","title":"Examples"},{"location":"cmd/flux_suspend_image_repository/#options","text":"-h, --help help for repository","title":"Options"},{"location":"cmd/flux_suspend_image_repository/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend_image_repository/#see-also","text":"flux suspend image - Suspend image automation objects","title":"SEE ALSO"},{"location":"cmd/flux_suspend_image_update/","text":"flux suspend image update \u00b6 Suspend reconciliation of an ImageUpdateAutomation Synopsis \u00b6 The suspend image update command disables the reconciliation of a ImageUpdateAutomation resource. flux suspend image update [name] [flags] Examples \u00b6 # Suspend reconciliation for an existing ImageUpdateAutomation flux suspend image update latest-images Options \u00b6 -h, --help help for update Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux suspend image - Suspend image automation objects","title":"Suspend image update"},{"location":"cmd/flux_suspend_image_update/#flux-suspend-image-update","text":"Suspend reconciliation of an ImageUpdateAutomation","title":"flux suspend image update"},{"location":"cmd/flux_suspend_image_update/#synopsis","text":"The suspend image update command disables the reconciliation of a ImageUpdateAutomation resource. flux suspend image update [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_suspend_image_update/#examples","text":"# Suspend reconciliation for an existing ImageUpdateAutomation flux suspend image update latest-images","title":"Examples"},{"location":"cmd/flux_suspend_image_update/#options","text":"-h, --help help for update","title":"Options"},{"location":"cmd/flux_suspend_image_update/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend_image_update/#see-also","text":"flux suspend image - Suspend image automation objects","title":"SEE ALSO"},{"location":"cmd/flux_suspend_kustomization/","text":"flux suspend kustomization \u00b6 Suspend reconciliation of Kustomization Synopsis \u00b6 The suspend command disables the reconciliation of a Kustomization resource. flux suspend kustomization [name] [flags] Examples \u00b6 # Suspend reconciliation for an existing Kustomization flux suspend ks podinfo Options \u00b6 -h, --help help for kustomization Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux suspend - Suspend resources","title":"Suspend kustomization"},{"location":"cmd/flux_suspend_kustomization/#flux-suspend-kustomization","text":"Suspend reconciliation of Kustomization","title":"flux suspend kustomization"},{"location":"cmd/flux_suspend_kustomization/#synopsis","text":"The suspend command disables the reconciliation of a Kustomization resource. flux suspend kustomization [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_suspend_kustomization/#examples","text":"# Suspend reconciliation for an existing Kustomization flux suspend ks podinfo","title":"Examples"},{"location":"cmd/flux_suspend_kustomization/#options","text":"-h, --help help for kustomization","title":"Options"},{"location":"cmd/flux_suspend_kustomization/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend_kustomization/#see-also","text":"flux suspend - Suspend resources","title":"SEE ALSO"},{"location":"cmd/flux_suspend_receiver/","text":"flux suspend receiver \u00b6 Suspend reconciliation of Receiver Synopsis \u00b6 The suspend command disables the reconciliation of a Receiver resource. flux suspend receiver [name] [flags] Examples \u00b6 # Suspend reconciliation for an existing Receiver flux suspend receiver main Options \u00b6 -h, --help help for receiver Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux suspend - Suspend resources","title":"Suspend receiver"},{"location":"cmd/flux_suspend_receiver/#flux-suspend-receiver","text":"Suspend reconciliation of Receiver","title":"flux suspend receiver"},{"location":"cmd/flux_suspend_receiver/#synopsis","text":"The suspend command disables the reconciliation of a Receiver resource. flux suspend receiver [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_suspend_receiver/#examples","text":"# Suspend reconciliation for an existing Receiver flux suspend receiver main","title":"Examples"},{"location":"cmd/flux_suspend_receiver/#options","text":"-h, --help help for receiver","title":"Options"},{"location":"cmd/flux_suspend_receiver/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend_receiver/#see-also","text":"flux suspend - Suspend resources","title":"SEE ALSO"},{"location":"cmd/flux_suspend_source/","text":"flux suspend source \u00b6 Suspend sources Synopsis \u00b6 The suspend sub-commands suspend the reconciliation of a source. Options \u00b6 -h, --help help for source Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux suspend - Suspend resources flux suspend source bucket - Suspend reconciliation of a Bucket flux suspend source chart - Suspend reconciliation of a HelmChart flux suspend source git - Suspend reconciliation of a GitRepository flux suspend source helm - Suspend reconciliation of a HelmRepository","title":"Suspend source"},{"location":"cmd/flux_suspend_source/#flux-suspend-source","text":"Suspend sources","title":"flux suspend source"},{"location":"cmd/flux_suspend_source/#synopsis","text":"The suspend sub-commands suspend the reconciliation of a source.","title":"Synopsis"},{"location":"cmd/flux_suspend_source/#options","text":"-h, --help help for source","title":"Options"},{"location":"cmd/flux_suspend_source/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend_source/#see-also","text":"flux suspend - Suspend resources flux suspend source bucket - Suspend reconciliation of a Bucket flux suspend source chart - Suspend reconciliation of a HelmChart flux suspend source git - Suspend reconciliation of a GitRepository flux suspend source helm - Suspend reconciliation of a HelmRepository","title":"SEE ALSO"},{"location":"cmd/flux_suspend_source_bucket/","text":"flux suspend source bucket \u00b6 Suspend reconciliation of a Bucket Synopsis \u00b6 The suspend command disables the reconciliation of a Bucket resource. flux suspend source bucket [name] [flags] Examples \u00b6 # Suspend reconciliation for an existing Bucket flux suspend source bucket podinfo Options \u00b6 -h, --help help for bucket Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux suspend source - Suspend sources","title":"Suspend source bucket"},{"location":"cmd/flux_suspend_source_bucket/#flux-suspend-source-bucket","text":"Suspend reconciliation of a Bucket","title":"flux suspend source bucket"},{"location":"cmd/flux_suspend_source_bucket/#synopsis","text":"The suspend command disables the reconciliation of a Bucket resource. flux suspend source bucket [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_suspend_source_bucket/#examples","text":"# Suspend reconciliation for an existing Bucket flux suspend source bucket podinfo","title":"Examples"},{"location":"cmd/flux_suspend_source_bucket/#options","text":"-h, --help help for bucket","title":"Options"},{"location":"cmd/flux_suspend_source_bucket/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend_source_bucket/#see-also","text":"flux suspend source - Suspend sources","title":"SEE ALSO"},{"location":"cmd/flux_suspend_source_chart/","text":"flux suspend source chart \u00b6 Suspend reconciliation of a HelmChart Synopsis \u00b6 The suspend command disables the reconciliation of a HelmChart resource. flux suspend source chart [name] [flags] Examples \u00b6 # Suspend reconciliation for an existing HelmChart flux suspend source chart podinfo Options \u00b6 -h, --help help for chart Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux suspend source - Suspend sources","title":"Suspend source chart"},{"location":"cmd/flux_suspend_source_chart/#flux-suspend-source-chart","text":"Suspend reconciliation of a HelmChart","title":"flux suspend source chart"},{"location":"cmd/flux_suspend_source_chart/#synopsis","text":"The suspend command disables the reconciliation of a HelmChart resource. flux suspend source chart [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_suspend_source_chart/#examples","text":"# Suspend reconciliation for an existing HelmChart flux suspend source chart podinfo","title":"Examples"},{"location":"cmd/flux_suspend_source_chart/#options","text":"-h, --help help for chart","title":"Options"},{"location":"cmd/flux_suspend_source_chart/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend_source_chart/#see-also","text":"flux suspend source - Suspend sources","title":"SEE ALSO"},{"location":"cmd/flux_suspend_source_git/","text":"flux suspend source git \u00b6 Suspend reconciliation of a GitRepository Synopsis \u00b6 The suspend command disables the reconciliation of a GitRepository resource. flux suspend source git [name] [flags] Examples \u00b6 # Suspend reconciliation for an existing GitRepository flux suspend source git podinfo Options \u00b6 -h, --help help for git Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux suspend source - Suspend sources","title":"Suspend source git"},{"location":"cmd/flux_suspend_source_git/#flux-suspend-source-git","text":"Suspend reconciliation of a GitRepository","title":"flux suspend source git"},{"location":"cmd/flux_suspend_source_git/#synopsis","text":"The suspend command disables the reconciliation of a GitRepository resource. flux suspend source git [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_suspend_source_git/#examples","text":"# Suspend reconciliation for an existing GitRepository flux suspend source git podinfo","title":"Examples"},{"location":"cmd/flux_suspend_source_git/#options","text":"-h, --help help for git","title":"Options"},{"location":"cmd/flux_suspend_source_git/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend_source_git/#see-also","text":"flux suspend source - Suspend sources","title":"SEE ALSO"},{"location":"cmd/flux_suspend_source_helm/","text":"flux suspend source helm \u00b6 Suspend reconciliation of a HelmRepository Synopsis \u00b6 The suspend command disables the reconciliation of a HelmRepository resource. flux suspend source helm [name] [flags] Examples \u00b6 # Suspend reconciliation for an existing HelmRepository flux suspend source helm bitnami Options \u00b6 -h, --help help for helm Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux suspend source - Suspend sources","title":"Suspend source helm"},{"location":"cmd/flux_suspend_source_helm/#flux-suspend-source-helm","text":"Suspend reconciliation of a HelmRepository","title":"flux suspend source helm"},{"location":"cmd/flux_suspend_source_helm/#synopsis","text":"The suspend command disables the reconciliation of a HelmRepository resource. flux suspend source helm [name] [flags]","title":"Synopsis"},{"location":"cmd/flux_suspend_source_helm/#examples","text":"# Suspend reconciliation for an existing HelmRepository flux suspend source helm bitnami","title":"Examples"},{"location":"cmd/flux_suspend_source_helm/#options","text":"-h, --help help for helm","title":"Options"},{"location":"cmd/flux_suspend_source_helm/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_suspend_source_helm/#see-also","text":"flux suspend source - Suspend sources","title":"SEE ALSO"},{"location":"cmd/flux_uninstall/","text":"flux uninstall \u00b6 Uninstall Flux and its custom resource definitions Synopsis \u00b6 The uninstall command removes the Flux components and the toolkit.fluxcd.io resources from the cluster. flux uninstall [flags] Examples \u00b6 # Uninstall Flux components, its custom resources and namespace flux uninstall --namespace=flux-system # Uninstall Flux but keep the namespace flux uninstall --namespace=infra --keep-namespace=true Options \u00b6 --dry-run only print the objects that would be deleted -h, --help help for uninstall --keep-namespace skip namespace deletion -s, --silent delete components without asking for confirmation Options inherited from parent commands \u00b6 --context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects SEE ALSO \u00b6 flux - Command line utility for assembling Kubernetes CD pipelines","title":"Uninstall"},{"location":"cmd/flux_uninstall/#flux-uninstall","text":"Uninstall Flux and its custom resource definitions","title":"flux uninstall"},{"location":"cmd/flux_uninstall/#synopsis","text":"The uninstall command removes the Flux components and the toolkit.fluxcd.io resources from the cluster. flux uninstall [flags]","title":"Synopsis"},{"location":"cmd/flux_uninstall/#examples","text":"# Uninstall Flux components, its custom resources and namespace flux uninstall --namespace=flux-system # Uninstall Flux but keep the namespace flux uninstall --namespace=infra --keep-namespace=true","title":"Examples"},{"location":"cmd/flux_uninstall/#options","text":"--dry-run only print the objects that would be deleted -h, --help help for uninstall --keep-namespace skip namespace deletion -s, --silent delete components without asking for confirmation","title":"Options"},{"location":"cmd/flux_uninstall/#options-inherited-from-parent-commands","text":"--context string kubernetes context to use --kubeconfig string path to the kubeconfig file (default \"~/.kube/config\") -n, --namespace string the namespace scope for this operation (default \"flux-system\") --timeout duration timeout for this operation (default 5m0s) --verbose print generated objects","title":"Options inherited from parent commands"},{"location":"cmd/flux_uninstall/#see-also","text":"flux - Command line utility for assembling Kubernetes CD pipelines","title":"SEE ALSO"},{"location":"components/","text":"GitOps Toolkit components \u00b6 The GitOps Toolkit is the set of APIs and controllers that make up the runtime for Flux v2. The APIs comprise Kubernetes custom resources, which can be created and updated by a cluster user, or by other automation tooling. You can use the toolkit to extend Flux, and to build your own systems for continuous delivery. The the source-watcher guide is a good place to start. A reference for each component and API type is linked below. Source Controller GitRepository CRD HelmRepository CRD HelmChart CRD Bucket CRD Kustomize Controller Kustomization CRD Helm Controller HelmRelease CRD Notification Controller Provider CRD Alert CRD Receiver CRD Image automation controllers ImageRepository CRD ImagePolicy CRD ImageUpdateAutomation CRD","title":"Overview"},{"location":"components/#gitops-toolkit-components","text":"The GitOps Toolkit is the set of APIs and controllers that make up the runtime for Flux v2. The APIs comprise Kubernetes custom resources, which can be created and updated by a cluster user, or by other automation tooling. You can use the toolkit to extend Flux, and to build your own systems for continuous delivery. The the source-watcher guide is a good place to start. A reference for each component and API type is linked below. Source Controller GitRepository CRD HelmRepository CRD HelmChart CRD Bucket CRD Kustomize Controller Kustomization CRD Helm Controller HelmRelease CRD Notification Controller Provider CRD Alert CRD Receiver CRD Image automation controllers ImageRepository CRD ImagePolicy CRD ImageUpdateAutomation CRD","title":"GitOps Toolkit components"},{"location":"components/helm/api/","text":"HelmRelease API reference Packages: helm.toolkit.fluxcd.io/v2beta1 helm.toolkit.fluxcd.io/v2beta1 Package v2beta1 contains API Schema definitions for the helm v2beta1 API group Resource Types: HelmRelease HelmRelease HelmRelease is the Schema for the helmreleases API Field Description apiVersion string helm.toolkit.fluxcd.io/v2beta1 kind string HelmRelease metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec HelmReleaseSpec chart HelmChartTemplate Chart defines the template of the v1beta1.HelmChart that should be created for this HelmRelease. interval Kubernetes meta/v1.Duration Interval at which to reconcile the Helm release. kubeConfig KubeConfig (Optional) KubeConfig for reconciling the HelmRelease on a remote cluster. When specified, KubeConfig takes precedence over ServiceAccountName. suspend bool (Optional) Suspend tells the controller to suspend reconciliation for this HelmRelease, it does not apply to already started reconciliations. Defaults to false. releaseName string (Optional) ReleaseName used for the Helm release. Defaults to a composition of \u2018[TargetNamespace-]Name\u2019. targetNamespace string (Optional) TargetNamespace to target when performing operations for the HelmRelease. Defaults to the namespace of the HelmRelease. storageNamespace string (Optional) StorageNamespace used for the Helm storage. Defaults to the namespace of the HelmRelease. dependsOn []Runtime dependency.CrossNamespaceDependencyReference (Optional) DependsOn may contain a dependency.CrossNamespaceDependencyReference slice with references to HelmRelease resources that must be ready before this HelmRelease can be reconciled. timeout Kubernetes meta/v1.Duration (Optional) Timeout is the time to wait for any individual Kubernetes operation (like Jobs for hooks) during the performance of a Helm action. Defaults to \u20185m0s\u2019. maxHistory int (Optional) MaxHistory is the number of revisions saved by Helm for this HelmRelease. Use \u20180\u2019 for an unlimited number of revisions; defaults to \u201810\u2019. serviceAccountName string (Optional) The name of the Kubernetes service account to impersonate when reconciling this HelmRelease. install Install (Optional) Install holds the configuration for Helm install actions for this HelmRelease. upgrade Upgrade (Optional) Upgrade holds the configuration for Helm upgrade actions for this HelmRelease. test Test (Optional) Test holds the configuration for Helm test actions for this HelmRelease. rollback Rollback (Optional) Rollback holds the configuration for Helm rollback actions for this HelmRelease. uninstall Uninstall (Optional) Uninstall holds the configuration for Helm uninstall actions for this HelmRelease. valuesFrom []ValuesReference ValuesFrom holds references to resources containing Helm values for this HelmRelease, and information about how they should be merged. values Kubernetes pkg/apis/apiextensions/v1.JSON (Optional) Values holds the values for this Helm release. postRenderers []PostRenderer (Optional) PostRenderers holds an array of Helm PostRenderers, which will be applied in order of their definition. status HelmReleaseStatus CrossNamespaceObjectReference ( Appears on: HelmChartTemplateSpec ) CrossNamespaceObjectReference contains enough information to let you locate the typed referenced object at cluster level. Field Description apiVersion string (Optional) APIVersion of the referent. kind string Kind of the referent. name string Name of the referent. namespace string (Optional) Namespace of the referent. DeploymentAction DeploymentAction defines a consistent interface for Install and Upgrade. HelmChartTemplate ( Appears on: HelmReleaseSpec ) HelmChartTemplate defines the template from which the controller will generate a v1beta1.HelmChart object in the same namespace as the referenced v1beta1.Source. Field Description spec HelmChartTemplateSpec Spec holds the template for the v1beta1.HelmChartSpec for this HelmRelease. chart string The name or path the Helm chart is available at in the SourceRef. version string (Optional) Version semver expression, ignored for charts from v1beta1.GitRepository and v1beta1.Bucket sources. Defaults to latest when omitted. sourceRef CrossNamespaceObjectReference The name and namespace of the v1beta1.Source the chart is available at. interval Kubernetes meta/v1.Duration (Optional) Interval at which to check the v1beta1.Source for updates. Defaults to \u2018HelmReleaseSpec.Interval\u2019. valuesFile string (Optional) Alternative values file to use as the default chart values, expected to be a relative path in the SourceRef. Ignored when omitted. HelmChartTemplateSpec ( Appears on: HelmChartTemplate ) HelmChartTemplateSpec defines the template from which the controller will generate a v1beta1.HelmChartSpec object. Field Description chart string The name or path the Helm chart is available at in the SourceRef. version string (Optional) Version semver expression, ignored for charts from v1beta1.GitRepository and v1beta1.Bucket sources. Defaults to latest when omitted. sourceRef CrossNamespaceObjectReference The name and namespace of the v1beta1.Source the chart is available at. interval Kubernetes meta/v1.Duration (Optional) Interval at which to check the v1beta1.Source for updates. Defaults to \u2018HelmReleaseSpec.Interval\u2019. valuesFile string (Optional) Alternative values file to use as the default chart values, expected to be a relative path in the SourceRef. Ignored when omitted. HelmReleaseSpec ( Appears on: HelmRelease ) HelmReleaseSpec defines the desired state of a Helm release. Field Description chart HelmChartTemplate Chart defines the template of the v1beta1.HelmChart that should be created for this HelmRelease. interval Kubernetes meta/v1.Duration Interval at which to reconcile the Helm release. kubeConfig KubeConfig (Optional) KubeConfig for reconciling the HelmRelease on a remote cluster. When specified, KubeConfig takes precedence over ServiceAccountName. suspend bool (Optional) Suspend tells the controller to suspend reconciliation for this HelmRelease, it does not apply to already started reconciliations. Defaults to false. releaseName string (Optional) ReleaseName used for the Helm release. Defaults to a composition of \u2018[TargetNamespace-]Name\u2019. targetNamespace string (Optional) TargetNamespace to target when performing operations for the HelmRelease. Defaults to the namespace of the HelmRelease. storageNamespace string (Optional) StorageNamespace used for the Helm storage. Defaults to the namespace of the HelmRelease. dependsOn []Runtime dependency.CrossNamespaceDependencyReference (Optional) DependsOn may contain a dependency.CrossNamespaceDependencyReference slice with references to HelmRelease resources that must be ready before this HelmRelease can be reconciled. timeout Kubernetes meta/v1.Duration (Optional) Timeout is the time to wait for any individual Kubernetes operation (like Jobs for hooks) during the performance of a Helm action. Defaults to \u20185m0s\u2019. maxHistory int (Optional) MaxHistory is the number of revisions saved by Helm for this HelmRelease. Use \u20180\u2019 for an unlimited number of revisions; defaults to \u201810\u2019. serviceAccountName string (Optional) The name of the Kubernetes service account to impersonate when reconciling this HelmRelease. install Install (Optional) Install holds the configuration for Helm install actions for this HelmRelease. upgrade Upgrade (Optional) Upgrade holds the configuration for Helm upgrade actions for this HelmRelease. test Test (Optional) Test holds the configuration for Helm test actions for this HelmRelease. rollback Rollback (Optional) Rollback holds the configuration for Helm rollback actions for this HelmRelease. uninstall Uninstall (Optional) Uninstall holds the configuration for Helm uninstall actions for this HelmRelease. valuesFrom []ValuesReference ValuesFrom holds references to resources containing Helm values for this HelmRelease, and information about how they should be merged. values Kubernetes pkg/apis/apiextensions/v1.JSON (Optional) Values holds the values for this Helm release. postRenderers []PostRenderer (Optional) PostRenderers holds an array of Helm PostRenderers, which will be applied in order of their definition. HelmReleaseStatus ( Appears on: HelmRelease ) HelmReleaseStatus defines the observed state of a HelmRelease. Field Description observedGeneration int64 (Optional) ObservedGeneration is the last observed generation. ReconcileRequestStatus github.com/fluxcd/pkg/apis/meta.ReconcileRequestStatus (Members of ReconcileRequestStatus are embedded into this type.) conditions []Kubernetes meta/v1.Condition (Optional) Conditions holds the conditions for the HelmRelease. lastAppliedRevision string (Optional) LastAppliedRevision is the revision of the last successfully applied source. lastAttemptedRevision string (Optional) LastAttemptedRevision is the revision of the last reconciliation attempt. lastAttemptedValuesChecksum string (Optional) LastAttemptedValuesChecksum is the SHA1 checksum of the values of the last reconciliation attempt. lastReleaseRevision int (Optional) LastReleaseRevision is the revision of the last successful Helm release. helmChart string (Optional) HelmChart is the namespaced name of the HelmChart resource created by the controller for the HelmRelease. failures int64 (Optional) Failures is the reconciliation failure count against the latest desired state. It is reset after a successful reconciliation. installFailures int64 (Optional) InstallFailures is the install failure count against the latest desired state. It is reset after a successful reconciliation. upgradeFailures int64 (Optional) UpgradeFailures is the upgrade failure count against the latest desired state. It is reset after a successful reconciliation. Install ( Appears on: HelmReleaseSpec ) Install holds the configuration for Helm install actions performed for this HelmRelease. Field Description timeout Kubernetes meta/v1.Duration (Optional) Timeout is the time to wait for any individual Kubernetes operation (like Jobs for hooks) during the performance of a Helm install action. Defaults to \u2018HelmReleaseSpec.Timeout\u2019. remediation InstallRemediation (Optional) Remediation holds the remediation configuration for when the Helm install action for the HelmRelease fails. The default is to not perform any action. disableWait bool (Optional) DisableWait disables the waiting for resources to be ready after a Helm install has been performed. disableHooks bool (Optional) DisableHooks prevents hooks from running during the Helm install action. disableOpenAPIValidation bool (Optional) DisableOpenAPIValidation prevents the Helm install action from validating rendered templates against the Kubernetes OpenAPI Schema. replace bool (Optional) Replace tells the Helm install action to re-use the \u2018ReleaseName\u2019, but only if that name is a deleted release which remains in the history. skipCRDs bool (Optional) SkipCRDs tells the Helm install action to not install any CRDs. By default, CRDs are installed if not already present. createNamespace bool (Optional) CreateNamespace tells the Helm install action to create the HelmReleaseSpec.TargetNamespace if it does not exist yet. On uninstall, the namespace will not be garbage collected. InstallRemediation ( Appears on: Install ) InstallRemediation holds the configuration for Helm install remediation. Field Description retries int (Optional) Retries is the number of retries that should be attempted on failures before bailing. Remediation, using an uninstall, is performed between each attempt. Defaults to \u20180\u2019, a negative integer equals to unlimited retries. ignoreTestFailures bool (Optional) IgnoreTestFailures tells the controller to skip remediation when the Helm tests are run after an install action but fail. Defaults to \u2018Test.IgnoreFailures\u2019. remediateLastFailure bool (Optional) RemediateLastFailure tells the controller to remediate the last failure, when no retries remain. Defaults to \u2018false\u2019. KubeConfig ( Appears on: HelmReleaseSpec ) KubeConfig references a Kubernetes secret that contains a kubeconfig file. Field Description secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference SecretRef holds the name to a secret that contains a \u2018value\u2019 key with the kubeconfig file as the value. It must be in the same namespace as the HelmRelease. It is recommended that the kubeconfig is self-contained, and the secret is regularly updated if credentials such as a cloud-access-token expire. Cloud specific cmd-path auth helpers will not function without adding binaries and credentials to the Pod that is responsible for reconciling the HelmRelease. Kustomize ( Appears on: PostRenderer ) Kustomize Helm PostRenderer specification. Field Description patchesStrategicMerge []Kubernetes pkg/apis/apiextensions/v1.JSON (Optional) Strategic merge patches, defined as inline YAML objects. patchesJson6902 []github.com/fluxcd/pkg/apis/kustomize.JSON6902Patch (Optional) JSON 6902 patches, defined as inline YAML objects. images []github.com/fluxcd/pkg/apis/kustomize.Image (Optional) Images is a list of (image name, new name, new tag or digest) for changing image names, tags or digests. This can also be achieved with a patch, but this operator is simpler to specify. PostRenderer ( Appears on: HelmReleaseSpec ) PostRenderer contains a Helm PostRenderer specification. Field Description kustomize Kustomize (Optional) Kustomization to apply as PostRenderer. Remediation Remediation defines a consistent interface for InstallRemediation and UpgradeRemediation. RemediationStrategy ( string alias) ( Appears on: UpgradeRemediation ) RemediationStrategy returns the strategy to use to remediate a failed install or upgrade. Rollback ( Appears on: HelmReleaseSpec ) Rollback holds the configuration for Helm rollback actions for this HelmRelease. Field Description timeout Kubernetes meta/v1.Duration (Optional) Timeout is the time to wait for any individual Kubernetes operation (like Jobs for hooks) during the performance of a Helm rollback action. Defaults to \u2018HelmReleaseSpec.Timeout\u2019. disableWait bool (Optional) DisableWait disables the waiting for resources to be ready after a Helm rollback has been performed. disableHooks bool (Optional) DisableHooks prevents hooks from running during the Helm rollback action. recreate bool (Optional) Recreate performs pod restarts for the resource if applicable. force bool (Optional) Force forces resource updates through a replacement strategy. cleanupOnFail bool (Optional) CleanupOnFail allows deletion of new resources created during the Helm rollback action when it fails. Test ( Appears on: HelmReleaseSpec ) Test holds the configuration for Helm test actions for this HelmRelease. Field Description enable bool (Optional) Enable enables Helm test actions for this HelmRelease after an Helm install or upgrade action has been performed. timeout Kubernetes meta/v1.Duration (Optional) Timeout is the time to wait for any individual Kubernetes operation during the performance of a Helm test action. Defaults to \u2018HelmReleaseSpec.Timeout\u2019. ignoreFailures bool (Optional) IgnoreFailures tells the controller to skip remediation when the Helm tests are run but fail. Can be overwritten for tests run after install or upgrade actions in \u2018Install.IgnoreTestFailures\u2019 and \u2018Upgrade.IgnoreTestFailures\u2019. Uninstall ( Appears on: HelmReleaseSpec ) Uninstall holds the configuration for Helm uninstall actions for this HelmRelease. Field Description timeout Kubernetes meta/v1.Duration (Optional) Timeout is the time to wait for any individual Kubernetes operation (like Jobs for hooks) during the performance of a Helm uninstall action. Defaults to \u2018HelmReleaseSpec.Timeout\u2019. disableHooks bool (Optional) DisableHooks prevents hooks from running during the Helm rollback action. keepHistory bool (Optional) KeepHistory tells Helm to remove all associated resources and mark the release as deleted, but retain the release history. Upgrade ( Appears on: HelmReleaseSpec ) Upgrade holds the configuration for Helm upgrade actions for this HelmRelease. Field Description timeout Kubernetes meta/v1.Duration (Optional) Timeout is the time to wait for any individual Kubernetes operation (like Jobs for hooks) during the performance of a Helm upgrade action. Defaults to \u2018HelmReleaseSpec.Timeout\u2019. remediation UpgradeRemediation (Optional) Remediation holds the remediation configuration for when the Helm upgrade action for the HelmRelease fails. The default is to not perform any action. disableWait bool (Optional) DisableWait disables the waiting for resources to be ready after a Helm upgrade has been performed. disableHooks bool (Optional) DisableHooks prevents hooks from running during the Helm upgrade action. disableOpenAPIValidation bool (Optional) DisableOpenAPIValidation prevents the Helm upgrade action from validating rendered templates against the Kubernetes OpenAPI Schema. force bool (Optional) Force forces resource updates through a replacement strategy. preserveValues bool (Optional) PreserveValues will make Helm reuse the last release\u2019s values and merge in overrides from \u2018Values\u2019. Setting this flag makes the HelmRelease non-declarative. cleanupOnFail bool (Optional) CleanupOnFail allows deletion of new resources created during the Helm upgrade action when it fails. UpgradeRemediation ( Appears on: Upgrade ) UpgradeRemediation holds the configuration for Helm upgrade remediation. Field Description retries int (Optional) Retries is the number of retries that should be attempted on failures before bailing. Remediation, using \u2018Strategy\u2019, is performed between each attempt. Defaults to \u20180\u2019, a negative integer equals to unlimited retries. ignoreTestFailures bool (Optional) IgnoreTestFailures tells the controller to skip remediation when the Helm tests are run after an upgrade action but fail. Defaults to \u2018Test.IgnoreFailures\u2019. remediateLastFailure bool (Optional) RemediateLastFailure tells the controller to remediate the last failure, when no retries remain. Defaults to \u2018false\u2019 unless \u2018Retries\u2019 is greater than 0. strategy RemediationStrategy (Optional) Strategy to use for failure remediation. Defaults to \u2018rollback\u2019. ValuesReference ( Appears on: HelmReleaseSpec ) ValuesReference contains a reference to a resource containing Helm values, and optionally the key they can be found at. Field Description kind string Kind of the values referent, valid values are (\u2018Secret\u2019, \u2018ConfigMap\u2019). name string Name of the values referent. Should reside in the same namespace as the referring resource. valuesKey string (Optional) ValuesKey is the data key where the values.yaml or a specific value can be found at. Defaults to \u2018values.yaml\u2019. targetPath string (Optional) TargetPath is the YAML dot notation path the value should be merged at. When set, the ValuesKey is expected to be a single flat value. Defaults to \u2018None\u2019, which results in the values getting merged at the root. optional bool (Optional) Optional marks this ValuesReference as optional. When set, a not found error for the values reference is ignored, but any ValuesKey, TargetPath or transient error will still result in a reconciliation failure. This page was automatically generated with gen-crd-api-reference-docs","title":"Helm API Reference"},{"location":"components/helm/controller/","text":"Helm Controller \u00b6 The Helm Controller is a Kubernetes operator, allowing one to declaratively manage Helm chart releases with Kubernetes manifests. The desired state of a Helm release is described through a Kubernetes Custom Resource named HelmRelease . Based on the creation, mutation or removal of a HelmRelease resource in the cluster, Helm actions are performed by the controller. Features: Watches for HelmRelease objects and generates HelmChart objects Supports HelmChart artifacts produced from HelmRepository and GitRepository sources Fetches artifacts produced by source-controller from HelmChart objects Watches HelmChart objects for revision changes (including semver ranges for charts from HelmRepository sources) Performs automated Helm actions, including Helm tests, rollbacks and uninstalls Offers extensive configuration options for automated remediation (rollback, uninstall, retry) on failed Helm install, upgrade or test actions Runs Helm install/upgrade in a specific order, taking into account the depends-on relationship defined in a set of HelmRelease objects Prunes Helm releases removed from cluster (garbage collection) Reports Helm releases statuses (alerting provided by notification-controller ) Built-in Kustomize compatible Helm post renderer, providing support for strategic merge, JSON 6902 and images patches Links: Source code fluxcd/helm-controller Specification docs","title":"Overview"},{"location":"components/helm/controller/#helm-controller","text":"The Helm Controller is a Kubernetes operator, allowing one to declaratively manage Helm chart releases with Kubernetes manifests. The desired state of a Helm release is described through a Kubernetes Custom Resource named HelmRelease . Based on the creation, mutation or removal of a HelmRelease resource in the cluster, Helm actions are performed by the controller. Features: Watches for HelmRelease objects and generates HelmChart objects Supports HelmChart artifacts produced from HelmRepository and GitRepository sources Fetches artifacts produced by source-controller from HelmChart objects Watches HelmChart objects for revision changes (including semver ranges for charts from HelmRepository sources) Performs automated Helm actions, including Helm tests, rollbacks and uninstalls Offers extensive configuration options for automated remediation (rollback, uninstall, retry) on failed Helm install, upgrade or test actions Runs Helm install/upgrade in a specific order, taking into account the depends-on relationship defined in a set of HelmRelease objects Prunes Helm releases removed from cluster (garbage collection) Reports Helm releases statuses (alerting provided by notification-controller ) Built-in Kustomize compatible Helm post renderer, providing support for strategic merge, JSON 6902 and images patches Links: Source code fluxcd/helm-controller Specification docs","title":"Helm Controller"},{"location":"components/helm/helmreleases/","text":"Helm Releases \u00b6 The HelmRelease API defines a resource for automated controller driven Helm releases. Specification \u00b6 A HelmRelease object defines a resource for controller driven reconciliation of Helm releases via Helm actions such as install, upgrade, test, uninstall, and rollback. This includes release placement (namespace/name), release content (chart/values overrides), action trigger configuration, individual action configuration, and statusing. // HelmReleaseSpec defines the desired state of a Helm Release. type HelmReleaseSpec struct { // Chart defines the template of the v1beta1.HelmChart that should be created // for this HelmRelease. // +required Chart HelmChartTemplate `json:\"chart\"` // Interval at which to reconcile the Helm release. // +required Interval metav1 . Duration `json:\"interval\"` // Suspend tells the controller to suspend reconciliation for this HelmRelease, // it does not apply to already started reconciliations. Defaults to false. // +optional Suspend bool `json:\"suspend,omitempty\"` // ReleaseName used for the Helm release. Defaults to a composition of // '[TargetNamespace-]Name'. // +kubebuilder:validation:MinLength=1 // +kubebuilder:validation:MaxLength=53 // +kubebuilder:validation:Optional // +optional ReleaseName string `json:\"releaseName,omitempty\"` // TargetNamespace to target when performing operations for the HelmRelease. // Defaults to the namespace of the HelmRelease. // +kubebuilder:validation:MinLength=1 // +kubebuilder:validation:MaxLength=63 // +kubebuilder:validation:Optional // +optional TargetNamespace string `json:\"targetNamespace,omitempty\"` // StorageNamespace used for the Helm storage. // Defaults to the namespace of the HelmRelease. // +kubebuilder:validation:MinLength=1 // +kubebuilder:validation:MaxLength=63 // +kubebuilder:validation:Optional // +optional StorageNamespace string `json:\"storageNamespace,omitempty\"` // DependsOn may contain a dependency.CrossNamespaceDependencyReference slice with // references to HelmRelease resources that must be ready before this HelmRelease // can be reconciled. // +optional DependsOn [] dependency . CrossNamespaceDependencyReference `json:\"dependsOn,omitempty\"` // Timeout is the time to wait for any individual Kubernetes operation (like Jobs // for hooks) during the performance of a Helm action. Defaults to '5m0s'. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // MaxHistory is the number of revisions saved by Helm for this HelmRelease. // Use '0' for an unlimited number of revisions; defaults to '10'. // +optional MaxHistory * int `json:\"maxHistory,omitempty\"` // Install holds the configuration for Helm install actions for this HelmRelease. // +optional Install * Install `json:\"install,omitempty\"` // Upgrade holds the configuration for Helm upgrade actions for this HelmRelease. // +optional Upgrade * Upgrade `json:\"upgrade,omitempty\"` // Test holds the configuration for Helm test actions for this HelmRelease. // +optional Test * Test `json:\"test,omitempty\"` // Rollback holds the configuration for Helm rollback actions for this HelmRelease. // +optional Rollback * Rollback `json:\"rollback,omitempty\"` // Uninstall holds the configuration for Helm uninstall actions for this HelmRelease. // +optional Uninstall * Uninstall `json:\"uninstall,omitempty\"` // ValuesFrom holds references to resources containing Helm values for this HelmRelease, // and information about how they should be merged. ValuesFrom [] ValuesReference `json:\"valuesFrom,omitempty\"` // Values holds the values for this Helm release. // +optional Values * apiextensionsv1 . JSON `json:\"values,omitempty\"` // KubeConfig for reconciling the HelmRelease on a remote cluster. // When specified, KubeConfig takes precedence over ServiceAccountName. // +optional KubeConfig * KubeConfig `json:\"kubeConfig,omitempty\"` // The name of the Kubernetes service account to impersonate // when reconciling this HelmRelease. // +optional ServiceAccountName string `json:\"serviceAccountName,omitempty\"` // PostRenderers holds an array of Helm PostRenderers, which will be applied in order // of their definition. // +optional PostRenderers [] PostRenderer `json:\"postRenderers,omitempty\"` } // KubeConfig references a Kubernetes secret that contains a kubeconfig file. type KubeConfig struct { // SecretRef holds the name to a secret that contains a 'value' key with // the kubeconfig file as the value. It must be in the same namespace as // the HelmRelease. // It is recommended that the kubeconfig is self-contained, and the secret // is regularly updated if credentials such as a cloud-access-token expire. // Cloud specific `cmd-path` auth helpers will not function without adding // binaries and credentials to the Pod that is responsible for reconciling // the HelmRelease. // +required SecretRef corev1 . LocalObjectReference `json:\"secretRef,omitempty\"` } // HelmChartTemplate defines the template from which the controller will // generate a v1beta1.HelmChart object in the same namespace as the referenced // v1beta1.Source. type HelmChartTemplate struct { // Spec holds the template for the v1beta1.HelmChartSpec for this HelmRelease. // +required Spec HelmChartTemplateSpec `json:\"spec\"` } // HelmChartTemplateSpec defines the template from which the controller will // generate a v1beta1.HelmChartSpec object. type HelmChartTemplateSpec struct { // The name or path the Helm chart is available at in the SourceRef. // +required Chart string `json:\"chart\"` // Version semver expression, ignored for charts from v1beta1.GitRepository and // v1beta1.Bucket sources. Defaults to latest when omitted. // +kubebuilder:default:=* // +optional Version string `json:\"version,omitempty\"` // The name and namespace of the v1beta1.Source the chart is available at. // +required SourceRef CrossNamespaceObjectReference `json:\"sourceRef\"` // Interval at which to check the v1beta1.Source for updates. Defaults to // 'HelmReleaseSpec.Interval'. // +optional Interval * metav1 . Duration `json:\"interval,omitempty\"` // Alternative values file to use as the default chart values, expected to be a // relative path in the SourceRef. Ignored when omitted. // +optional ValuesFile string `json:\"valuesFile,omitempty\"` } // Install holds the configuration for Helm install actions performed for this // HelmRelease. type Install struct { // Timeout is the time to wait for any individual Kubernetes operation (like // Jobs for hooks) during the performance of a Helm install action. Defaults to // 'HelmReleaseSpec.Timeout'. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // Remediation holds the remediation configuration for when the Helm install // action for the HelmRelease fails. The default is to not perform any action. // +optional Remediation * InstallRemediation `json:\"remediation,omitempty\"` // DisableWait disables the waiting for resources to be ready after a Helm // install has been performed. // +optional DisableWait bool `json:\"disableWait,omitempty\"` // DisableHooks prevents hooks from running during the Helm install action. // +optional DisableHooks bool `json:\"disableHooks,omitempty\"` // DisableOpenAPIValidation prevents the Helm install action from validating // rendered templates against the Kubernetes OpenAPI Schema. // +optional DisableOpenAPIValidation bool `json:\"disableOpenAPIValidation,omitempty\"` // Replace tells the Helm install action to re-use the 'ReleaseName', but only // if that name is a deleted release which remains in the history. // +optional Replace bool `json:\"replace,omitempty\"` // SkipCRDs tells the Helm install action to not install any CRDs. By default, // CRDs are installed if not already present. // +optional SkipCRDs bool `json:\"skipCRDs,omitempty\"` // CreateNamespace tells the Helm install action to create the // HelmReleaseSpec.TargetNamespace if it does not exist yet. // On uninstall, the namespace will not be garbage collected. // +optional CreateNamespace bool `json:\"createNamespace,omitempty\"` } // InstallRemediation holds the configuration for Helm install remediation. type InstallRemediation struct { // Retries is the number of retries that should be attempted on failures before // bailing. Remediation, using an uninstall, is performed between each attempt. // Defaults to '0', a negative integer equals to unlimited retries. // +optional Retries int `json:\"retries,omitempty\"` // IgnoreTestFailures tells the controller to skip remediation when the Helm // tests are run after an install action but fail. Defaults to // 'Test.IgnoreFailures'. // +optional IgnoreTestFailures * bool `json:\"ignoreTestFailures,omitempty\"` // RemediateLastFailure tells the controller to remediate the last failure, when // no retries remain. Defaults to 'false'. // +optional RemediateLastFailure * bool `json:\"remediateLastFailure,omitempty\"` } // Upgrade holds the configuration for Helm upgrade actions for this // HelmRelease. type Upgrade struct { // Timeout is the time to wait for any individual Kubernetes operation (like // Jobs for hooks) during the performance of a Helm upgrade action. Defaults to // 'HelmReleaseSpec.Timeout'. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // Remediation holds the remediation configuration for when the Helm upgrade // action for the HelmRelease fails. The default is to not perform any action. // +optional Remediation * UpgradeRemediation `json:\"remediation,omitempty\"` // DisableWait disables the waiting for resources to be ready after a Helm // upgrade has been performed. // +optional DisableWait bool `json:\"disableWait,omitempty\"` // DisableHooks prevents hooks from running during the Helm upgrade action. // +optional DisableHooks bool `json:\"disableHooks,omitempty\"` // DisableOpenAPIValidation prevents the Helm upgrade action from validating // rendered templates against the Kubernetes OpenAPI Schema. // +optional DisableOpenAPIValidation bool `json:\"disableOpenAPIValidation,omitempty\"` // Force forces resource updates through a replacement strategy. // +optional Force bool `json:\"force,omitempty\"` // PreserveValues will make Helm reuse the last release's values and merge in // overrides from 'Values'. Setting this flag makes the HelmRelease // non-declarative. // +optional PreserveValues bool `json:\"preserveValues,omitempty\"` // CleanupOnFail allows deletion of new resources created during the Helm // upgrade action when it fails. // +optional CleanupOnFail bool `json:\"cleanupOnFail,omitempty\"` } // UpgradeRemediation holds the configuration for Helm upgrade remediation. type UpgradeRemediation struct { // Retries is the number of retries that should be attempted on failures before // bailing. Remediation, using 'Strategy', is performed between each attempt. // Defaults to '0', a negative integer equals to unlimited retries. // +optional Retries int `json:\"retries,omitempty\"` // IgnoreTestFailures tells the controller to skip remediation when the Helm // tests are run after an upgrade action but fail. // Defaults to 'Test.IgnoreFailures'. // +optional IgnoreTestFailures * bool `json:\"ignoreTestFailures,omitempty\"` // RemediateLastFailure tells the controller to remediate the last failure, when // no retries remain. Defaults to 'false' unless 'Retries' is greater than 0. // +optional RemediateLastFailure * bool `json:\"remediateLastFailure,omitempty\"` // Strategy to use for failure remediation. Defaults to 'rollback'. // +kubebuilder:validation:Enum=rollback;uninstall // +optional Strategy * RemediationStrategy `json:\"strategy,omitempty\"` } // Test holds the configuration for Helm test actions for this HelmRelease. type Test struct { // Enable enables Helm test actions for this HelmRelease after an Helm install // or upgrade action has been performed. // +optional Enable bool `json:\"enable,omitempty\"` // Timeout is the time to wait for any individual Kubernetes operation during // the performance of a Helm test action. Defaults to 'HelmReleaseSpec.Timeout'. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // IgnoreFailures tells the controller to skip remediation when the Helm tests // are run but fail. Can be overwritten for tests run after install or upgrade // actions in 'Install.IgnoreTestFailures' and 'Upgrade.IgnoreTestFailures'. // +optional IgnoreFailures bool `json:\"ignoreFailures,omitempty\"` } // Rollback holds the configuration for Helm rollback actions for this // HelmRelease. type Rollback struct { // Timeout is the time to wait for any individual Kubernetes operation (like // Jobs for hooks) during the performance of a Helm rollback action. Defaults to // 'HelmReleaseSpec.Timeout'. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // DisableWait disables the waiting for resources to be ready after a Helm // rollback has been performed. // +optional DisableWait bool `json:\"disableWait,omitempty\"` // DisableHooks prevents hooks from running during the Helm rollback action. // +optional DisableHooks bool `json:\"disableHooks,omitempty\"` // Recreate performs pod restarts for the resource if applicable. // +optional Recreate bool `json:\"recreate,omitempty\"` // Force forces resource updates through a replacement strategy. // +optional Force bool `json:\"force,omitempty\"` // CleanupOnFail allows deletion of new resources created during the Helm // rollback action when it fails. // +optional CleanupOnFail bool `json:\"cleanupOnFail,omitempty\"` } // Uninstall holds the configuration for Helm uninstall actions for this // HelmRelease. type Uninstall struct { // Timeout is the time to wait for any individual Kubernetes operation (like // Jobs for hooks) during the performance of a Helm uninstall action. Defaults // to 'HelmReleaseSpec.Timeout'. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // DisableHooks prevents hooks from running during the Helm rollback action. // +optional DisableHooks bool `json:\"disableHooks,omitempty\"` // KeepHistory tells Helm to remove all associated resources and mark the // release as deleted, but retain the release history. // +optional KeepHistory bool `json:\"keepHistory,omitempty\"` } // Kustomize Helm PostRenderer specification. type Kustomize struct { // Strategic merge patches, defined as inline YAML objects. // +optional PatchesStrategicMerge [] apiextensionsv1 . JSON `json:\"patchesStrategicMerge,omitempty\"` // JSON 6902 patches, defined as inline YAML objects. // +optional PatchesJSON6902 [] kustomize . JSON6902Patch `json:\"patchesJson6902,omitempty\"` // Images is a list of (image name, new name, new tag or digest) // for changing image names, tags or digests. This can also be achieved with a // patch, but this operator is simpler to specify. // +optional Images [] kustomize . Image `json:\"images,omitempty\" yaml:\"images,omitempty\"` } // PostRenderer contains a Helm PostRenderer specification. type PostRenderer struct { // Kustomization to apply as PostRenderer. // +optional Kustomize * Kustomize `json:\"kustomize,omitempty\"` } Reference types \u00b6 // CrossNamespaceObjectReference contains enough information to let you locate the // typed referenced object at cluster level. type CrossNamespaceObjectReference struct { // APIVersion of the referent. // +optional APIVersion string `json:\"apiVersion,omitempty\"` // Kind of the referent. // +kubebuilder:validation:Enum=HelmRepository // +required Kind string `json:\"kind,omitempty\"` // Name of the referent. // +kubebuilder:validation:MinLength=1 // +kubebuilder:validation:MaxLength=253 // +required Name string `json:\"name\"` // Namespace of the referent. // +kubebuilder:validation:MinLength=1 // +kubebuilder:validation:MaxLength=63 // +kubebuilder:validation:Optional // +optional Namespace string `json:\"namespace,omitempty\"` } // ValuesReference contains a reference to a resource containing Helm values, // and optionally the key they can be found at. type ValuesReference struct { // Kind of the values referent, valid values are ('Secret', 'ConfigMap'). // +kubebuilder:validation:Enum=Secret;ConfigMap // +required Kind string `json:\"kind\"` // Name of the values referent. Should reside in the same namespace as the // referring resource. // +kubebuilder:validation:MinLength=1 // +kubebuilder:validation:MaxLength=253 // +required Name string `json:\"name\"` // ValuesKey is the data key where the values.yaml or a specific value can be // found at. Defaults to 'values.yaml'. // +optional ValuesKey string `json:\"valuesKey,omitempty\"` // TargetPath is the YAML dot notation path the value should be merged at. When // set, the ValuesKey is expected to be a single flat value. Defaults to 'None', // which results in the values getting merged at the root. // +optional TargetPath string `json:\"targetPath,omitempty\"` // Optional marks this ValuesReference as optional. When set, a not found error // for the values reference is ignored, but any ValuesKey, TargetPath or // transient error will still result in a reconciliation failure. // +optional Optional bool `json:\"optional,omitempty\"` } Status specification \u00b6 // HelmReleaseStatus defines the observed state of a HelmRelease. type HelmReleaseStatus struct { // ObservedGeneration is the last observed generation. // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // LastHandledReconcileAt is the last manual reconciliation request (by // annotating the HelmRelease) handled by the reconciler. // +optional LastHandledReconcileAt string `json:\"lastHandledReconcileAt,omitempty\"` // Conditions holds the conditions for the HelmRelease. // +optional Conditions [] meta . Condition `json:\"conditions,omitempty\"` // LastAppliedRevision is the revision of the last successfully applied source. // +optional LastAppliedRevision string `json:\"lastAppliedRevision,omitempty\"` // LastAttemptedRevision is the revision of the last reconciliation attempt. // +optional LastAttemptedRevision string `json:\"lastAttemptedRevision,omitempty\"` // LastAttemptedValuesChecksum is the SHA1 checksum of the values of the last // reconciliation attempt. // +optional LastAttemptedValuesChecksum string `json:\"lastAttemptedValuesChecksum,omitempty\"` // LastReleaseRevision is the revision of the last successful Helm release. // +optional LastReleaseRevision int `json:\"lastReleaseRevision,omitempty\"` // HelmChart is the namespaced name of the HelmChart resource created by // the controller for the HelmRelease. // +optional HelmChart string `json:\"helmChart,omitempty\"` // Failures is the reconciliation failure count against the latest observed // state. It is reset after a successful reconciliation. // +optional Failures int64 `json:\"failures,omitempty\"` // InstallFailures is the install failure count against the latest observed // state. It is reset after a successful reconciliation. // +optional InstallFailures int64 `json:\"installFailures,omitempty\"` // UpgradeFailures is the upgrade failure count against the latest observed // state. It is reset after a successful reconciliation. // +optional UpgradeFailures int64 `json:\"upgradeFailures,omitempty\"` } Condition types \u00b6 const ( // ReleasedCondition represents the status of the last release attempt // (install/upgrade/test) against the latest desired state. ReleasedCondition string = \"Released\" // TestSuccessCondition represents the status of the last test attempt against // the latest desired state. TestSuccessCondition string = \"TestSuccess\" // RemediatedCondition represents the status of the last remediation attempt // (uninstall/rollback) due to a failure of the last release attempt against the // latest desired state. RemediatedCondition string = \"Remediated\" ) Condition reasons \u00b6 const ( // InstallSucceededReason represents the fact that the Helm install for the // HelmRelease succeeded. InstallSucceededReason string = \"InstallSucceeded\" // InstallFailedReason represents the fact that the Helm install for the // HelmRelease failed. InstallFailedReason string = \"InstallFailed\" // UpgradeSucceededReason represents the fact that the Helm upgrade for the // HelmRelease succeeded. UpgradeSucceededReason string = \"UpgradeSucceeded\" // UpgradeFailedReason represents the fact that the Helm upgrade for the // HelmRelease failed. UpgradeFailedReason string = \"UpgradeFailed\" // TestSucceededReason represents the fact that the Helm tests for the // HelmRelease succeeded. TestSucceededReason string = \"TestSucceeded\" // TestFailedReason represents the fact that the Helm tests for the HelmRelease // failed. TestFailedReason string = \"TestFailed\" // RollbackSucceededReason represents the fact that the Helm rollback for the // HelmRelease succeeded. RollbackSucceededReason string = \"RollbackSucceeded\" // RollbackFailedReason represents the fact that the Helm test for the // HelmRelease failed. RollbackFailedReason string = \"RollbackFailed\" // UninstallSucceededReason represents the fact that the Helm uninstall for the // HelmRelease succeeded. UninstallSucceededReason string = \"UninstallSucceeded\" // UninstallFailedReason represents the fact that the Helm uninstall for the // HelmRelease failed. UninstallFailedReason string = \"UninstallFailed\" // ArtifactFailedReason represents the fact that the artifact download for the // HelmRelease failed. ArtifactFailedReason string = \"ArtifactFailed\" // InitFailedReason represents the fact that the initialization of the Helm // configuration failed. InitFailedReason string = \"InitFailed\" // GetLastReleaseFailedReason represents the fact that observing the last // release failed. GetLastReleaseFailedReason string = \"GetLastReleaseFailed\" ) Helm release placement \u00b6 The namespace/name in which to deploy and store the Helm release defaults to the namespace/name of the HelmRelease . These can be overridden respectively via spec.targetNamespace , spec.storageNamespace and spec.releaseName . If spec.targetNamespace is set, spec.releaseName defaults to <spec.targetNamespace>-<metadata.name> . Note: that configuring the spec.targetNamespace only defines the namespace the release is made in, the metadata for the release (also known as the \"Helm storage\") will be stored in the metadata.namespace or spec.storageNamespace of the HelmRelease . Helm chart template \u00b6 The spec.chart.spec values are used by the helm-controller as a template to create a new HelmChart resource with the given spec. The spec.chart.spec.sourceRef is a reference to an object managed by source-controller . When the source revision changes, it generates a Kubernetes event that triggers a new release. Supported source types: HelmRepository GitRepository Bucket The HelmChart is created in the same namespace as the sourceRef , with a name matching the HelmRelease <metadata.namespace>-<metadata.name> . The chart.spec.chart can either contain: The name of the chart as made available by the HelmRepository (without any aliases), for example: podinfo The relative path the chart can be found at in the GitRepository , for example: ./charts/podinfo The chart.spec.version can be a fixed semver, or any semver range (i.e. >=4.0.0 <5.0.0 ). It is ignored for HelmRelease resources that reference a GitRepository or Bucket source. Values overrides \u00b6 The simplest way to define values overrides is inline via spec.values . It is also possible to define a list of ConfigMap and Secret resources from which to take values via spec.valuesFrom . The values are merged in the order given, with the later values overwriting earlier, and then spec.values overwriting those: spec : values : replicaCount : 2 valuesFrom : - kind : ConfigMap name : prod-env-values valuesKey : values-prod.yaml - kind : Secret name : prod-tls-values valuesKey : crt targetPath : tls.crt optional : true The definition of the listed keys for items in spec.valuesFrom is as follows: kind : Kind of the values referent ( ConfigMap or Secret ). name : Name of the values referent, in the same namespace as the HelmRelease . valuesKey (Optional) : The data key where the values.yaml or a specific value can be found. Defaults to values.yaml when omitted. targetPath (Optional) : The YAML dot notation path at which the value should be merged. When set, the valuesKey is expected to be a single flat value. Defaults to None when omitted, which results in the values getting merged at the root. optional (Optional) : Whether this values reference is optional. When true , a not found error for the values reference is ignored, but any valuesKey, targetPath or transient error will still result in a reconciliation failure. Defaults to false when omitted. Note: that the targetPath supports the same formatting as you would supply as an argument to the helm binary using --set [path]=[value] . In addition to this, the referred value can contain the same value formats (e.g. {a,b,c} for a list). You can read more about the available formats and limitations in the Helm documentation . Reconciliation \u00b6 If no Helm release with the matching namespace/name is found it will be installed. It will be upgraded any time the desired state is updated, which consists of: spec (and thus metadata.generation ) Latest HelmChart revision available ConfigMap and Secret values overrides . Changes to these do not trigger an immediate reconciliation, but will be handled upon the next reconciliation. This is to avoid a large number of upgrades occurring when multiple resources are updated. If the latest Helm release revision was not made by the helm-controller, it may not match the desired state, so an upgrade is made in this case as well. The spec.interval tells the reconciler at which interval to reconcile the release. The interval time units are s , m and h e.g. interval: 5m , the minimum value should be 60 seconds. The reconciler can be told to reconcile the HelmRelease outside of the specified interval by annotating the object with a reconcile.fluxcd.io/requestedAt annotation. For example: kubectl annotate --overwrite helmrelease/podinfo reconcile.fluxcd.io/requesteddAt = \" $( date +%s ) \" Reconciliation can be suspended by setting spec.suspend to true . The timeout for any individual Kubernetes operation (like Jobs for hooks) during the performance of Helm actions can be configured via spec.timeout and can be overridden per action via spec.<action>.timeout . Disabling resource waiting \u00b6 For install, upgrade, and rollback actions resource waiting is enabled by default, but can be disabled by setting spec.<action>.disableWait . HelmRelease dependencies \u00b6 When applying a HelmRelease , you may need to make sure other releases are Ready before the release is reconciled. For example, because your chart relies on the presence of a Custom Resource Definition installed by another HelmRelease . The spec.dependsOn field allows you to specify each of these dependencies. Assuming two HelmRelease resources: backend - contains the backend of the application frontend - contains the frontend of the application and relies on the backend apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : backend namespace : default spec : interval : 5m chart : spec : chart : podinfo version : \">=4.0.0 <5.0.0\" sourceRef : kind : HelmRepository name : podinfo namespace : default interval : 1m upgrade : remediation : remediateLastFailure : true test : enable : true values : service : grpcService : backend resources : requests : cpu : 100m memory : 64Mi --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : frontend namespace : default spec : interval : 5m chart : spec : chart : podinfo version : \">=4.0.0 <5.0.0\" sourceRef : kind : HelmRepository name : podinfo namespace : default interval : 1m dependsOn : - name : backend upgrade : remediation : remediateLastFailure : true test : enable : true values : backend : http://backend-podinfo:9898/echo resources : requests : cpu : 100m memory : 64Mi Note that this does not account for upgrade ordering. Kubernetes only allows applying one resource ( HelmRelease in this case) at a time, so there is no way for the controller to know when a dependency HelmRelease may be updated. Also, circular dependencies between HelmRelease resources must be avoided, otherwise the interdependent HelmRelease resources will never be reconciled. Configuring Helm test actions \u00b6 To make the controller run the Helm tests available for your chart after a successful Helm install or upgrade, spec.test.enable should be set to true . By default, when tests are enabled, failures in tests are considered release failures, and thus are subject to the triggering Helm action's remediation configuration. However, test failures can be ignored by setting spec.test.ignoreFailures to true . In this case, no remediation will be taken, and the test failure will not affect the Released and Ready status conditions. This can be overridden per Helm action by setting spec.install.remediation.ignoreTestFailures or spec.upgrade.remediation.ignoreTestFailures . apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : default spec : interval : 5m chart : spec : chart : podinfo version : \">=4.0.0 <5.0.0\" sourceRef : kind : HelmRepository name : podinfo namespace : default interval : 1m test : enable : true ignoreFailures : true values : resources : requests : cpu : 100m memory : 64Mi Configuring failure remediation \u00b6 From time to time a Helm install/upgrade and accompanying Helm test may fail. When this occurs, by default no action is taken, and the release is left in a failed state. However, several automatic failure remediation options can be set via spec.install.remediation and spec.upgrade.remediation . The retries can be set to configure the number of retries after an initial failure. A negative integer results in infinite retries. This implicitly opts-in to a remediation action between each attempt. The remediation action for install failures is an uninstall. The remediation action for upgrade failures is by default a rollback, however spec.upgrade.remediation.strategy can be set to uninstall , in which case after the uninstall, the spec.install configuration takes over. One can also opt-in to remediation of the last failure (when no retries remain) by setting spec.<action>.remediation.remediateLastFailure to true . For upgrades, this defaults to true if at least one retry is configured. apiVersion : helm.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : default spec : interval : 5m chart : spec : chart : podinfo version : \">=4.0.0 <5.0.0\" sourceRef : kind : HelmRepository name : podinfo namespace : default interval : 1m install : remediation : retries : 3 upgrade : remediation : remediateLastFailure : false values : resources : requests : cpu : 100m memory : 64Mi Role-based access control \u00b6 By default, a HelmRelease runs under the cluster admin account and can create, modify, delete cluster level objects (cluster roles, cluster role binding, CRDs, etc) and namespeced objects (deployments, ingresses, etc). For certain HelmReleases a cluster admin may wish to control what types of Kubernetes objects can be reconciled and under which namespace. To restrict a HelmRelease , one can assign a service account under which the reconciliation is performed. Assuming you want to restrict a group of HelmReleases to a single namespace, you can create an account with a role binding that grants access only to that namespace: apiVersion : v1 kind : Namespace metadata : name : webapp --- apiVersion : v1 kind : ServiceAccount metadata : name : webapp-reconciler namespace : webapp --- apiVersion : rbac.authorization.k8s.io/v1 kind : Role metadata : name : webapp-reconciler namespace : webapp rules : - apiGroups : [ \"*\" ] resources : [ \"*\" ] verbs : [ \"*\" ] --- apiVersion : rbac.authorization.k8s.io/v1 kind : RoleBinding metadata : name : webapp-reconciler namespace : webapp roleRef : apiGroup : rbac.authorization.k8s.io kind : Role name : webapp-reconciler subjects : - kind : ServiceAccount name : webapp-reconciler namespace : webapp Note that the namespace, RBAC and service account manifests should be placed in a Git source and applied with a Kustomization. Create a HelmRelease that prevents altering the cluster state outside of the webapp namespace: apiVersion : helm.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : webapp spec : serviceAccountName : webapp-reconciler interval : 5m chart : spec : chart : podinfo sourceRef : kind : HelmRepository name : podinfo When the controller reconciles the podinfo release, it will impersonate the webapp-reconciler account. If the chart contains cluster level objects like CRDs, the reconciliation will fail since the account it runs under has no permissions to alter objects outside of the webapp namespace. Remote Clusters / Cluster-API \u00b6 If the spec.kubeConfig field is set, Helm actions will run against the default cluster specified in that KubeConfig instead of the local cluster that is responsible for the reconciliation of the HelmRelease. The secret defined in the spec.kubeConfig.secretRef must exist in the same namespace as the HelmRelease. On every reconciliation, the KubeConfig bytes will be loaded from the values key of the secret's data, and the secret can thus be regularly updated if cluster-access-tokens have to rotate due to expiration. The Helm storage is stored on the remote cluster in a namespace that equals to the namespace of the HelmRelease, or the configured spec.storageNamespace . The release itself is made in a namespace that equals to the namespace of the HelmRelease, or the configured spec.targetNamespace . The namespaces are expected to exist, with the exception that spec.targetNamespace can be created on demand by Helm when spec.createNamespace is set to true . Other references to Kubernetes resources in the HelmRelease, like ValuesReference resources, are expected to exist on the reconciling cluster. This composes well with Cluster API bootstrap providers such as CAPBK (kubeadm), as well as the CAPA (AWS) EKS integration. To reconcile a HelmRelease to a CAPI controlled cluster, put the HelmRelease in the same namespace as your Cluster object, and set the spec.kubeConfig.secretRef.name to <cluster-name>-kubeconfig : apiVersion : cluster.x-k8s.io/v1alpha3 kind : Cluster metadata : name : stage # the kubeconfig Secret will contain the Cluster name namespace : capi-stage spec : clusterNetwork : pods : cidrBlocks : - 10.100.0.0/16 serviceDomain : stage-cluster.local services : cidrBlocks : - 10.200.0.0/12 controlPlaneRef : apiVersion : controlplane.cluster.x-k8s.io/v1alpha3 kind : KubeadmControlPlane name : stage-control-plane namespace : capi-stage infrastructureRef : apiVersion : infrastructure.cluster.x-k8s.io/v1alpha3 kind : DockerCluster name : stage namespace : capi-stage --- # ... unrelated Cluster API objects omitted for brevity ... --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : kube-prometheus-stack namespace : capi-stage spec : kubeConfig : secretRef : name : stage-kubeconfig # Cluster API creates this for the matching Cluster chart : spec : chart : prometheus version : \">=4.0.0 <5.0.0\" sourceRef : kind : HelmRepository name : prometheus-community install : remediation : retries : -1 The Cluster and HelmRelease can be created at the same time if the install remediation configuration is set to a forgiving amount of retries. The HelmRelease will then eventually reconcile once the cluster is available. If you wish to target clusters created by other means than CAPI, you can create a ServiceAccount on the remote cluster, generate a KubeConfig for that account, and then create a secret on the cluster where helm-controller is running e.g.: kubectl -n default create secret generic prod-kubeconfig \\ --from-file = value = ./kubeconfig Note that the KubeConfig should be self-contained and not rely on binaries, environment, or credential files from the helm-controller Pod. This matches the constraints of KubeConfigs from current Cluster API providers. KubeConfigs with cmd-path in them likely won't work without a custom, per-provider installation of helm-controller. Post Renderers \u00b6 HelmRelease resources has a built-in Kustomize compatible Post Renderer , which provides the following Kustomize directives: patchesStrategicMerge patchesJson6902 images The following example uses the built-in kustomize Post Renderer to apply a strategic merge patch, which adds a toleration to the Helm rendered output: apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : metrics-server namespace : kube-system spec : interval : 1m chart : spec : chart : metrics-server version : \"5.3.4\" sourceRef : kind : HelmRepository name : bitnami namespace : kube-system interval : 1m postRenderers : # Instruct helm-controller to use built-in \"kustomize\" post renderer. - kustomize : # Array of inline strategic merge patch definitions as YAML object. # Note, this is a YAML object and not a string, to avoid syntax # indention errors. patchesStrategicMerge : - kind : Deployment apiVersion : apps/v1 metadata : name : metrics-server spec : template : spec : tolerations : - key : \"workload-type\" operator : \"Equal\" value : \"cluster-services\" effect : \"NoSchedule\" # Array of inline JSON6902 patch definitions as YAML object. # Note, this is a YAML object and not a string, to avoid syntax # indention errors. patchesJson6902 : - target : version : v1 kind : Deployment name : metrics-server patch : - op : add path : /spec/template/priorityClassName value : system-cluster-critical images : - name : docker.io/bitnami/metrics-server newName : docker.io/bitnami/metrics-server newTag : 0.4.1-debian-10-r54 Status \u00b6 When the controller completes a reconciliation, it reports the result in the status sub-resource. The following status.condtions types are advertised. Here, \"desired state\" is as detailed in reconciliation : Ready - status of the last reconciliation attempt Released - status of the last release attempt (install/upgrade/test) against the latest desired state TestSuccess - status of the last test attempt against the latest desired state Remediated - status of the last remediation attempt (uninstall/rollback) due to a failure of the last release attempt against the latest desired state For example, you can wait for a successful helm-controller reconciliation with: kubectl wait helmrelease/podinfo --for = condition = ready Each of these conditions also include descriptive reason / message fields as to why the status is as such. Examples \u00b6 Install success \u00b6 status : conditions : - lastTransitionTime : \"2020-07-13T13:13:40Z\" message : Helm install succeeded reason : InstallSucceeded status : \"True\" type : Released - lastTransitionTime : \"2020-07-13T13:13:40Z\" message : Helm test succeeded reason : TestSucceeded status : \"True\" type : TestSuccess - lastTransitionTime : \"2020-07-13T13:13:42Z\" message : release reconciliation succeeded reason : ReconciliationSucceeded status : \"True\" type : Ready lastAppliedRevision : 4.0.6 lastAttemptedRevision : 4.0.6 lastReleaseRevision : 1 observedGeneration : 2 Upgrade failure \u00b6 status : conditions : - lastTransitionTime : \"2020-07-13T13:17:28Z\" message : 'error validating \"\": error validating data: ValidationError(Deployment.spec.replicas): invalid type for io.k8s.api.apps.v1.DeploymentSpec.replicas: got \"string\", expected \"integer\"' reason : UpgradeFailed status : \"False\" type : Released - lastTransitionTime : \"2020-07-13T13:17:28Z\" message : 'error validating \"\": error validating data: ValidationError(Deployment.spec.replicas): invalid type for io.k8s.api.apps.v1.DeploymentSpec.replicas: got \"string\", expected \"integer\"' reason : UpgradeFailed status : \"False\" type : Ready failures : 1 lastAppliedRevision : 4.0.6 lastAttemptedRevision : 4.0.6 lastReleaseRevision : 1 observedGeneration : 3 Ignored test failure \u00b6 status : conditions : - lastTransitionTime : \"2020-07-13T13:13:40Z\" message : Helm install succeeded reason : InstallSucceeded status : \"True\" type : Released - lastTransitionTime : \"2020-07-13T13:13:40Z\" message : Helm test failed reason : TestFailed status : \"False\" type : TestSuccess - lastTransitionTime : \"2020-07-13T13:13:42Z\" message : release reconciliation succeeded reason : ReconciliationSucceeded status : \"True\" type : Ready lastAppliedRevision : 4.0.6 lastAttemptedRevision : 4.0.6 lastReleaseRevision : 1 observedGeneration : 2","title":"HelmRelease CRD"},{"location":"components/helm/helmreleases/#helm-releases","text":"The HelmRelease API defines a resource for automated controller driven Helm releases.","title":"Helm Releases"},{"location":"components/helm/helmreleases/#specification","text":"A HelmRelease object defines a resource for controller driven reconciliation of Helm releases via Helm actions such as install, upgrade, test, uninstall, and rollback. This includes release placement (namespace/name), release content (chart/values overrides), action trigger configuration, individual action configuration, and statusing. // HelmReleaseSpec defines the desired state of a Helm Release. type HelmReleaseSpec struct { // Chart defines the template of the v1beta1.HelmChart that should be created // for this HelmRelease. // +required Chart HelmChartTemplate `json:\"chart\"` // Interval at which to reconcile the Helm release. // +required Interval metav1 . Duration `json:\"interval\"` // Suspend tells the controller to suspend reconciliation for this HelmRelease, // it does not apply to already started reconciliations. Defaults to false. // +optional Suspend bool `json:\"suspend,omitempty\"` // ReleaseName used for the Helm release. Defaults to a composition of // '[TargetNamespace-]Name'. // +kubebuilder:validation:MinLength=1 // +kubebuilder:validation:MaxLength=53 // +kubebuilder:validation:Optional // +optional ReleaseName string `json:\"releaseName,omitempty\"` // TargetNamespace to target when performing operations for the HelmRelease. // Defaults to the namespace of the HelmRelease. // +kubebuilder:validation:MinLength=1 // +kubebuilder:validation:MaxLength=63 // +kubebuilder:validation:Optional // +optional TargetNamespace string `json:\"targetNamespace,omitempty\"` // StorageNamespace used for the Helm storage. // Defaults to the namespace of the HelmRelease. // +kubebuilder:validation:MinLength=1 // +kubebuilder:validation:MaxLength=63 // +kubebuilder:validation:Optional // +optional StorageNamespace string `json:\"storageNamespace,omitempty\"` // DependsOn may contain a dependency.CrossNamespaceDependencyReference slice with // references to HelmRelease resources that must be ready before this HelmRelease // can be reconciled. // +optional DependsOn [] dependency . CrossNamespaceDependencyReference `json:\"dependsOn,omitempty\"` // Timeout is the time to wait for any individual Kubernetes operation (like Jobs // for hooks) during the performance of a Helm action. Defaults to '5m0s'. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // MaxHistory is the number of revisions saved by Helm for this HelmRelease. // Use '0' for an unlimited number of revisions; defaults to '10'. // +optional MaxHistory * int `json:\"maxHistory,omitempty\"` // Install holds the configuration for Helm install actions for this HelmRelease. // +optional Install * Install `json:\"install,omitempty\"` // Upgrade holds the configuration for Helm upgrade actions for this HelmRelease. // +optional Upgrade * Upgrade `json:\"upgrade,omitempty\"` // Test holds the configuration for Helm test actions for this HelmRelease. // +optional Test * Test `json:\"test,omitempty\"` // Rollback holds the configuration for Helm rollback actions for this HelmRelease. // +optional Rollback * Rollback `json:\"rollback,omitempty\"` // Uninstall holds the configuration for Helm uninstall actions for this HelmRelease. // +optional Uninstall * Uninstall `json:\"uninstall,omitempty\"` // ValuesFrom holds references to resources containing Helm values for this HelmRelease, // and information about how they should be merged. ValuesFrom [] ValuesReference `json:\"valuesFrom,omitempty\"` // Values holds the values for this Helm release. // +optional Values * apiextensionsv1 . JSON `json:\"values,omitempty\"` // KubeConfig for reconciling the HelmRelease on a remote cluster. // When specified, KubeConfig takes precedence over ServiceAccountName. // +optional KubeConfig * KubeConfig `json:\"kubeConfig,omitempty\"` // The name of the Kubernetes service account to impersonate // when reconciling this HelmRelease. // +optional ServiceAccountName string `json:\"serviceAccountName,omitempty\"` // PostRenderers holds an array of Helm PostRenderers, which will be applied in order // of their definition. // +optional PostRenderers [] PostRenderer `json:\"postRenderers,omitempty\"` } // KubeConfig references a Kubernetes secret that contains a kubeconfig file. type KubeConfig struct { // SecretRef holds the name to a secret that contains a 'value' key with // the kubeconfig file as the value. It must be in the same namespace as // the HelmRelease. // It is recommended that the kubeconfig is self-contained, and the secret // is regularly updated if credentials such as a cloud-access-token expire. // Cloud specific `cmd-path` auth helpers will not function without adding // binaries and credentials to the Pod that is responsible for reconciling // the HelmRelease. // +required SecretRef corev1 . LocalObjectReference `json:\"secretRef,omitempty\"` } // HelmChartTemplate defines the template from which the controller will // generate a v1beta1.HelmChart object in the same namespace as the referenced // v1beta1.Source. type HelmChartTemplate struct { // Spec holds the template for the v1beta1.HelmChartSpec for this HelmRelease. // +required Spec HelmChartTemplateSpec `json:\"spec\"` } // HelmChartTemplateSpec defines the template from which the controller will // generate a v1beta1.HelmChartSpec object. type HelmChartTemplateSpec struct { // The name or path the Helm chart is available at in the SourceRef. // +required Chart string `json:\"chart\"` // Version semver expression, ignored for charts from v1beta1.GitRepository and // v1beta1.Bucket sources. Defaults to latest when omitted. // +kubebuilder:default:=* // +optional Version string `json:\"version,omitempty\"` // The name and namespace of the v1beta1.Source the chart is available at. // +required SourceRef CrossNamespaceObjectReference `json:\"sourceRef\"` // Interval at which to check the v1beta1.Source for updates. Defaults to // 'HelmReleaseSpec.Interval'. // +optional Interval * metav1 . Duration `json:\"interval,omitempty\"` // Alternative values file to use as the default chart values, expected to be a // relative path in the SourceRef. Ignored when omitted. // +optional ValuesFile string `json:\"valuesFile,omitempty\"` } // Install holds the configuration for Helm install actions performed for this // HelmRelease. type Install struct { // Timeout is the time to wait for any individual Kubernetes operation (like // Jobs for hooks) during the performance of a Helm install action. Defaults to // 'HelmReleaseSpec.Timeout'. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // Remediation holds the remediation configuration for when the Helm install // action for the HelmRelease fails. The default is to not perform any action. // +optional Remediation * InstallRemediation `json:\"remediation,omitempty\"` // DisableWait disables the waiting for resources to be ready after a Helm // install has been performed. // +optional DisableWait bool `json:\"disableWait,omitempty\"` // DisableHooks prevents hooks from running during the Helm install action. // +optional DisableHooks bool `json:\"disableHooks,omitempty\"` // DisableOpenAPIValidation prevents the Helm install action from validating // rendered templates against the Kubernetes OpenAPI Schema. // +optional DisableOpenAPIValidation bool `json:\"disableOpenAPIValidation,omitempty\"` // Replace tells the Helm install action to re-use the 'ReleaseName', but only // if that name is a deleted release which remains in the history. // +optional Replace bool `json:\"replace,omitempty\"` // SkipCRDs tells the Helm install action to not install any CRDs. By default, // CRDs are installed if not already present. // +optional SkipCRDs bool `json:\"skipCRDs,omitempty\"` // CreateNamespace tells the Helm install action to create the // HelmReleaseSpec.TargetNamespace if it does not exist yet. // On uninstall, the namespace will not be garbage collected. // +optional CreateNamespace bool `json:\"createNamespace,omitempty\"` } // InstallRemediation holds the configuration for Helm install remediation. type InstallRemediation struct { // Retries is the number of retries that should be attempted on failures before // bailing. Remediation, using an uninstall, is performed between each attempt. // Defaults to '0', a negative integer equals to unlimited retries. // +optional Retries int `json:\"retries,omitempty\"` // IgnoreTestFailures tells the controller to skip remediation when the Helm // tests are run after an install action but fail. Defaults to // 'Test.IgnoreFailures'. // +optional IgnoreTestFailures * bool `json:\"ignoreTestFailures,omitempty\"` // RemediateLastFailure tells the controller to remediate the last failure, when // no retries remain. Defaults to 'false'. // +optional RemediateLastFailure * bool `json:\"remediateLastFailure,omitempty\"` } // Upgrade holds the configuration for Helm upgrade actions for this // HelmRelease. type Upgrade struct { // Timeout is the time to wait for any individual Kubernetes operation (like // Jobs for hooks) during the performance of a Helm upgrade action. Defaults to // 'HelmReleaseSpec.Timeout'. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // Remediation holds the remediation configuration for when the Helm upgrade // action for the HelmRelease fails. The default is to not perform any action. // +optional Remediation * UpgradeRemediation `json:\"remediation,omitempty\"` // DisableWait disables the waiting for resources to be ready after a Helm // upgrade has been performed. // +optional DisableWait bool `json:\"disableWait,omitempty\"` // DisableHooks prevents hooks from running during the Helm upgrade action. // +optional DisableHooks bool `json:\"disableHooks,omitempty\"` // DisableOpenAPIValidation prevents the Helm upgrade action from validating // rendered templates against the Kubernetes OpenAPI Schema. // +optional DisableOpenAPIValidation bool `json:\"disableOpenAPIValidation,omitempty\"` // Force forces resource updates through a replacement strategy. // +optional Force bool `json:\"force,omitempty\"` // PreserveValues will make Helm reuse the last release's values and merge in // overrides from 'Values'. Setting this flag makes the HelmRelease // non-declarative. // +optional PreserveValues bool `json:\"preserveValues,omitempty\"` // CleanupOnFail allows deletion of new resources created during the Helm // upgrade action when it fails. // +optional CleanupOnFail bool `json:\"cleanupOnFail,omitempty\"` } // UpgradeRemediation holds the configuration for Helm upgrade remediation. type UpgradeRemediation struct { // Retries is the number of retries that should be attempted on failures before // bailing. Remediation, using 'Strategy', is performed between each attempt. // Defaults to '0', a negative integer equals to unlimited retries. // +optional Retries int `json:\"retries,omitempty\"` // IgnoreTestFailures tells the controller to skip remediation when the Helm // tests are run after an upgrade action but fail. // Defaults to 'Test.IgnoreFailures'. // +optional IgnoreTestFailures * bool `json:\"ignoreTestFailures,omitempty\"` // RemediateLastFailure tells the controller to remediate the last failure, when // no retries remain. Defaults to 'false' unless 'Retries' is greater than 0. // +optional RemediateLastFailure * bool `json:\"remediateLastFailure,omitempty\"` // Strategy to use for failure remediation. Defaults to 'rollback'. // +kubebuilder:validation:Enum=rollback;uninstall // +optional Strategy * RemediationStrategy `json:\"strategy,omitempty\"` } // Test holds the configuration for Helm test actions for this HelmRelease. type Test struct { // Enable enables Helm test actions for this HelmRelease after an Helm install // or upgrade action has been performed. // +optional Enable bool `json:\"enable,omitempty\"` // Timeout is the time to wait for any individual Kubernetes operation during // the performance of a Helm test action. Defaults to 'HelmReleaseSpec.Timeout'. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // IgnoreFailures tells the controller to skip remediation when the Helm tests // are run but fail. Can be overwritten for tests run after install or upgrade // actions in 'Install.IgnoreTestFailures' and 'Upgrade.IgnoreTestFailures'. // +optional IgnoreFailures bool `json:\"ignoreFailures,omitempty\"` } // Rollback holds the configuration for Helm rollback actions for this // HelmRelease. type Rollback struct { // Timeout is the time to wait for any individual Kubernetes operation (like // Jobs for hooks) during the performance of a Helm rollback action. Defaults to // 'HelmReleaseSpec.Timeout'. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // DisableWait disables the waiting for resources to be ready after a Helm // rollback has been performed. // +optional DisableWait bool `json:\"disableWait,omitempty\"` // DisableHooks prevents hooks from running during the Helm rollback action. // +optional DisableHooks bool `json:\"disableHooks,omitempty\"` // Recreate performs pod restarts for the resource if applicable. // +optional Recreate bool `json:\"recreate,omitempty\"` // Force forces resource updates through a replacement strategy. // +optional Force bool `json:\"force,omitempty\"` // CleanupOnFail allows deletion of new resources created during the Helm // rollback action when it fails. // +optional CleanupOnFail bool `json:\"cleanupOnFail,omitempty\"` } // Uninstall holds the configuration for Helm uninstall actions for this // HelmRelease. type Uninstall struct { // Timeout is the time to wait for any individual Kubernetes operation (like // Jobs for hooks) during the performance of a Helm uninstall action. Defaults // to 'HelmReleaseSpec.Timeout'. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // DisableHooks prevents hooks from running during the Helm rollback action. // +optional DisableHooks bool `json:\"disableHooks,omitempty\"` // KeepHistory tells Helm to remove all associated resources and mark the // release as deleted, but retain the release history. // +optional KeepHistory bool `json:\"keepHistory,omitempty\"` } // Kustomize Helm PostRenderer specification. type Kustomize struct { // Strategic merge patches, defined as inline YAML objects. // +optional PatchesStrategicMerge [] apiextensionsv1 . JSON `json:\"patchesStrategicMerge,omitempty\"` // JSON 6902 patches, defined as inline YAML objects. // +optional PatchesJSON6902 [] kustomize . JSON6902Patch `json:\"patchesJson6902,omitempty\"` // Images is a list of (image name, new name, new tag or digest) // for changing image names, tags or digests. This can also be achieved with a // patch, but this operator is simpler to specify. // +optional Images [] kustomize . Image `json:\"images,omitempty\" yaml:\"images,omitempty\"` } // PostRenderer contains a Helm PostRenderer specification. type PostRenderer struct { // Kustomization to apply as PostRenderer. // +optional Kustomize * Kustomize `json:\"kustomize,omitempty\"` }","title":"Specification"},{"location":"components/helm/helmreleases/#reference-types","text":"// CrossNamespaceObjectReference contains enough information to let you locate the // typed referenced object at cluster level. type CrossNamespaceObjectReference struct { // APIVersion of the referent. // +optional APIVersion string `json:\"apiVersion,omitempty\"` // Kind of the referent. // +kubebuilder:validation:Enum=HelmRepository // +required Kind string `json:\"kind,omitempty\"` // Name of the referent. // +kubebuilder:validation:MinLength=1 // +kubebuilder:validation:MaxLength=253 // +required Name string `json:\"name\"` // Namespace of the referent. // +kubebuilder:validation:MinLength=1 // +kubebuilder:validation:MaxLength=63 // +kubebuilder:validation:Optional // +optional Namespace string `json:\"namespace,omitempty\"` } // ValuesReference contains a reference to a resource containing Helm values, // and optionally the key they can be found at. type ValuesReference struct { // Kind of the values referent, valid values are ('Secret', 'ConfigMap'). // +kubebuilder:validation:Enum=Secret;ConfigMap // +required Kind string `json:\"kind\"` // Name of the values referent. Should reside in the same namespace as the // referring resource. // +kubebuilder:validation:MinLength=1 // +kubebuilder:validation:MaxLength=253 // +required Name string `json:\"name\"` // ValuesKey is the data key where the values.yaml or a specific value can be // found at. Defaults to 'values.yaml'. // +optional ValuesKey string `json:\"valuesKey,omitempty\"` // TargetPath is the YAML dot notation path the value should be merged at. When // set, the ValuesKey is expected to be a single flat value. Defaults to 'None', // which results in the values getting merged at the root. // +optional TargetPath string `json:\"targetPath,omitempty\"` // Optional marks this ValuesReference as optional. When set, a not found error // for the values reference is ignored, but any ValuesKey, TargetPath or // transient error will still result in a reconciliation failure. // +optional Optional bool `json:\"optional,omitempty\"` }","title":"Reference types"},{"location":"components/helm/helmreleases/#status-specification","text":"// HelmReleaseStatus defines the observed state of a HelmRelease. type HelmReleaseStatus struct { // ObservedGeneration is the last observed generation. // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // LastHandledReconcileAt is the last manual reconciliation request (by // annotating the HelmRelease) handled by the reconciler. // +optional LastHandledReconcileAt string `json:\"lastHandledReconcileAt,omitempty\"` // Conditions holds the conditions for the HelmRelease. // +optional Conditions [] meta . Condition `json:\"conditions,omitempty\"` // LastAppliedRevision is the revision of the last successfully applied source. // +optional LastAppliedRevision string `json:\"lastAppliedRevision,omitempty\"` // LastAttemptedRevision is the revision of the last reconciliation attempt. // +optional LastAttemptedRevision string `json:\"lastAttemptedRevision,omitempty\"` // LastAttemptedValuesChecksum is the SHA1 checksum of the values of the last // reconciliation attempt. // +optional LastAttemptedValuesChecksum string `json:\"lastAttemptedValuesChecksum,omitempty\"` // LastReleaseRevision is the revision of the last successful Helm release. // +optional LastReleaseRevision int `json:\"lastReleaseRevision,omitempty\"` // HelmChart is the namespaced name of the HelmChart resource created by // the controller for the HelmRelease. // +optional HelmChart string `json:\"helmChart,omitempty\"` // Failures is the reconciliation failure count against the latest observed // state. It is reset after a successful reconciliation. // +optional Failures int64 `json:\"failures,omitempty\"` // InstallFailures is the install failure count against the latest observed // state. It is reset after a successful reconciliation. // +optional InstallFailures int64 `json:\"installFailures,omitempty\"` // UpgradeFailures is the upgrade failure count against the latest observed // state. It is reset after a successful reconciliation. // +optional UpgradeFailures int64 `json:\"upgradeFailures,omitempty\"` }","title":"Status specification"},{"location":"components/helm/helmreleases/#condition-types","text":"const ( // ReleasedCondition represents the status of the last release attempt // (install/upgrade/test) against the latest desired state. ReleasedCondition string = \"Released\" // TestSuccessCondition represents the status of the last test attempt against // the latest desired state. TestSuccessCondition string = \"TestSuccess\" // RemediatedCondition represents the status of the last remediation attempt // (uninstall/rollback) due to a failure of the last release attempt against the // latest desired state. RemediatedCondition string = \"Remediated\" )","title":"Condition types"},{"location":"components/helm/helmreleases/#condition-reasons","text":"const ( // InstallSucceededReason represents the fact that the Helm install for the // HelmRelease succeeded. InstallSucceededReason string = \"InstallSucceeded\" // InstallFailedReason represents the fact that the Helm install for the // HelmRelease failed. InstallFailedReason string = \"InstallFailed\" // UpgradeSucceededReason represents the fact that the Helm upgrade for the // HelmRelease succeeded. UpgradeSucceededReason string = \"UpgradeSucceeded\" // UpgradeFailedReason represents the fact that the Helm upgrade for the // HelmRelease failed. UpgradeFailedReason string = \"UpgradeFailed\" // TestSucceededReason represents the fact that the Helm tests for the // HelmRelease succeeded. TestSucceededReason string = \"TestSucceeded\" // TestFailedReason represents the fact that the Helm tests for the HelmRelease // failed. TestFailedReason string = \"TestFailed\" // RollbackSucceededReason represents the fact that the Helm rollback for the // HelmRelease succeeded. RollbackSucceededReason string = \"RollbackSucceeded\" // RollbackFailedReason represents the fact that the Helm test for the // HelmRelease failed. RollbackFailedReason string = \"RollbackFailed\" // UninstallSucceededReason represents the fact that the Helm uninstall for the // HelmRelease succeeded. UninstallSucceededReason string = \"UninstallSucceeded\" // UninstallFailedReason represents the fact that the Helm uninstall for the // HelmRelease failed. UninstallFailedReason string = \"UninstallFailed\" // ArtifactFailedReason represents the fact that the artifact download for the // HelmRelease failed. ArtifactFailedReason string = \"ArtifactFailed\" // InitFailedReason represents the fact that the initialization of the Helm // configuration failed. InitFailedReason string = \"InitFailed\" // GetLastReleaseFailedReason represents the fact that observing the last // release failed. GetLastReleaseFailedReason string = \"GetLastReleaseFailed\" )","title":"Condition reasons"},{"location":"components/helm/helmreleases/#helm-release-placement","text":"The namespace/name in which to deploy and store the Helm release defaults to the namespace/name of the HelmRelease . These can be overridden respectively via spec.targetNamespace , spec.storageNamespace and spec.releaseName . If spec.targetNamespace is set, spec.releaseName defaults to <spec.targetNamespace>-<metadata.name> . Note: that configuring the spec.targetNamespace only defines the namespace the release is made in, the metadata for the release (also known as the \"Helm storage\") will be stored in the metadata.namespace or spec.storageNamespace of the HelmRelease .","title":"Helm release placement"},{"location":"components/helm/helmreleases/#helm-chart-template","text":"The spec.chart.spec values are used by the helm-controller as a template to create a new HelmChart resource with the given spec. The spec.chart.spec.sourceRef is a reference to an object managed by source-controller . When the source revision changes, it generates a Kubernetes event that triggers a new release. Supported source types: HelmRepository GitRepository Bucket The HelmChart is created in the same namespace as the sourceRef , with a name matching the HelmRelease <metadata.namespace>-<metadata.name> . The chart.spec.chart can either contain: The name of the chart as made available by the HelmRepository (without any aliases), for example: podinfo The relative path the chart can be found at in the GitRepository , for example: ./charts/podinfo The chart.spec.version can be a fixed semver, or any semver range (i.e. >=4.0.0 <5.0.0 ). It is ignored for HelmRelease resources that reference a GitRepository or Bucket source.","title":"Helm chart template"},{"location":"components/helm/helmreleases/#values-overrides","text":"The simplest way to define values overrides is inline via spec.values . It is also possible to define a list of ConfigMap and Secret resources from which to take values via spec.valuesFrom . The values are merged in the order given, with the later values overwriting earlier, and then spec.values overwriting those: spec : values : replicaCount : 2 valuesFrom : - kind : ConfigMap name : prod-env-values valuesKey : values-prod.yaml - kind : Secret name : prod-tls-values valuesKey : crt targetPath : tls.crt optional : true The definition of the listed keys for items in spec.valuesFrom is as follows: kind : Kind of the values referent ( ConfigMap or Secret ). name : Name of the values referent, in the same namespace as the HelmRelease . valuesKey (Optional) : The data key where the values.yaml or a specific value can be found. Defaults to values.yaml when omitted. targetPath (Optional) : The YAML dot notation path at which the value should be merged. When set, the valuesKey is expected to be a single flat value. Defaults to None when omitted, which results in the values getting merged at the root. optional (Optional) : Whether this values reference is optional. When true , a not found error for the values reference is ignored, but any valuesKey, targetPath or transient error will still result in a reconciliation failure. Defaults to false when omitted. Note: that the targetPath supports the same formatting as you would supply as an argument to the helm binary using --set [path]=[value] . In addition to this, the referred value can contain the same value formats (e.g. {a,b,c} for a list). You can read more about the available formats and limitations in the Helm documentation .","title":"Values overrides"},{"location":"components/helm/helmreleases/#reconciliation","text":"If no Helm release with the matching namespace/name is found it will be installed. It will be upgraded any time the desired state is updated, which consists of: spec (and thus metadata.generation ) Latest HelmChart revision available ConfigMap and Secret values overrides . Changes to these do not trigger an immediate reconciliation, but will be handled upon the next reconciliation. This is to avoid a large number of upgrades occurring when multiple resources are updated. If the latest Helm release revision was not made by the helm-controller, it may not match the desired state, so an upgrade is made in this case as well. The spec.interval tells the reconciler at which interval to reconcile the release. The interval time units are s , m and h e.g. interval: 5m , the minimum value should be 60 seconds. The reconciler can be told to reconcile the HelmRelease outside of the specified interval by annotating the object with a reconcile.fluxcd.io/requestedAt annotation. For example: kubectl annotate --overwrite helmrelease/podinfo reconcile.fluxcd.io/requesteddAt = \" $( date +%s ) \" Reconciliation can be suspended by setting spec.suspend to true . The timeout for any individual Kubernetes operation (like Jobs for hooks) during the performance of Helm actions can be configured via spec.timeout and can be overridden per action via spec.<action>.timeout .","title":"Reconciliation"},{"location":"components/helm/helmreleases/#disabling-resource-waiting","text":"For install, upgrade, and rollback actions resource waiting is enabled by default, but can be disabled by setting spec.<action>.disableWait .","title":"Disabling resource waiting"},{"location":"components/helm/helmreleases/#helmrelease-dependencies","text":"When applying a HelmRelease , you may need to make sure other releases are Ready before the release is reconciled. For example, because your chart relies on the presence of a Custom Resource Definition installed by another HelmRelease . The spec.dependsOn field allows you to specify each of these dependencies. Assuming two HelmRelease resources: backend - contains the backend of the application frontend - contains the frontend of the application and relies on the backend apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : backend namespace : default spec : interval : 5m chart : spec : chart : podinfo version : \">=4.0.0 <5.0.0\" sourceRef : kind : HelmRepository name : podinfo namespace : default interval : 1m upgrade : remediation : remediateLastFailure : true test : enable : true values : service : grpcService : backend resources : requests : cpu : 100m memory : 64Mi --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : frontend namespace : default spec : interval : 5m chart : spec : chart : podinfo version : \">=4.0.0 <5.0.0\" sourceRef : kind : HelmRepository name : podinfo namespace : default interval : 1m dependsOn : - name : backend upgrade : remediation : remediateLastFailure : true test : enable : true values : backend : http://backend-podinfo:9898/echo resources : requests : cpu : 100m memory : 64Mi Note that this does not account for upgrade ordering. Kubernetes only allows applying one resource ( HelmRelease in this case) at a time, so there is no way for the controller to know when a dependency HelmRelease may be updated. Also, circular dependencies between HelmRelease resources must be avoided, otherwise the interdependent HelmRelease resources will never be reconciled.","title":"HelmRelease dependencies"},{"location":"components/helm/helmreleases/#configuring-helm-test-actions","text":"To make the controller run the Helm tests available for your chart after a successful Helm install or upgrade, spec.test.enable should be set to true . By default, when tests are enabled, failures in tests are considered release failures, and thus are subject to the triggering Helm action's remediation configuration. However, test failures can be ignored by setting spec.test.ignoreFailures to true . In this case, no remediation will be taken, and the test failure will not affect the Released and Ready status conditions. This can be overridden per Helm action by setting spec.install.remediation.ignoreTestFailures or spec.upgrade.remediation.ignoreTestFailures . apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : default spec : interval : 5m chart : spec : chart : podinfo version : \">=4.0.0 <5.0.0\" sourceRef : kind : HelmRepository name : podinfo namespace : default interval : 1m test : enable : true ignoreFailures : true values : resources : requests : cpu : 100m memory : 64Mi","title":"Configuring Helm test actions"},{"location":"components/helm/helmreleases/#configuring-failure-remediation","text":"From time to time a Helm install/upgrade and accompanying Helm test may fail. When this occurs, by default no action is taken, and the release is left in a failed state. However, several automatic failure remediation options can be set via spec.install.remediation and spec.upgrade.remediation . The retries can be set to configure the number of retries after an initial failure. A negative integer results in infinite retries. This implicitly opts-in to a remediation action between each attempt. The remediation action for install failures is an uninstall. The remediation action for upgrade failures is by default a rollback, however spec.upgrade.remediation.strategy can be set to uninstall , in which case after the uninstall, the spec.install configuration takes over. One can also opt-in to remediation of the last failure (when no retries remain) by setting spec.<action>.remediation.remediateLastFailure to true . For upgrades, this defaults to true if at least one retry is configured. apiVersion : helm.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : default spec : interval : 5m chart : spec : chart : podinfo version : \">=4.0.0 <5.0.0\" sourceRef : kind : HelmRepository name : podinfo namespace : default interval : 1m install : remediation : retries : 3 upgrade : remediation : remediateLastFailure : false values : resources : requests : cpu : 100m memory : 64Mi","title":"Configuring failure remediation"},{"location":"components/helm/helmreleases/#role-based-access-control","text":"By default, a HelmRelease runs under the cluster admin account and can create, modify, delete cluster level objects (cluster roles, cluster role binding, CRDs, etc) and namespeced objects (deployments, ingresses, etc). For certain HelmReleases a cluster admin may wish to control what types of Kubernetes objects can be reconciled and under which namespace. To restrict a HelmRelease , one can assign a service account under which the reconciliation is performed. Assuming you want to restrict a group of HelmReleases to a single namespace, you can create an account with a role binding that grants access only to that namespace: apiVersion : v1 kind : Namespace metadata : name : webapp --- apiVersion : v1 kind : ServiceAccount metadata : name : webapp-reconciler namespace : webapp --- apiVersion : rbac.authorization.k8s.io/v1 kind : Role metadata : name : webapp-reconciler namespace : webapp rules : - apiGroups : [ \"*\" ] resources : [ \"*\" ] verbs : [ \"*\" ] --- apiVersion : rbac.authorization.k8s.io/v1 kind : RoleBinding metadata : name : webapp-reconciler namespace : webapp roleRef : apiGroup : rbac.authorization.k8s.io kind : Role name : webapp-reconciler subjects : - kind : ServiceAccount name : webapp-reconciler namespace : webapp Note that the namespace, RBAC and service account manifests should be placed in a Git source and applied with a Kustomization. Create a HelmRelease that prevents altering the cluster state outside of the webapp namespace: apiVersion : helm.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : webapp spec : serviceAccountName : webapp-reconciler interval : 5m chart : spec : chart : podinfo sourceRef : kind : HelmRepository name : podinfo When the controller reconciles the podinfo release, it will impersonate the webapp-reconciler account. If the chart contains cluster level objects like CRDs, the reconciliation will fail since the account it runs under has no permissions to alter objects outside of the webapp namespace.","title":"Role-based access control"},{"location":"components/helm/helmreleases/#remote-clusters-cluster-api","text":"If the spec.kubeConfig field is set, Helm actions will run against the default cluster specified in that KubeConfig instead of the local cluster that is responsible for the reconciliation of the HelmRelease. The secret defined in the spec.kubeConfig.secretRef must exist in the same namespace as the HelmRelease. On every reconciliation, the KubeConfig bytes will be loaded from the values key of the secret's data, and the secret can thus be regularly updated if cluster-access-tokens have to rotate due to expiration. The Helm storage is stored on the remote cluster in a namespace that equals to the namespace of the HelmRelease, or the configured spec.storageNamespace . The release itself is made in a namespace that equals to the namespace of the HelmRelease, or the configured spec.targetNamespace . The namespaces are expected to exist, with the exception that spec.targetNamespace can be created on demand by Helm when spec.createNamespace is set to true . Other references to Kubernetes resources in the HelmRelease, like ValuesReference resources, are expected to exist on the reconciling cluster. This composes well with Cluster API bootstrap providers such as CAPBK (kubeadm), as well as the CAPA (AWS) EKS integration. To reconcile a HelmRelease to a CAPI controlled cluster, put the HelmRelease in the same namespace as your Cluster object, and set the spec.kubeConfig.secretRef.name to <cluster-name>-kubeconfig : apiVersion : cluster.x-k8s.io/v1alpha3 kind : Cluster metadata : name : stage # the kubeconfig Secret will contain the Cluster name namespace : capi-stage spec : clusterNetwork : pods : cidrBlocks : - 10.100.0.0/16 serviceDomain : stage-cluster.local services : cidrBlocks : - 10.200.0.0/12 controlPlaneRef : apiVersion : controlplane.cluster.x-k8s.io/v1alpha3 kind : KubeadmControlPlane name : stage-control-plane namespace : capi-stage infrastructureRef : apiVersion : infrastructure.cluster.x-k8s.io/v1alpha3 kind : DockerCluster name : stage namespace : capi-stage --- # ... unrelated Cluster API objects omitted for brevity ... --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : kube-prometheus-stack namespace : capi-stage spec : kubeConfig : secretRef : name : stage-kubeconfig # Cluster API creates this for the matching Cluster chart : spec : chart : prometheus version : \">=4.0.0 <5.0.0\" sourceRef : kind : HelmRepository name : prometheus-community install : remediation : retries : -1 The Cluster and HelmRelease can be created at the same time if the install remediation configuration is set to a forgiving amount of retries. The HelmRelease will then eventually reconcile once the cluster is available. If you wish to target clusters created by other means than CAPI, you can create a ServiceAccount on the remote cluster, generate a KubeConfig for that account, and then create a secret on the cluster where helm-controller is running e.g.: kubectl -n default create secret generic prod-kubeconfig \\ --from-file = value = ./kubeconfig Note that the KubeConfig should be self-contained and not rely on binaries, environment, or credential files from the helm-controller Pod. This matches the constraints of KubeConfigs from current Cluster API providers. KubeConfigs with cmd-path in them likely won't work without a custom, per-provider installation of helm-controller.","title":"Remote Clusters / Cluster-API"},{"location":"components/helm/helmreleases/#post-renderers","text":"HelmRelease resources has a built-in Kustomize compatible Post Renderer , which provides the following Kustomize directives: patchesStrategicMerge patchesJson6902 images The following example uses the built-in kustomize Post Renderer to apply a strategic merge patch, which adds a toleration to the Helm rendered output: apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : metrics-server namespace : kube-system spec : interval : 1m chart : spec : chart : metrics-server version : \"5.3.4\" sourceRef : kind : HelmRepository name : bitnami namespace : kube-system interval : 1m postRenderers : # Instruct helm-controller to use built-in \"kustomize\" post renderer. - kustomize : # Array of inline strategic merge patch definitions as YAML object. # Note, this is a YAML object and not a string, to avoid syntax # indention errors. patchesStrategicMerge : - kind : Deployment apiVersion : apps/v1 metadata : name : metrics-server spec : template : spec : tolerations : - key : \"workload-type\" operator : \"Equal\" value : \"cluster-services\" effect : \"NoSchedule\" # Array of inline JSON6902 patch definitions as YAML object. # Note, this is a YAML object and not a string, to avoid syntax # indention errors. patchesJson6902 : - target : version : v1 kind : Deployment name : metrics-server patch : - op : add path : /spec/template/priorityClassName value : system-cluster-critical images : - name : docker.io/bitnami/metrics-server newName : docker.io/bitnami/metrics-server newTag : 0.4.1-debian-10-r54","title":"Post Renderers"},{"location":"components/helm/helmreleases/#status","text":"When the controller completes a reconciliation, it reports the result in the status sub-resource. The following status.condtions types are advertised. Here, \"desired state\" is as detailed in reconciliation : Ready - status of the last reconciliation attempt Released - status of the last release attempt (install/upgrade/test) against the latest desired state TestSuccess - status of the last test attempt against the latest desired state Remediated - status of the last remediation attempt (uninstall/rollback) due to a failure of the last release attempt against the latest desired state For example, you can wait for a successful helm-controller reconciliation with: kubectl wait helmrelease/podinfo --for = condition = ready Each of these conditions also include descriptive reason / message fields as to why the status is as such.","title":"Status"},{"location":"components/helm/helmreleases/#examples","text":"","title":"Examples"},{"location":"components/helm/helmreleases/#install-success","text":"status : conditions : - lastTransitionTime : \"2020-07-13T13:13:40Z\" message : Helm install succeeded reason : InstallSucceeded status : \"True\" type : Released - lastTransitionTime : \"2020-07-13T13:13:40Z\" message : Helm test succeeded reason : TestSucceeded status : \"True\" type : TestSuccess - lastTransitionTime : \"2020-07-13T13:13:42Z\" message : release reconciliation succeeded reason : ReconciliationSucceeded status : \"True\" type : Ready lastAppliedRevision : 4.0.6 lastAttemptedRevision : 4.0.6 lastReleaseRevision : 1 observedGeneration : 2","title":"Install success"},{"location":"components/helm/helmreleases/#upgrade-failure","text":"status : conditions : - lastTransitionTime : \"2020-07-13T13:17:28Z\" message : 'error validating \"\": error validating data: ValidationError(Deployment.spec.replicas): invalid type for io.k8s.api.apps.v1.DeploymentSpec.replicas: got \"string\", expected \"integer\"' reason : UpgradeFailed status : \"False\" type : Released - lastTransitionTime : \"2020-07-13T13:17:28Z\" message : 'error validating \"\": error validating data: ValidationError(Deployment.spec.replicas): invalid type for io.k8s.api.apps.v1.DeploymentSpec.replicas: got \"string\", expected \"integer\"' reason : UpgradeFailed status : \"False\" type : Ready failures : 1 lastAppliedRevision : 4.0.6 lastAttemptedRevision : 4.0.6 lastReleaseRevision : 1 observedGeneration : 3","title":"Upgrade failure"},{"location":"components/helm/helmreleases/#ignored-test-failure","text":"status : conditions : - lastTransitionTime : \"2020-07-13T13:13:40Z\" message : Helm install succeeded reason : InstallSucceeded status : \"True\" type : Released - lastTransitionTime : \"2020-07-13T13:13:40Z\" message : Helm test failed reason : TestFailed status : \"False\" type : TestSuccess - lastTransitionTime : \"2020-07-13T13:13:42Z\" message : release reconciliation succeeded reason : ReconciliationSucceeded status : \"True\" type : Ready lastAppliedRevision : 4.0.6 lastAttemptedRevision : 4.0.6 lastReleaseRevision : 1 observedGeneration : 2","title":"Ignored test failure"},{"location":"components/image/automation-api/","text":"Image update automation API reference Packages: image.toolkit.fluxcd.io/v1alpha1 image.toolkit.fluxcd.io/v1alpha1 Package v1alpha1 contains API types for the image v1alpha1 API group. The types here are concerned with automated updates to git, based on metadata from OCI image registries gathered by the image-reflector-controller. Resource Types: CommitSpec ( Appears on: ImageUpdateAutomationSpec ) CommitSpec specifies how to commit changes to the git repository Field Description authorName string AuthorName gives the name to provide when making a commit authorEmail string AuthorEmail gives the email to provide when making a commit messageTemplate string (Optional) MessageTemplate provides a template for the commit message, into which will be interpolated the details of the change made. GitCheckoutSpec ( Appears on: ImageUpdateAutomationSpec ) Field Description gitRepositoryRef Kubernetes core/v1.LocalObjectReference GitRepositoryRef refers to the resource giving access details to a git repository to update files in. branch string Branch gives the branch to clone from the git repository. ImageUpdateAutomation ImageUpdateAutomation is the Schema for the imageupdateautomations API Field Description metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec ImageUpdateAutomationSpec checkout GitCheckoutSpec Checkout gives the parameters for cloning the git repository, ready to make changes. interval Kubernetes meta/v1.Duration Interval gives an lower bound for how often the automation run should be attempted. update UpdateStrategy Update gives the specification for how to update the files in the repository. This can be left empty, to use the default value. commit CommitSpec Commit specifies how to commit to the git repo suspend bool (Optional) Suspend tells the controller to not run this automation, until it is unset (or set to false). Defaults to false. status ImageUpdateAutomationStatus ImageUpdateAutomationSpec ( Appears on: ImageUpdateAutomation ) ImageUpdateAutomationSpec defines the desired state of ImageUpdateAutomation Field Description checkout GitCheckoutSpec Checkout gives the parameters for cloning the git repository, ready to make changes. interval Kubernetes meta/v1.Duration Interval gives an lower bound for how often the automation run should be attempted. update UpdateStrategy Update gives the specification for how to update the files in the repository. This can be left empty, to use the default value. commit CommitSpec Commit specifies how to commit to the git repo suspend bool (Optional) Suspend tells the controller to not run this automation, until it is unset (or set to false). Defaults to false. ImageUpdateAutomationStatus ( Appears on: ImageUpdateAutomation ) ImageUpdateAutomationStatus defines the observed state of ImageUpdateAutomation Field Description lastAutomationRunTime Kubernetes meta/v1.Time (Optional) LastAutomationRunTime records the last time the controller ran this automation through to completion (even if no updates were made). lastPushCommit string (Optional) LastPushCommit records the SHA1 of the last commit made by the controller, for this automation object lastPushTime Kubernetes meta/v1.Time (Optional) LastPushTime records the time of the last pushed change. observedGeneration int64 (Optional) conditions []Kubernetes meta/v1.Condition (Optional) ReconcileRequestStatus github.com/fluxcd/pkg/apis/meta.ReconcileRequestStatus (Members of ReconcileRequestStatus are embedded into this type.) UpdateStrategy ( Appears on: ImageUpdateAutomationSpec ) UpdateStrategy is a union of the various strategies for updating the Git repository. Parameters for each strategy (if any) can be inlined here. Field Description strategy UpdateStrategyName Strategy names the strategy to be used. UpdateStrategyName ( string alias) ( Appears on: UpdateStrategy ) UpdateStrategyName is the type for names that go in .update.strategy. NB the value in the const immediately below. This page was automatically generated with gen-crd-api-reference-docs","title":"Automation API Reference"},{"location":"components/image/controller/","text":"Image reflector and automation controllers \u00b6 The image-reflector-controller and image-automation-controller work together to update a Git repository when new container images are available. The image-reflector-controller scans image repositories and reflects the image metadata in Kubernetes resources. The image-automation-controller updates YAML files based on the latest images scanned, and commits the changes to a given Git repository. Links: Source code fluxcd/image-reflector-controller Reflector specification docs Source code fluxcd/image-automation-controller Automation specification docs","title":"Overview"},{"location":"components/image/controller/#image-reflector-and-automation-controllers","text":"The image-reflector-controller and image-automation-controller work together to update a Git repository when new container images are available. The image-reflector-controller scans image repositories and reflects the image metadata in Kubernetes resources. The image-automation-controller updates YAML files based on the latest images scanned, and commits the changes to a given Git repository. Links: Source code fluxcd/image-reflector-controller Reflector specification docs Source code fluxcd/image-automation-controller Automation specification docs","title":"Image reflector and automation controllers"},{"location":"components/image/imagepolicies/","text":"Image Policies \u00b6 The ImagePolicy type gives rules for selecting a \"latest\" image from a scanned ImageRepository . This can be used to drive automation, as with the image-automation-controller ; or more generally, to inform other processes of the state of an image repository. Specification \u00b6 // ImagePolicySpec defines the parameters for calculating the // ImagePolicy type ImagePolicySpec struct { // ImageRepositoryRef points at the object specifying the image // being scanned // +required ImageRepositoryRef corev1 . LocalObjectReference `json:\"imageRepositoryRef\"` // Policy gives the particulars of the policy to be followed in // selecting the most recent image // +required Policy ImagePolicyChoice `json:\"policy\"` // FilterTags enables filtering for only a subset of tags based on a set of // rules. If no rules are provided, all the tags from the repository will be // ordered and compared. // +optional FilterTags * TagFilter `json:\"filterTags,omitempty\"` } The field ImageRepositoryRef names an ImageRepository object in the same namespace. It is this object that provides the scanned image metadata for the policy to use in selecting an image. Policy \u00b6 The ImagePolicy field specifies how to choose a latest image given the image metadata. The choice is between SemVer : interpreting all tags as semver versions, and choosing the highest version available that fits the given semver constraints ; or, Alphabetical : choosing the last tag when all the tags are sorted alphabetically (in either ascending or descending order); or, Numerical : choosing the last tag when all the tags are sorted numerically (in either ascending or descending order). // ImagePolicyChoice is a union of all the types of policy that can be supplied. type ImagePolicyChoice struct { // SemVer gives a semantic version range to check against the tags available. // +optional SemVer * SemVerPolicy `json:\"semver,omitempty\"` // Alphabetical set of rules to use for alphabetical ordering of the tags. // +optional Alphabetical * AlphabeticalPolicy `json:\"alphabetical,omitempty\"` // Numerical set of rules to use for numerical ordering of the tags. // +optional Numerical * NumericalPolicy `json:\"numerical,omitempty\"` } // SemVerPolicy specifies a semantic version policy. type SemVerPolicy struct { // Range gives a semver range for the image tag; the highest // version within the range that's a tag yields the latest image. // +required Range string `json:\"range\"` } // AlphabeticalPolicy specifies a alphabetical ordering policy. type AlphabeticalPolicy struct { // Order specifies the sorting order of the tags. Given the letters of the // alphabet as tags, ascending order would select Z, and descending order // would select A. // +kubebuilder:default:=\"asc\" // +kubebuilder:validation:Enum=asc;desc // +optional Order string `json:\"order,omitempty\"` } // NumericalPolicy specifies a numerical ordering policy. type NumericalPolicy struct { // Order specifies the sorting order of the tags. Given the integer values // from 0 to 9 as tags, ascending order would select 9, and descending order // would select 0. // +kubebuilder:default:=\"asc\" // +kubebuilder:validation:Enum=asc;desc // +optional Order string `json:\"order,omitempty\"` } FilterTags \u00b6 // TagFilter enables filtering tags based on a set of defined rules type TagFilter struct { // Pattern specifies a regular expression pattern used to filter for image // tags. // +optional Pattern string `json:\"pattern\"` // Extract allows a capture group to be extracted from the specified regular // expression pattern, useful before tag evaluation. // +optional Extract string `json:\"extract\"` } The FilterTags field gives you the opportunity to filter the image tags before they are considered by the policy rule. The Pattern field takes a regular expression which can match anywhere in the tag string. Only tags that match the pattern are considered by the policy rule. The optional Extract value will be expanded for each tag that matches the pattern. The resulting values will be supplied to the policy rule instead of the original tags. If Extract is empty, then the tags that match the pattern will be used as they are. Status \u00b6 // ImagePolicyStatus defines the observed state of ImagePolicy type ImagePolicyStatus struct { // LatestImage gives the first in the list of images scanned by // the image repository, when filtered and ordered according to // the policy. LatestImage string `json:\"latestImage,omitempty\"` // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // +optional Conditions [] metav1 . Condition `json:\"conditions,omitempty\"` } The LatestImage field contains the image selected by the policy rule, when it has run successfully. Conditions \u00b6 There is one condition that may be present: the GitOps toolkit-standard ReadyCondition . This will be marked as true when the policy rule has selected an image. Examples \u00b6 Select the latest main branch build tagged as ${GIT_BRANCH}-${GIT_SHA:0:7}-$(date +%s) (numerical): kind : ImagePolicy spec : filterTags : pattern : '^main-[a-fA-F0-9]+-(?P<ts>.*)' extract : '$ts' policy : numerical : order : asc A more strict filter would be ^main-[a-fA-F0-9]+-(?P<ts>[1-9][0-9]*) . Before applying policies in-cluster, you can validate your filters using a Go regular expression tester or regex101.com . Select the latest stable version (semver): kind : ImagePolicy spec : policy : semver : range : '>=1.0.0' Select the latest stable patch version in the 1.x range (semver): kind : ImagePolicy spec : policy : semver : range : '>=1.0.0 <2.0.0' Select the latest version including pre-releases (semver): kind : ImagePolicy spec : policy : semver : range : '>=1.0.0-0' Select the latest release candidate (semver): kind : ImagePolicy spec : filterTags : pattern : '.*-rc.*' policy : semver : range : '^1.x-0' Select the latest release tagged as RELEASE.<RFC3339-TIMESTAMP> e.g. Minio (alphabetical): kind : ImagePolicy spec : filterTags : pattern : '^RELEASE\\.(?P<timestamp>.*)Z$' extract : '$timestamp' policy : alphabetical : order : asc","title":"ImagePolicy CRD"},{"location":"components/image/imagepolicies/#image-policies","text":"The ImagePolicy type gives rules for selecting a \"latest\" image from a scanned ImageRepository . This can be used to drive automation, as with the image-automation-controller ; or more generally, to inform other processes of the state of an image repository.","title":"Image Policies"},{"location":"components/image/imagepolicies/#specification","text":"// ImagePolicySpec defines the parameters for calculating the // ImagePolicy type ImagePolicySpec struct { // ImageRepositoryRef points at the object specifying the image // being scanned // +required ImageRepositoryRef corev1 . LocalObjectReference `json:\"imageRepositoryRef\"` // Policy gives the particulars of the policy to be followed in // selecting the most recent image // +required Policy ImagePolicyChoice `json:\"policy\"` // FilterTags enables filtering for only a subset of tags based on a set of // rules. If no rules are provided, all the tags from the repository will be // ordered and compared. // +optional FilterTags * TagFilter `json:\"filterTags,omitempty\"` } The field ImageRepositoryRef names an ImageRepository object in the same namespace. It is this object that provides the scanned image metadata for the policy to use in selecting an image.","title":"Specification"},{"location":"components/image/imagepolicies/#policy","text":"The ImagePolicy field specifies how to choose a latest image given the image metadata. The choice is between SemVer : interpreting all tags as semver versions, and choosing the highest version available that fits the given semver constraints ; or, Alphabetical : choosing the last tag when all the tags are sorted alphabetically (in either ascending or descending order); or, Numerical : choosing the last tag when all the tags are sorted numerically (in either ascending or descending order). // ImagePolicyChoice is a union of all the types of policy that can be supplied. type ImagePolicyChoice struct { // SemVer gives a semantic version range to check against the tags available. // +optional SemVer * SemVerPolicy `json:\"semver,omitempty\"` // Alphabetical set of rules to use for alphabetical ordering of the tags. // +optional Alphabetical * AlphabeticalPolicy `json:\"alphabetical,omitempty\"` // Numerical set of rules to use for numerical ordering of the tags. // +optional Numerical * NumericalPolicy `json:\"numerical,omitempty\"` } // SemVerPolicy specifies a semantic version policy. type SemVerPolicy struct { // Range gives a semver range for the image tag; the highest // version within the range that's a tag yields the latest image. // +required Range string `json:\"range\"` } // AlphabeticalPolicy specifies a alphabetical ordering policy. type AlphabeticalPolicy struct { // Order specifies the sorting order of the tags. Given the letters of the // alphabet as tags, ascending order would select Z, and descending order // would select A. // +kubebuilder:default:=\"asc\" // +kubebuilder:validation:Enum=asc;desc // +optional Order string `json:\"order,omitempty\"` } // NumericalPolicy specifies a numerical ordering policy. type NumericalPolicy struct { // Order specifies the sorting order of the tags. Given the integer values // from 0 to 9 as tags, ascending order would select 9, and descending order // would select 0. // +kubebuilder:default:=\"asc\" // +kubebuilder:validation:Enum=asc;desc // +optional Order string `json:\"order,omitempty\"` }","title":"Policy"},{"location":"components/image/imagepolicies/#filtertags","text":"// TagFilter enables filtering tags based on a set of defined rules type TagFilter struct { // Pattern specifies a regular expression pattern used to filter for image // tags. // +optional Pattern string `json:\"pattern\"` // Extract allows a capture group to be extracted from the specified regular // expression pattern, useful before tag evaluation. // +optional Extract string `json:\"extract\"` } The FilterTags field gives you the opportunity to filter the image tags before they are considered by the policy rule. The Pattern field takes a regular expression which can match anywhere in the tag string. Only tags that match the pattern are considered by the policy rule. The optional Extract value will be expanded for each tag that matches the pattern. The resulting values will be supplied to the policy rule instead of the original tags. If Extract is empty, then the tags that match the pattern will be used as they are.","title":"FilterTags"},{"location":"components/image/imagepolicies/#status","text":"// ImagePolicyStatus defines the observed state of ImagePolicy type ImagePolicyStatus struct { // LatestImage gives the first in the list of images scanned by // the image repository, when filtered and ordered according to // the policy. LatestImage string `json:\"latestImage,omitempty\"` // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // +optional Conditions [] metav1 . Condition `json:\"conditions,omitempty\"` } The LatestImage field contains the image selected by the policy rule, when it has run successfully.","title":"Status"},{"location":"components/image/imagepolicies/#conditions","text":"There is one condition that may be present: the GitOps toolkit-standard ReadyCondition . This will be marked as true when the policy rule has selected an image.","title":"Conditions"},{"location":"components/image/imagepolicies/#examples","text":"Select the latest main branch build tagged as ${GIT_BRANCH}-${GIT_SHA:0:7}-$(date +%s) (numerical): kind : ImagePolicy spec : filterTags : pattern : '^main-[a-fA-F0-9]+-(?P<ts>.*)' extract : '$ts' policy : numerical : order : asc A more strict filter would be ^main-[a-fA-F0-9]+-(?P<ts>[1-9][0-9]*) . Before applying policies in-cluster, you can validate your filters using a Go regular expression tester or regex101.com . Select the latest stable version (semver): kind : ImagePolicy spec : policy : semver : range : '>=1.0.0' Select the latest stable patch version in the 1.x range (semver): kind : ImagePolicy spec : policy : semver : range : '>=1.0.0 <2.0.0' Select the latest version including pre-releases (semver): kind : ImagePolicy spec : policy : semver : range : '>=1.0.0-0' Select the latest release candidate (semver): kind : ImagePolicy spec : filterTags : pattern : '.*-rc.*' policy : semver : range : '^1.x-0' Select the latest release tagged as RELEASE.<RFC3339-TIMESTAMP> e.g. Minio (alphabetical): kind : ImagePolicy spec : filterTags : pattern : '^RELEASE\\.(?P<timestamp>.*)Z$' extract : '$timestamp' policy : alphabetical : order : asc","title":"Examples"},{"location":"components/image/imagerepositories/","text":"Image Repositories \u00b6 The ImageRepository API specifies how to scan OCI image repositories. A repository is a collection of images -- e.g., alpine , as opposed to a specific image, e.g., alpine:3.1 . ImagePolicy objects can then refer to an ImageRepository in order to select a specific image from those scanned. Specification \u00b6 The ImageRepository type holds details for scanning a particular image repository. // ImageRepositorySpec defines the parameters for scanning an image // repository, e.g., `fluxcd/flux`. type ImageRepositorySpec struct { // Image is the name of the image repository // +required Image string `json:\"image,omitempty\"` // Interval is the length of time to wait between // scans of the image repository. // +required Interval metav1 . Duration `json:\"interval,omitempty\"` // Timeout for image scanning. // Defaults to 'Interval' duration. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // SecretRef can be given the name of a secret containing // credentials to use for the image registry. The secret should be // created with `kubectl create secret docker-registry`, or the // equivalent. // +optional SecretRef * meta . LocalObjectReference `json:\"secretRef,omitempty\"` // CertSecretRef can be given the name of a secret containing // either or both of // // - a PEM-encoded client certificate (`certFile`) and private // key (`keyFile`); // - a PEM-encoded CA certificate (`caFile`) // // and whichever are supplied, will be used for connecting to the // registry. The client cert and key are useful if you are // authenticating with a certificate; the CA cert is useful if // you are using a self-signed server certificate. // +optional CertSecretRef * meta . LocalObjectReference `json:\"certSecretRef,omitempty\"` // This flag tells the controller to suspend subsequent image scans. // It does not apply to already started scans. Defaults to false. // +optional Suspend bool `json:\"suspend,omitempty\"` } The Suspend field can be set to true to stop the controller scanning the image repository specified; remove the field value or set to false to resume scanning. secretRef for credentials The secretRef names a secret in the same namespace that holds credentials for accessing the image repository. This secret is expected to be in the same format as for imagePullSecrets . The usual way to create such a secret is with kubectl create secret docker-registry ... If you are running on a platform (e.g., AWS) that links service permissions (e.g., access to ECR) to service accounts, you may need to create the secret using tooling for that platform instead. There is advice specific to some platforms in the image automation guide . For a publicly accessible image repository, you don't need to provide a secretRef . certSecretRef for TLS certificates The certSecretRef field names a secret with TLS certificate data. This is for two separate purposes: to provide a client certificate and private key, if you use a certificate to authenticate with the image registry; and, to provide a CA certificate, if the registry uses a self-signed certificate. These will often go together, if you are hosting an image registry yourself. All the files in the secret are expected to be PEM-encoded . This is an ASCII format for certificates and keys; openssl and such tools will typically give you an option of PEM output. Assuming you have obtained a certificate file and private key and put them in the files client.crt and client.key respectively, you can create a secret with kubectl like this: SECRET_NAME = tls-certs kubectl create secret generic $SECRET_NAME \\ --from-file = certFile = client.crt \\ --from-file = keyFile = client.key You could also prepare a secret and encrypt it ; the important bit is that the data keys in the secret are certFile and keyFile . If you have a CA certificate for the client to use, the data key for that is caFile . Adapting the previous example, if you have the certificate in the file ca.crt , and the client certificate and key as before, the whole command would be: SECRET_NAME = tls-certs kubectl create secret generic $SECRET_NAME \\ --from-file = certFile = client.crt \\ --from-file = keyFile = client.key \\ --from-file = caFile = ca.crt Status \u00b6 // ImageRepositoryStatus defines the observed state of ImageRepository type ImageRepositoryStatus struct { // +optional Conditions [] metav1 . Condition `json:\"conditions,omitempty\"` // ObservedGeneration is the last reconciled generation. // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // CannonicalName is the name of the image repository with all the // implied bits made explicit; e.g., `docker.io/library/alpine` // rather than `alpine`. // +optional CanonicalImageName string `json:\"canonicalImageName,omitempty\"` // LastScanResult contains the number of fetched tags. // +optional LastScanResult * ScanResult `json:\"lastScanResult,omitempty\"` meta . ReconcileRequestStatus `json:\",inline\"` } The CanonicalName field gives the fully expanded image name, filling in any parts left implicit in the spec. For instance, alpine expands to docker.io/library/alpine . The LastScanResult field gives a summary of the most recent scan: type ScanResult struct { TagCount int `json:\"tagCount\"` ScanTime metav1 . Time `json:\"scanTime,omitempty\"` } Conditions \u00b6 There is one condition used: the GitOps toolkit-standard ReadyCondition . This will be marked as true when a scan succeeds, and false when a scan fails. Examples \u00b6 Fetch metadata for a public image every ten minutes: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImageRepository metadata : name : podinfo namespace : flux-system spec : interval : 10m image : ghcr.io/stefanprodan/podinfo Fetch metadata for a private image every minute: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImageRepository metadata : name : podinfo namespace : flux-system spec : interval : 1m0s image : docker.io/org/image secretRef : name : regcred For private images, you can create a Kubernetes secret in the same namespace as the ImageRepository with kubectl create secret docker-registry , and reference it under secretRef .","title":"ImageRepository CRD"},{"location":"components/image/imagerepositories/#image-repositories","text":"The ImageRepository API specifies how to scan OCI image repositories. A repository is a collection of images -- e.g., alpine , as opposed to a specific image, e.g., alpine:3.1 . ImagePolicy objects can then refer to an ImageRepository in order to select a specific image from those scanned.","title":"Image Repositories"},{"location":"components/image/imagerepositories/#specification","text":"The ImageRepository type holds details for scanning a particular image repository. // ImageRepositorySpec defines the parameters for scanning an image // repository, e.g., `fluxcd/flux`. type ImageRepositorySpec struct { // Image is the name of the image repository // +required Image string `json:\"image,omitempty\"` // Interval is the length of time to wait between // scans of the image repository. // +required Interval metav1 . Duration `json:\"interval,omitempty\"` // Timeout for image scanning. // Defaults to 'Interval' duration. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // SecretRef can be given the name of a secret containing // credentials to use for the image registry. The secret should be // created with `kubectl create secret docker-registry`, or the // equivalent. // +optional SecretRef * meta . LocalObjectReference `json:\"secretRef,omitempty\"` // CertSecretRef can be given the name of a secret containing // either or both of // // - a PEM-encoded client certificate (`certFile`) and private // key (`keyFile`); // - a PEM-encoded CA certificate (`caFile`) // // and whichever are supplied, will be used for connecting to the // registry. The client cert and key are useful if you are // authenticating with a certificate; the CA cert is useful if // you are using a self-signed server certificate. // +optional CertSecretRef * meta . LocalObjectReference `json:\"certSecretRef,omitempty\"` // This flag tells the controller to suspend subsequent image scans. // It does not apply to already started scans. Defaults to false. // +optional Suspend bool `json:\"suspend,omitempty\"` } The Suspend field can be set to true to stop the controller scanning the image repository specified; remove the field value or set to false to resume scanning. secretRef for credentials The secretRef names a secret in the same namespace that holds credentials for accessing the image repository. This secret is expected to be in the same format as for imagePullSecrets . The usual way to create such a secret is with kubectl create secret docker-registry ... If you are running on a platform (e.g., AWS) that links service permissions (e.g., access to ECR) to service accounts, you may need to create the secret using tooling for that platform instead. There is advice specific to some platforms in the image automation guide . For a publicly accessible image repository, you don't need to provide a secretRef . certSecretRef for TLS certificates The certSecretRef field names a secret with TLS certificate data. This is for two separate purposes: to provide a client certificate and private key, if you use a certificate to authenticate with the image registry; and, to provide a CA certificate, if the registry uses a self-signed certificate. These will often go together, if you are hosting an image registry yourself. All the files in the secret are expected to be PEM-encoded . This is an ASCII format for certificates and keys; openssl and such tools will typically give you an option of PEM output. Assuming you have obtained a certificate file and private key and put them in the files client.crt and client.key respectively, you can create a secret with kubectl like this: SECRET_NAME = tls-certs kubectl create secret generic $SECRET_NAME \\ --from-file = certFile = client.crt \\ --from-file = keyFile = client.key You could also prepare a secret and encrypt it ; the important bit is that the data keys in the secret are certFile and keyFile . If you have a CA certificate for the client to use, the data key for that is caFile . Adapting the previous example, if you have the certificate in the file ca.crt , and the client certificate and key as before, the whole command would be: SECRET_NAME = tls-certs kubectl create secret generic $SECRET_NAME \\ --from-file = certFile = client.crt \\ --from-file = keyFile = client.key \\ --from-file = caFile = ca.crt","title":"Specification"},{"location":"components/image/imagerepositories/#status","text":"// ImageRepositoryStatus defines the observed state of ImageRepository type ImageRepositoryStatus struct { // +optional Conditions [] metav1 . Condition `json:\"conditions,omitempty\"` // ObservedGeneration is the last reconciled generation. // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // CannonicalName is the name of the image repository with all the // implied bits made explicit; e.g., `docker.io/library/alpine` // rather than `alpine`. // +optional CanonicalImageName string `json:\"canonicalImageName,omitempty\"` // LastScanResult contains the number of fetched tags. // +optional LastScanResult * ScanResult `json:\"lastScanResult,omitempty\"` meta . ReconcileRequestStatus `json:\",inline\"` } The CanonicalName field gives the fully expanded image name, filling in any parts left implicit in the spec. For instance, alpine expands to docker.io/library/alpine . The LastScanResult field gives a summary of the most recent scan: type ScanResult struct { TagCount int `json:\"tagCount\"` ScanTime metav1 . Time `json:\"scanTime,omitempty\"` }","title":"Status"},{"location":"components/image/imagerepositories/#conditions","text":"There is one condition used: the GitOps toolkit-standard ReadyCondition . This will be marked as true when a scan succeeds, and false when a scan fails.","title":"Conditions"},{"location":"components/image/imagerepositories/#examples","text":"Fetch metadata for a public image every ten minutes: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImageRepository metadata : name : podinfo namespace : flux-system spec : interval : 10m image : ghcr.io/stefanprodan/podinfo Fetch metadata for a private image every minute: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImageRepository metadata : name : podinfo namespace : flux-system spec : interval : 1m0s image : docker.io/org/image secretRef : name : regcred For private images, you can create a Kubernetes secret in the same namespace as the ImageRepository with kubectl create secret docker-registry , and reference it under secretRef .","title":"Examples"},{"location":"components/image/imageupdateautomations/","text":"Image Update Automations \u00b6 The ImageUpdateAutomation type defines an automation process that will update a git repository, based on image policiy objects in the same namespace. The updates are governed by marking fields to be updated in each YAML file. For each field marked, the automation process checks the image policy named, and updates the field value if there is a new image selected by the policy. The marker format is shown in the image automation guide . Specification \u00b6 // ImageUpdateAutomationSpec defines the desired state of ImageUpdateAutomation type ImageUpdateAutomationSpec struct { // Checkout gives the parameters for cloning the git repository, // ready to make changes. // +required Checkout GitCheckoutSpec `json:\"checkout\"` // Interval gives an lower bound for how often the automation // run should be attempted. // +required Interval metav1 . Duration `json:\"interval\"` // Update gives the specification for how to update the files in // the repository. This can be left empty, to use the default // value. // +kubebuilder:default={\"strategy\":\"Setters\"} Update * UpdateStrategy `json:\"update,omitempty\"` // Commit specifies how to commit to the git repo // +required Commit CommitSpec `json:\"commit\"` // Suspend tells the controller to not run this automation, until // it is unset (or set to false). Defaults to false. // +optional Suspend bool `json:\"suspend,omitempty\"` } See the sections below, regarding checkout , update , and commit . The required interval field gives a period for automation runs, in duration notation ; e.g., \"5m\" . While suspend has a value of true , the automation will not run. Checkout \u00b6 The checkout value specifies the git repository and branch in which to commit changes: type GitCheckoutSpec struct { // GitRepositoryRef refers to the resource giving access details // to a git repository to update files in. // +required GitRepositoryRef corev1 . LocalObjectReference `json:\"gitRepositoryRef\"` // Branch gives the branch to clone from the git repository. // +required Branch string `json:\"branch\"` } The gitRepositoryRef field names a GitRepository object in the same namespace. To be able to commit changes back, the GitRepository object must refer to credentials with write access; e.g., if using a GitHub deploy key, \"Allow write access\" should be checked when creating it. Only the url , secretRef and gitImplementation (see just below) fields of the GitRepository are used. The branch field names the branch in the git repository to check out; this will also be the branch the controller pushes commits to. Git implementation The gitImplementation field controls which git library is used. This will matter if you run on Azure, and possibly otherwise -- see the source controller documentation for more details. Update strategy \u00b6 The update field specifies how to carry out updates on the git repository. There is one strategy possible at present -- {strategy: Setters} . This field may be left empty, to default to that value. // UpdateStrategyName is the type for names that go in // .update.strategy. NB the value in the const immediately below. // +kubebuilder:validation:Enum=Setters type UpdateStrategyName string const ( // UpdateStrategySetters is the name of the update strategy that // uses kyaml setters. NB the value in the enum annotation for the // type, above. UpdateStrategySetters UpdateStrategyName = \"Setters\" ) // UpdateStrategy is a union of the various strategies for updating // the Git repository. Parameters for each strategy (if any) can be // inlined here. type UpdateStrategy struct { // Strategy names the strategy to be used. // +required Strategy UpdateStrategyName `json:\"strategy\"` } Setters strategy At present, there is one strategy: \"Setters\". This uses field markers referring to image policies, as described in the image automation guide . Commit \u00b6 The commit field specifies how to construct a commit, once changes have been made to the files according to the update strategy. // CommitSpec specifies how to commit changes to the git repository type CommitSpec struct { // AuthorName gives the name to provide when making a commit // +required AuthorName string `json:\"authorName\"` // AuthorEmail gives the email to provide when making a commit // +required AuthorEmail string `json:\"authorEmail\"` // MessageTemplate provides a template for the commit message, // into which will be interpolated the details of the change made. // +optional MessageTemplate string `json:\"messageTemplate,omitempty\"` } The authorName and authorEmail are used together to give the author of the commit. For example, spec : # checkout, update, etc. commit : authorName : Fluxbot authorEmail : flux@example.com will result in commits with the author Fluxbot <flux@example.com> . The messageTemplate field is a string which will be used as the commit message. If empty, there is a default message; but you will likely want to provide your own, especially if you want to put tokens in to control how CI reacts to commits made by automation. For example, spec : commit : messsageTemplate : | Automated image update by Flux [ci skip] Status \u00b6 The status of an ImageUpdateAutomation object records the result of the last automation run. // ImageUpdateAutomationStatus defines the observed state of ImageUpdateAutomation type ImageUpdateAutomationStatus struct { // LastAutomationRunTime records the last time the controller ran // this automation through to completion (even if no updates were // made). // +optional LastAutomationRunTime * metav1 . Time `json:\"lastAutomationRunTime,omitempty\"` // LastPushCommit records the SHA1 of the last commit made by the // controller, for this automation object // +optional LastPushCommit string `json:\"lastPushCommit,omitempty\"` // LastPushTime records the time of the last pushed change. // +optional LastPushTime * metav1 . Time `json:\"lastPushTime,omitempty\"` // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // +optional Conditions [] metav1 . Condition `json:\"conditions,omitempty\"` meta . ReconcileRequestStatus `json:\",inline\"` } The lastAutomationRunTime gives the time of the last automation run, whether or not it made a commit. The lastPushCommit field records the SHA1 hash of the last commit pushed to the origin git repository, and the lastPushTime gives the time that push occurred. Conditions \u00b6 There is one condition maintained by the controller, which is the usual ReadyCondition condition. This will be recorded as True when automation has run without errors, whether or not it resulted in a commit.","title":"ImageUpdateAutomation CRD"},{"location":"components/image/imageupdateautomations/#image-update-automations","text":"The ImageUpdateAutomation type defines an automation process that will update a git repository, based on image policiy objects in the same namespace. The updates are governed by marking fields to be updated in each YAML file. For each field marked, the automation process checks the image policy named, and updates the field value if there is a new image selected by the policy. The marker format is shown in the image automation guide .","title":"Image Update Automations"},{"location":"components/image/imageupdateautomations/#specification","text":"// ImageUpdateAutomationSpec defines the desired state of ImageUpdateAutomation type ImageUpdateAutomationSpec struct { // Checkout gives the parameters for cloning the git repository, // ready to make changes. // +required Checkout GitCheckoutSpec `json:\"checkout\"` // Interval gives an lower bound for how often the automation // run should be attempted. // +required Interval metav1 . Duration `json:\"interval\"` // Update gives the specification for how to update the files in // the repository. This can be left empty, to use the default // value. // +kubebuilder:default={\"strategy\":\"Setters\"} Update * UpdateStrategy `json:\"update,omitempty\"` // Commit specifies how to commit to the git repo // +required Commit CommitSpec `json:\"commit\"` // Suspend tells the controller to not run this automation, until // it is unset (or set to false). Defaults to false. // +optional Suspend bool `json:\"suspend,omitempty\"` } See the sections below, regarding checkout , update , and commit . The required interval field gives a period for automation runs, in duration notation ; e.g., \"5m\" . While suspend has a value of true , the automation will not run.","title":"Specification"},{"location":"components/image/imageupdateautomations/#checkout","text":"The checkout value specifies the git repository and branch in which to commit changes: type GitCheckoutSpec struct { // GitRepositoryRef refers to the resource giving access details // to a git repository to update files in. // +required GitRepositoryRef corev1 . LocalObjectReference `json:\"gitRepositoryRef\"` // Branch gives the branch to clone from the git repository. // +required Branch string `json:\"branch\"` } The gitRepositoryRef field names a GitRepository object in the same namespace. To be able to commit changes back, the GitRepository object must refer to credentials with write access; e.g., if using a GitHub deploy key, \"Allow write access\" should be checked when creating it. Only the url , secretRef and gitImplementation (see just below) fields of the GitRepository are used. The branch field names the branch in the git repository to check out; this will also be the branch the controller pushes commits to. Git implementation The gitImplementation field controls which git library is used. This will matter if you run on Azure, and possibly otherwise -- see the source controller documentation for more details.","title":"Checkout"},{"location":"components/image/imageupdateautomations/#update-strategy","text":"The update field specifies how to carry out updates on the git repository. There is one strategy possible at present -- {strategy: Setters} . This field may be left empty, to default to that value. // UpdateStrategyName is the type for names that go in // .update.strategy. NB the value in the const immediately below. // +kubebuilder:validation:Enum=Setters type UpdateStrategyName string const ( // UpdateStrategySetters is the name of the update strategy that // uses kyaml setters. NB the value in the enum annotation for the // type, above. UpdateStrategySetters UpdateStrategyName = \"Setters\" ) // UpdateStrategy is a union of the various strategies for updating // the Git repository. Parameters for each strategy (if any) can be // inlined here. type UpdateStrategy struct { // Strategy names the strategy to be used. // +required Strategy UpdateStrategyName `json:\"strategy\"` } Setters strategy At present, there is one strategy: \"Setters\". This uses field markers referring to image policies, as described in the image automation guide .","title":"Update strategy"},{"location":"components/image/imageupdateautomations/#commit","text":"The commit field specifies how to construct a commit, once changes have been made to the files according to the update strategy. // CommitSpec specifies how to commit changes to the git repository type CommitSpec struct { // AuthorName gives the name to provide when making a commit // +required AuthorName string `json:\"authorName\"` // AuthorEmail gives the email to provide when making a commit // +required AuthorEmail string `json:\"authorEmail\"` // MessageTemplate provides a template for the commit message, // into which will be interpolated the details of the change made. // +optional MessageTemplate string `json:\"messageTemplate,omitempty\"` } The authorName and authorEmail are used together to give the author of the commit. For example, spec : # checkout, update, etc. commit : authorName : Fluxbot authorEmail : flux@example.com will result in commits with the author Fluxbot <flux@example.com> . The messageTemplate field is a string which will be used as the commit message. If empty, there is a default message; but you will likely want to provide your own, especially if you want to put tokens in to control how CI reacts to commits made by automation. For example, spec : commit : messsageTemplate : | Automated image update by Flux [ci skip]","title":"Commit"},{"location":"components/image/imageupdateautomations/#status","text":"The status of an ImageUpdateAutomation object records the result of the last automation run. // ImageUpdateAutomationStatus defines the observed state of ImageUpdateAutomation type ImageUpdateAutomationStatus struct { // LastAutomationRunTime records the last time the controller ran // this automation through to completion (even if no updates were // made). // +optional LastAutomationRunTime * metav1 . Time `json:\"lastAutomationRunTime,omitempty\"` // LastPushCommit records the SHA1 of the last commit made by the // controller, for this automation object // +optional LastPushCommit string `json:\"lastPushCommit,omitempty\"` // LastPushTime records the time of the last pushed change. // +optional LastPushTime * metav1 . Time `json:\"lastPushTime,omitempty\"` // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // +optional Conditions [] metav1 . Condition `json:\"conditions,omitempty\"` meta . ReconcileRequestStatus `json:\",inline\"` } The lastAutomationRunTime gives the time of the last automation run, whether or not it made a commit. The lastPushCommit field records the SHA1 hash of the last commit pushed to the origin git repository, and the lastPushTime gives the time that push occurred.","title":"Status"},{"location":"components/image/imageupdateautomations/#conditions","text":"There is one condition maintained by the controller, which is the usual ReadyCondition condition. This will be recorded as True when automation has run without errors, whether or not it resulted in a commit.","title":"Conditions"},{"location":"components/image/reflector-api/","text":"Image reflector API reference Packages: image.toolkit.fluxcd.io/v1alpha1 image.toolkit.fluxcd.io/v1alpha1 Package v1alpha1 contains API types for the image v1alpha1 API group. These types are concerned with reflecting metadata from OCI image repositories into a cluster, so they can be consulted for e.g., automation. Resource Types: AlphabeticalPolicy ( Appears on: ImagePolicyChoice ) AlphabeticalPolicy specifices a alphabetical ordering policy. Field Description order string (Optional) Order specifies the sorting order of the tags. Given the letters of the alphabet as tags, ascending order would select Z, and descending order would select A. ImagePolicy ImagePolicy is the Schema for the imagepolicies API Field Description metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec ImagePolicySpec imageRepositoryRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference ImageRepositoryRef points at the object specifying the image being scanned policy ImagePolicyChoice Policy gives the particulars of the policy to be followed in selecting the most recent image filterTags TagFilter (Optional) FilterTags enables filtering for only a subset of tags based on a set of rules. If no rules are provided, all the tags from the repository will be ordered and compared. status ImagePolicyStatus ImagePolicyChoice ( Appears on: ImagePolicySpec ) ImagePolicyChoice is a union of all the types of policy that can be supplied. Field Description semver SemVerPolicy (Optional) SemVer gives a semantic version range to check against the tags available. alphabetical AlphabeticalPolicy (Optional) Alphabetical set of rules to use for alphabetical ordering of the tags. ImagePolicySpec ( Appears on: ImagePolicy ) ImagePolicySpec defines the parameters for calculating the ImagePolicy Field Description imageRepositoryRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference ImageRepositoryRef points at the object specifying the image being scanned policy ImagePolicyChoice Policy gives the particulars of the policy to be followed in selecting the most recent image filterTags TagFilter (Optional) FilterTags enables filtering for only a subset of tags based on a set of rules. If no rules are provided, all the tags from the repository will be ordered and compared. ImagePolicyStatus ( Appears on: ImagePolicy ) ImagePolicyStatus defines the observed state of ImagePolicy Field Description latestImage string LatestImage gives the first in the list of images scanned by the image repository, when filtered and ordered according to the policy. observedGeneration int64 (Optional) conditions []Kubernetes meta/v1.Condition (Optional) ImageRepository ImageRepository is the Schema for the imagerepositories API Field Description metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec ImageRepositorySpec image string Image is the name of the image repository interval Kubernetes meta/v1.Duration Interval is the length of time to wait between scans of the image repository. timeout Kubernetes meta/v1.Duration (Optional) Timeout for image scanning. Defaults to \u2018Interval\u2019 duration. secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) SecretRef can be given the name of a secret containing credentials to use for the image registry. The secret should be created with kubectl create secret docker-registry , or the equivalent. certSecretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) CertSecretRef can be given the name of a secret containing either or both of a PEM-encoded client certificate ( certFile ) and private key ( keyFile ); a PEM-encoded CA certificate ( caFile ) and whichever are supplied, will be used for connecting to the registry. The client cert and key are useful if you are authenticating with a certificate; the CA cert is useful if you are using a self-signed server certificate. suspend bool (Optional) This flag tells the controller to suspend subsequent image scans. It does not apply to already started scans. Defaults to false. status ImageRepositoryStatus ImageRepositorySpec ( Appears on: ImageRepository ) ImageRepositorySpec defines the parameters for scanning an image repository, e.g., fluxcd/flux . Field Description image string Image is the name of the image repository interval Kubernetes meta/v1.Duration Interval is the length of time to wait between scans of the image repository. timeout Kubernetes meta/v1.Duration (Optional) Timeout for image scanning. Defaults to \u2018Interval\u2019 duration. secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) SecretRef can be given the name of a secret containing credentials to use for the image registry. The secret should be created with kubectl create secret docker-registry , or the equivalent. certSecretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) CertSecretRef can be given the name of a secret containing either or both of a PEM-encoded client certificate ( certFile ) and private key ( keyFile ); a PEM-encoded CA certificate ( caFile ) and whichever are supplied, will be used for connecting to the registry. The client cert and key are useful if you are authenticating with a certificate; the CA cert is useful if you are using a self-signed server certificate. suspend bool (Optional) This flag tells the controller to suspend subsequent image scans. It does not apply to already started scans. Defaults to false. ImageRepositoryStatus ( Appears on: ImageRepository ) ImageRepositoryStatus defines the observed state of ImageRepository Field Description conditions []Kubernetes meta/v1.Condition (Optional) observedGeneration int64 (Optional) ObservedGeneration is the last reconciled generation. canonicalImageName string (Optional) CanonicalName is the name of the image repository with all the implied bits made explicit; e.g., docker.io/library/alpine rather than alpine . lastScanResult ScanResult (Optional) LastScanResult contains the number of fetched tags. ReconcileRequestStatus github.com/fluxcd/pkg/apis/meta.ReconcileRequestStatus (Members of ReconcileRequestStatus are embedded into this type.) ScanResult ( Appears on: ImageRepositoryStatus ) Field Description tagCount int scanTime Kubernetes meta/v1.Time SemVerPolicy ( Appears on: ImagePolicyChoice ) SemVerPolicy specifices a semantic version policy. Field Description range string Range gives a semver range for the image tag; the highest version within the range that\u2019s a tag yields the latest image. TagFilter ( Appears on: ImagePolicySpec ) TagFilter enables filtering tags based on a set of defined rules Field Description pattern string (Optional) Pattern specifies a regular expression pattern used to filter for image tags. extract string (Optional) Extract allows a capture group to be extracted from the specified regular expression pattern, useful before tag evaluation. This page was automatically generated with gen-crd-api-reference-docs","title":"Reflector api"},{"location":"components/kustomize/api/","text":"Kustomize API reference Packages: kustomize.toolkit.fluxcd.io/v1beta1 kustomize.toolkit.fluxcd.io/v1beta1 Package v1beta1 contains API Schema definitions for the kustomize v1beta1 API group Resource Types: Kustomization Kustomization Kustomization is the Schema for the kustomizations API. Field Description apiVersion string kustomize.toolkit.fluxcd.io/v1beta1 kind string Kustomization metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec KustomizationSpec dependsOn []Runtime dependency.CrossNamespaceDependencyReference (Optional) DependsOn may contain a dependency.CrossNamespaceDependencyReference slice with references to Kustomization resources that must be ready before this Kustomization can be reconciled. decryption Decryption (Optional) Decrypt Kubernetes secrets before applying them on the cluster. interval Kubernetes meta/v1.Duration The interval at which to reconcile the Kustomization. retryInterval Kubernetes meta/v1.Duration (Optional) The interval at which to retry a previously failed reconciliation. When not specified, the controller uses the KustomizationSpec.Interval value to retry failures. kubeConfig KubeConfig (Optional) The KubeConfig for reconciling the Kustomization on a remote cluster. When specified, KubeConfig takes precedence over ServiceAccountName. path string (Optional) Path to the directory containing the kustomization.yaml file, or the set of plain YAMLs a kustomization.yaml should be generated for. Defaults to \u2018None\u2019, which translates to the root path of the SourceRef. postBuild PostBuild (Optional) PostBuild describes which actions to perform on the YAML manifest generated by building the kustomize overlay. prune bool Prune enables garbage collection. healthChecks []github.com/fluxcd/pkg/apis/meta.NamespacedObjectKindReference (Optional) A list of resources to be included in the health assessment. patchesStrategicMerge []Kubernetes pkg/apis/apiextensions/v1.JSON (Optional) Strategic merge patches, defined as inline YAML objects. patchesJson6902 []github.com/fluxcd/pkg/apis/kustomize.JSON6902Patch (Optional) JSON 6902 patches, defined as inline YAML objects. images []github.com/fluxcd/pkg/apis/kustomize.Image (Optional) Images is a list of (image name, new name, new tag or digest) for changing image names, tags or digests. This can also be achieved with a patch, but this operator is simpler to specify. serviceAccountName string (Optional) The name of the Kubernetes service account to impersonate when reconciling this Kustomization. sourceRef CrossNamespaceSourceReference Reference of the source where the kustomization file is. suspend bool (Optional) This flag tells the controller to suspend subsequent kustomize executions, it does not apply to already started executions. Defaults to false. targetNamespace string (Optional) TargetNamespace sets or overrides the namespace in the kustomization.yaml file. timeout Kubernetes meta/v1.Duration (Optional) Timeout for validation, apply and health checking operations. Defaults to \u2018Interval\u2019 duration. validation string (Optional) Validate the Kubernetes objects before applying them on the cluster. The validation strategy can be \u2018client\u2019 (local dry-run), \u2018server\u2019 (APIServer dry-run) or \u2018none\u2019. When \u2018Force\u2019 is \u2018true\u2019, validation will fallback to \u2018client\u2019 if set to \u2018server\u2019 because server-side validation is not supported in this scenario. force bool (Optional) Force instructs the controller to recreate resources when patching fails due to an immutable field change. status KustomizationStatus CrossNamespaceSourceReference ( Appears on: KustomizationSpec ) CrossNamespaceSourceReference contains enough information to let you locate the typed referenced object at cluster level Field Description apiVersion string (Optional) API version of the referent kind string Kind of the referent name string Name of the referent namespace string (Optional) Namespace of the referent, defaults to the Kustomization namespace Decryption ( Appears on: KustomizationSpec ) Decryption defines how decryption is handled for Kubernetes manifests. Field Description provider string Provider is the name of the decryption engine. secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) The secret name containing the private OpenPGP keys used for decryption. KubeConfig ( Appears on: KustomizationSpec ) KubeConfig references a Kubernetes secret that contains a kubeconfig file. Field Description secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference SecretRef holds the name to a secret that contains a \u2018value\u2019 key with the kubeconfig file as the value. It must be in the same namespace as the Kustomization. It is recommended that the kubeconfig is self-contained, and the secret is regularly updated if credentials such as a cloud-access-token expire. Cloud specific cmd-path auth helpers will not function without adding binaries and credentials to the Pod that is responsible for reconciling the Kustomization. KustomizationSpec ( Appears on: Kustomization ) KustomizationSpec defines the desired state of a kustomization. Field Description dependsOn []Runtime dependency.CrossNamespaceDependencyReference (Optional) DependsOn may contain a dependency.CrossNamespaceDependencyReference slice with references to Kustomization resources that must be ready before this Kustomization can be reconciled. decryption Decryption (Optional) Decrypt Kubernetes secrets before applying them on the cluster. interval Kubernetes meta/v1.Duration The interval at which to reconcile the Kustomization. retryInterval Kubernetes meta/v1.Duration (Optional) The interval at which to retry a previously failed reconciliation. When not specified, the controller uses the KustomizationSpec.Interval value to retry failures. kubeConfig KubeConfig (Optional) The KubeConfig for reconciling the Kustomization on a remote cluster. When specified, KubeConfig takes precedence over ServiceAccountName. path string (Optional) Path to the directory containing the kustomization.yaml file, or the set of plain YAMLs a kustomization.yaml should be generated for. Defaults to \u2018None\u2019, which translates to the root path of the SourceRef. postBuild PostBuild (Optional) PostBuild describes which actions to perform on the YAML manifest generated by building the kustomize overlay. prune bool Prune enables garbage collection. healthChecks []github.com/fluxcd/pkg/apis/meta.NamespacedObjectKindReference (Optional) A list of resources to be included in the health assessment. patchesStrategicMerge []Kubernetes pkg/apis/apiextensions/v1.JSON (Optional) Strategic merge patches, defined as inline YAML objects. patchesJson6902 []github.com/fluxcd/pkg/apis/kustomize.JSON6902Patch (Optional) JSON 6902 patches, defined as inline YAML objects. images []github.com/fluxcd/pkg/apis/kustomize.Image (Optional) Images is a list of (image name, new name, new tag or digest) for changing image names, tags or digests. This can also be achieved with a patch, but this operator is simpler to specify. serviceAccountName string (Optional) The name of the Kubernetes service account to impersonate when reconciling this Kustomization. sourceRef CrossNamespaceSourceReference Reference of the source where the kustomization file is. suspend bool (Optional) This flag tells the controller to suspend subsequent kustomize executions, it does not apply to already started executions. Defaults to false. targetNamespace string (Optional) TargetNamespace sets or overrides the namespace in the kustomization.yaml file. timeout Kubernetes meta/v1.Duration (Optional) Timeout for validation, apply and health checking operations. Defaults to \u2018Interval\u2019 duration. validation string (Optional) Validate the Kubernetes objects before applying them on the cluster. The validation strategy can be \u2018client\u2019 (local dry-run), \u2018server\u2019 (APIServer dry-run) or \u2018none\u2019. When \u2018Force\u2019 is \u2018true\u2019, validation will fallback to \u2018client\u2019 if set to \u2018server\u2019 because server-side validation is not supported in this scenario. force bool (Optional) Force instructs the controller to recreate resources when patching fails due to an immutable field change. KustomizationStatus ( Appears on: Kustomization ) KustomizationStatus defines the observed state of a kustomization. Field Description observedGeneration int64 (Optional) ObservedGeneration is the last reconciled generation. conditions []Kubernetes meta/v1.Condition (Optional) lastAppliedRevision string (Optional) The last successfully applied revision. The revision format for Git sources is / . lastAttemptedRevision string (Optional) LastAttemptedRevision is the revision of the last reconciliation attempt. ReconcileRequestStatus github.com/fluxcd/pkg/apis/meta.ReconcileRequestStatus (Members of ReconcileRequestStatus are embedded into this type.) snapshot Snapshot (Optional) The last successfully applied revision metadata. PostBuild ( Appears on: KustomizationSpec ) PostBuild describes which actions to perform on the YAML manifest generated by building the kustomize overlay. Field Description substitute map[string]string (Optional) Substitute holds a map of key/value pairs. The variables defined in your YAML manifests that match any of the keys defined in the map will be substituted with the set value. Includes support for bash string replacement functions e.g. ${var:=default}, ${var:position} and ${var/substring/replacement}. substituteFrom []SubstituteReference (Optional) SubstituteFrom holds references to ConfigMaps and Secrets containing the variables and their values to be substituted in the YAML manifests. The ConfigMap and the Secret data keys represent the var names and they must match the vars declared in the manifests for the substitution to happen. Snapshot ( Appears on: KustomizationStatus ) Snapshot holds the metadata of the Kubernetes objects generated for a source revision Field Description checksum string The manifests sha1 checksum. entries []SnapshotEntry A list of Kubernetes kinds grouped by namespace. SnapshotEntry ( Appears on: Snapshot ) Snapshot holds the metadata of namespaced Kubernetes objects Field Description namespace string (Optional) The namespace of this entry. kinds map[string]string The list of Kubernetes kinds. SubstituteReference ( Appears on: PostBuild ) SubstituteReference contains a reference to a resource containing the variables name and value. Field Description kind string Kind of the values referent, valid values are (\u2018Secret\u2019, \u2018ConfigMap\u2019). name string Name of the values referent. Should reside in the same namespace as the referring resource. This page was automatically generated with gen-crd-api-reference-docs","title":"Kustomize API Reference"},{"location":"components/kustomize/controller/","text":"Kustomize Controller \u00b6 The kustomize-controller is a Kubernetes operator, specialized in running continuous delivery pipelines for infrastructure and workloads defined with Kubernetes manifests and assembled with Kustomize. Features: Reconciles the cluster state from multiple sources (provided by source-controller) Generates manifests with Kustomize (from plain Kubernetes yamls or Kustomize overlays) Validates manifests against Kubernetes API Impersonates service accounts (multi-tenancy RBAC) Health assessment of the deployed workloads Runs pipelines in a specific order (depends-on relationship) Prunes objects removed from source (garbage collection) Reports cluster state changes (alerting provided by notification-controller) Links: Source code fluxcd/kustomize-controller Specification docs","title":"Overview"},{"location":"components/kustomize/controller/#kustomize-controller","text":"The kustomize-controller is a Kubernetes operator, specialized in running continuous delivery pipelines for infrastructure and workloads defined with Kubernetes manifests and assembled with Kustomize. Features: Reconciles the cluster state from multiple sources (provided by source-controller) Generates manifests with Kustomize (from plain Kubernetes yamls or Kustomize overlays) Validates manifests against Kubernetes API Impersonates service accounts (multi-tenancy RBAC) Health assessment of the deployed workloads Runs pipelines in a specific order (depends-on relationship) Prunes objects removed from source (garbage collection) Reports cluster state changes (alerting provided by notification-controller) Links: Source code fluxcd/kustomize-controller Specification docs","title":"Kustomize Controller"},{"location":"components/kustomize/kustomization/","text":"Kustomization \u00b6 The Kustomization API defines a pipeline for fetching, decrypting, building, validating and applying Kubernetes manifests. Specification \u00b6 A Kustomization object defines the source of Kubernetes manifests by referencing an object managed by source-controller , the path to the Kustomization file within that source, and the interval at which the kustomize build output is applied on the cluster. type KustomizationSpec struct { // DependsOn may contain a dependency.CrossNamespaceDependencyReference slice // with references to Kustomization resources that must be ready before this // Kustomization can be reconciled. // +optional DependsOn [] dependency . CrossNamespaceDependencyReference `json:\"dependsOn,omitempty\"` // Decrypt Kubernetes secrets before applying them on the cluster. // +optional Decryption * Decryption `json:\"decryption,omitempty\"` // The interval at which to reconcile the Kustomization. // +required Interval metav1 . Duration `json:\"interval\"` // The interval at which to retry a previously failed reconciliation. // When not specified, the controller uses the KustomizationSpec.Interval // value to retry failures. // +optional RetryInterval * metav1 . Duration `json:\"retryInterval,omitempty\"` // The KubeConfig for reconciling the Kustomization on a remote cluster. // When specified, KubeConfig takes precedence over ServiceAccountName. // +optional KubeConfig * KubeConfig `json:\"kubeConfig,omitempty\"` // Path to the directory containing the kustomization.yaml file, or the // set of plain YAMLs a kustomization.yaml should be generated for. // Defaults to 'None', which translates to the root path of the SourceRef. // +optional Path string `json:\"path,omitempty\"` // PostBuild describes which actions to perform on the YAML manifest // generated by building the kustomize overlay. // +optional PostBuild * PostBuild `json:\"postBuild,omitempty\"` // Enables garbage collection. // +required Prune bool `json:\"prune\"` // A list of resources to be included in the health assessment. // +optional HealthChecks [] meta . NamespacedObjectKindReference `json:\"healthChecks,omitempty\"` // Strategic merge patches, defined as inline YAML objects. // +optional PatchesStrategicMerge [] apiextensionsv1 . JSON `json:\"patchesStrategicMerge,omitempty\"` // JSON 6902 patches, defined as inline YAML objects. // +optional PatchesJSON6902 [] kustomize . JSON6902Patch `json:\"patchesJson6902,omitempty\"` // Images is a list of (image name, new name, new tag or digest) // for changing image names, tags or digests. This can also be achieved with a // patch, but this operator is simpler to specify. // +optional Images [] kustomize . Image `json:\"images,omitempty\"` // The name of the Kubernetes service account to impersonate // when reconciling this Kustomization. // +optional ServiceAccountName string `json:\"serviceAccountName,omitempty\"` // Reference of the source where the kustomization file is. // +required SourceRef CrossNamespaceSourceReference `json:\"sourceRef\"` // This flag tells the controller to suspend subsequent kustomize executions, // it does not apply to already started executions. Defaults to false. // +optional Suspend bool `json:\"suspend,omitempty\"` // TargetNamespace sets or overrides the namespace in the // kustomization.yaml file. // +optional TargetNamespace string `json:\"targetNamespace,omitempty\"` // Timeout for validation, apply and health checking operations. // Defaults to 'Interval' duration. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // Validate the Kubernetes objects before applying them on the cluster. // The validation strategy can be 'client' (local dry-run), 'server' (APIServer dry-run) or 'none'. // +kubebuilder:validation:Enum=none;client;server // +optional Validation string `json:\"validation,omitempty\"` // Force instructs the controller to recreate resources // when patching fails due to an immutable field change. // +kubebuilder:default:=false // +optional Force bool `json:\"force,omitempty\"` } The decryption section defines how decryption is handled for Kubernetes manifests: type Decryption struct { // Provider is the name of the decryption engine. // +kubebuilder:validation:Enum=sops // +required Provider string `json:\"provider\"` // The secret name containing the private OpenPGP keys used for decryption. // +optional SecretRef * meta . LocalObjectReference `json:\"secretRef,omitempty\"` } KubeConfig references a Kubernetes Secret for applying to another cluster. This can be used with Cluster API: type KubeConfig struct { // SecretRef holds the name to a secret that contains a 'value' key with // the kubeconfig file as the value. It must be in the same namespace as // the Kustomization. // It is recommended that the kubeconfig is self-contained, and the secret // is regularly updated if credentials such as a cloud-access-token expire. // Cloud specific `cmd-path` auth helpers will not function without adding // binaries and credentials to the Pod that is responsible for reconciling // the Kustomization. // +required SecretRef meta . LocalObjectReference `json:\"secretRef,omitempty\"` } Image contains the name, new name and new tag that will replace the original container image: type Image struct { // Name of the image to be replaced. // +required Name string `json:\"name\"` // NewName is the name of the image used to replace the original one. // +required NewName string `json:\"newName\"` // NewTag is the image tag used to replace the original tag. // +required NewTag string `json:\"newTag\"` } The post-build section defines which actions to perform on the YAML manifest after kustomize build: type PostBuild struct { // Substitute holds a map of key/value pairs. // The variables defined in your YAML manifests // that match any of the keys defined in the map // will be substituted with the set value. // Includes support for bash string replacement functions // e.g. ${var:=default}, ${var:position} and ${var/substring/replacement}. // +optional Substitute map [ string ] string `json:\"substitute,omitempty\"` // SubstituteFrom holds references to ConfigMaps and Secrets containing // the variables and their values to be substituted in the YAML manifests. // The ConfigMap and the Secret data keys represent the var names and they // must match the vars declared in the manifests for the substitution to happen. // +optional SubstituteFrom [] SubstituteReference `json:\"substituteFrom,omitempty\"` } The status sub-resource records the result of the last reconciliation: type KustomizationStatus struct { // ObservedGeneration is the last reconciled generation. // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // +optional Conditions [] metav1 . Condition `json:\"conditions,omitempty\"` // The last successfully applied revision. // The revision format for Git sources is <branch|tag>/<commit-sha>. // +optional LastAppliedRevision string `json:\"lastAppliedRevision,omitempty\"` // LastAttemptedRevision is the revision of the last reconciliation attempt. // +optional LastAttemptedRevision string `json:\"lastAttemptedRevision,omitempty\"` // LastHandledReconcileAt is the last manual reconciliation request (by // annotating the Kustomization) handled by the reconciler. // +optional LastHandledReconcileAt string `json:\"lastHandledReconcileAt,omitempty\"` // The last successfully applied revision metadata. // +optional Snapshot * Snapshot `json:\"snapshot\"` } Status condition types: const ( // ReadyCondition is the name of the condition that // records the readiness status of a Kustomization. ReadyCondition string = \"Ready\" ) Status condition reasons: const ( // ReconciliationSucceededReason represents the fact that the // reconciliation of the Kustomization has succeeded. ReconciliationSucceededReason string = \"ReconciliationSucceeded\" // ReconciliationFailedReason represents the fact that the // reconciliation of the Kustomization has failed. ReconciliationFailedReason string = \"ReconciliationFailed\" // ProgressingReason represents the fact that the // reconciliation of the Kustomization is underway. ProgressingReason string = \"Progressing\" // DependencyNotReady represents the fact that // one of the dependencies of the Kustomization is not ready. DependencyNotReadyReason string = \"DependencyNotReady\" // PruneFailedReason represents the fact that the // pruning of the Kustomization failed. PruneFailedReason string = \"PruneFailed\" // ArtifactFailedReason represents the fact that the // artifact download of the kustomization failed. ArtifactFailedReason string = \"ArtifactFailed\" // BuildFailedReason represents the fact that the // kustomize build of the Kustomization failed. BuildFailedReason string = \"BuildFailed\" // HealthCheckFailedReason represents the fact that // one of the health checks of the Kustomization failed. HealthCheckFailedReason string = \"HealthCheckFailed\" // ValidationFailedReason represents the fact that the // validation of the Kustomization manifests has failed. ValidationFailedReason string = \"ValidationFailed\" ) Source reference \u00b6 The Kustomization spec.sourceRef is a reference to an object managed by source-controller . When the source revision changes, it generates a Kubernetes event that triggers a kustomize build and apply. Source supported types: GitRepository Bucket Note that the source should contain the kustomization.yaml and all the Kubernetes manifests and configuration files referenced in the kustomization.yaml. If your Git repository or S3 bucket contains only plain manifests, then a kustomization.yaml will be automatically generated. Generate kustomization.yaml \u00b6 If your repository contains plain Kubernetes manifests, the kustomization.yaml file is automatically generated for all the Kubernetes manifests in the spec.path and sub-directories. This expects all YAML files present under that path to be valid kubernetes manifests and needs non-kubernetes ones to be excluded using .sourceignore file or spec.ignore on GitRepository object. Example of excluding CI workflows and SOPS config files: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 5m url : https://github.com/stefanprodan/podinfo ignore : | .git/ .github/ .sops.yaml .gitlab-ci.yml It is recommended to generate the kustomization.yaml on your own and store it in Git, this way you can validate your manifests in CI (example script here ). Assuming your manifests are inside ./clusters/my-cluster , you can generate a kustomization.yaml with: cd clusters/my-cluster # create kustomization kustomize create --autodetect --recursive # validate kustomization kustomize build | kubeval --ignore-missing-schemas Reconciliation \u00b6 The Kustomization spec.interval tells the controller at which interval to fetch the Kubernetes manifest for the source, build the Kustomization and apply it on the cluster. The interval time units are s , m and h e.g. interval: 5m , the minimum value should be over 60 seconds. The Kustomization execution can be suspended by setting spec.suspend to true . With spec.force you can tell the controller to replace the resources in-cluster if the patching fails due to immutable fields changes. The controller can be told to reconcile the Kustomization outside of the specified interval by annotating the Kustomization object with: const ( // ReconcileAtAnnotation is the annotation used for triggering a // reconciliation outside of the defined schedule. ReconcileAtAnnotation string = \"reconcile.fluxcd.io/requestedAt\" ) On-demand execution example: kubectl annotate --overwrite kustomization/podinfo reconcile.fluxcd.io/requestedAt = \" $( date +%s ) \" List all Kubernetes objects reconciled from a Kustomization: kubectl get all --all-namespaces \\ -l = kustomize.toolkit.fluxcd.io/name = \"<Kustomization name>\" \\ -l = kustomize.toolkit.fluxcd.io/namespace = \"<Kustomization namespace>\" Garbage collection \u00b6 To enable garbage collection, set spec.prune to true . Garbage collection means that the Kubernetes objects that were previously applied on the cluster but are missing from the current source revision, are removed from cluster automatically. Garbage collection is also performed when a Kustomization object is deleted, triggering a removal of all Kubernetes objects previously applied on the cluster. To keep track of the Kubernetes objects reconciled from a Kustomization, the following labels are injected into the manifests: labels : kustomize.toolkit.fluxcd.io/name : \"<Kustomization name>\" kustomize.toolkit.fluxcd.io/namespace : \"<Kustomization namespace>\" kustomize.toolkit.fluxcd.io/checksum : \"<manifests checksum>\" The checksum label value is updated if the content of spec.path changes. When pruning is disabled, the checksum label is omitted. You can disable pruning for certain resources by either labeling or annotating them with: kustomize.toolkit.fluxcd.io/prune : disabled Health assessment \u00b6 A Kustomization can contain a series of health checks used to determine the rollout status of the deployed workloads and the ready status of custom resources. A health check entry can reference one of the following types: Kubernetes builtin kinds: Deployment, DaemonSet, StatefulSet, PersistentVolumeClaim, Pod, PodDisruptionBudget, Job, CronJob, Service, Secret, ConfigMap, CustomResourceDefinition Toolkit kinds: HelmRelease, HelmRepository, GitRepository, etc Custom resources that are compatible with kstatus Assuming the Kustomization source contains a Kubernetes Deployment named backend , a health check can be defined as follows: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : backend namespace : default spec : interval : 5m path : \"./webapp/backend/\" prune : true sourceRef : kind : GitRepository name : webapp healthChecks : - apiVersion : apps/v1 kind : Deployment name : backend namespace : dev timeout : 2m After applying the kustomize build output, the controller verifies if the rollout completed successfully. If the deployment was successful, the Kustomization ready condition is marked as true , if the rollout failed, or if it takes more than the specified timeout to complete, then the Kustomization ready condition is set to false . If the deployment becomes healthy on the next execution, then the Kustomization is marked as ready. When a Kustomization contains HelmRelease objects, instead of checking the underling Deployments, you can define a health check that waits for the HelmReleases to be reconciled with: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : webapp namespace : default spec : interval : 15m path : \"./releases/\" prune : true sourceRef : kind : GitRepository name : webapp healthChecks : - apiVersion : helm.toolkit.fluxcd.io/v1beta1 kind : HelmRelease name : frontend namespace : dev - apiVersion : helm.toolkit.fluxcd.io/v1beta1 kind : HelmRelease name : backend namespace : dev timeout : 5m If all the HelmRelease objects are successfully installed or upgraded, then the Kustomization will be marked as ready. Kustomization dependencies \u00b6 When applying a Kustomization, you may need to make sure other resources exist before the workloads defined in your Kustomization are deployed. For example, a namespace must exist before applying resources to it. With spec.dependsOn you can specify that the execution of a Kustomization follows another. When you add dependsOn entries to a Kustomization, that Kustomization is applied only after all of its dependencies are ready. The readiness state of a Kustomization is determined by its last apply status condition. Assuming two Kustomizations: cert-manager - reconciles the cert-manager CRDs and controller certs - reconciles the cert-manager custom resources You can instruct the controller to apply the cert-manager Kustomization before certs : apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : cert-manager namespace : flux-system spec : interval : 5m path : \"./cert-manager/controller\" prune : true sourceRef : kind : GitRepository name : flux-system healthChecks : - apiVersion : apps/v1 kind : Deployment name : cert-manager namespace : cert-manager --- apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : certs namespace : flux-system spec : dependsOn : - name : cert-manager interval : 5m path : \"./cert-manager/certs\" prune : true sourceRef : kind : GitRepository name : flux-system When combined with health assessment, a Kustomization will run after all its dependencies health checks are passing. For example, a service mesh proxy injector should be running before deploying applications inside the mesh. Note that circular dependencies between Kustomizations must be avoided, otherwise the interdependent Kustomizations will never be applied on the cluster. Role-based access control \u00b6 By default, a Kustomization apply runs under the cluster admin account and can create, modify, delete cluster level objects (namespaces, CRDs, etc) and namespeced objects (deployments, ingresses, etc). For certain Kustomizations a cluster admin may wish to control what types of Kubernetes objects can be reconciled and under which namespaces. To restrict a Kustomization, one can assign a service account under which the reconciliation is performed. Assuming you want to restrict a group of Kustomizations to a single namespace, you can create an account with a role binding that grants access only to that namespace: apiVersion : v1 kind : Namespace metadata : name : webapp --- apiVersion : v1 kind : ServiceAccount metadata : name : webapp-reconciler namespace : webapp --- apiVersion : rbac.authorization.k8s.io/v1 kind : Role metadata : name : webapp-reconciler namespace : webapp rules : - apiGroups : [ '*' ] resources : [ '*' ] verbs : [ '*' ] --- apiVersion : rbac.authorization.k8s.io/v1 kind : RoleBinding metadata : name : webapp-reconciler namespace : webapp roleRef : apiGroup : rbac.authorization.k8s.io kind : Role name : webapp-reconciler subjects : - kind : ServiceAccount name : webapp-reconciler namespace : webapp Note that the namespace, RBAC and service account manifests should be placed in a Git source and applied with a Kustomization. The Kustomizations that are running under that service account should depend-on the one that contains the account. Create a Kustomization that prevents altering the cluster state outside of the webapp namespace: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : backend namespace : webapp spec : serviceAccountName : webapp-reconciler dependsOn : - name : common interval : 5m path : \"./webapp/backend/\" prune : true sourceRef : kind : GitRepository name : webapp When the controller reconciles the frontend-webapp Kustomization, it will impersonate the webapp-reconciler account. If the Kustomization contains cluster level objects like CRDs or objects belonging to a different namespace, the reconciliation will fail since the account it runs under has no permissions to alter objects outside of the webapp namespace. Override kustomize config \u00b6 The Kustomization has a set of fields to extend and/or override the Kustomize patches and namespace on all the Kubernetes objects reconciled by the resource, offering support for the following Kustomize directives: namespace patchesStrategicMerge patchesJson6902 images Target namespace \u00b6 To configure the Kustomize namespace and overwrite the namespace of all the Kubernetes objects reconciled by the Kustomization , spec.targetNamespace can be defined: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : flux-system spec : # ...omitted for brevity targetNamespace : test The targetNamespace is expected to exist. Strategic Merge patches \u00b6 To add Kustomize patchesStrategicMerge entries to the configuration, spec.patchesStrategicMerge can be defined with a list of strategic merge patches in YAML format: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : flux-system spec : # ...omitted for brevity patchesStrategicMerge : - apiVersion : apps/v1 kind : Deployment metadata : name : podinfo spec : template : spec : serviceAccount : custom-service-account JSON 6902 patches \u00b6 To add Kustomize patchesJson6902 entries to the configuration, and patch resources using the JSON 6902 standard , spec.patchesJson6902 , the items must contain a target selector and JSON 6902 patch document: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : flux-system spec : # ...omitted for brevity patchesJson6902 : - target : version : v1 kind : Deployment name : podinfo patch : - op : add path : /metadata/annotations/key value : value Images \u00b6 To add Kustomize images entries to the configuration, and overwrite the name, tag or digest of container images without creating patches, spec.images can be defined: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : flux-system spec : # ...omitted for brevity images : - name : podinfo newName : my-registry/podinfo newTag : v1 - name : podinfo newTag : 1.8.0 - name : podinfo newName : my-podinfo - name : podinfo digest : sha256:24a0c4b4a4c0eb97a1aabb8e29f18e917d05abfe1b7a7c07857230879ce7d3d3 Variable substitution \u00b6 With spec.postBuild.substitute you can provide a map of key/value pairs holding the variables to be substituted in the final YAML manifest, after kustomize build. With spec.postBuild.substituteFrom you can provide a list of ConfigMaps and Secrets from which the variables are loaded. The ConfigMap and Secret data keys are used as the var names. This offers basic templating for your manifests including support for bash string replacement functions e.g.: ${var:=default} ${var:position} ${var:position:length} ${var/substring/replacement} Assuming you have manifests with the following variables: apiVersion : v1 kind : Namespace metadata : name : apps labels : environment : ${cluster_env:=dev} region : \"${cluster_region}\" You can specify the variables and their values in the Kustomization definition under substitute and/or substituteFrom post build section: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : apps spec : interval : 5m path : \"./apps/\" postBuild : substitute : cluster_env : \"prod\" cluster_region : \"eu-central-1\" substituteFrom : - kind : ConfigMap name : cluster-vars - kind : Secret name : cluster-secret-vars The var values which are specified in-line with substitute take precedence over the ones in substituteFrom . Note that if you want to avoid var substitutions in scripts embedded in ConfigMaps or container commands, you must use the format $var instead of ${var} . All the undefined variables in the format ${var} will be substituted with string empty, unless a default is provided e.g. ${var:=default} . You can disable the variable substitution for certain resources by either labeling or annotating them with: kustomize.toolkit.fluxcd.io/substitute : disabled You can replicate the controller post-build substitutions locally using kustomize and Drone's envsubst : $ go install github.com/drone/envsubst/cmd/envsubst $ export cluster_region = eu-central-1 $ kustomize build ./apps/ | $GOPATH /bin/envsubst --- apiVersion: v1 kind: Namespace metadata: name: apps labels: environment: dev region: eu-central-1 Remote Clusters / Cluster-API \u00b6 If the kubeConfig field is set, objects will be applied, health-checked, pruned, and deleted for the default cluster specified in that KubeConfig instead of using the in-cluster ServiceAccount. The secret defined in the kubeConfig.SecretRef must exist in the same namespace as the Kustomization. On every reconciliation, the KubeConfig bytes will be loaded from the values key of the secret's data, and the secret can thus be regularly updated if cluster-access-tokens have to rotate due to expiration. This composes well with Cluster API bootstrap providers such as CAPBK (kubeadm) as well as the CAPA (AWS) EKS integration. To reconcile a Kustomization to a CAPI controlled cluster, put the Kustomization in the same namespace as your Cluster object, and set the kubeConfig.secretRef.name to <cluster-name>-kubeconfig : apiVersion : cluster.x-k8s.io/v1alpha3 kind : Cluster metadata : name : stage # the kubeconfig Secret will contain the Cluster name namespace : capi-stage spec : clusterNetwork : pods : cidrBlocks : - 10.100.0.0/16 serviceDomain : stage-cluster.local services : cidrBlocks : - 10.200.0.0/12 controlPlaneRef : apiVersion : controlplane.cluster.x-k8s.io/v1alpha3 kind : KubeadmControlPlane name : stage-control-plane namespace : capi-stage infrastructureRef : apiVersion : infrastructure.cluster.x-k8s.io/v1alpha3 kind : DockerCluster name : stage namespace : capi-stage --- # ... unrelated Cluster API objects omitted for brevity ... --- apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : cluster-addons namespace : capi-stage spec : interval : 5m path : \"./config/addons/\" prune : true sourceRef : kind : GitRepository name : cluster-addons kubeConfig : secretRef : name : stage-kubeconfig # Cluster API creates this for the matching Cluster The Cluster and Kustomization can be created at the same time. The Kustomization will eventually reconcile once the cluster is available. If you wish to target clusters created by other means than CAPI, you can create a ServiceAccount on the remote cluster, generate a KubeConfig for that account, and then create a secret on the cluster where kustomize-controller is running e.g.: kubectl create secret generic prod-kubeconfig \\ --from-file = value = ./kubeconfig Note that the KubeConfig should be self-contained and not rely on binaries, environment, or credential files from the kustomize-controller Pod. This matches the constraints of KubeConfigs from current Cluster API providers. KubeConfigs with cmd-path in them likely won't work without a custom, per-provider installation of kustomize-controller. Secrets decryption \u00b6 In order to store secrets safely in a public or private Git repository, you can use Mozilla SOPS and encrypt your Kubernetes Secrets data with OpenPGP keys. Generate a GPG key without passphrase using gnupg then use sops to encrypt a Kubernetes secret: sops --pgp = FBC7B9E2A4F9289AC0C1D4843D16CEE4A27381B4 \\ --encrypt --encrypted-regex '^(data|stringData)$' --in-place my-secret.yaml Commit and push the encrypted file to Git. Note that you should encrypt only the data section, encrypting the Kubernetes secret metadata, kind or apiVersion is not supported by kustomize-controller. Create a secret in the default namespace with the OpenPGP private key: gpg --export-secret-keys --armor FBC7B9E2A4F9289AC0C1D4843D16CEE4A27381B4 | kubectl -n default create secret generic sops-gpg \\ --from-file = sops.asc = /dev/stdin Configure decryption by referring the private key secret: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : my-secrets namespace : default spec : interval : 5m path : \"./\" sourceRef : kind : GitRepository name : my-secrets decryption : provider : sops secretRef : name : sops-pgp Status \u00b6 When the controller completes a Kustomization apply, reports the result in the status sub-resource. A successful reconciliation sets the ready condition to true and updates the revision field: status : conditions : - lastTransitionTime : \"2020-09-17T19:28:48Z\" message : \"Applied revision: master/a1afe267b54f38b46b487f6e938a6fd508278c07\" reason : ReconciliationSucceeded status : \"True\" type : Ready lastAppliedRevision : master/a1afe267b54f38b46b487f6e938a6fd508278c07 lastAttemptedRevision : master/a1afe267b54f38b46b487f6e938a6fd508278c07 You can wait for the kustomize controller to complete a reconciliation with: kubectl wait kustomization/backend --for = condition = ready The controller logs the Kubernetes objects: { \"level\" : \"info\" , \"ts\" : \"2020-09-17T07:27:11.921Z\" , \"logger\" : \"controllers.Kustomization\" , \"msg\" : \"Kustomization applied in 1.436096591s\" , \"kustomization\" : \"default/backend\" , \"output\" : { \"service/backend\" : \"created\" , \"deployment.apps/backend\" : \"created\" , \"horizontalpodautoscaler.autoscaling/backend\" : \"created\" } } A failed reconciliation sets the ready condition to false : status : conditions : - lastTransitionTime : \"2020-09-17T07:26:48Z\" message : \"The Service 'backend' is invalid: spec.type: Unsupported value: 'Ingress'\" reason : ValidationFailed status : \"False\" type : Ready lastAppliedRevision : master/a1afe267b54f38b46b487f6e938a6fd508278c07 lastAttemptedRevision : master/7c500d302e38e7e4a3f327343a8a5c21acaaeb87 Note that the last applied revision is updated only on a successful reconciliation. When a reconciliation fails, the controller logs the error and issues a Kubernetes event: { \"level\" : \"error\" , \"ts\" : \"2020-09-17T07:27:11.921Z\" , \"logger\" : \"controllers.Kustomization\" , \"kustomization\" : \"default/backend\" , \"error\" : \"The Service 'backend' is invalid: spec.type: Unsupported value: 'Ingress'\" }","title":"Kustomization CRD"},{"location":"components/kustomize/kustomization/#kustomization","text":"The Kustomization API defines a pipeline for fetching, decrypting, building, validating and applying Kubernetes manifests.","title":"Kustomization"},{"location":"components/kustomize/kustomization/#specification","text":"A Kustomization object defines the source of Kubernetes manifests by referencing an object managed by source-controller , the path to the Kustomization file within that source, and the interval at which the kustomize build output is applied on the cluster. type KustomizationSpec struct { // DependsOn may contain a dependency.CrossNamespaceDependencyReference slice // with references to Kustomization resources that must be ready before this // Kustomization can be reconciled. // +optional DependsOn [] dependency . CrossNamespaceDependencyReference `json:\"dependsOn,omitempty\"` // Decrypt Kubernetes secrets before applying them on the cluster. // +optional Decryption * Decryption `json:\"decryption,omitempty\"` // The interval at which to reconcile the Kustomization. // +required Interval metav1 . Duration `json:\"interval\"` // The interval at which to retry a previously failed reconciliation. // When not specified, the controller uses the KustomizationSpec.Interval // value to retry failures. // +optional RetryInterval * metav1 . Duration `json:\"retryInterval,omitempty\"` // The KubeConfig for reconciling the Kustomization on a remote cluster. // When specified, KubeConfig takes precedence over ServiceAccountName. // +optional KubeConfig * KubeConfig `json:\"kubeConfig,omitempty\"` // Path to the directory containing the kustomization.yaml file, or the // set of plain YAMLs a kustomization.yaml should be generated for. // Defaults to 'None', which translates to the root path of the SourceRef. // +optional Path string `json:\"path,omitempty\"` // PostBuild describes which actions to perform on the YAML manifest // generated by building the kustomize overlay. // +optional PostBuild * PostBuild `json:\"postBuild,omitempty\"` // Enables garbage collection. // +required Prune bool `json:\"prune\"` // A list of resources to be included in the health assessment. // +optional HealthChecks [] meta . NamespacedObjectKindReference `json:\"healthChecks,omitempty\"` // Strategic merge patches, defined as inline YAML objects. // +optional PatchesStrategicMerge [] apiextensionsv1 . JSON `json:\"patchesStrategicMerge,omitempty\"` // JSON 6902 patches, defined as inline YAML objects. // +optional PatchesJSON6902 [] kustomize . JSON6902Patch `json:\"patchesJson6902,omitempty\"` // Images is a list of (image name, new name, new tag or digest) // for changing image names, tags or digests. This can also be achieved with a // patch, but this operator is simpler to specify. // +optional Images [] kustomize . Image `json:\"images,omitempty\"` // The name of the Kubernetes service account to impersonate // when reconciling this Kustomization. // +optional ServiceAccountName string `json:\"serviceAccountName,omitempty\"` // Reference of the source where the kustomization file is. // +required SourceRef CrossNamespaceSourceReference `json:\"sourceRef\"` // This flag tells the controller to suspend subsequent kustomize executions, // it does not apply to already started executions. Defaults to false. // +optional Suspend bool `json:\"suspend,omitempty\"` // TargetNamespace sets or overrides the namespace in the // kustomization.yaml file. // +optional TargetNamespace string `json:\"targetNamespace,omitempty\"` // Timeout for validation, apply and health checking operations. // Defaults to 'Interval' duration. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // Validate the Kubernetes objects before applying them on the cluster. // The validation strategy can be 'client' (local dry-run), 'server' (APIServer dry-run) or 'none'. // +kubebuilder:validation:Enum=none;client;server // +optional Validation string `json:\"validation,omitempty\"` // Force instructs the controller to recreate resources // when patching fails due to an immutable field change. // +kubebuilder:default:=false // +optional Force bool `json:\"force,omitempty\"` } The decryption section defines how decryption is handled for Kubernetes manifests: type Decryption struct { // Provider is the name of the decryption engine. // +kubebuilder:validation:Enum=sops // +required Provider string `json:\"provider\"` // The secret name containing the private OpenPGP keys used for decryption. // +optional SecretRef * meta . LocalObjectReference `json:\"secretRef,omitempty\"` } KubeConfig references a Kubernetes Secret for applying to another cluster. This can be used with Cluster API: type KubeConfig struct { // SecretRef holds the name to a secret that contains a 'value' key with // the kubeconfig file as the value. It must be in the same namespace as // the Kustomization. // It is recommended that the kubeconfig is self-contained, and the secret // is regularly updated if credentials such as a cloud-access-token expire. // Cloud specific `cmd-path` auth helpers will not function without adding // binaries and credentials to the Pod that is responsible for reconciling // the Kustomization. // +required SecretRef meta . LocalObjectReference `json:\"secretRef,omitempty\"` } Image contains the name, new name and new tag that will replace the original container image: type Image struct { // Name of the image to be replaced. // +required Name string `json:\"name\"` // NewName is the name of the image used to replace the original one. // +required NewName string `json:\"newName\"` // NewTag is the image tag used to replace the original tag. // +required NewTag string `json:\"newTag\"` } The post-build section defines which actions to perform on the YAML manifest after kustomize build: type PostBuild struct { // Substitute holds a map of key/value pairs. // The variables defined in your YAML manifests // that match any of the keys defined in the map // will be substituted with the set value. // Includes support for bash string replacement functions // e.g. ${var:=default}, ${var:position} and ${var/substring/replacement}. // +optional Substitute map [ string ] string `json:\"substitute,omitempty\"` // SubstituteFrom holds references to ConfigMaps and Secrets containing // the variables and their values to be substituted in the YAML manifests. // The ConfigMap and the Secret data keys represent the var names and they // must match the vars declared in the manifests for the substitution to happen. // +optional SubstituteFrom [] SubstituteReference `json:\"substituteFrom,omitempty\"` } The status sub-resource records the result of the last reconciliation: type KustomizationStatus struct { // ObservedGeneration is the last reconciled generation. // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // +optional Conditions [] metav1 . Condition `json:\"conditions,omitempty\"` // The last successfully applied revision. // The revision format for Git sources is <branch|tag>/<commit-sha>. // +optional LastAppliedRevision string `json:\"lastAppliedRevision,omitempty\"` // LastAttemptedRevision is the revision of the last reconciliation attempt. // +optional LastAttemptedRevision string `json:\"lastAttemptedRevision,omitempty\"` // LastHandledReconcileAt is the last manual reconciliation request (by // annotating the Kustomization) handled by the reconciler. // +optional LastHandledReconcileAt string `json:\"lastHandledReconcileAt,omitempty\"` // The last successfully applied revision metadata. // +optional Snapshot * Snapshot `json:\"snapshot\"` } Status condition types: const ( // ReadyCondition is the name of the condition that // records the readiness status of a Kustomization. ReadyCondition string = \"Ready\" ) Status condition reasons: const ( // ReconciliationSucceededReason represents the fact that the // reconciliation of the Kustomization has succeeded. ReconciliationSucceededReason string = \"ReconciliationSucceeded\" // ReconciliationFailedReason represents the fact that the // reconciliation of the Kustomization has failed. ReconciliationFailedReason string = \"ReconciliationFailed\" // ProgressingReason represents the fact that the // reconciliation of the Kustomization is underway. ProgressingReason string = \"Progressing\" // DependencyNotReady represents the fact that // one of the dependencies of the Kustomization is not ready. DependencyNotReadyReason string = \"DependencyNotReady\" // PruneFailedReason represents the fact that the // pruning of the Kustomization failed. PruneFailedReason string = \"PruneFailed\" // ArtifactFailedReason represents the fact that the // artifact download of the kustomization failed. ArtifactFailedReason string = \"ArtifactFailed\" // BuildFailedReason represents the fact that the // kustomize build of the Kustomization failed. BuildFailedReason string = \"BuildFailed\" // HealthCheckFailedReason represents the fact that // one of the health checks of the Kustomization failed. HealthCheckFailedReason string = \"HealthCheckFailed\" // ValidationFailedReason represents the fact that the // validation of the Kustomization manifests has failed. ValidationFailedReason string = \"ValidationFailed\" )","title":"Specification"},{"location":"components/kustomize/kustomization/#source-reference","text":"The Kustomization spec.sourceRef is a reference to an object managed by source-controller . When the source revision changes, it generates a Kubernetes event that triggers a kustomize build and apply. Source supported types: GitRepository Bucket Note that the source should contain the kustomization.yaml and all the Kubernetes manifests and configuration files referenced in the kustomization.yaml. If your Git repository or S3 bucket contains only plain manifests, then a kustomization.yaml will be automatically generated.","title":"Source reference"},{"location":"components/kustomize/kustomization/#generate-kustomizationyaml","text":"If your repository contains plain Kubernetes manifests, the kustomization.yaml file is automatically generated for all the Kubernetes manifests in the spec.path and sub-directories. This expects all YAML files present under that path to be valid kubernetes manifests and needs non-kubernetes ones to be excluded using .sourceignore file or spec.ignore on GitRepository object. Example of excluding CI workflows and SOPS config files: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 5m url : https://github.com/stefanprodan/podinfo ignore : | .git/ .github/ .sops.yaml .gitlab-ci.yml It is recommended to generate the kustomization.yaml on your own and store it in Git, this way you can validate your manifests in CI (example script here ). Assuming your manifests are inside ./clusters/my-cluster , you can generate a kustomization.yaml with: cd clusters/my-cluster # create kustomization kustomize create --autodetect --recursive # validate kustomization kustomize build | kubeval --ignore-missing-schemas","title":"Generate kustomization.yaml"},{"location":"components/kustomize/kustomization/#reconciliation","text":"The Kustomization spec.interval tells the controller at which interval to fetch the Kubernetes manifest for the source, build the Kustomization and apply it on the cluster. The interval time units are s , m and h e.g. interval: 5m , the minimum value should be over 60 seconds. The Kustomization execution can be suspended by setting spec.suspend to true . With spec.force you can tell the controller to replace the resources in-cluster if the patching fails due to immutable fields changes. The controller can be told to reconcile the Kustomization outside of the specified interval by annotating the Kustomization object with: const ( // ReconcileAtAnnotation is the annotation used for triggering a // reconciliation outside of the defined schedule. ReconcileAtAnnotation string = \"reconcile.fluxcd.io/requestedAt\" ) On-demand execution example: kubectl annotate --overwrite kustomization/podinfo reconcile.fluxcd.io/requestedAt = \" $( date +%s ) \" List all Kubernetes objects reconciled from a Kustomization: kubectl get all --all-namespaces \\ -l = kustomize.toolkit.fluxcd.io/name = \"<Kustomization name>\" \\ -l = kustomize.toolkit.fluxcd.io/namespace = \"<Kustomization namespace>\"","title":"Reconciliation"},{"location":"components/kustomize/kustomization/#garbage-collection","text":"To enable garbage collection, set spec.prune to true . Garbage collection means that the Kubernetes objects that were previously applied on the cluster but are missing from the current source revision, are removed from cluster automatically. Garbage collection is also performed when a Kustomization object is deleted, triggering a removal of all Kubernetes objects previously applied on the cluster. To keep track of the Kubernetes objects reconciled from a Kustomization, the following labels are injected into the manifests: labels : kustomize.toolkit.fluxcd.io/name : \"<Kustomization name>\" kustomize.toolkit.fluxcd.io/namespace : \"<Kustomization namespace>\" kustomize.toolkit.fluxcd.io/checksum : \"<manifests checksum>\" The checksum label value is updated if the content of spec.path changes. When pruning is disabled, the checksum label is omitted. You can disable pruning for certain resources by either labeling or annotating them with: kustomize.toolkit.fluxcd.io/prune : disabled","title":"Garbage collection"},{"location":"components/kustomize/kustomization/#health-assessment","text":"A Kustomization can contain a series of health checks used to determine the rollout status of the deployed workloads and the ready status of custom resources. A health check entry can reference one of the following types: Kubernetes builtin kinds: Deployment, DaemonSet, StatefulSet, PersistentVolumeClaim, Pod, PodDisruptionBudget, Job, CronJob, Service, Secret, ConfigMap, CustomResourceDefinition Toolkit kinds: HelmRelease, HelmRepository, GitRepository, etc Custom resources that are compatible with kstatus Assuming the Kustomization source contains a Kubernetes Deployment named backend , a health check can be defined as follows: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : backend namespace : default spec : interval : 5m path : \"./webapp/backend/\" prune : true sourceRef : kind : GitRepository name : webapp healthChecks : - apiVersion : apps/v1 kind : Deployment name : backend namespace : dev timeout : 2m After applying the kustomize build output, the controller verifies if the rollout completed successfully. If the deployment was successful, the Kustomization ready condition is marked as true , if the rollout failed, or if it takes more than the specified timeout to complete, then the Kustomization ready condition is set to false . If the deployment becomes healthy on the next execution, then the Kustomization is marked as ready. When a Kustomization contains HelmRelease objects, instead of checking the underling Deployments, you can define a health check that waits for the HelmReleases to be reconciled with: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : webapp namespace : default spec : interval : 15m path : \"./releases/\" prune : true sourceRef : kind : GitRepository name : webapp healthChecks : - apiVersion : helm.toolkit.fluxcd.io/v1beta1 kind : HelmRelease name : frontend namespace : dev - apiVersion : helm.toolkit.fluxcd.io/v1beta1 kind : HelmRelease name : backend namespace : dev timeout : 5m If all the HelmRelease objects are successfully installed or upgraded, then the Kustomization will be marked as ready.","title":"Health assessment"},{"location":"components/kustomize/kustomization/#kustomization-dependencies","text":"When applying a Kustomization, you may need to make sure other resources exist before the workloads defined in your Kustomization are deployed. For example, a namespace must exist before applying resources to it. With spec.dependsOn you can specify that the execution of a Kustomization follows another. When you add dependsOn entries to a Kustomization, that Kustomization is applied only after all of its dependencies are ready. The readiness state of a Kustomization is determined by its last apply status condition. Assuming two Kustomizations: cert-manager - reconciles the cert-manager CRDs and controller certs - reconciles the cert-manager custom resources You can instruct the controller to apply the cert-manager Kustomization before certs : apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : cert-manager namespace : flux-system spec : interval : 5m path : \"./cert-manager/controller\" prune : true sourceRef : kind : GitRepository name : flux-system healthChecks : - apiVersion : apps/v1 kind : Deployment name : cert-manager namespace : cert-manager --- apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : certs namespace : flux-system spec : dependsOn : - name : cert-manager interval : 5m path : \"./cert-manager/certs\" prune : true sourceRef : kind : GitRepository name : flux-system When combined with health assessment, a Kustomization will run after all its dependencies health checks are passing. For example, a service mesh proxy injector should be running before deploying applications inside the mesh. Note that circular dependencies between Kustomizations must be avoided, otherwise the interdependent Kustomizations will never be applied on the cluster.","title":"Kustomization dependencies"},{"location":"components/kustomize/kustomization/#role-based-access-control","text":"By default, a Kustomization apply runs under the cluster admin account and can create, modify, delete cluster level objects (namespaces, CRDs, etc) and namespeced objects (deployments, ingresses, etc). For certain Kustomizations a cluster admin may wish to control what types of Kubernetes objects can be reconciled and under which namespaces. To restrict a Kustomization, one can assign a service account under which the reconciliation is performed. Assuming you want to restrict a group of Kustomizations to a single namespace, you can create an account with a role binding that grants access only to that namespace: apiVersion : v1 kind : Namespace metadata : name : webapp --- apiVersion : v1 kind : ServiceAccount metadata : name : webapp-reconciler namespace : webapp --- apiVersion : rbac.authorization.k8s.io/v1 kind : Role metadata : name : webapp-reconciler namespace : webapp rules : - apiGroups : [ '*' ] resources : [ '*' ] verbs : [ '*' ] --- apiVersion : rbac.authorization.k8s.io/v1 kind : RoleBinding metadata : name : webapp-reconciler namespace : webapp roleRef : apiGroup : rbac.authorization.k8s.io kind : Role name : webapp-reconciler subjects : - kind : ServiceAccount name : webapp-reconciler namespace : webapp Note that the namespace, RBAC and service account manifests should be placed in a Git source and applied with a Kustomization. The Kustomizations that are running under that service account should depend-on the one that contains the account. Create a Kustomization that prevents altering the cluster state outside of the webapp namespace: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : backend namespace : webapp spec : serviceAccountName : webapp-reconciler dependsOn : - name : common interval : 5m path : \"./webapp/backend/\" prune : true sourceRef : kind : GitRepository name : webapp When the controller reconciles the frontend-webapp Kustomization, it will impersonate the webapp-reconciler account. If the Kustomization contains cluster level objects like CRDs or objects belonging to a different namespace, the reconciliation will fail since the account it runs under has no permissions to alter objects outside of the webapp namespace.","title":"Role-based access control"},{"location":"components/kustomize/kustomization/#override-kustomize-config","text":"The Kustomization has a set of fields to extend and/or override the Kustomize patches and namespace on all the Kubernetes objects reconciled by the resource, offering support for the following Kustomize directives: namespace patchesStrategicMerge patchesJson6902 images","title":"Override kustomize config"},{"location":"components/kustomize/kustomization/#target-namespace","text":"To configure the Kustomize namespace and overwrite the namespace of all the Kubernetes objects reconciled by the Kustomization , spec.targetNamespace can be defined: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : flux-system spec : # ...omitted for brevity targetNamespace : test The targetNamespace is expected to exist.","title":"Target namespace"},{"location":"components/kustomize/kustomization/#strategic-merge-patches","text":"To add Kustomize patchesStrategicMerge entries to the configuration, spec.patchesStrategicMerge can be defined with a list of strategic merge patches in YAML format: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : flux-system spec : # ...omitted for brevity patchesStrategicMerge : - apiVersion : apps/v1 kind : Deployment metadata : name : podinfo spec : template : spec : serviceAccount : custom-service-account","title":"Strategic Merge patches"},{"location":"components/kustomize/kustomization/#json-6902-patches","text":"To add Kustomize patchesJson6902 entries to the configuration, and patch resources using the JSON 6902 standard , spec.patchesJson6902 , the items must contain a target selector and JSON 6902 patch document: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : flux-system spec : # ...omitted for brevity patchesJson6902 : - target : version : v1 kind : Deployment name : podinfo patch : - op : add path : /metadata/annotations/key value : value","title":"JSON 6902 patches"},{"location":"components/kustomize/kustomization/#images","text":"To add Kustomize images entries to the configuration, and overwrite the name, tag or digest of container images without creating patches, spec.images can be defined: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : flux-system spec : # ...omitted for brevity images : - name : podinfo newName : my-registry/podinfo newTag : v1 - name : podinfo newTag : 1.8.0 - name : podinfo newName : my-podinfo - name : podinfo digest : sha256:24a0c4b4a4c0eb97a1aabb8e29f18e917d05abfe1b7a7c07857230879ce7d3d3","title":"Images"},{"location":"components/kustomize/kustomization/#variable-substitution","text":"With spec.postBuild.substitute you can provide a map of key/value pairs holding the variables to be substituted in the final YAML manifest, after kustomize build. With spec.postBuild.substituteFrom you can provide a list of ConfigMaps and Secrets from which the variables are loaded. The ConfigMap and Secret data keys are used as the var names. This offers basic templating for your manifests including support for bash string replacement functions e.g.: ${var:=default} ${var:position} ${var:position:length} ${var/substring/replacement} Assuming you have manifests with the following variables: apiVersion : v1 kind : Namespace metadata : name : apps labels : environment : ${cluster_env:=dev} region : \"${cluster_region}\" You can specify the variables and their values in the Kustomization definition under substitute and/or substituteFrom post build section: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : apps spec : interval : 5m path : \"./apps/\" postBuild : substitute : cluster_env : \"prod\" cluster_region : \"eu-central-1\" substituteFrom : - kind : ConfigMap name : cluster-vars - kind : Secret name : cluster-secret-vars The var values which are specified in-line with substitute take precedence over the ones in substituteFrom . Note that if you want to avoid var substitutions in scripts embedded in ConfigMaps or container commands, you must use the format $var instead of ${var} . All the undefined variables in the format ${var} will be substituted with string empty, unless a default is provided e.g. ${var:=default} . You can disable the variable substitution for certain resources by either labeling or annotating them with: kustomize.toolkit.fluxcd.io/substitute : disabled You can replicate the controller post-build substitutions locally using kustomize and Drone's envsubst : $ go install github.com/drone/envsubst/cmd/envsubst $ export cluster_region = eu-central-1 $ kustomize build ./apps/ | $GOPATH /bin/envsubst --- apiVersion: v1 kind: Namespace metadata: name: apps labels: environment: dev region: eu-central-1","title":"Variable substitution"},{"location":"components/kustomize/kustomization/#remote-clusters-cluster-api","text":"If the kubeConfig field is set, objects will be applied, health-checked, pruned, and deleted for the default cluster specified in that KubeConfig instead of using the in-cluster ServiceAccount. The secret defined in the kubeConfig.SecretRef must exist in the same namespace as the Kustomization. On every reconciliation, the KubeConfig bytes will be loaded from the values key of the secret's data, and the secret can thus be regularly updated if cluster-access-tokens have to rotate due to expiration. This composes well with Cluster API bootstrap providers such as CAPBK (kubeadm) as well as the CAPA (AWS) EKS integration. To reconcile a Kustomization to a CAPI controlled cluster, put the Kustomization in the same namespace as your Cluster object, and set the kubeConfig.secretRef.name to <cluster-name>-kubeconfig : apiVersion : cluster.x-k8s.io/v1alpha3 kind : Cluster metadata : name : stage # the kubeconfig Secret will contain the Cluster name namespace : capi-stage spec : clusterNetwork : pods : cidrBlocks : - 10.100.0.0/16 serviceDomain : stage-cluster.local services : cidrBlocks : - 10.200.0.0/12 controlPlaneRef : apiVersion : controlplane.cluster.x-k8s.io/v1alpha3 kind : KubeadmControlPlane name : stage-control-plane namespace : capi-stage infrastructureRef : apiVersion : infrastructure.cluster.x-k8s.io/v1alpha3 kind : DockerCluster name : stage namespace : capi-stage --- # ... unrelated Cluster API objects omitted for brevity ... --- apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : cluster-addons namespace : capi-stage spec : interval : 5m path : \"./config/addons/\" prune : true sourceRef : kind : GitRepository name : cluster-addons kubeConfig : secretRef : name : stage-kubeconfig # Cluster API creates this for the matching Cluster The Cluster and Kustomization can be created at the same time. The Kustomization will eventually reconcile once the cluster is available. If you wish to target clusters created by other means than CAPI, you can create a ServiceAccount on the remote cluster, generate a KubeConfig for that account, and then create a secret on the cluster where kustomize-controller is running e.g.: kubectl create secret generic prod-kubeconfig \\ --from-file = value = ./kubeconfig Note that the KubeConfig should be self-contained and not rely on binaries, environment, or credential files from the kustomize-controller Pod. This matches the constraints of KubeConfigs from current Cluster API providers. KubeConfigs with cmd-path in them likely won't work without a custom, per-provider installation of kustomize-controller.","title":"Remote Clusters / Cluster-API"},{"location":"components/kustomize/kustomization/#secrets-decryption","text":"In order to store secrets safely in a public or private Git repository, you can use Mozilla SOPS and encrypt your Kubernetes Secrets data with OpenPGP keys. Generate a GPG key without passphrase using gnupg then use sops to encrypt a Kubernetes secret: sops --pgp = FBC7B9E2A4F9289AC0C1D4843D16CEE4A27381B4 \\ --encrypt --encrypted-regex '^(data|stringData)$' --in-place my-secret.yaml Commit and push the encrypted file to Git. Note that you should encrypt only the data section, encrypting the Kubernetes secret metadata, kind or apiVersion is not supported by kustomize-controller. Create a secret in the default namespace with the OpenPGP private key: gpg --export-secret-keys --armor FBC7B9E2A4F9289AC0C1D4843D16CEE4A27381B4 | kubectl -n default create secret generic sops-gpg \\ --from-file = sops.asc = /dev/stdin Configure decryption by referring the private key secret: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : my-secrets namespace : default spec : interval : 5m path : \"./\" sourceRef : kind : GitRepository name : my-secrets decryption : provider : sops secretRef : name : sops-pgp","title":"Secrets decryption"},{"location":"components/kustomize/kustomization/#status","text":"When the controller completes a Kustomization apply, reports the result in the status sub-resource. A successful reconciliation sets the ready condition to true and updates the revision field: status : conditions : - lastTransitionTime : \"2020-09-17T19:28:48Z\" message : \"Applied revision: master/a1afe267b54f38b46b487f6e938a6fd508278c07\" reason : ReconciliationSucceeded status : \"True\" type : Ready lastAppliedRevision : master/a1afe267b54f38b46b487f6e938a6fd508278c07 lastAttemptedRevision : master/a1afe267b54f38b46b487f6e938a6fd508278c07 You can wait for the kustomize controller to complete a reconciliation with: kubectl wait kustomization/backend --for = condition = ready The controller logs the Kubernetes objects: { \"level\" : \"info\" , \"ts\" : \"2020-09-17T07:27:11.921Z\" , \"logger\" : \"controllers.Kustomization\" , \"msg\" : \"Kustomization applied in 1.436096591s\" , \"kustomization\" : \"default/backend\" , \"output\" : { \"service/backend\" : \"created\" , \"deployment.apps/backend\" : \"created\" , \"horizontalpodautoscaler.autoscaling/backend\" : \"created\" } } A failed reconciliation sets the ready condition to false : status : conditions : - lastTransitionTime : \"2020-09-17T07:26:48Z\" message : \"The Service 'backend' is invalid: spec.type: Unsupported value: 'Ingress'\" reason : ValidationFailed status : \"False\" type : Ready lastAppliedRevision : master/a1afe267b54f38b46b487f6e938a6fd508278c07 lastAttemptedRevision : master/7c500d302e38e7e4a3f327343a8a5c21acaaeb87 Note that the last applied revision is updated only on a successful reconciliation. When a reconciliation fails, the controller logs the error and issues a Kubernetes event: { \"level\" : \"error\" , \"ts\" : \"2020-09-17T07:27:11.921Z\" , \"logger\" : \"controllers.Kustomization\" , \"kustomization\" : \"default/backend\" , \"error\" : \"The Service 'backend' is invalid: spec.type: Unsupported value: 'Ingress'\" }","title":"Status"},{"location":"components/notification/alert/","text":"Alert \u00b6 The Alert API defines how events are filtered by severity and involved object, and what provider to use for dispatching. Specification \u00b6 Spec: type AlertSpec struct { // Send events using this provider. // +required ProviderRef meta . LocalObjectReference `json:\"providerRef\"` // Filter events based on severity, defaults to ('info'). // +kubebuilder:validation:Enum=info;error // +optional EventSeverity string `json:\"eventSeverity,omitempty\"` // Filter events based on the involved objects. // +required EventSources [] CrossNamespaceObjectReference `json:\"eventSources\"` // A list of Golang regular expressions to be used for excluding messages. // +optional ExclusionList [] string `json:\"exclusionList,omitempty\"` // Short description of the impact and affected cluster. // +optional Summary string `json:\"summary,omitempty\"` // This flag tells the controller to suspend subsequent events dispatching. // Defaults to false. // +optional Suspend bool `json:\"suspend,omitempty\"` } Status: // ProviderStatus defines the observed state of Provider type ProviderStatus struct { // +optional Conditions [] Condition `json:\"conditions,omitempty\"` } Status condition types: const ( // ReadyCondition represents the fact that a given object has passed // validation and was acknowledge by the controller. ReadyCondition string = \"Ready\" ) Example \u00b6 apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : name : webapp namespace : default spec : providerRef : name : on-call-slack eventSeverity : info eventSources : - kind : GitRepository name : webapp - kind : Bucket name : secrets - kind : Kustomization name : webapp-backend - kind : Kustomization name : webapp-frontend The event severity can be set to info or error . To target all resources of a particular kind in a namespace, you can use the * wildcard: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : name : all-kustomizations namespace : default spec : providerRef : name : dev-msteams eventSeverity : error eventSources : - kind : Kustomization namespace : default name : '*' suspend : false If you don't specify an event source namespace, the alert namespace will be used. You can add a summary to describe the impact of an event: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : name : ingress namespace : nginx spec : summary : \"Ingress traffic affected in production (us-west-2)\" providerRef : name : on-call-slack eventSeverity : error eventSources : - kind : HelmRelease name : nginx-ingress Skip alerting if the message matches a Go regex from the exclusion list: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : name : flux-system namespace : flux-system spec : providerRef : name : on-call-slack eventSeverity : error eventSources : - kind : GitRepository name : flux-system exclusionList : - \"waiting.*socket\" The above definition will not send alerts for transient Git clone errors like: unable to clone 'ssh://git@ssh.dev.azure.com/v3/...', error: SSH could not read data: Error waiting on socket","title":"Alert CRD"},{"location":"components/notification/alert/#alert","text":"The Alert API defines how events are filtered by severity and involved object, and what provider to use for dispatching.","title":"Alert"},{"location":"components/notification/alert/#specification","text":"Spec: type AlertSpec struct { // Send events using this provider. // +required ProviderRef meta . LocalObjectReference `json:\"providerRef\"` // Filter events based on severity, defaults to ('info'). // +kubebuilder:validation:Enum=info;error // +optional EventSeverity string `json:\"eventSeverity,omitempty\"` // Filter events based on the involved objects. // +required EventSources [] CrossNamespaceObjectReference `json:\"eventSources\"` // A list of Golang regular expressions to be used for excluding messages. // +optional ExclusionList [] string `json:\"exclusionList,omitempty\"` // Short description of the impact and affected cluster. // +optional Summary string `json:\"summary,omitempty\"` // This flag tells the controller to suspend subsequent events dispatching. // Defaults to false. // +optional Suspend bool `json:\"suspend,omitempty\"` } Status: // ProviderStatus defines the observed state of Provider type ProviderStatus struct { // +optional Conditions [] Condition `json:\"conditions,omitempty\"` } Status condition types: const ( // ReadyCondition represents the fact that a given object has passed // validation and was acknowledge by the controller. ReadyCondition string = \"Ready\" )","title":"Specification"},{"location":"components/notification/alert/#example","text":"apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : name : webapp namespace : default spec : providerRef : name : on-call-slack eventSeverity : info eventSources : - kind : GitRepository name : webapp - kind : Bucket name : secrets - kind : Kustomization name : webapp-backend - kind : Kustomization name : webapp-frontend The event severity can be set to info or error . To target all resources of a particular kind in a namespace, you can use the * wildcard: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : name : all-kustomizations namespace : default spec : providerRef : name : dev-msteams eventSeverity : error eventSources : - kind : Kustomization namespace : default name : '*' suspend : false If you don't specify an event source namespace, the alert namespace will be used. You can add a summary to describe the impact of an event: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : name : ingress namespace : nginx spec : summary : \"Ingress traffic affected in production (us-west-2)\" providerRef : name : on-call-slack eventSeverity : error eventSources : - kind : HelmRelease name : nginx-ingress Skip alerting if the message matches a Go regex from the exclusion list: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : name : flux-system namespace : flux-system spec : providerRef : name : on-call-slack eventSeverity : error eventSources : - kind : GitRepository name : flux-system exclusionList : - \"waiting.*socket\" The above definition will not send alerts for transient Git clone errors like: unable to clone 'ssh://git@ssh.dev.azure.com/v3/...', error: SSH could not read data: Error waiting on socket","title":"Example"},{"location":"components/notification/api/","text":"Notification API reference Packages: notification.toolkit.fluxcd.io/v1beta1 notification.toolkit.fluxcd.io/v1beta1 Package v1beta1 contains API Schema definitions for the notification v1beta1 API group Resource Types: Alert Provider Receiver Alert Alert is the Schema for the alerts API Field Description apiVersion string notification.toolkit.fluxcd.io/v1beta1 kind string Alert metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec AlertSpec providerRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference Send events using this provider. eventSeverity string (Optional) Filter events based on severity, defaults to (\u2018info\u2019). If set to \u2018info\u2019 no events will be filtered. eventSources []CrossNamespaceObjectReference Filter events based on the involved objects. exclusionList []string (Optional) A list of Golang regular expressions to be used for excluding messages. summary string (Optional) Short description of the impact and affected cluster. suspend bool (Optional) This flag tells the controller to suspend subsequent events dispatching. Defaults to false. status AlertStatus Provider Provider is the Schema for the providers API Field Description apiVersion string notification.toolkit.fluxcd.io/v1beta1 kind string Provider metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec ProviderSpec type string Type of provider channel string (Optional) Alert channel for this provider username string (Optional) Bot username for this provider address string (Optional) HTTP/S webhook address of this provider proxy string (Optional) HTTP/S address of the proxy secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) Secret reference containing the provider webhook URL using \u201caddress\u201d as data key status ProviderStatus Receiver Receiver is the Schema for the receivers API Field Description apiVersion string notification.toolkit.fluxcd.io/v1beta1 kind string Receiver metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec ReceiverSpec type string Type of webhook sender, used to determine the validation procedure and payload deserialization. events []string (Optional) A list of events to handle, e.g. \u2018push\u2019 for GitHub or \u2018Push Hook\u2019 for GitLab. resources []CrossNamespaceObjectReference A list of resources to be notified about changes. secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference Secret reference containing the token used to validate the payload authenticity suspend bool (Optional) This flag tells the controller to suspend subsequent events handling. Defaults to false. status ReceiverStatus AlertSpec ( Appears on: Alert ) AlertSpec defines an alerting rule for events involving a list of objects Field Description providerRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference Send events using this provider. eventSeverity string (Optional) Filter events based on severity, defaults to (\u2018info\u2019). If set to \u2018info\u2019 no events will be filtered. eventSources []CrossNamespaceObjectReference Filter events based on the involved objects. exclusionList []string (Optional) A list of Golang regular expressions to be used for excluding messages. summary string (Optional) Short description of the impact and affected cluster. suspend bool (Optional) This flag tells the controller to suspend subsequent events dispatching. Defaults to false. AlertStatus ( Appears on: Alert ) AlertStatus defines the observed state of Alert Field Description conditions []Kubernetes meta/v1.Condition (Optional) CrossNamespaceObjectReference ( Appears on: AlertSpec , ReceiverSpec ) CrossNamespaceObjectReference contains enough information to let you locate the typed referenced object at cluster level Field Description apiVersion string (Optional) API version of the referent kind string Kind of the referent name string Name of the referent namespace string (Optional) Namespace of the referent ProviderSpec ( Appears on: Provider ) ProviderSpec defines the desired state of Provider Field Description type string Type of provider channel string (Optional) Alert channel for this provider username string (Optional) Bot username for this provider address string (Optional) HTTP/S webhook address of this provider proxy string (Optional) HTTP/S address of the proxy secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) Secret reference containing the provider webhook URL using \u201caddress\u201d as data key ProviderStatus ( Appears on: Provider ) ProviderStatus defines the observed state of Provider Field Description conditions []Kubernetes meta/v1.Condition (Optional) ReceiverSpec ( Appears on: Receiver ) ReceiverSpec defines the desired state of Receiver Field Description type string Type of webhook sender, used to determine the validation procedure and payload deserialization. events []string (Optional) A list of events to handle, e.g. \u2018push\u2019 for GitHub or \u2018Push Hook\u2019 for GitLab. resources []CrossNamespaceObjectReference A list of resources to be notified about changes. secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference Secret reference containing the token used to validate the payload authenticity suspend bool (Optional) This flag tells the controller to suspend subsequent events handling. Defaults to false. ReceiverStatus ( Appears on: Receiver ) ReceiverStatus defines the observed state of Receiver Field Description conditions []Kubernetes meta/v1.Condition (Optional) url string (Optional) Generated webhook URL in the format of \u2018/hook/sha256sum(token+name+namespace)\u2019. This page was automatically generated with gen-crd-api-reference-docs","title":"Notification API Reference"},{"location":"components/notification/controller/","text":"Notification Controller \u00b6 The Notification Controller is a Kubernetes operator, specialized in handling inbound and outbound events. The controller handles events coming from external systems (GitHub, GitLab, Bitbucket, Harbor, Jenkins, etc) and notifies the GitOps toolkit controllers about source changes. The controller handles events emitted by the GitOps toolkit controllers (source, kustomize, helm) and dispatches them to external systems (Slack, Microsoft Teams, Discord, Rocker) based on event severity and involved objects. Links: Source code fluxcd/notification-controller Specification docs","title":"Overview"},{"location":"components/notification/controller/#notification-controller","text":"The Notification Controller is a Kubernetes operator, specialized in handling inbound and outbound events. The controller handles events coming from external systems (GitHub, GitLab, Bitbucket, Harbor, Jenkins, etc) and notifies the GitOps toolkit controllers about source changes. The controller handles events emitted by the GitOps toolkit controllers (source, kustomize, helm) and dispatches them to external systems (Slack, Microsoft Teams, Discord, Rocker) based on event severity and involved objects. Links: Source code fluxcd/notification-controller Specification docs","title":"Notification Controller"},{"location":"components/notification/event/","text":"Event \u00b6 The Event API defines what information a report of an event issued by a controller should contain. Specification \u00b6 Spec: type Event struct { // The object that this event is about. // +required InvolvedObject corev1 . ObjectReference `json:\"involvedObject\"` // Severity type of this event (info, error) // +required Severity string `json:\"severity\"` // The time at which this event was recorded. // +required Timestamp metav1 . Time `json:\"timestamp\"` // A human-readable description of this event. // Maximum length 39,000 characters // +required Message string `json:\"message\"` // A machine understandable string that gives the reason // for the transition into the object's current status. // +required Reason string `json:\"reason\"` // Metadata of this event, e.g. apply change set. // +optional Metadata map [ string ] string `json:\"metadata,omitempty\"` // Name of the controller that emitted this event, e.g. `source-controller`. // +required ReportingController string `json:\"reportingController\"` // ID of the controller instance, e.g. `source-controller-xyzf`. // +optional ReportingInstance string `json:\"reportingInstance,omitempty\"` } Event severity: const ( EventSeverityInfo string = \"info\" EventSeverityError string = \"error\" ) Controller implementations can use the fluxcd/pkg/runtime/events package to push events to notification-controller API.","title":"Event"},{"location":"components/notification/event/#event","text":"The Event API defines what information a report of an event issued by a controller should contain.","title":"Event"},{"location":"components/notification/event/#specification","text":"Spec: type Event struct { // The object that this event is about. // +required InvolvedObject corev1 . ObjectReference `json:\"involvedObject\"` // Severity type of this event (info, error) // +required Severity string `json:\"severity\"` // The time at which this event was recorded. // +required Timestamp metav1 . Time `json:\"timestamp\"` // A human-readable description of this event. // Maximum length 39,000 characters // +required Message string `json:\"message\"` // A machine understandable string that gives the reason // for the transition into the object's current status. // +required Reason string `json:\"reason\"` // Metadata of this event, e.g. apply change set. // +optional Metadata map [ string ] string `json:\"metadata,omitempty\"` // Name of the controller that emitted this event, e.g. `source-controller`. // +required ReportingController string `json:\"reportingController\"` // ID of the controller instance, e.g. `source-controller-xyzf`. // +optional ReportingInstance string `json:\"reportingInstance,omitempty\"` } Event severity: const ( EventSeverityInfo string = \"info\" EventSeverityError string = \"error\" ) Controller implementations can use the fluxcd/pkg/runtime/events package to push events to notification-controller API.","title":"Specification"},{"location":"components/notification/provider/","text":"Provider \u00b6 The Provider API defines how events are encoded and the webhook address where they are dispatched. Specification \u00b6 Spec: type ProviderSpec struct { // Type of provider // +kubebuilder:validation:Enum=slack;discord;msteams;rocket;generic;github;gitlab // +required Type string `json:\"type\"` // Alert channel for this provider // +optional Channel string `json:\"channel,omitempty\"` // Bot username for this provider // +optional Username string `json:\"username,omitempty\"` // HTTP/S webhook address of this provider // +kubebuilder:validation:Pattern=\"^(http|https)://\" // +optional Address string `json:\"address,omitempty\"` // HTTP/S address of the proxy // +kubebuilder:validation:Pattern=\"^(http|https)://\" // +optional Proxy string `json:\"proxy,omitempty\"` // Secret reference containing the provider webhook URL // +optional SecretRef * meta . LocalObjectReference `json:\"secretRef,omitempty\"` } Notification providers: Slack Discord Microsoft Teams Rocket Generic webhook Git commit status providers: GitHub GitLab Bitbucket Azure DevOps Status: // ProviderStatus defines the observed state of Provider type ProviderStatus struct { // +optional Conditions [] Condition `json:\"conditions,omitempty\"` } Status condition types: const ( // ReadyCondition represents the fact that a given object has passed // validation and was acknowledge by the controller. ReadyCondition string = \"Ready\" ) Example \u00b6 Notifications \u00b6 apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Provider metadata : name : slack namespace : default spec : type : slack channel : general # webhook address (ignored if secretRef is specified) address : https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK # HTTP(S) proxy (optional) proxy : https://proxy.corp:8080 # secret containing the webhook address (optional) secretRef : name : webhook-url Webhook URL secret: kubectl create secret generic webhook-url \\ --from-literal = address = https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK Note that the secret must contain an address field. The provider type can be: slack , msteams , rocket , discord , github or generic . When type generic is specified, the notification controller will post the incoming event in JSON format to the webhook address. Git commit status \u00b6 The GitHub, GitLab, Bitbucket, and Azure DevOps provider will write to the commit status in the git repository from which the event originates from. Limitations The git notification providers require that a commit hash present in the meta data of the event. There for the the providers will only work with Kustomization as an event source, as it is the only resource which includes this data. apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Provider metadata : name : podinfo namespace : default spec : # provider type can be github or gitlab type : github address : https://github.com/stefanprodan/podinfo secretRef : name : api-token Authentication \u00b6 GitHub. GitLab, and Azure DevOps use personal access tokens to authenticate with their API: GitHub personal access token GitLab personal access token Azure DevOps personal access token The providers require a secret in the same format, with the personal access token as the value for the token key: apiVersion : v1 kind : Secret metadata : name : api-token namespace : default data : token : <personal-access-tokens> Bitbucket authenticates using an app password . It requires both the username and the password when authenticating. There for the token needs to be passed with the format <username>:<app-password> . A token that is not in this format will cause the provider to fail. apiVersion : v1 kind : Secret metadata : name : api-token namespace : default data : token : <username>:<app-password> Generic webhook \u00b6 The generic webhook triggers an HTTP POST request to the provided endpoint. The Gotk-Component header identifies which component this event is coming from, e.g. source-controller , kustomize-controller . POST / HTTP/1.1 Host: example.com Accept-Encoding: gzip Content-Length: 452 Content-Type: application/json Gotk-Component: source-controller User-Agent: Go-http-client/1.1 The body of the request looks like this: { \"involvedObject\" : { \"kind\" : \"GitRepository\" , \"namespace\" : \"flux-system\" , \"name\" : \"flux-system\" , \"uid\" : \"cc4d0095-83f4-4f08-98f2-d2e9f3731fb9\" , \"apiVersion\" : \"source.toolkit.fluxcd.io/v1beta1\" , \"resourceVersion\" : \"56921\" , }, \"severity\" : \"info\" , \"timestamp\" : \"2006-01-02T15:04:05Z\" , \"message\" : \"Fetched revision: main/731f7eaddfb6af01cb2173e18f0f75b0ba780ef1\" , \"reason\" : \"info\" , \"reportingController\" : \"source-controller\" , \"reportingInstance\" : \"source-controller-7c7b47f5f-8bhrp\" , } The involvedObject key contains the object that triggered the event.","title":"Provider CRD"},{"location":"components/notification/provider/#provider","text":"The Provider API defines how events are encoded and the webhook address where they are dispatched.","title":"Provider"},{"location":"components/notification/provider/#specification","text":"Spec: type ProviderSpec struct { // Type of provider // +kubebuilder:validation:Enum=slack;discord;msteams;rocket;generic;github;gitlab // +required Type string `json:\"type\"` // Alert channel for this provider // +optional Channel string `json:\"channel,omitempty\"` // Bot username for this provider // +optional Username string `json:\"username,omitempty\"` // HTTP/S webhook address of this provider // +kubebuilder:validation:Pattern=\"^(http|https)://\" // +optional Address string `json:\"address,omitempty\"` // HTTP/S address of the proxy // +kubebuilder:validation:Pattern=\"^(http|https)://\" // +optional Proxy string `json:\"proxy,omitempty\"` // Secret reference containing the provider webhook URL // +optional SecretRef * meta . LocalObjectReference `json:\"secretRef,omitempty\"` } Notification providers: Slack Discord Microsoft Teams Rocket Generic webhook Git commit status providers: GitHub GitLab Bitbucket Azure DevOps Status: // ProviderStatus defines the observed state of Provider type ProviderStatus struct { // +optional Conditions [] Condition `json:\"conditions,omitempty\"` } Status condition types: const ( // ReadyCondition represents the fact that a given object has passed // validation and was acknowledge by the controller. ReadyCondition string = \"Ready\" )","title":"Specification"},{"location":"components/notification/provider/#example","text":"","title":"Example"},{"location":"components/notification/provider/#notifications","text":"apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Provider metadata : name : slack namespace : default spec : type : slack channel : general # webhook address (ignored if secretRef is specified) address : https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK # HTTP(S) proxy (optional) proxy : https://proxy.corp:8080 # secret containing the webhook address (optional) secretRef : name : webhook-url Webhook URL secret: kubectl create secret generic webhook-url \\ --from-literal = address = https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK Note that the secret must contain an address field. The provider type can be: slack , msteams , rocket , discord , github or generic . When type generic is specified, the notification controller will post the incoming event in JSON format to the webhook address.","title":"Notifications"},{"location":"components/notification/provider/#git-commit-status","text":"The GitHub, GitLab, Bitbucket, and Azure DevOps provider will write to the commit status in the git repository from which the event originates from. Limitations The git notification providers require that a commit hash present in the meta data of the event. There for the the providers will only work with Kustomization as an event source, as it is the only resource which includes this data. apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Provider metadata : name : podinfo namespace : default spec : # provider type can be github or gitlab type : github address : https://github.com/stefanprodan/podinfo secretRef : name : api-token","title":"Git commit status"},{"location":"components/notification/provider/#authentication","text":"GitHub. GitLab, and Azure DevOps use personal access tokens to authenticate with their API: GitHub personal access token GitLab personal access token Azure DevOps personal access token The providers require a secret in the same format, with the personal access token as the value for the token key: apiVersion : v1 kind : Secret metadata : name : api-token namespace : default data : token : <personal-access-tokens> Bitbucket authenticates using an app password . It requires both the username and the password when authenticating. There for the token needs to be passed with the format <username>:<app-password> . A token that is not in this format will cause the provider to fail. apiVersion : v1 kind : Secret metadata : name : api-token namespace : default data : token : <username>:<app-password>","title":"Authentication"},{"location":"components/notification/provider/#generic-webhook","text":"The generic webhook triggers an HTTP POST request to the provided endpoint. The Gotk-Component header identifies which component this event is coming from, e.g. source-controller , kustomize-controller . POST / HTTP/1.1 Host: example.com Accept-Encoding: gzip Content-Length: 452 Content-Type: application/json Gotk-Component: source-controller User-Agent: Go-http-client/1.1 The body of the request looks like this: { \"involvedObject\" : { \"kind\" : \"GitRepository\" , \"namespace\" : \"flux-system\" , \"name\" : \"flux-system\" , \"uid\" : \"cc4d0095-83f4-4f08-98f2-d2e9f3731fb9\" , \"apiVersion\" : \"source.toolkit.fluxcd.io/v1beta1\" , \"resourceVersion\" : \"56921\" , }, \"severity\" : \"info\" , \"timestamp\" : \"2006-01-02T15:04:05Z\" , \"message\" : \"Fetched revision: main/731f7eaddfb6af01cb2173e18f0f75b0ba780ef1\" , \"reason\" : \"info\" , \"reportingController\" : \"source-controller\" , \"reportingInstance\" : \"source-controller-7c7b47f5f-8bhrp\" , } The involvedObject key contains the object that triggered the event.","title":"Generic webhook"},{"location":"components/notification/receiver/","text":"Receiver \u00b6 The Receiver API defines a webhook receiver that triggers reconciliation for a group of resources. Specification \u00b6 type ReceiverSpec struct { // Type of webhook sender, used to determine // the validation procedure and payload deserialization. // +kubebuilder:validation:Enum=generic;generic-hmac;github;gitlab;bitbucket;harbor;dockerhub;quay;gcr;nexus // +required Type string `json:\"type\"` // A list of events to handle, // e.g. 'push' for GitHub or 'Push Hook' for GitLab. // +optional Events [] string `json:\"events\"` // A list of resources to be notified about changes. // +required Resources [] CrossNamespaceObjectReference `json:\"resources\"` // Secret reference containing the token used // to validate the payload authenticity // +required SecretRef meta . LocalObjectReference `json:\"secretRef,omitempty\"` // This flag tells the controller to suspend subsequent events handling. // Defaults to false. // +optional Suspend bool `json:\"suspend,omitempty\"` } Receiver types: const ( GenericReceiver string = \"generic\" GenericHMACReceiver string = \"generic-hmac\" GitHubReceiver string = \"github\" GitLabReceiver string = \"gitlab\" BitbucketReceiver string = \"bitbucket\" HarborReceiver string = \"harbor\" DockerHubReceiver string = \"dockerhub\" QuayReceiver string = \"quay\" GCRReceiver string = \"gcr\" NexusReceiver string = \"nexus\" ) Status \u00b6 type ReceiverStatus struct { // Generated webhook URL in the format // of '/hook/sha256sum(token+name+namespace)'. // +required URL string `json:\"url\"` } Example \u00b6 Generate a random string and create a secret with a token field: TOKEN = $( head -c 12 /dev/urandom | shasum | cut -d ' ' -f1 ) echo $TOKEN kubectl create secret generic webhook-token \\ --from-literal = token = $TOKEN Generic receiver \u00b6 apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : generic-receiver namespace : default spec : type : generic secretRef : name : webhook-token resources : - kind : GitRepository name : webapp namespace : default - kind : HelmRepository name : webapp namespace : default - kind : Bucket name : webapp namespace : default - kind : ImageRepository name : webapp namespace : default When the receiver type is set to generic , the controller will not perform token validation nor event filtering. Generic HMAC receiver \u00b6 apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : generic-hmac-receiver namespace : default spec : type : generic-hmac secretRef : name : webhook-token resources : - kind : GitRepository name : webapp namespace : default This generic receiver verifies that the request is legitimate using HMAC. The controller uses the X-Signature header to get the hash signature. The signature should be prefixed with the hash function( sha1 , sha256 , or sha512 ) like this: <hash-function>=<hash-signation> . Generate hash signature using OpenSSL: printf '<request-body>' | openssl dgst -sha1 -r -hmac \"<secret-key>\" | awk '{print $1}' You can use the flag sha256 or sha512 if you want a different hash function. Send a HTTP POST request to the webhook URL: curl <webhook-url> -X POST -H \"X-Signature: sha1=<generated-hash>\" -d '<request-body>' Generate hash signature using Go: func sign ( payload , key string ) string { h := hmac . New ( sha1 . New , [] byte ( key )) h . Write ([] byte ( payload )) return fmt . Sprintf ( \"%x\" , h . Sum ( nil )) } // set headers req . Header . Set ( \"X-Signature\" , fmt . Sprintf ( \"sha1=%s\" , sign ( payload , key ))) GitHub receiver \u00b6 apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : github-receiver namespace : default spec : type : github events : - \"ping\" - \"push\" secretRef : name : webhook-token resources : - kind : GitRepository name : webapp - kind : HelmRepository name : webapp Note that you have to set the generated token as the GitHub webhook secret value. The controller uses the X-Hub-Signature HTTP header to verify that the request is legitimate. GitLab receiver \u00b6 apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : gitlab-receiver namespace : default spec : type : gitlab events : - \"Push Hook\" - \"Tag Push Hook\" secretRef : name : webhook-token resources : - kind : GitRepository name : webapp-frontend - kind : GitRepository name : webapp-backend Note that you have to configure the GitLab webhook with the generated token. The controller uses the X-Gitlab-Token HTTP header to verify that the request is legitimate. Bitbucket server receiver \u00b6 apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : bitbucket-receiver namespace : default spec : type : bitbucket events : - \"repo:refs_changed\" secretRef : name : webhook-token resources : - kind : GitRepository name : webapp Note that you have to set the generated token as the Bitbucket server webhook secret value. The controller uses the X-Hub-Signature HTTP header to verify that the request is legitimate. Harbor receiver \u00b6 apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : harbor-receiver namespace : default spec : type : harbor secretRef : name : webhook-token resources : - kind : HelmRepository name : webapp - kind : ImageRepository name : webapp Note that you have to set the generated token as the Harbor webhook authentication header. The controller uses the Authentication HTTP header to verify that the request is legitimate. DockerHub receiver \u00b6 apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : dockerhub-receiver namespace : default spec : type : dockerhub secretRef : name : webhook-token resources : - kind : ImageRepository name : webapp Quay receiver \u00b6 apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : quay-receiver namespace : default spec : type : quay secretRef : name : webhook-token resources : - kind : ImageRepository name : webapp Nexus receiver \u00b6 apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : nexus-receiver namespace : default spec : type : nexus secretRef : name : webhook-token resources : - kind : ImageRepository name : webapp Note that you have to fill in the generated token as the secret key when creating the Nexus Webhook Capability. See Nexus Webhook Capability The controller uses the X-Nexus-Webhook-Signature HTTP header to verify that the request is legitimate. GCR receiver \u00b6 apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : gcr-receiver namespace : default spec : type : gcr secretRef : name : webhook-token resources : - kind : ImageRepository name : webapp namespace : default Note that the controller decodes the JWT from the authorization header of the push request and verifies it against the GCP API. For more information, take a look at this documentation .","title":"Receiver CRD"},{"location":"components/notification/receiver/#receiver","text":"The Receiver API defines a webhook receiver that triggers reconciliation for a group of resources.","title":"Receiver"},{"location":"components/notification/receiver/#specification","text":"type ReceiverSpec struct { // Type of webhook sender, used to determine // the validation procedure and payload deserialization. // +kubebuilder:validation:Enum=generic;generic-hmac;github;gitlab;bitbucket;harbor;dockerhub;quay;gcr;nexus // +required Type string `json:\"type\"` // A list of events to handle, // e.g. 'push' for GitHub or 'Push Hook' for GitLab. // +optional Events [] string `json:\"events\"` // A list of resources to be notified about changes. // +required Resources [] CrossNamespaceObjectReference `json:\"resources\"` // Secret reference containing the token used // to validate the payload authenticity // +required SecretRef meta . LocalObjectReference `json:\"secretRef,omitempty\"` // This flag tells the controller to suspend subsequent events handling. // Defaults to false. // +optional Suspend bool `json:\"suspend,omitempty\"` } Receiver types: const ( GenericReceiver string = \"generic\" GenericHMACReceiver string = \"generic-hmac\" GitHubReceiver string = \"github\" GitLabReceiver string = \"gitlab\" BitbucketReceiver string = \"bitbucket\" HarborReceiver string = \"harbor\" DockerHubReceiver string = \"dockerhub\" QuayReceiver string = \"quay\" GCRReceiver string = \"gcr\" NexusReceiver string = \"nexus\" )","title":"Specification"},{"location":"components/notification/receiver/#status","text":"type ReceiverStatus struct { // Generated webhook URL in the format // of '/hook/sha256sum(token+name+namespace)'. // +required URL string `json:\"url\"` }","title":"Status"},{"location":"components/notification/receiver/#example","text":"Generate a random string and create a secret with a token field: TOKEN = $( head -c 12 /dev/urandom | shasum | cut -d ' ' -f1 ) echo $TOKEN kubectl create secret generic webhook-token \\ --from-literal = token = $TOKEN","title":"Example"},{"location":"components/notification/receiver/#generic-receiver","text":"apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : generic-receiver namespace : default spec : type : generic secretRef : name : webhook-token resources : - kind : GitRepository name : webapp namespace : default - kind : HelmRepository name : webapp namespace : default - kind : Bucket name : webapp namespace : default - kind : ImageRepository name : webapp namespace : default When the receiver type is set to generic , the controller will not perform token validation nor event filtering.","title":"Generic receiver"},{"location":"components/notification/receiver/#generic-hmac-receiver","text":"apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : generic-hmac-receiver namespace : default spec : type : generic-hmac secretRef : name : webhook-token resources : - kind : GitRepository name : webapp namespace : default This generic receiver verifies that the request is legitimate using HMAC. The controller uses the X-Signature header to get the hash signature. The signature should be prefixed with the hash function( sha1 , sha256 , or sha512 ) like this: <hash-function>=<hash-signation> . Generate hash signature using OpenSSL: printf '<request-body>' | openssl dgst -sha1 -r -hmac \"<secret-key>\" | awk '{print $1}' You can use the flag sha256 or sha512 if you want a different hash function. Send a HTTP POST request to the webhook URL: curl <webhook-url> -X POST -H \"X-Signature: sha1=<generated-hash>\" -d '<request-body>' Generate hash signature using Go: func sign ( payload , key string ) string { h := hmac . New ( sha1 . New , [] byte ( key )) h . Write ([] byte ( payload )) return fmt . Sprintf ( \"%x\" , h . Sum ( nil )) } // set headers req . Header . Set ( \"X-Signature\" , fmt . Sprintf ( \"sha1=%s\" , sign ( payload , key )))","title":"Generic HMAC receiver"},{"location":"components/notification/receiver/#github-receiver","text":"apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : github-receiver namespace : default spec : type : github events : - \"ping\" - \"push\" secretRef : name : webhook-token resources : - kind : GitRepository name : webapp - kind : HelmRepository name : webapp Note that you have to set the generated token as the GitHub webhook secret value. The controller uses the X-Hub-Signature HTTP header to verify that the request is legitimate.","title":"GitHub receiver"},{"location":"components/notification/receiver/#gitlab-receiver","text":"apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : gitlab-receiver namespace : default spec : type : gitlab events : - \"Push Hook\" - \"Tag Push Hook\" secretRef : name : webhook-token resources : - kind : GitRepository name : webapp-frontend - kind : GitRepository name : webapp-backend Note that you have to configure the GitLab webhook with the generated token. The controller uses the X-Gitlab-Token HTTP header to verify that the request is legitimate.","title":"GitLab receiver"},{"location":"components/notification/receiver/#bitbucket-server-receiver","text":"apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : bitbucket-receiver namespace : default spec : type : bitbucket events : - \"repo:refs_changed\" secretRef : name : webhook-token resources : - kind : GitRepository name : webapp Note that you have to set the generated token as the Bitbucket server webhook secret value. The controller uses the X-Hub-Signature HTTP header to verify that the request is legitimate.","title":"Bitbucket server receiver"},{"location":"components/notification/receiver/#harbor-receiver","text":"apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : harbor-receiver namespace : default spec : type : harbor secretRef : name : webhook-token resources : - kind : HelmRepository name : webapp - kind : ImageRepository name : webapp Note that you have to set the generated token as the Harbor webhook authentication header. The controller uses the Authentication HTTP header to verify that the request is legitimate.","title":"Harbor receiver"},{"location":"components/notification/receiver/#dockerhub-receiver","text":"apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : dockerhub-receiver namespace : default spec : type : dockerhub secretRef : name : webhook-token resources : - kind : ImageRepository name : webapp","title":"DockerHub receiver"},{"location":"components/notification/receiver/#quay-receiver","text":"apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : quay-receiver namespace : default spec : type : quay secretRef : name : webhook-token resources : - kind : ImageRepository name : webapp","title":"Quay receiver"},{"location":"components/notification/receiver/#nexus-receiver","text":"apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : nexus-receiver namespace : default spec : type : nexus secretRef : name : webhook-token resources : - kind : ImageRepository name : webapp Note that you have to fill in the generated token as the secret key when creating the Nexus Webhook Capability. See Nexus Webhook Capability The controller uses the X-Nexus-Webhook-Signature HTTP header to verify that the request is legitimate.","title":"Nexus receiver"},{"location":"components/notification/receiver/#gcr-receiver","text":"apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : gcr-receiver namespace : default spec : type : gcr secretRef : name : webhook-token resources : - kind : ImageRepository name : webapp namespace : default Note that the controller decodes the JWT from the authorization header of the push request and verifies it against the GCP API. For more information, take a look at this documentation .","title":"GCR receiver"},{"location":"components/source/api/","text":"Source API reference Packages: source.toolkit.fluxcd.io/v1beta1 source.toolkit.fluxcd.io/v1beta1 Package v1beta1 contains API Schema definitions for the source v1beta1 API group Resource Types: Bucket GitRepository HelmChart HelmRepository Bucket Bucket is the Schema for the buckets API Field Description apiVersion string source.toolkit.fluxcd.io/v1beta1 kind string Bucket metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec BucketSpec provider string (Optional) The S3 compatible storage provider name, default (\u2018generic\u2019). bucketName string The bucket name. endpoint string The bucket endpoint address. insecure bool (Optional) Insecure allows connecting to a non-TLS S3 HTTP endpoint. region string (Optional) The bucket region. secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) The name of the secret containing authentication credentials for the Bucket. interval Kubernetes meta/v1.Duration The interval at which to check for bucket updates. timeout Kubernetes meta/v1.Duration (Optional) The timeout for download operations, defaults to 20s. ignore string (Optional) Ignore overrides the set of excluded patterns in the .sourceignore format (which is the same as .gitignore). If not provided, a default will be used, consult the documentation for your version to find out what those are. suspend bool (Optional) This flag tells the controller to suspend the reconciliation of this source. status BucketStatus GitRepository GitRepository is the Schema for the gitrepositories API Field Description apiVersion string source.toolkit.fluxcd.io/v1beta1 kind string GitRepository metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec GitRepositorySpec url string The repository URL, can be a HTTP/S or SSH address. secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) The secret name containing the Git credentials. For HTTPS repositories the secret must contain username and password fields. For SSH repositories the secret must contain identity, identity.pub and known_hosts fields. interval Kubernetes meta/v1.Duration The interval at which to check for repository updates. timeout Kubernetes meta/v1.Duration (Optional) The timeout for remote Git operations like cloning, defaults to 20s. ref GitRepositoryRef (Optional) The Git reference to checkout and monitor for changes, defaults to master branch. verify GitRepositoryVerification (Optional) Verify OpenPGP signature for the Git commit HEAD points to. ignore string (Optional) Ignore overrides the set of excluded patterns in the .sourceignore format (which is the same as .gitignore). If not provided, a default will be used, consult the documentation for your version to find out what those are. suspend bool (Optional) This flag tells the controller to suspend the reconciliation of this source. gitImplementation string (Optional) Determines which git client library to use. Defaults to go-git, valid values are (\u2018go-git\u2019, \u2018libgit2\u2019). status GitRepositoryStatus HelmChart HelmChart is the Schema for the helmcharts API Field Description apiVersion string source.toolkit.fluxcd.io/v1beta1 kind string HelmChart metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec HelmChartSpec chart string The name or path the Helm chart is available at in the SourceRef. version string (Optional) The chart version semver expression, ignored for charts from GitRepository and Bucket sources. Defaults to latest when omitted. sourceRef LocalHelmChartSourceReference The reference to the Source the chart is available at. interval Kubernetes meta/v1.Duration The interval at which to check the Source for updates. valuesFile string (Optional) Alternative values file to use as the default chart values, expected to be a relative path in the SourceRef. Ignored when omitted. suspend bool (Optional) This flag tells the controller to suspend the reconciliation of this source. status HelmChartStatus HelmRepository HelmRepository is the Schema for the helmrepositories API Field Description apiVersion string source.toolkit.fluxcd.io/v1beta1 kind string HelmRepository metadata Kubernetes meta/v1.ObjectMeta Refer to the Kubernetes API documentation for the fields of the metadata field. spec HelmRepositorySpec url string The Helm repository URL, a valid URL contains at least a protocol and host. secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) The name of the secret containing authentication credentials for the Helm repository. For HTTP/S basic auth the secret must contain username and password fields. For TLS the secret must contain a certFile and keyFile, and/or caCert fields. interval Kubernetes meta/v1.Duration The interval at which to check the upstream for updates. timeout Kubernetes meta/v1.Duration (Optional) The timeout of index downloading, defaults to 60s. suspend bool (Optional) This flag tells the controller to suspend the reconciliation of this source. status HelmRepositoryStatus Artifact ( Appears on: BucketStatus , GitRepositoryStatus , HelmChartStatus , HelmRepositoryStatus ) Artifact represents the output of a source synchronisation. Field Description path string Path is the relative file path of this artifact. url string URL is the HTTP address of this artifact. revision string (Optional) Revision is a human readable identifier traceable in the origin source system. It can be a Git commit SHA, Git tag, a Helm index timestamp, a Helm chart version, etc. checksum string (Optional) Checksum is the SHA1 checksum of the artifact. lastUpdateTime Kubernetes meta/v1.Time LastUpdateTime is the timestamp corresponding to the last update of this artifact. BucketSpec ( Appears on: Bucket ) BucketSpec defines the desired state of an S3 compatible bucket Field Description provider string (Optional) The S3 compatible storage provider name, default (\u2018generic\u2019). bucketName string The bucket name. endpoint string The bucket endpoint address. insecure bool (Optional) Insecure allows connecting to a non-TLS S3 HTTP endpoint. region string (Optional) The bucket region. secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) The name of the secret containing authentication credentials for the Bucket. interval Kubernetes meta/v1.Duration The interval at which to check for bucket updates. timeout Kubernetes meta/v1.Duration (Optional) The timeout for download operations, defaults to 20s. ignore string (Optional) Ignore overrides the set of excluded patterns in the .sourceignore format (which is the same as .gitignore). If not provided, a default will be used, consult the documentation for your version to find out what those are. suspend bool (Optional) This flag tells the controller to suspend the reconciliation of this source. BucketStatus ( Appears on: Bucket ) BucketStatus defines the observed state of a bucket Field Description observedGeneration int64 (Optional) ObservedGeneration is the last observed generation. conditions []Kubernetes meta/v1.Condition (Optional) Conditions holds the conditions for the Bucket. url string (Optional) URL is the download link for the artifact output of the last Bucket sync. artifact Artifact (Optional) Artifact represents the output of the last successful Bucket sync. ReconcileRequestStatus github.com/fluxcd/pkg/apis/meta.ReconcileRequestStatus (Members of ReconcileRequestStatus are embedded into this type.) GitRepositoryRef ( Appears on: GitRepositorySpec ) GitRepositoryRef defines the Git ref used for pull and checkout operations. Field Description branch string (Optional) The Git branch to checkout, defaults to master. tag string (Optional) The Git tag to checkout, takes precedence over Branch. semver string (Optional) The Git tag semver expression, takes precedence over Tag. commit string (Optional) The Git commit SHA to checkout, if specified Tag filters will be ignored. GitRepositorySpec ( Appears on: GitRepository ) GitRepositorySpec defines the desired state of a Git repository. Field Description url string The repository URL, can be a HTTP/S or SSH address. secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) The secret name containing the Git credentials. For HTTPS repositories the secret must contain username and password fields. For SSH repositories the secret must contain identity, identity.pub and known_hosts fields. interval Kubernetes meta/v1.Duration The interval at which to check for repository updates. timeout Kubernetes meta/v1.Duration (Optional) The timeout for remote Git operations like cloning, defaults to 20s. ref GitRepositoryRef (Optional) The Git reference to checkout and monitor for changes, defaults to master branch. verify GitRepositoryVerification (Optional) Verify OpenPGP signature for the Git commit HEAD points to. ignore string (Optional) Ignore overrides the set of excluded patterns in the .sourceignore format (which is the same as .gitignore). If not provided, a default will be used, consult the documentation for your version to find out what those are. suspend bool (Optional) This flag tells the controller to suspend the reconciliation of this source. gitImplementation string (Optional) Determines which git client library to use. Defaults to go-git, valid values are (\u2018go-git\u2019, \u2018libgit2\u2019). GitRepositoryStatus ( Appears on: GitRepository ) GitRepositoryStatus defines the observed state of a Git repository. Field Description observedGeneration int64 (Optional) ObservedGeneration is the last observed generation. conditions []Kubernetes meta/v1.Condition (Optional) Conditions holds the conditions for the GitRepository. url string (Optional) URL is the download link for the artifact output of the last repository sync. artifact Artifact (Optional) Artifact represents the output of the last successful repository sync. ReconcileRequestStatus github.com/fluxcd/pkg/apis/meta.ReconcileRequestStatus (Members of ReconcileRequestStatus are embedded into this type.) GitRepositoryVerification ( Appears on: GitRepositorySpec ) GitRepositoryVerification defines the OpenPGP signature verification process. Field Description mode string Mode describes what git object should be verified, currently (\u2018head\u2019). secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference The secret name containing the public keys of all trusted Git authors. HelmChartSpec ( Appears on: HelmChart ) HelmChartSpec defines the desired state of a Helm chart. Field Description chart string The name or path the Helm chart is available at in the SourceRef. version string (Optional) The chart version semver expression, ignored for charts from GitRepository and Bucket sources. Defaults to latest when omitted. sourceRef LocalHelmChartSourceReference The reference to the Source the chart is available at. interval Kubernetes meta/v1.Duration The interval at which to check the Source for updates. valuesFile string (Optional) Alternative values file to use as the default chart values, expected to be a relative path in the SourceRef. Ignored when omitted. suspend bool (Optional) This flag tells the controller to suspend the reconciliation of this source. HelmChartStatus ( Appears on: HelmChart ) HelmChartStatus defines the observed state of the HelmChart. Field Description observedGeneration int64 (Optional) ObservedGeneration is the last observed generation. conditions []Kubernetes meta/v1.Condition (Optional) Conditions holds the conditions for the HelmChart. url string (Optional) URL is the download link for the last chart pulled. artifact Artifact (Optional) Artifact represents the output of the last successful chart sync. ReconcileRequestStatus github.com/fluxcd/pkg/apis/meta.ReconcileRequestStatus (Members of ReconcileRequestStatus are embedded into this type.) HelmRepositorySpec ( Appears on: HelmRepository ) HelmRepositorySpec defines the reference to a Helm repository. Field Description url string The Helm repository URL, a valid URL contains at least a protocol and host. secretRef github.com/fluxcd/pkg/apis/meta.LocalObjectReference (Optional) The name of the secret containing authentication credentials for the Helm repository. For HTTP/S basic auth the secret must contain username and password fields. For TLS the secret must contain a certFile and keyFile, and/or caCert fields. interval Kubernetes meta/v1.Duration The interval at which to check the upstream for updates. timeout Kubernetes meta/v1.Duration (Optional) The timeout of index downloading, defaults to 60s. suspend bool (Optional) This flag tells the controller to suspend the reconciliation of this source. HelmRepositoryStatus ( Appears on: HelmRepository ) HelmRepositoryStatus defines the observed state of the HelmRepository. Field Description observedGeneration int64 (Optional) ObservedGeneration is the last observed generation. conditions []Kubernetes meta/v1.Condition (Optional) Conditions holds the conditions for the HelmRepository. url string (Optional) URL is the download link for the last index fetched. artifact Artifact (Optional) Artifact represents the output of the last successful repository sync. ReconcileRequestStatus github.com/fluxcd/pkg/apis/meta.ReconcileRequestStatus (Members of ReconcileRequestStatus are embedded into this type.) LocalHelmChartSourceReference ( Appears on: HelmChartSpec ) LocalHelmChartSourceReference contains enough information to let you locate the typed referenced object at namespace level. Field Description apiVersion string (Optional) APIVersion of the referent. kind string Kind of the referent, valid values are (\u2018HelmRepository\u2019, \u2018GitRepository\u2019, \u2018Bucket\u2019). name string Name of the referent. Source Source interface must be supported by all API types. This page was automatically generated with gen-crd-api-reference-docs","title":"Source API Reference"},{"location":"components/source/buckets/","text":"Object storage buckets \u00b6 The Bucket API defines a source for artifacts coming from S3 compatible storage such as Minio, Amazon S3, Google Cloud Storage, Alibaba Cloud OSS and others. Specification \u00b6 Bucket: // BucketSpec defines the desired state of an S3 compatible bucket type BucketSpec struct { // The S3 compatible storage provider name, default ('generic'). // +kubebuilder:validation:Enum=generic;aws // +optional Provider string `json:\"provider,omitempty\"` // The bucket name. // +required BucketName string `json:\"bucketName\"` // The bucket endpoint address. // +required Endpoint string `json:\"endpoint\"` // Insecure allows connecting to a non-TLS S3 HTTP endpoint. // +optional Insecure bool `json:\"insecure,omitempty\"` // The bucket region. // +optional Region string `json:\"region,omitempty\"` // The name of the secret containing authentication credentials // for the Bucket. // +optional SecretRef * corev1 . LocalObjectReference `json:\"secretRef,omitempty\"` // The interval at which to check for bucket updates. // +required Interval metav1 . Duration `json:\"interval\"` // The timeout for download operations, defaults to 20s. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // Ignore overrides the set of excluded patterns in the .sourceignore format // (which is the same as .gitignore). If not provided, a default will be used, // consult the documentation for your version to find out what those are. // +optional Ignore * string `json:\"ignore,omitempty\"` // This flag tells the controller to suspend the reconciliation of this source. // +optional Suspend bool `json:\"suspend,omitempty\"` } Supported providers: const ( GenericBucketProvider string = \"generic\" AmazonBucketProvider string = \"aws\" ) Status \u00b6 // BucketStatus defines the observed state of a bucket type BucketStatus struct { // ObservedGeneration is the last observed generation. // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // Conditions holds the conditions for the Bucket. // +optional Conditions [] meta . Condition `json:\"conditions,omitempty\"` // URL is the download link for the artifact output of the last Bucket sync. // +optional URL string `json:\"url,omitempty\"` // Artifact represents the output of the last successful Bucket sync. // +optional Artifact * Artifact `json:\"artifact,omitempty\"` // LastHandledReconcileAt is the last manual reconciliation request (by // annotating the Bucket) handled by the reconciler. // +optional LastHandledReconcileAt string `json:\"lastHandledReconcileAt,omitempty\"` } Condition reasons \u00b6 const ( // BucketOperationSucceedReason represents the fact that the bucket listing and // download operations succeeded. BucketOperationSucceedReason string = \"BucketOperationSucceed\" // BucketOperationFailedReason represents the fact that the bucket listing or // download operations failed. BucketOperationFailedReason string = \"BucketOperationFailed\" ) Artifact \u00b6 The resource exposes the latest synchronized state from S3 as an artifact in a gzip compressed TAR archive ( <bucket checksum>.tar.gz ). Excluding files \u00b6 Git files ( .git/ , .gitignore , .gitmodules , and .gitattributes ) are excluded from the archive by default, as well as some extensions ( .jpg, .jpeg, .gif, .png, .wmv, .flv, .tar.gz, .zip ) Excluding additional files from the archive is possible by adding a .sourceignore file in the root of the bucket. The .sourceignore file follows the .gitignore pattern format , pattern entries may overrule default exclusions. Another option is to use the spec.ignore field, for example: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : Bucket metadata : name : podinfo namespace : default spec : ignore : | # exclude all /* # include deploy dir !/deploy # exclude file extensions from deploy dir /deploy/**/*.md /deploy/**/*.txt When specified, spec.ignore overrides the default exclusion list. Spec examples \u00b6 Static authentication \u00b6 Authentication credentials can be provided with a Kubernetes secret that contains accesskey and secretkey fields: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : Bucket metadata : name : podinfo namespace : default spec : interval : 1m provider : generic bucketName : podinfo endpoint : minio.minio.svc.cluster.local:9000 insecure : true secretRef : name : minio-credentials --- apiVersion : v1 kind : Secret metadata : name : minio-credentials namespace : default type : Opaque data : accesskey : <BASE64> secretkey : <BASE64> Note: that for Google Cloud Storage you have to enable S3 compatible access in your GCP project. AWS IAM authentication \u00b6 When the provider is aws and the secretRef is not specified, the credentials are retrieve from the EC2 service: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : Bucket metadata : name : podinfo namespace : default spec : interval : 5m provider : aws bucketName : podinfo endpoint : s3.amazonaws.com region : us-east-1 timeout : 30s Note: that on EKS you have to create an IAM role for the source-controller service account that grants access to the bucket. Status examples \u00b6 Successful download: status : artifact : checksum : b249024b8544521792a079c4037d0a06dd0497a9 lastUpdateTime : \"2020-09-18T08:34:49Z\" path : bucket/source-system/podinfo/aeaba8b6dd51c53084f99b098cfae4f5148ad410.tar.gz revision : aeaba8b6dd51c53084f99b098cfae4f5148ad410 url : http://localhost:9090/bucket/source-system/podinfo/aeaba8b6dd51c53084f99b098cfae4f5148ad410.tar.gz conditions : - lastTransitionTime : \"2020-09-18T08:34:49Z\" message : 'Fetched revision: aeaba8b6dd51c53084f99b098cfae4f5148ad410' reason : BucketOperationSucceed status : \"True\" type : Ready observedGeneration : 2 url : http://localhost:9090/bucket/source-system/podinfo/latest.tar.gz Failed download: status : conditions : - lastTransitionTime : \"2020-09-18T08:34:49Z\" message : \"bucket 'test' not found\" reason : BucketOperationFailed status : \"False\" type : Ready Wait for ready condition: kubectl -n gitios-system wait bucket/podinfo --for = condition = ready --timeout = 1m","title":"Bucket CRD"},{"location":"components/source/buckets/#object-storage-buckets","text":"The Bucket API defines a source for artifacts coming from S3 compatible storage such as Minio, Amazon S3, Google Cloud Storage, Alibaba Cloud OSS and others.","title":"Object storage buckets"},{"location":"components/source/buckets/#specification","text":"Bucket: // BucketSpec defines the desired state of an S3 compatible bucket type BucketSpec struct { // The S3 compatible storage provider name, default ('generic'). // +kubebuilder:validation:Enum=generic;aws // +optional Provider string `json:\"provider,omitempty\"` // The bucket name. // +required BucketName string `json:\"bucketName\"` // The bucket endpoint address. // +required Endpoint string `json:\"endpoint\"` // Insecure allows connecting to a non-TLS S3 HTTP endpoint. // +optional Insecure bool `json:\"insecure,omitempty\"` // The bucket region. // +optional Region string `json:\"region,omitempty\"` // The name of the secret containing authentication credentials // for the Bucket. // +optional SecretRef * corev1 . LocalObjectReference `json:\"secretRef,omitempty\"` // The interval at which to check for bucket updates. // +required Interval metav1 . Duration `json:\"interval\"` // The timeout for download operations, defaults to 20s. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // Ignore overrides the set of excluded patterns in the .sourceignore format // (which is the same as .gitignore). If not provided, a default will be used, // consult the documentation for your version to find out what those are. // +optional Ignore * string `json:\"ignore,omitempty\"` // This flag tells the controller to suspend the reconciliation of this source. // +optional Suspend bool `json:\"suspend,omitempty\"` } Supported providers: const ( GenericBucketProvider string = \"generic\" AmazonBucketProvider string = \"aws\" )","title":"Specification"},{"location":"components/source/buckets/#status","text":"// BucketStatus defines the observed state of a bucket type BucketStatus struct { // ObservedGeneration is the last observed generation. // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // Conditions holds the conditions for the Bucket. // +optional Conditions [] meta . Condition `json:\"conditions,omitempty\"` // URL is the download link for the artifact output of the last Bucket sync. // +optional URL string `json:\"url,omitempty\"` // Artifact represents the output of the last successful Bucket sync. // +optional Artifact * Artifact `json:\"artifact,omitempty\"` // LastHandledReconcileAt is the last manual reconciliation request (by // annotating the Bucket) handled by the reconciler. // +optional LastHandledReconcileAt string `json:\"lastHandledReconcileAt,omitempty\"` }","title":"Status"},{"location":"components/source/buckets/#condition-reasons","text":"const ( // BucketOperationSucceedReason represents the fact that the bucket listing and // download operations succeeded. BucketOperationSucceedReason string = \"BucketOperationSucceed\" // BucketOperationFailedReason represents the fact that the bucket listing or // download operations failed. BucketOperationFailedReason string = \"BucketOperationFailed\" )","title":"Condition reasons"},{"location":"components/source/buckets/#artifact","text":"The resource exposes the latest synchronized state from S3 as an artifact in a gzip compressed TAR archive ( <bucket checksum>.tar.gz ).","title":"Artifact"},{"location":"components/source/buckets/#excluding-files","text":"Git files ( .git/ , .gitignore , .gitmodules , and .gitattributes ) are excluded from the archive by default, as well as some extensions ( .jpg, .jpeg, .gif, .png, .wmv, .flv, .tar.gz, .zip ) Excluding additional files from the archive is possible by adding a .sourceignore file in the root of the bucket. The .sourceignore file follows the .gitignore pattern format , pattern entries may overrule default exclusions. Another option is to use the spec.ignore field, for example: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : Bucket metadata : name : podinfo namespace : default spec : ignore : | # exclude all /* # include deploy dir !/deploy # exclude file extensions from deploy dir /deploy/**/*.md /deploy/**/*.txt When specified, spec.ignore overrides the default exclusion list.","title":"Excluding files"},{"location":"components/source/buckets/#spec-examples","text":"","title":"Spec examples"},{"location":"components/source/buckets/#static-authentication","text":"Authentication credentials can be provided with a Kubernetes secret that contains accesskey and secretkey fields: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : Bucket metadata : name : podinfo namespace : default spec : interval : 1m provider : generic bucketName : podinfo endpoint : minio.minio.svc.cluster.local:9000 insecure : true secretRef : name : minio-credentials --- apiVersion : v1 kind : Secret metadata : name : minio-credentials namespace : default type : Opaque data : accesskey : <BASE64> secretkey : <BASE64> Note: that for Google Cloud Storage you have to enable S3 compatible access in your GCP project.","title":"Static authentication"},{"location":"components/source/buckets/#aws-iam-authentication","text":"When the provider is aws and the secretRef is not specified, the credentials are retrieve from the EC2 service: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : Bucket metadata : name : podinfo namespace : default spec : interval : 5m provider : aws bucketName : podinfo endpoint : s3.amazonaws.com region : us-east-1 timeout : 30s Note: that on EKS you have to create an IAM role for the source-controller service account that grants access to the bucket.","title":"AWS IAM authentication"},{"location":"components/source/buckets/#status-examples","text":"Successful download: status : artifact : checksum : b249024b8544521792a079c4037d0a06dd0497a9 lastUpdateTime : \"2020-09-18T08:34:49Z\" path : bucket/source-system/podinfo/aeaba8b6dd51c53084f99b098cfae4f5148ad410.tar.gz revision : aeaba8b6dd51c53084f99b098cfae4f5148ad410 url : http://localhost:9090/bucket/source-system/podinfo/aeaba8b6dd51c53084f99b098cfae4f5148ad410.tar.gz conditions : - lastTransitionTime : \"2020-09-18T08:34:49Z\" message : 'Fetched revision: aeaba8b6dd51c53084f99b098cfae4f5148ad410' reason : BucketOperationSucceed status : \"True\" type : Ready observedGeneration : 2 url : http://localhost:9090/bucket/source-system/podinfo/latest.tar.gz Failed download: status : conditions : - lastTransitionTime : \"2020-09-18T08:34:49Z\" message : \"bucket 'test' not found\" reason : BucketOperationFailed status : \"False\" type : Ready Wait for ready condition: kubectl -n gitios-system wait bucket/podinfo --for = condition = ready --timeout = 1m","title":"Status examples"},{"location":"components/source/controller/","text":"Source Controller \u00b6 The main role of the source management component is to provide a common interface for artifacts acquisition. The source API defines a set of Kubernetes objects that cluster admins and various automated operators can interact with to offload the Git and Helm repositories operations to a dedicated controller. Features: Validate source definitions Authenticate to sources (SSH, user/password, API token) Validate source authenticity (PGP) Detect source changes based on update policies (semver) Fetch resources on-demand and on-a-schedule Package the fetched resources into a well-known format (tar.gz, yaml) Make the artifacts addressable by their source identifier (sha, version, ts) Make the artifacts available in-cluster to interested 3rd parties Notify interested 3rd parties of source changes and availability (status conditions, events, hooks) Links: Source code fluxcd/source-controller Specification docs","title":"Overview"},{"location":"components/source/controller/#source-controller","text":"The main role of the source management component is to provide a common interface for artifacts acquisition. The source API defines a set of Kubernetes objects that cluster admins and various automated operators can interact with to offload the Git and Helm repositories operations to a dedicated controller. Features: Validate source definitions Authenticate to sources (SSH, user/password, API token) Validate source authenticity (PGP) Detect source changes based on update policies (semver) Fetch resources on-demand and on-a-schedule Package the fetched resources into a well-known format (tar.gz, yaml) Make the artifacts addressable by their source identifier (sha, version, ts) Make the artifacts available in-cluster to interested 3rd parties Notify interested 3rd parties of source changes and availability (status conditions, events, hooks) Links: Source code fluxcd/source-controller Specification docs","title":"Source Controller"},{"location":"components/source/gitrepositories/","text":"Git Repositories \u00b6 The GitRepository API defines a source for artifacts coming from Git. The resource exposes the latest synchronized state from Git as an artifact in a gzip compressed TAR archive . Specification \u00b6 Git repository: // GitRepositorySpec defines the desired state of a Git repository. type GitRepositorySpec struct { // The repository URL, can be a HTTP/S or SSH address. // +kubebuilder:validation:Pattern=\"^(http|https|ssh)://\" // +required URL string `json:\"url\"` // The secret name containing the Git credentials. // For HTTPS repositories the secret must contain username and password // fields. // For SSH repositories the secret must contain identity, identity.pub and // known_hosts fields. // +optional SecretRef * corev1 . LocalObjectReference `json:\"secretRef,omitempty\"` // The interval at which to check for repository updates. // +required Interval metav1 . Duration `json:\"interval\"` // The timeout for remote Git operations like cloning, defaults to 20s. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // The Git reference to checkout and monitor for changes, defaults to // master branch. // +optional Reference * GitRepositoryRef `json:\"ref,omitempty\"` // Verify OpenPGP signature for the Git commit HEAD points to. // +optional Verification * GitRepositoryVerification `json:\"verify,omitempty\"` // Ignore overrides the set of excluded patterns in the .sourceignore format // (which is the same as .gitignore). If not provided, a default will be used, // consult the documentation for your version to find out what those are. // +optional Ignore * string `json:\"ignore,omitempty\"` // This flag tells the controller to suspend the reconciliation of this source. // +optional Suspend bool `json:\"suspend,omitempty\"` // Determines which git client library to use. // Defaults to go-git, valid values are ('go-git', 'libgit2'). // +kubebuilder:validation:Enum=go-git;libgit2 // +kubebuilder:default:=go-git // +optional GitImplementation string `json:\"gitImplementation,omitempty\"` } Git repository reference: // GitRepositoryRef defines the Git ref used for pull and checkout operations. type GitRepositoryRef struct { // The Git branch to checkout, defaults to master. // +optional Branch string `json:\"branch,omitempty\"` // The Git tag to checkout, takes precedence over Branch. // +optional Tag string `json:\"tag,omitempty\"` // The Git tag semver expression, takes precedence over Tag. // +optional SemVer string `json:\"semver,omitempty\"` // The Git commit SHA to checkout, if specified Tag filters will be ignored. // +optional Commit string `json:\"commit,omitempty\"` } Git repository cryptographic provenance verification: // GitRepositoryVerification defines the OpenPGP signature verification process. type GitRepositoryVerification struct { // Mode describes what git object should be verified, currently ('head'). // +kubebuilder:validation:Enum=head Mode string `json:\"mode\"` // The secret name containing the public keys of all trusted Git authors. SecretRef corev1 . LocalObjectReference `json:\"secretRef,omitempty\"` } Status \u00b6 // GitRepositoryStatus defines the observed state of the GitRepository. type GitRepositoryStatus struct { // Conditions holds the conditions for the GitRepository. // +optional Conditions [] meta . Condition `json:\"conditions,omitempty\"` // URL is the download link for the artifact output of the last repository // sync. // +optional URL string `json:\"url,omitempty\"` // Artifact represents the output of the last successful repository sync. // +optional Artifact * Artifact `json:\"artifact,omitempty\"` // LastHandledReconcileAt is the last manual reconciliation request (by // annotating the GitRepository) handled by the reconciler. // +optional LastHandledReconcileAt string `json:\"lastHandledReconcileAt,omitempty\"` } Condition reasons \u00b6 const ( // GitOperationSucceedReason represents the fact that the git // clone, pull and checkout operations succeeded. GitOperationSucceedReason string = \"GitOperationSucceed\" // GitOperationFailedReason represents the fact that the git // clone, pull or checkout operations failed. GitOperationFailedReason string = \"GitOperationFailed\" ) Artifact \u00b6 The GitRepository API defines a source for artifacts coming from Git. The resource exposes the latest synchronized state from Git as an artifact in a gzip compressed TAR archive ( <commit hash>.tar.gz ). Excluding files \u00b6 Git files ( .git/ , .gitignore , .gitmodules , and .gitattributes ) are excluded from the archive by default, as well as some extensions ( .jpg, .jpeg, .gif, .png, .wmv, .flv, .tar.gz, .zip ) Excluding additional files from the archive is possible by adding a .sourceignore file in the root of the repository. The .sourceignore file follows the .gitignore pattern format , pattern entries may overrule default exclusions. Another option is to use the spec.ignore field, for example: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 5m url : https://github.com/stefanprodan/podinfo ignore : | # exclude all /* # include deploy dir !/deploy # exclude file extensions from deploy dir /deploy/**/*.md /deploy/**/*.txt When specified, spec.ignore overrides the default exclusion list. Git Implementation \u00b6 You can skip this section unless you know that you need support for either specific git wire protocol functionality. Changing the git implementation comes with its own set of drawbacks. Some git providers like Azure DevOps require that the git client supports specific capabilities to be able to communicate. The initial library used in source-controller did not support this functionality while other libraries that did were missing other critical functionality, specifically the ability to do shallow cloning. Shallow cloning is important as it allows source-controller to only fetch the latest commits, instead of the whole git history. For some very large repositories this means downloading GB of data that could fill the disk and also impact the traffic costs. To be able to support Azure DevOps a compromise solution was built, giving the user the option to select the git library while accepting the drawbacks. Git Implementation Shallow Clones V2 Protocol Support 'go-git' true false 'libgit2' false true Pull the master branch from a repository in Azure DevOps. apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://dev.azure.com/org/proj/_git/repo gitImplementation : libgit2 Spec examples \u00b6 Checkout strategies \u00b6 Pull the master branch of a public repository every minute: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo Pull a specific branch: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo ref : branch : v3.x Checkout a specific commit from a branch: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo ref : branch : master commit : 363a6a8fe6a7f13e05d34c163b0ef02a777da20a Pull a specific tag: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo ref : tag : 3.2.0 Pull tag based on a semver range : apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo ref : semver : \">=3.1.0-rc.1 <3.2.0\" HTTPS authentication \u00b6 HTTPS authentication requires a Kubernetes secret with username and password fields: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo secretRef : name : https-credentials --- apiVersion : v1 kind : Secret metadata : name : https-credentials namespace : default type : Opaque data : username : <BASE64> password : <BASE64> Note: that self-signed certificates are not supported. SSH authentication \u00b6 SSH authentication requires a Kubernetes secret with identity and known_hosts fields: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : ssh://git@github.com/stefanprodan/podinfo secretRef : name : ssh-credentials --- apiVersion : v1 kind : Secret metadata : name : ssh-credentials namespace : default type : Opaque data : identity : <BASE64> identity.pub : <BASE64> known_hosts : <BASE64> Note: that the SSH address does not support SCP syntax. The URL format is ssh://user@host:port/org/repository . Example of generating the SSH credentials secret: ssh-keygen -q -N \"\" -f ./identity ssh-keyscan github.com > ./known_hosts kubectl create secret generic ssh-credentials \\ --from-file = ./identity \\ --from-file = ./identity.pub \\ --from-file = ./known_hosts GPG signature verification \u00b6 Verify the OpenPGP signature for the commit that master branch HEAD points to: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo ref : branch : master verify : mode : head secretRef : name : pgp-public-keys --- apiVersion : v1 kind : Secret metadata : name : pgp-public-keys namespace : default type : Opaque data : author1.asc : <BASE64> author2.asc : <BASE64> Example of generating the PGP public keys secret: gpg --export --armor 3CB12BA185C47B67 > author1.asc gpg --export --armor 6A7436E8790F8689 > author2.asc kubectl create secret generic pgp-public-keys \\ --from-file = author1.asc \\ --from-file = author2.asc Self-signed certificates \u00b6 Cloning over HTTPS from a Git repository with a self-signed certificate: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://customdomain.com/stefanprodan/podinfo secretRef : name : https-credentials gitImplementation : libgit2 --- apiVersion : v1 kind : Secret metadata : name : https-credentials namespace : default type : Opaque data : username : <BASE64> password : <BASE64> caFile : <BASE64> Note that the Git implementation has to be libgit2 as go-git does not support custom CA verification. It is also possible to specify a caFile for public repositories, in that case the username and password can be omitted. Status examples \u00b6 Successful sync: status : artifact : lastUpdateTime : \"2020-04-07T06:59:23Z\" path : /data/gitrepository/default/podinfo/363a6a8fe6a7f13e05d34c163b0ef02a777da20a.tar.gz revision : master/363a6a8fe6a7f13e05d34c163b0ef02a777da20a url : http://<host>/gitrepository/default/podinfo/363a6a8fe6a7f13e05d34c163b0ef02a777da20a.tar.gz conditions : - lastTransitionTime : \"2020-04-07T06:59:23Z\" message : 'Git repoistory artifacts are available at: /data/gitrepository/default/podinfo/363a6a8fe6a7f13e05d34c163b0ef02a777da20a.tar.gz' reason : GitOperationSucceed status : \"True\" type : Ready url : http://<host>/gitrepository/default/podinfo/latest.tar.gz Failed authentication: status : conditions : - lastTransitionTime : \"2020-04-06T06:48:59Z\" message : 'git clone error ssh: handshake failed: ssh: unable to authenticate, attempted methods [none publickey], no supported methods remain' reason : AuthenticationFailed status : \"False\" type : Ready Failed PGP signature verification: status : conditions : - lastTransitionTime : \"2020-04-06T06:48:59Z\" message : 'PGP signature of {Stefan Prodan 2020-04-04 13:36:58 +0300 +0300} can not be verified' reason : VerificationFailed status : \"False\" type : Ready Wait for ready condition: kubectl wait gitrepository/podinfo --for = condition = ready --timeout = 1m","title":"GitRepository CRD"},{"location":"components/source/gitrepositories/#git-repositories","text":"The GitRepository API defines a source for artifacts coming from Git. The resource exposes the latest synchronized state from Git as an artifact in a gzip compressed TAR archive .","title":"Git Repositories"},{"location":"components/source/gitrepositories/#specification","text":"Git repository: // GitRepositorySpec defines the desired state of a Git repository. type GitRepositorySpec struct { // The repository URL, can be a HTTP/S or SSH address. // +kubebuilder:validation:Pattern=\"^(http|https|ssh)://\" // +required URL string `json:\"url\"` // The secret name containing the Git credentials. // For HTTPS repositories the secret must contain username and password // fields. // For SSH repositories the secret must contain identity, identity.pub and // known_hosts fields. // +optional SecretRef * corev1 . LocalObjectReference `json:\"secretRef,omitempty\"` // The interval at which to check for repository updates. // +required Interval metav1 . Duration `json:\"interval\"` // The timeout for remote Git operations like cloning, defaults to 20s. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // The Git reference to checkout and monitor for changes, defaults to // master branch. // +optional Reference * GitRepositoryRef `json:\"ref,omitempty\"` // Verify OpenPGP signature for the Git commit HEAD points to. // +optional Verification * GitRepositoryVerification `json:\"verify,omitempty\"` // Ignore overrides the set of excluded patterns in the .sourceignore format // (which is the same as .gitignore). If not provided, a default will be used, // consult the documentation for your version to find out what those are. // +optional Ignore * string `json:\"ignore,omitempty\"` // This flag tells the controller to suspend the reconciliation of this source. // +optional Suspend bool `json:\"suspend,omitempty\"` // Determines which git client library to use. // Defaults to go-git, valid values are ('go-git', 'libgit2'). // +kubebuilder:validation:Enum=go-git;libgit2 // +kubebuilder:default:=go-git // +optional GitImplementation string `json:\"gitImplementation,omitempty\"` } Git repository reference: // GitRepositoryRef defines the Git ref used for pull and checkout operations. type GitRepositoryRef struct { // The Git branch to checkout, defaults to master. // +optional Branch string `json:\"branch,omitempty\"` // The Git tag to checkout, takes precedence over Branch. // +optional Tag string `json:\"tag,omitempty\"` // The Git tag semver expression, takes precedence over Tag. // +optional SemVer string `json:\"semver,omitempty\"` // The Git commit SHA to checkout, if specified Tag filters will be ignored. // +optional Commit string `json:\"commit,omitempty\"` } Git repository cryptographic provenance verification: // GitRepositoryVerification defines the OpenPGP signature verification process. type GitRepositoryVerification struct { // Mode describes what git object should be verified, currently ('head'). // +kubebuilder:validation:Enum=head Mode string `json:\"mode\"` // The secret name containing the public keys of all trusted Git authors. SecretRef corev1 . LocalObjectReference `json:\"secretRef,omitempty\"` }","title":"Specification"},{"location":"components/source/gitrepositories/#status","text":"// GitRepositoryStatus defines the observed state of the GitRepository. type GitRepositoryStatus struct { // Conditions holds the conditions for the GitRepository. // +optional Conditions [] meta . Condition `json:\"conditions,omitempty\"` // URL is the download link for the artifact output of the last repository // sync. // +optional URL string `json:\"url,omitempty\"` // Artifact represents the output of the last successful repository sync. // +optional Artifact * Artifact `json:\"artifact,omitempty\"` // LastHandledReconcileAt is the last manual reconciliation request (by // annotating the GitRepository) handled by the reconciler. // +optional LastHandledReconcileAt string `json:\"lastHandledReconcileAt,omitempty\"` }","title":"Status"},{"location":"components/source/gitrepositories/#condition-reasons","text":"const ( // GitOperationSucceedReason represents the fact that the git // clone, pull and checkout operations succeeded. GitOperationSucceedReason string = \"GitOperationSucceed\" // GitOperationFailedReason represents the fact that the git // clone, pull or checkout operations failed. GitOperationFailedReason string = \"GitOperationFailed\" )","title":"Condition reasons"},{"location":"components/source/gitrepositories/#artifact","text":"The GitRepository API defines a source for artifacts coming from Git. The resource exposes the latest synchronized state from Git as an artifact in a gzip compressed TAR archive ( <commit hash>.tar.gz ).","title":"Artifact"},{"location":"components/source/gitrepositories/#excluding-files","text":"Git files ( .git/ , .gitignore , .gitmodules , and .gitattributes ) are excluded from the archive by default, as well as some extensions ( .jpg, .jpeg, .gif, .png, .wmv, .flv, .tar.gz, .zip ) Excluding additional files from the archive is possible by adding a .sourceignore file in the root of the repository. The .sourceignore file follows the .gitignore pattern format , pattern entries may overrule default exclusions. Another option is to use the spec.ignore field, for example: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 5m url : https://github.com/stefanprodan/podinfo ignore : | # exclude all /* # include deploy dir !/deploy # exclude file extensions from deploy dir /deploy/**/*.md /deploy/**/*.txt When specified, spec.ignore overrides the default exclusion list.","title":"Excluding files"},{"location":"components/source/gitrepositories/#git-implementation","text":"You can skip this section unless you know that you need support for either specific git wire protocol functionality. Changing the git implementation comes with its own set of drawbacks. Some git providers like Azure DevOps require that the git client supports specific capabilities to be able to communicate. The initial library used in source-controller did not support this functionality while other libraries that did were missing other critical functionality, specifically the ability to do shallow cloning. Shallow cloning is important as it allows source-controller to only fetch the latest commits, instead of the whole git history. For some very large repositories this means downloading GB of data that could fill the disk and also impact the traffic costs. To be able to support Azure DevOps a compromise solution was built, giving the user the option to select the git library while accepting the drawbacks. Git Implementation Shallow Clones V2 Protocol Support 'go-git' true false 'libgit2' false true Pull the master branch from a repository in Azure DevOps. apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://dev.azure.com/org/proj/_git/repo gitImplementation : libgit2","title":"Git Implementation"},{"location":"components/source/gitrepositories/#spec-examples","text":"","title":"Spec examples"},{"location":"components/source/gitrepositories/#checkout-strategies","text":"Pull the master branch of a public repository every minute: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo Pull a specific branch: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo ref : branch : v3.x Checkout a specific commit from a branch: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo ref : branch : master commit : 363a6a8fe6a7f13e05d34c163b0ef02a777da20a Pull a specific tag: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo ref : tag : 3.2.0 Pull tag based on a semver range : apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo ref : semver : \">=3.1.0-rc.1 <3.2.0\"","title":"Checkout strategies"},{"location":"components/source/gitrepositories/#https-authentication","text":"HTTPS authentication requires a Kubernetes secret with username and password fields: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo secretRef : name : https-credentials --- apiVersion : v1 kind : Secret metadata : name : https-credentials namespace : default type : Opaque data : username : <BASE64> password : <BASE64> Note: that self-signed certificates are not supported.","title":"HTTPS authentication"},{"location":"components/source/gitrepositories/#ssh-authentication","text":"SSH authentication requires a Kubernetes secret with identity and known_hosts fields: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : ssh://git@github.com/stefanprodan/podinfo secretRef : name : ssh-credentials --- apiVersion : v1 kind : Secret metadata : name : ssh-credentials namespace : default type : Opaque data : identity : <BASE64> identity.pub : <BASE64> known_hosts : <BASE64> Note: that the SSH address does not support SCP syntax. The URL format is ssh://user@host:port/org/repository . Example of generating the SSH credentials secret: ssh-keygen -q -N \"\" -f ./identity ssh-keyscan github.com > ./known_hosts kubectl create secret generic ssh-credentials \\ --from-file = ./identity \\ --from-file = ./identity.pub \\ --from-file = ./known_hosts","title":"SSH authentication"},{"location":"components/source/gitrepositories/#gpg-signature-verification","text":"Verify the OpenPGP signature for the commit that master branch HEAD points to: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://github.com/stefanprodan/podinfo ref : branch : master verify : mode : head secretRef : name : pgp-public-keys --- apiVersion : v1 kind : Secret metadata : name : pgp-public-keys namespace : default type : Opaque data : author1.asc : <BASE64> author2.asc : <BASE64> Example of generating the PGP public keys secret: gpg --export --armor 3CB12BA185C47B67 > author1.asc gpg --export --armor 6A7436E8790F8689 > author2.asc kubectl create secret generic pgp-public-keys \\ --from-file = author1.asc \\ --from-file = author2.asc","title":"GPG signature verification"},{"location":"components/source/gitrepositories/#self-signed-certificates","text":"Cloning over HTTPS from a Git repository with a self-signed certificate: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : default spec : interval : 1m url : https://customdomain.com/stefanprodan/podinfo secretRef : name : https-credentials gitImplementation : libgit2 --- apiVersion : v1 kind : Secret metadata : name : https-credentials namespace : default type : Opaque data : username : <BASE64> password : <BASE64> caFile : <BASE64> Note that the Git implementation has to be libgit2 as go-git does not support custom CA verification. It is also possible to specify a caFile for public repositories, in that case the username and password can be omitted.","title":"Self-signed certificates"},{"location":"components/source/gitrepositories/#status-examples","text":"Successful sync: status : artifact : lastUpdateTime : \"2020-04-07T06:59:23Z\" path : /data/gitrepository/default/podinfo/363a6a8fe6a7f13e05d34c163b0ef02a777da20a.tar.gz revision : master/363a6a8fe6a7f13e05d34c163b0ef02a777da20a url : http://<host>/gitrepository/default/podinfo/363a6a8fe6a7f13e05d34c163b0ef02a777da20a.tar.gz conditions : - lastTransitionTime : \"2020-04-07T06:59:23Z\" message : 'Git repoistory artifacts are available at: /data/gitrepository/default/podinfo/363a6a8fe6a7f13e05d34c163b0ef02a777da20a.tar.gz' reason : GitOperationSucceed status : \"True\" type : Ready url : http://<host>/gitrepository/default/podinfo/latest.tar.gz Failed authentication: status : conditions : - lastTransitionTime : \"2020-04-06T06:48:59Z\" message : 'git clone error ssh: handshake failed: ssh: unable to authenticate, attempted methods [none publickey], no supported methods remain' reason : AuthenticationFailed status : \"False\" type : Ready Failed PGP signature verification: status : conditions : - lastTransitionTime : \"2020-04-06T06:48:59Z\" message : 'PGP signature of {Stefan Prodan 2020-04-04 13:36:58 +0300 +0300} can not be verified' reason : VerificationFailed status : \"False\" type : Ready Wait for ready condition: kubectl wait gitrepository/podinfo --for = condition = ready --timeout = 1m","title":"Status examples"},{"location":"components/source/helmcharts/","text":"Helm Charts \u00b6 The HelmChart API defines a source for Helm chart artifacts coming from HelmRepository sources . The resource exposes the latest pulled or packaged chart as an artifact. Specification \u00b6 Helm chart: // HelmChartSpec defines the desired state of a Helm chart. type HelmChartSpec struct { // The name or path the Helm chart is available at in the SourceRef. // +required Chart string `json:\"chart\"` // The chart version semver expression, ignored for charts from GitRepository // and Bucket sources. Defaults to latest when omitted. // +optional Version string `json:\"version,omitempty\"` // The reference to the Source the chart is available at. // +required SourceRef LocalHelmChartSourceReference `json:\"sourceRef\"` // The interval at which to check the Source for updates. // +required Interval metav1 . Duration `json:\"interval\"` // Alternative values file to use as the default chart values, expected to be a // relative path in the SourceRef. Ignored when omitted. // +optional ValuesFile string `json:\"valuesFile,omitempty\"` // This flag tells the controller to suspend the reconciliation of this source. // +optional Suspend bool `json:\"suspend,omitempty\"` } Reference types \u00b6 // LocalHelmChartSourceReference contains enough information to let you locate // the typed referenced object at namespace level. type LocalHelmChartSourceReference struct { // APIVersion of the referent. // +optional APIVersion string `json:\"apiVersion,omitempty\"` // Kind of the referent, valid values are ('HelmRepository', 'GitRepository', // 'Bucket'). // +kubebuilder:validation:Enum=HelmRepository;GitRepository;Bucket // +required Kind string `json:\"kind\"` // Name of the referent. // +required Name string `json:\"name\"` } Status \u00b6 // HelmChartStatus defines the observed state of the HelmChart. type HelmChartStatus struct { // ObservedGeneration is the last observed generation. // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // Conditions holds the conditions for the HelmChart. // +optional Conditions [] meta . Condition `json:\"conditions,omitempty\"` // URL is the download link for the last chart pulled. // +optional URL string `json:\"url,omitempty\"` // Artifact represents the output of the last successful chart sync. // +optional Artifact * Artifact `json:\"artifact,omitempty\"` // LastHandledReconcileAt is the last manual reconciliation request (by // annotating the HelmChart) handled by the reconciler. // +optional LastHandledReconcileAt string `json:\"lastHandledReconcileAt,omitempty\"` } Condition reasons \u00b6 const ( // ChartPullFailedReason represents the fact that the pull of the Helm chart // failed. ChartPullFailedReason string = \"ChartPullFailed\" // ChartPullSucceededReason represents the fact that the pull of the Helm chart // succeeded. ChartPullSucceededReason string = \"ChartPullSucceeded\" // ChartPackageFailedReason represent the fact that the package of the Helm // chart failed. ChartPackageFailedReason string = \"ChartPackageFailed\" // ChartPackageSucceededReason represents the fact that the package of the Helm // chart succeeded. ChartPackageSucceededReason string = \"ChartPackageSucceeded\" ) Spec examples \u00b6 Pull a specific chart version every five minutes: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmChart metadata : name : redis namespace : default spec : chart : redis version : 10.5.7 sourceRef : name : stable kind : HelmRepository interval : 5m Pull the latest chart version that matches the semver range every ten minutes: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmChart metadata : name : redis namespace : default spec : chart : redis version : 10.5.x sourceRef : name : stable kind : HelmRepository interval : 10m Check a Git repository every ten minutes for a new version in the Chart.yaml , and package a new chart if the revision differs: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmChart metadata : name : podinfo namespace : default spec : chart : ./charts/podinfo sourceRef : name : podinfo kind : GitRepository interval : 10m Check a S3 compatible bucket every ten minutes for a new version in the Chart.yaml , and package a new chart if the revision differs: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmChart metadata : name : podinfo namespace : default spec : chart : ./podinfo sourceRef : name : charts kind : Bucket interval : 10m Status examples \u00b6 Successful chart pull: status : url : http://<host>/helmchart/default/redis/redis-10.5.7.tgz conditions : - lastTransitionTime : \"2020-04-10T09:34:45Z\" message : Helm chart is available at /data/helmchart/default/redis/redis-10.5.7.tgz reason : ChartPullSucceeded status : \"True\" type : Ready Failed chart pull: status : conditions : - lastTransitionTime : \"2020-04-10T09:34:45Z\" message : 'invalid chart URL format' reason : ChartPullFailed status : \"False\" type : Ready Wait for ready condition: kubectl wait helmchart/redis --for = condition = ready --timeout = 1m","title":"HelmChart CRD"},{"location":"components/source/helmcharts/#helm-charts","text":"The HelmChart API defines a source for Helm chart artifacts coming from HelmRepository sources . The resource exposes the latest pulled or packaged chart as an artifact.","title":"Helm Charts"},{"location":"components/source/helmcharts/#specification","text":"Helm chart: // HelmChartSpec defines the desired state of a Helm chart. type HelmChartSpec struct { // The name or path the Helm chart is available at in the SourceRef. // +required Chart string `json:\"chart\"` // The chart version semver expression, ignored for charts from GitRepository // and Bucket sources. Defaults to latest when omitted. // +optional Version string `json:\"version,omitempty\"` // The reference to the Source the chart is available at. // +required SourceRef LocalHelmChartSourceReference `json:\"sourceRef\"` // The interval at which to check the Source for updates. // +required Interval metav1 . Duration `json:\"interval\"` // Alternative values file to use as the default chart values, expected to be a // relative path in the SourceRef. Ignored when omitted. // +optional ValuesFile string `json:\"valuesFile,omitempty\"` // This flag tells the controller to suspend the reconciliation of this source. // +optional Suspend bool `json:\"suspend,omitempty\"` }","title":"Specification"},{"location":"components/source/helmcharts/#reference-types","text":"// LocalHelmChartSourceReference contains enough information to let you locate // the typed referenced object at namespace level. type LocalHelmChartSourceReference struct { // APIVersion of the referent. // +optional APIVersion string `json:\"apiVersion,omitempty\"` // Kind of the referent, valid values are ('HelmRepository', 'GitRepository', // 'Bucket'). // +kubebuilder:validation:Enum=HelmRepository;GitRepository;Bucket // +required Kind string `json:\"kind\"` // Name of the referent. // +required Name string `json:\"name\"` }","title":"Reference types"},{"location":"components/source/helmcharts/#status","text":"// HelmChartStatus defines the observed state of the HelmChart. type HelmChartStatus struct { // ObservedGeneration is the last observed generation. // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // Conditions holds the conditions for the HelmChart. // +optional Conditions [] meta . Condition `json:\"conditions,omitempty\"` // URL is the download link for the last chart pulled. // +optional URL string `json:\"url,omitempty\"` // Artifact represents the output of the last successful chart sync. // +optional Artifact * Artifact `json:\"artifact,omitempty\"` // LastHandledReconcileAt is the last manual reconciliation request (by // annotating the HelmChart) handled by the reconciler. // +optional LastHandledReconcileAt string `json:\"lastHandledReconcileAt,omitempty\"` }","title":"Status"},{"location":"components/source/helmcharts/#condition-reasons","text":"const ( // ChartPullFailedReason represents the fact that the pull of the Helm chart // failed. ChartPullFailedReason string = \"ChartPullFailed\" // ChartPullSucceededReason represents the fact that the pull of the Helm chart // succeeded. ChartPullSucceededReason string = \"ChartPullSucceeded\" // ChartPackageFailedReason represent the fact that the package of the Helm // chart failed. ChartPackageFailedReason string = \"ChartPackageFailed\" // ChartPackageSucceededReason represents the fact that the package of the Helm // chart succeeded. ChartPackageSucceededReason string = \"ChartPackageSucceeded\" )","title":"Condition reasons"},{"location":"components/source/helmcharts/#spec-examples","text":"Pull a specific chart version every five minutes: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmChart metadata : name : redis namespace : default spec : chart : redis version : 10.5.7 sourceRef : name : stable kind : HelmRepository interval : 5m Pull the latest chart version that matches the semver range every ten minutes: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmChart metadata : name : redis namespace : default spec : chart : redis version : 10.5.x sourceRef : name : stable kind : HelmRepository interval : 10m Check a Git repository every ten minutes for a new version in the Chart.yaml , and package a new chart if the revision differs: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmChart metadata : name : podinfo namespace : default spec : chart : ./charts/podinfo sourceRef : name : podinfo kind : GitRepository interval : 10m Check a S3 compatible bucket every ten minutes for a new version in the Chart.yaml , and package a new chart if the revision differs: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmChart metadata : name : podinfo namespace : default spec : chart : ./podinfo sourceRef : name : charts kind : Bucket interval : 10m","title":"Spec examples"},{"location":"components/source/helmcharts/#status-examples","text":"Successful chart pull: status : url : http://<host>/helmchart/default/redis/redis-10.5.7.tgz conditions : - lastTransitionTime : \"2020-04-10T09:34:45Z\" message : Helm chart is available at /data/helmchart/default/redis/redis-10.5.7.tgz reason : ChartPullSucceeded status : \"True\" type : Ready Failed chart pull: status : conditions : - lastTransitionTime : \"2020-04-10T09:34:45Z\" message : 'invalid chart URL format' reason : ChartPullFailed status : \"False\" type : Ready Wait for ready condition: kubectl wait helmchart/redis --for = condition = ready --timeout = 1m","title":"Status examples"},{"location":"components/source/helmrepositories/","text":"Helm Repositories \u00b6 The HelmRepository API defines a source for Helm repositories. The resource exposes the latest synchronized repository index as an artifact. Specification \u00b6 Helm repository: // HelmRepositorySpec defines the reference to a Helm repository. type HelmRepositorySpec struct { // The Helm repository URL, a valid URL contains at least a protocol and host. // +required URL string `json:\"url\"` // The name of the secret containing authentication credentials for the Helm // repository. // For HTTP/S basic auth the secret must contain username and // password fields. // For TLS the secret must contain a certFile and keyFile, and/or // caCert fields. // +optional SecretRef * corev1 . LocalObjectReference `json:\"secretRef,omitempty\"` // The interval at which to check the upstream for updates. // +required Interval metav1 . Duration `json:\"interval\"` // The timeout of index downloading, defaults to 60s. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // This flag tells the controller to suspend the reconciliation of this source. // +optional Suspend bool `json:\"suspend,omitempty\"` } Status \u00b6 // HelmRepositoryStatus defines the observed state of the HelmRepository. type HelmRepositoryStatus struct { // ObservedGeneration is the last observed generation. // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // Conditions holds the conditions for the HelmRepository. // +optional Conditions [] meta . Condition `json:\"conditions,omitempty\"` // URL is the download link for the last index fetched. // +optional URL string `json:\"url,omitempty\"` // Artifact represents the output of the last successful repository sync. // +optional Artifact * Artifact `json:\"artifact,omitempty\"` // LastHandledReconcileAt is the last manual reconciliation request (by // annotating the HelmRepository) handled by the reconciler. // +optional LastHandledReconcileAt string `json:\"lastHandledReconcileAt,omitempty\"` } Condition reasons \u00b6 const ( // IndexationFailedReason represents the fact that the indexation of the given // Helm repository failed. IndexationFailedReason string = \"IndexationFailed\" // IndexationSucceededReason represents the fact that the indexation of the // given Helm repository succeeded. IndexationSucceededReason string = \"IndexationSucceed\" ) Spec examples \u00b6 Pull the index of a public Helm repository every ten minutes: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : stable namespace : default spec : url : https://kubernetes-charts.storage.googleapis.com/ interval : 10m Pull the index of a private Helm repository every minute: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : private namespace : default spec : url : https://charts.example.com secretRef : name : https-credentials interval : 1m --- apiVersion : v1 kind : Secret metadata : name : https-credentials namespace : default type : Opaque data : username : <BASE64> password : <BASE64> certFile : <BASE64> keyFile : <BASE64> caFile : <BASE64> Status examples \u00b6 Successful indexation: status : url : http://<host>/helmrepository/default/stable/index.yaml conditions : - lastTransitionTime : \"2020-04-10T09:34:45Z\" message : Helm repository index is available at /data/helmrepository/default/stable/index-21c195d78e699e4b656e2885887d019627838993.yaml reason : IndexationSucceeded status : \"True\" type : Ready Failed indexation: status : conditions : - lastTransitionTime : \"2020-04-10T09:27:21Z\" message : 'failed to fetch https://invalid.example.com/index.yaml : 404 Not Found' reason : IndexationFailed status : \"False\" type : Ready Invalid repository URL: status : conditions : - lastTransitionTime : \"2020-04-10T09:27:21Z\" message : scheme \"invalid\" not supported reason : URLInvalid status : \"False\" type : Ready Wait for ready condition: kubectl wait helmrepository/stable --for = condition = ready --timeout = 1m","title":"HelmRepository CRD"},{"location":"components/source/helmrepositories/#helm-repositories","text":"The HelmRepository API defines a source for Helm repositories. The resource exposes the latest synchronized repository index as an artifact.","title":"Helm Repositories"},{"location":"components/source/helmrepositories/#specification","text":"Helm repository: // HelmRepositorySpec defines the reference to a Helm repository. type HelmRepositorySpec struct { // The Helm repository URL, a valid URL contains at least a protocol and host. // +required URL string `json:\"url\"` // The name of the secret containing authentication credentials for the Helm // repository. // For HTTP/S basic auth the secret must contain username and // password fields. // For TLS the secret must contain a certFile and keyFile, and/or // caCert fields. // +optional SecretRef * corev1 . LocalObjectReference `json:\"secretRef,omitempty\"` // The interval at which to check the upstream for updates. // +required Interval metav1 . Duration `json:\"interval\"` // The timeout of index downloading, defaults to 60s. // +optional Timeout * metav1 . Duration `json:\"timeout,omitempty\"` // This flag tells the controller to suspend the reconciliation of this source. // +optional Suspend bool `json:\"suspend,omitempty\"` }","title":"Specification"},{"location":"components/source/helmrepositories/#status","text":"// HelmRepositoryStatus defines the observed state of the HelmRepository. type HelmRepositoryStatus struct { // ObservedGeneration is the last observed generation. // +optional ObservedGeneration int64 `json:\"observedGeneration,omitempty\"` // Conditions holds the conditions for the HelmRepository. // +optional Conditions [] meta . Condition `json:\"conditions,omitempty\"` // URL is the download link for the last index fetched. // +optional URL string `json:\"url,omitempty\"` // Artifact represents the output of the last successful repository sync. // +optional Artifact * Artifact `json:\"artifact,omitempty\"` // LastHandledReconcileAt is the last manual reconciliation request (by // annotating the HelmRepository) handled by the reconciler. // +optional LastHandledReconcileAt string `json:\"lastHandledReconcileAt,omitempty\"` }","title":"Status"},{"location":"components/source/helmrepositories/#condition-reasons","text":"const ( // IndexationFailedReason represents the fact that the indexation of the given // Helm repository failed. IndexationFailedReason string = \"IndexationFailed\" // IndexationSucceededReason represents the fact that the indexation of the // given Helm repository succeeded. IndexationSucceededReason string = \"IndexationSucceed\" )","title":"Condition reasons"},{"location":"components/source/helmrepositories/#spec-examples","text":"Pull the index of a public Helm repository every ten minutes: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : stable namespace : default spec : url : https://kubernetes-charts.storage.googleapis.com/ interval : 10m Pull the index of a private Helm repository every minute: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : private namespace : default spec : url : https://charts.example.com secretRef : name : https-credentials interval : 1m --- apiVersion : v1 kind : Secret metadata : name : https-credentials namespace : default type : Opaque data : username : <BASE64> password : <BASE64> certFile : <BASE64> keyFile : <BASE64> caFile : <BASE64>","title":"Spec examples"},{"location":"components/source/helmrepositories/#status-examples","text":"Successful indexation: status : url : http://<host>/helmrepository/default/stable/index.yaml conditions : - lastTransitionTime : \"2020-04-10T09:34:45Z\" message : Helm repository index is available at /data/helmrepository/default/stable/index-21c195d78e699e4b656e2885887d019627838993.yaml reason : IndexationSucceeded status : \"True\" type : Ready Failed indexation: status : conditions : - lastTransitionTime : \"2020-04-10T09:27:21Z\" message : 'failed to fetch https://invalid.example.com/index.yaml : 404 Not Found' reason : IndexationFailed status : \"False\" type : Ready Invalid repository URL: status : conditions : - lastTransitionTime : \"2020-04-10T09:27:21Z\" message : scheme \"invalid\" not supported reason : URLInvalid status : \"False\" type : Ready Wait for ready condition: kubectl wait helmrepository/stable --for = condition = ready --timeout = 1m","title":"Status examples"},{"location":"contributing/","text":"Contributing \u00b6 Flux is Apache 2.0 licensed and accepts contributions via GitHub pull requests. This document outlines some of the conventions on to make it easier to get your contribution accepted. We gratefully welcome improvements to issues and documentation as well as to code. Certificate of Origin \u00b6 By contributing to this project you agree to the Developer Certificate of Origin (DCO). This document was created by the Linux Kernel community and is a simple statement that you, as a contributor, have the legal right to make the contribution. We require all commits to be signed. By signing off with your signature, you certify that you wrote the patch or otherwise have the right to contribute the material by the rules of the DCO : Signed-off-by: Jane Doe <jane.doe@example.com> The signature must contain your real name (sorry, no pseudonyms or anonymous contributions) If your user.name and user.email are configured in your Git config, you can sign your commit automatically with git commit -s . Communications \u00b6 For realtime communications we use Slack: To join the conversation, simply join the CNCF Slack workspace and use the #flux-dev channel. To discuss ideas and specifications we use Github Discussions . For announcements we use a mailing list as well. Simply subscribe to flux-dev on cncf.io to join the conversation (there you can also add calendar invites to your Google calendar for our Flux meeting ). Understanding Flux and the GitOps Toolkit \u00b6 If you are entirely new to Flux and the GitOps Toolkit, you might want to take a look at the introductory talk and demo . This project is composed of: /f/flux2 : The Flux CLI /f/source-manager : Kubernetes operator for managing sources /f/kustomize-controller : Kubernetes operator for building GitOps pipelines with Kustomize /f/helm-controller : Kubernetes operator for building GitOps pipelines with Helm /f/notification-controller : Kubernetes operator for handling inbound and outbound events Understanding the code \u00b6 To get started with developing controllers, you might want to review our guide which walks you through writing a short and concise controller that watches out for source changes. How to run the test suite \u00b6 You can run the unit tests by simply doing make test Acceptance policy \u00b6 These things will make a PR more likely to be accepted: a well-described requirement tests for new code tests for old code! new code and tests follow the conventions in old code and tests a good commit message (see below) all code must abide Go Code Review Comments names should abide What's in a name code must build on both Linux and Darwin, via plain go build code should have appropriate test coverage and tests should be written to work with go test In general, we will merge a PR once one maintainer has endorsed it. For substantial changes, more people may become involved, and you might get asked to resubmit the PR or divide the changes into more than one PR. Format of the Commit Message \u00b6 For the GitOps Toolkit controllers we prefer the following rules for good commit messages: Limit the subject to 50 characters and write as the continuation of the sentence \"If applied, this commit will ...\" Explain what and why in the body, if more than a trivial change; wrap it at 72 characters. The following article has some more helpful advice on documenting your work.","title":"Contributing"},{"location":"contributing/#contributing","text":"Flux is Apache 2.0 licensed and accepts contributions via GitHub pull requests. This document outlines some of the conventions on to make it easier to get your contribution accepted. We gratefully welcome improvements to issues and documentation as well as to code.","title":"Contributing"},{"location":"contributing/#certificate-of-origin","text":"By contributing to this project you agree to the Developer Certificate of Origin (DCO). This document was created by the Linux Kernel community and is a simple statement that you, as a contributor, have the legal right to make the contribution. We require all commits to be signed. By signing off with your signature, you certify that you wrote the patch or otherwise have the right to contribute the material by the rules of the DCO : Signed-off-by: Jane Doe <jane.doe@example.com> The signature must contain your real name (sorry, no pseudonyms or anonymous contributions) If your user.name and user.email are configured in your Git config, you can sign your commit automatically with git commit -s .","title":"Certificate of Origin"},{"location":"contributing/#communications","text":"For realtime communications we use Slack: To join the conversation, simply join the CNCF Slack workspace and use the #flux-dev channel. To discuss ideas and specifications we use Github Discussions . For announcements we use a mailing list as well. Simply subscribe to flux-dev on cncf.io to join the conversation (there you can also add calendar invites to your Google calendar for our Flux meeting ).","title":"Communications"},{"location":"contributing/#understanding-flux-and-the-gitops-toolkit","text":"If you are entirely new to Flux and the GitOps Toolkit, you might want to take a look at the introductory talk and demo . This project is composed of: /f/flux2 : The Flux CLI /f/source-manager : Kubernetes operator for managing sources /f/kustomize-controller : Kubernetes operator for building GitOps pipelines with Kustomize /f/helm-controller : Kubernetes operator for building GitOps pipelines with Helm /f/notification-controller : Kubernetes operator for handling inbound and outbound events","title":"Understanding Flux and the GitOps Toolkit"},{"location":"contributing/#understanding-the-code","text":"To get started with developing controllers, you might want to review our guide which walks you through writing a short and concise controller that watches out for source changes.","title":"Understanding the code"},{"location":"contributing/#how-to-run-the-test-suite","text":"You can run the unit tests by simply doing make test","title":"How to run the test suite"},{"location":"contributing/#acceptance-policy","text":"These things will make a PR more likely to be accepted: a well-described requirement tests for new code tests for old code! new code and tests follow the conventions in old code and tests a good commit message (see below) all code must abide Go Code Review Comments names should abide What's in a name code must build on both Linux and Darwin, via plain go build code should have appropriate test coverage and tests should be written to work with go test In general, we will merge a PR once one maintainer has endorsed it. For substantial changes, more people may become involved, and you might get asked to resubmit the PR or divide the changes into more than one PR.","title":"Acceptance policy"},{"location":"contributing/#format-of-the-commit-message","text":"For the GitOps Toolkit controllers we prefer the following rules for good commit messages: Limit the subject to 50 characters and write as the continuation of the sentence \"If applied, this commit will ...\" Explain what and why in the body, if more than a trivial change; wrap it at 72 characters. The following article has some more helpful advice on documenting your work.","title":"Format of the Commit Message"},{"location":"core-concepts/","text":"Core Concepts \u00b6 Work in progress This document is a work in progress. These are some core concepts in Flux. GitOps \u00b6 GitOps is a way of managing your infrastructure and applications so that whole system is described declaratively and version controlled (most likely in a Git repository), and having an automated process that ensures that the deployed environment matches the state specified in a repository. For more information, take a look at \"What is GitOps?\" . Sources \u00b6 A Source defines the origin of a source and the requirements to obtain it (e.g. credentials, version selectors). For example, the latest 1.x tag available from a Git repository over SSH. Sources produce an artifact that is consumed by other Flux elements to perform actions, like applying the contents of the artifact on the cluster. A source may be shared by multiple consumers to deduplicate configuration and/or storage. The origin of the source is checked for changes on a defined interval, if there is a newer version available that matches the criteria, a new artifact is produced. All sources are specified as Custom Resources in a Kubernetes cluster, examples of sources are GitRepository , HelmRepository and Bucket resources. For more information, take a look at the source controller documentation . Reconciliation \u00b6 Reconciliation refers to ensuring that a given state (e.g application running in the cluster, infrastructure) matches a desired state declaratively defined somewhere (e.g a git repository). There are various examples of these in flux e.g: HelmRelease reconciliation: ensures the state of the Helm release matches what is defined in the resource, performs a release if this is not the case (including revision changes of a HelmChart resource). Bucket reconciliation: downloads and archives the contents of the declared bucket on a given interval and stores this as an artifact, records the observed revision of the artifact and the artifact itself in the status of resource. Kustomization reconciliation: ensures the state of the application deployed on a cluster matches resources contained in a git repository. Kustomization \u00b6 The kustomization represents a local set of Kubernetes resources that Flux is supposed to reconcile in the cluster. The reconciliation runs every one minute by default but this can be specified in the kustomization. If you make any changes to the cluster using kubectl edit or kubectl patch , it will be promptly reverted. You either suspend the reconciliation or push your changes to a Git repository. For more information, take a look at this documentation . Bootstrap \u00b6 The process of installing the Flux components in a complete GitOps way is called a bootstrap. The manifests are applied to the cluster, a GitRepository and Kustomization are created for the Flux components, and the manifests are pushed to an existing Git repository (or a new one is created). Flux can manage itself just as it manages other resources. The bootstrap is done using the flux CLI flux bootstrap . For more information, take a look at the documentation for the bootstrap command .","title":"Core Concepts"},{"location":"core-concepts/#core-concepts","text":"Work in progress This document is a work in progress. These are some core concepts in Flux.","title":"Core Concepts"},{"location":"core-concepts/#gitops","text":"GitOps is a way of managing your infrastructure and applications so that whole system is described declaratively and version controlled (most likely in a Git repository), and having an automated process that ensures that the deployed environment matches the state specified in a repository. For more information, take a look at \"What is GitOps?\" .","title":"GitOps"},{"location":"core-concepts/#sources","text":"A Source defines the origin of a source and the requirements to obtain it (e.g. credentials, version selectors). For example, the latest 1.x tag available from a Git repository over SSH. Sources produce an artifact that is consumed by other Flux elements to perform actions, like applying the contents of the artifact on the cluster. A source may be shared by multiple consumers to deduplicate configuration and/or storage. The origin of the source is checked for changes on a defined interval, if there is a newer version available that matches the criteria, a new artifact is produced. All sources are specified as Custom Resources in a Kubernetes cluster, examples of sources are GitRepository , HelmRepository and Bucket resources. For more information, take a look at the source controller documentation .","title":"Sources"},{"location":"core-concepts/#reconciliation","text":"Reconciliation refers to ensuring that a given state (e.g application running in the cluster, infrastructure) matches a desired state declaratively defined somewhere (e.g a git repository). There are various examples of these in flux e.g: HelmRelease reconciliation: ensures the state of the Helm release matches what is defined in the resource, performs a release if this is not the case (including revision changes of a HelmChart resource). Bucket reconciliation: downloads and archives the contents of the declared bucket on a given interval and stores this as an artifact, records the observed revision of the artifact and the artifact itself in the status of resource. Kustomization reconciliation: ensures the state of the application deployed on a cluster matches resources contained in a git repository.","title":"Reconciliation"},{"location":"core-concepts/#kustomization","text":"The kustomization represents a local set of Kubernetes resources that Flux is supposed to reconcile in the cluster. The reconciliation runs every one minute by default but this can be specified in the kustomization. If you make any changes to the cluster using kubectl edit or kubectl patch , it will be promptly reverted. You either suspend the reconciliation or push your changes to a Git repository. For more information, take a look at this documentation .","title":"Kustomization"},{"location":"core-concepts/#bootstrap","text":"The process of installing the Flux components in a complete GitOps way is called a bootstrap. The manifests are applied to the cluster, a GitRepository and Kustomization are created for the Flux components, and the manifests are pushed to an existing Git repository (or a new one is created). Flux can manage itself just as it manages other resources. The bootstrap is done using the flux CLI flux bootstrap . For more information, take a look at the documentation for the bootstrap command .","title":"Bootstrap"},{"location":"dev-guides/debugging/","text":"Advanced debugging \u00b6 This guide covers more advanced debugging topics such as collecting runtime profiling data from GitOps Toolkit components. As a user, this page normally should be a last resort, but you may be asked by a maintainer to share a collected profile to debug e.g. performance issues. Pprof \u00b6 The GitOps Toolkit components serve pprof runtime profiling data on their metrics HTTP server (default :8080 ). Endpoints \u00b6 Endpoint Path Index /debug/pprof/ CPU profile /debug/pprof/profile Symbol /debug/pprof/symbol Trace /debug/pprof/trace Collecting a profile \u00b6 To collect a profile, port-forward to the component's metrics endpoint and collect the data from the endpoint of choice: $ kubectl port-forward -n <namespace> deploy/<component> 8080 $ curl -Sk -v http://localhost:8080/debug/pprof/heap > heap.out The collected profile can be analyzed using go , or shared with one of the maintainers. Resource usage \u00b6 As kubectl top gives a limited (and at times inaccurate) overview of resource usage, it is often better to make use of the Grafana metrics to gather insights. See monitoring for a guide on how to visualize this data with a Grafana dashboard.","title":"Advanced debugging"},{"location":"dev-guides/debugging/#advanced-debugging","text":"This guide covers more advanced debugging topics such as collecting runtime profiling data from GitOps Toolkit components. As a user, this page normally should be a last resort, but you may be asked by a maintainer to share a collected profile to debug e.g. performance issues.","title":"Advanced debugging"},{"location":"dev-guides/debugging/#pprof","text":"The GitOps Toolkit components serve pprof runtime profiling data on their metrics HTTP server (default :8080 ).","title":"Pprof"},{"location":"dev-guides/debugging/#endpoints","text":"Endpoint Path Index /debug/pprof/ CPU profile /debug/pprof/profile Symbol /debug/pprof/symbol Trace /debug/pprof/trace","title":"Endpoints"},{"location":"dev-guides/debugging/#collecting-a-profile","text":"To collect a profile, port-forward to the component's metrics endpoint and collect the data from the endpoint of choice: $ kubectl port-forward -n <namespace> deploy/<component> 8080 $ curl -Sk -v http://localhost:8080/debug/pprof/heap > heap.out The collected profile can be analyzed using go , or shared with one of the maintainers.","title":"Collecting a profile"},{"location":"dev-guides/debugging/#resource-usage","text":"As kubectl top gives a limited (and at times inaccurate) overview of resource usage, it is often better to make use of the Grafana metrics to gather insights. See monitoring for a guide on how to visualize this data with a Grafana dashboard.","title":"Resource usage"},{"location":"dev-guides/source-watcher/","text":"Watching for source changes \u00b6 In this guide you'll be developing a Kubernetes controller with Kubebuilder that subscribes to GitRepository events and reacts to revision changes by downloading the artifact produced by source-controller . Prerequisites \u00b6 On your dev machine install the following tools: go >= 1.15 kubebuilder >= 2.3 kind >= 0.8 kubectl >= 1.18 kustomize >= 3.5 docker >= 19.03 Install Flux \u00b6 Create a cluster for testing: kind create cluster --name dev Install the Flux CLI: curl -s https://toolkit.fluxcd.io/install.sh | sudo bash Verify that your dev machine satisfies the prerequisites with: flux check --pre Install source-controller on the dev cluster: flux install Clone the sample controller \u00b6 You'll be using fluxcd/source-watcher as a template for developing your own controller. The source-watcher was scaffolded with kubebuilder init . Clone the source-watcher repository: git clone https://github.com/fluxcd/source-watcher cd source-watcher Build the controller: make Run the controller \u00b6 Port forward to source-controller artifacts server: kubectl -n flux-system port-forward svc/source-controller 8181 :80 Export the local address as SOURCE_HOST : export SOURCE_HOST = localhost:8181 Run source-watcher locally: make run Create a Git source: flux create source git test \\ --url = https://github.com/stefanprodan/podinfo \\ --tag = 4 .0.0 The source-watcher should log the revision: New revision detected {\"gitrepository\": \"flux-system/test\", \"revision\": \"4.0.0/ab953493ee14c3c9800bda0251e0c507f9741408\"} Extracted tarball into /var/folders/77/3y6x_p2j2g9fspdkzjbm5_s40000gn/T/test292235827: 123 files, 29 dirs (32.603415ms) Processing files... Change the Git tag: flux create source git test \\ --url = https://github.com/stefanprodan/podinfo \\ --tag = 4 .0.1 The source-watcher should log the new revision: New revision detected {\"gitrepository\": \"flux-system/test\", \"revision\": \"4.0.1/113360052b3153e439a0cf8de76b8e3d2a7bdf27\"} The source-controller reports the revision under GitRepository.Status.Artifact.Revision in the format: <branch|tag>/<commit> . How it works \u00b6 The GitRepositoryWatcher controller does the following: subscribes to GitRepository events detects when the Git revision changes downloads and extracts the source artifact write to stdout the extracted file names // GitRepositoryWatcher watches GitRepository objects for revision changes type GitRepositoryWatcher struct { client . Client Log logr . Logger Scheme * runtime . Scheme } // +kubebuilder:rbac:groups=source.toolkit.fluxcd.io,resources=gitrepositories,verbs=get;list;watch // +kubebuilder:rbac:groups=source.toolkit.fluxcd.io,resources=gitrepositories/status,verbs=get func ( r * GitRepositoryWatcher ) Reconcile ( req ctrl . Request ) ( ctrl . Result , error ) { // set timeout for the reconciliation ctx , cancel := context . WithTimeout ( context . Background (), 15 * time . Second ) defer cancel () // get source object var repository sourcev1 . GitRepository if err := r . Get ( ctx , req . NamespacedName , & repository ); err != nil { return ctrl . Result {}, client . IgnoreNotFound ( err ) } log := r . Log . WithValues ( strings . ToLower ( repository . Kind ), req . NamespacedName ) log . Info ( \"New revision detected\" , \"revision\" , repository . Status . Artifact . Revision ) // create tmp dir tmpDir , err := ioutil . TempDir ( \"\" , repository . Name ) if err != nil { return ctrl . Result {}, fmt . Errorf ( \"unable to create temp dir, error: %w\" , err ) } defer os . RemoveAll ( tmpDir ) // download and extract artifact summary , err := r . fetchArtifact ( ctx , repository , tmpDir ) if err != nil { return ctrl . Result {}, fmt . Errorf ( \"unable to fetch artifact, error: %w\" , err ) } log . Info ( summary ) // list artifact content files , err := ioutil . ReadDir ( tmpDir ) if err != nil { return ctrl . Result {}, fmt . Errorf ( \"unable to list files, error: %w\" , err ) } // do something with the artifact content for _ , f := range files { log . Info ( \"Processing \" + f . Name ()) } return ctrl . Result {}, nil } func ( r * GitRepositoryWatcher ) SetupWithManager ( mgr ctrl . Manager ) error { return ctrl . NewControllerManagedBy ( mgr ). For ( & sourcev1 . GitRepository {}). WithEventFilter ( GitRepositoryRevisionChangePredicate {}). Complete ( r ) } To add the watcher to an existing project, copy the controller and the revision change predicate to your controllers dir: gitrepository_watcher.go gitrepository_predicate.go In your main.go init function, register the Source API schema: import sourcev1 \"github.com/fluxcd/source-controller/api/v1beta1\" func init () { _ = clientgoscheme . AddToScheme ( scheme ) _ = sourcev1 . AddToScheme ( scheme ) // +kubebuilder:scaffold:scheme } Start the controller in the main function: func main () { if err = ( & controllers . GitRepositoryWatcher { Client : mgr . GetClient (), Log : ctrl . Log . WithName ( \"controllers\" ). WithName ( \"GitRepositoryWatcher\" ), Scheme : mgr . GetScheme (), }). SetupWithManager ( mgr ); err != nil { setupLog . Error ( err , \"unable to create controller\" , \"controller\" , \"GitRepositoryWatcher\" ) os . Exit ( 1 ) } } Note that the watcher controller depends on Kubernetes client-go >= 1.18. Your go.mod should require controller-runtime v0.6 or newer: require ( k8s . io / apimachinery v0 .19.4 k8s . io / client - go v0 .19.4 sigs . k8s . io / controller - runtime v0 .6.4 ) That's it! Happy hacking!","title":"Watching for source changes"},{"location":"dev-guides/source-watcher/#watching-for-source-changes","text":"In this guide you'll be developing a Kubernetes controller with Kubebuilder that subscribes to GitRepository events and reacts to revision changes by downloading the artifact produced by source-controller .","title":"Watching for source changes"},{"location":"dev-guides/source-watcher/#prerequisites","text":"On your dev machine install the following tools: go >= 1.15 kubebuilder >= 2.3 kind >= 0.8 kubectl >= 1.18 kustomize >= 3.5 docker >= 19.03","title":"Prerequisites"},{"location":"dev-guides/source-watcher/#install-flux","text":"Create a cluster for testing: kind create cluster --name dev Install the Flux CLI: curl -s https://toolkit.fluxcd.io/install.sh | sudo bash Verify that your dev machine satisfies the prerequisites with: flux check --pre Install source-controller on the dev cluster: flux install","title":"Install Flux"},{"location":"dev-guides/source-watcher/#clone-the-sample-controller","text":"You'll be using fluxcd/source-watcher as a template for developing your own controller. The source-watcher was scaffolded with kubebuilder init . Clone the source-watcher repository: git clone https://github.com/fluxcd/source-watcher cd source-watcher Build the controller: make","title":"Clone the sample controller"},{"location":"dev-guides/source-watcher/#run-the-controller","text":"Port forward to source-controller artifacts server: kubectl -n flux-system port-forward svc/source-controller 8181 :80 Export the local address as SOURCE_HOST : export SOURCE_HOST = localhost:8181 Run source-watcher locally: make run Create a Git source: flux create source git test \\ --url = https://github.com/stefanprodan/podinfo \\ --tag = 4 .0.0 The source-watcher should log the revision: New revision detected {\"gitrepository\": \"flux-system/test\", \"revision\": \"4.0.0/ab953493ee14c3c9800bda0251e0c507f9741408\"} Extracted tarball into /var/folders/77/3y6x_p2j2g9fspdkzjbm5_s40000gn/T/test292235827: 123 files, 29 dirs (32.603415ms) Processing files... Change the Git tag: flux create source git test \\ --url = https://github.com/stefanprodan/podinfo \\ --tag = 4 .0.1 The source-watcher should log the new revision: New revision detected {\"gitrepository\": \"flux-system/test\", \"revision\": \"4.0.1/113360052b3153e439a0cf8de76b8e3d2a7bdf27\"} The source-controller reports the revision under GitRepository.Status.Artifact.Revision in the format: <branch|tag>/<commit> .","title":"Run the controller"},{"location":"dev-guides/source-watcher/#how-it-works","text":"The GitRepositoryWatcher controller does the following: subscribes to GitRepository events detects when the Git revision changes downloads and extracts the source artifact write to stdout the extracted file names // GitRepositoryWatcher watches GitRepository objects for revision changes type GitRepositoryWatcher struct { client . Client Log logr . Logger Scheme * runtime . Scheme } // +kubebuilder:rbac:groups=source.toolkit.fluxcd.io,resources=gitrepositories,verbs=get;list;watch // +kubebuilder:rbac:groups=source.toolkit.fluxcd.io,resources=gitrepositories/status,verbs=get func ( r * GitRepositoryWatcher ) Reconcile ( req ctrl . Request ) ( ctrl . Result , error ) { // set timeout for the reconciliation ctx , cancel := context . WithTimeout ( context . Background (), 15 * time . Second ) defer cancel () // get source object var repository sourcev1 . GitRepository if err := r . Get ( ctx , req . NamespacedName , & repository ); err != nil { return ctrl . Result {}, client . IgnoreNotFound ( err ) } log := r . Log . WithValues ( strings . ToLower ( repository . Kind ), req . NamespacedName ) log . Info ( \"New revision detected\" , \"revision\" , repository . Status . Artifact . Revision ) // create tmp dir tmpDir , err := ioutil . TempDir ( \"\" , repository . Name ) if err != nil { return ctrl . Result {}, fmt . Errorf ( \"unable to create temp dir, error: %w\" , err ) } defer os . RemoveAll ( tmpDir ) // download and extract artifact summary , err := r . fetchArtifact ( ctx , repository , tmpDir ) if err != nil { return ctrl . Result {}, fmt . Errorf ( \"unable to fetch artifact, error: %w\" , err ) } log . Info ( summary ) // list artifact content files , err := ioutil . ReadDir ( tmpDir ) if err != nil { return ctrl . Result {}, fmt . Errorf ( \"unable to list files, error: %w\" , err ) } // do something with the artifact content for _ , f := range files { log . Info ( \"Processing \" + f . Name ()) } return ctrl . Result {}, nil } func ( r * GitRepositoryWatcher ) SetupWithManager ( mgr ctrl . Manager ) error { return ctrl . NewControllerManagedBy ( mgr ). For ( & sourcev1 . GitRepository {}). WithEventFilter ( GitRepositoryRevisionChangePredicate {}). Complete ( r ) } To add the watcher to an existing project, copy the controller and the revision change predicate to your controllers dir: gitrepository_watcher.go gitrepository_predicate.go In your main.go init function, register the Source API schema: import sourcev1 \"github.com/fluxcd/source-controller/api/v1beta1\" func init () { _ = clientgoscheme . AddToScheme ( scheme ) _ = sourcev1 . AddToScheme ( scheme ) // +kubebuilder:scaffold:scheme } Start the controller in the main function: func main () { if err = ( & controllers . GitRepositoryWatcher { Client : mgr . GetClient (), Log : ctrl . Log . WithName ( \"controllers\" ). WithName ( \"GitRepositoryWatcher\" ), Scheme : mgr . GetScheme (), }). SetupWithManager ( mgr ); err != nil { setupLog . Error ( err , \"unable to create controller\" , \"controller\" , \"GitRepositoryWatcher\" ) os . Exit ( 1 ) } } Note that the watcher controller depends on Kubernetes client-go >= 1.18. Your go.mod should require controller-runtime v0.6 or newer: require ( k8s . io / apimachinery v0 .19.4 k8s . io / client - go v0 .19.4 sigs . k8s . io / controller - runtime v0 .6.4 ) That's it! Happy hacking!","title":"How it works"},{"location":"faq/","text":"Frequently asked questions \u00b6 Kustomize questions \u00b6 Are there two Kustomization types? \u00b6 Yes, the kustomization.kustomize.toolkit.fluxcd.io is a Kubernetes custom resource while kustomization.kustomize.config.k8s.io is the type used to configure a Kustomize overlay . The kustomization.kustomize.toolkit.fluxcd.io object refers to a kustomization.yaml file path inside a Git repository or Bucket source. How do I use them together? \u00b6 Assuming an app repository with ./deploy/prod/kustomization.yaml : apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization resources : - deployment.yaml - service.yaml - ingress.yaml Define a source of type gitrepository.source.toolkit.fluxcd.io that pulls changes from the app repository every 5 minutes inside the cluster: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : my-app namespace : default spec : interval : 5m url : https://github.com/my-org/my-app ref : branch : main Then define a kustomization.kustomize.toolkit.fluxcd.io that uses the kustomization.yaml from ./deploy/prod to determine which resources to create, update or delete: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : my-app namespace : default spec : interval : 15m path : \"./deploy/prod\" prune : true sourceRef : kind : GitRepository name : my-app What is a Kustomization reconciliation? \u00b6 In the above example, we pull changes from Git every 5 minutes, and a new commit will trigger a reconciliation of all the Kustomization objects using that source. Depending on your configuration, a reconciliation can mean: generating a kustomization.yaml file in the specified path building the kustomize overlay decrypting secrets validating the manifests with client or server-side dry-run applying changes on the cluster health checking of deployed workloads garbage collection of resources removed from Git issuing events about the reconciliation result recoding metrics about the reconciliation process The 15 minutes reconciliation interval, is the interval at which you want to undo manual changes .e.g. kubectl set image deployment/my-app by reapplying the latest commit on the cluster. Note that a reconciliation will override all fields of a Kubernetes object, that diverge from Git. For example, you'll have to omit the spec.replicas field from your Deployments YAMLs if you are using a HorizontalPodAutoscaler that changes the replicas in-cluster. Can I use repositories with plain YAMLs? \u00b6 Yes, you can specify the path where the Kubernetes manifests are, and kustomize-controller will generate a kustomization.yaml if one doesn't exist. Assuming an app repository with the following structure: \u251c\u2500\u2500 deploy \u2502 \u2514\u2500\u2500 prod \u2502 \u251c\u2500\u2500 .yamllint.yaml \u2502 \u251c\u2500\u2500 deployment.yaml \u2502 \u251c\u2500\u2500 service.yaml \u2502 \u2514\u2500\u2500 ingress.yaml \u2514\u2500\u2500 src Create a GitRepository definition and exclude all the files that are not Kubernetes manifests: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : my-app namespace : default spec : interval : 5m url : https://github.com/my-org/my-app ref : branch : main ignore : | # exclude all /* # include deploy dir !/deploy # exclude non-Kubernetes YAMLs /deploy/**/.yamllint.yaml Then create a Kustomization definition to reconcile the ./deploy/prod dir: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : my-app namespace : default spec : interval : 15m path : \"./deploy/prod\" prune : true sourceRef : kind : GitRepository name : my-app With the above configuration, source-controller will pull the Kubernetes manifests from the app repository and kustomize-controller will generate a kustomization.yaml including all the resources found with ./deploy/prod/**/*.yaml . The kustomize-controller creates kustomization.yaml files similar to: cd ./deploy/prod && kustomize create --autodetect --recursive What is the behavior of Kustomize used by Flux \u00b6 We referred to the Kustomization CLI flags here, so that you can replicate the same behavior using the CLI. The behavior of Kustomize used by the controller is currently configured as following: --allow_id_changes is set to false, so it does not change any resource IDs. --enable_kyaml is disabled by default, so it currently used k8sdeps to process YAMLs. --enable_alpha_plugins is disabled by default, so it uses only the built-in plugins. --load_restrictor is set to LoadRestrictionsNone , so it allows loading files outside the dir containing kustomization.yaml . --reorder resources is done in the legacy mode, so the output will have namespaces and cluster roles/role bindings first, CRDs before CRs, and webhooks last. kustomization.yaml validation To validate changes before committing and/or merging, a validation utility script is available , it runs kustomize locally or in CI with the same set of flags as the controller and validates the output using kubeval . Helm questions \u00b6 How to debug \"not ready\" errors? \u00b6 Misconfiguring the HelmRelease.spec.chart , like a typo in the chart name, version or chart source URL would result in a \"HelmChart is not ready\" error displayed by: $ flux get helmreleases --all-namespaces NAMESPACE NAME READY MESSAGE default podinfo False HelmChart 'default/default-podinfo' is not ready In order to get to the root cause, first make sure the source e.g. the HelmRepository is configured properly and has access to the remote index.yaml : $ flux get sources helm --all-namespaces NAMESPACE NAME READY MESSAGE default podinfo False failed to fetch https://stefanprodan.github.io/podinfo2/index.yaml : 404 Not Found If the source is Ready , then the error must be caused by the chart, for example due to an invalid chart name or non-existing version: $ flux get sources chart --all-namespaces NAMESPACE NAME READY MESSAGE default default-podinfo False no chart version found for podinfo-9.0.0 Can I use Flux HelmReleases without GitOps? \u00b6 Yes, you can install the Flux components directly on a cluster and manage Helm releases with kubectl . Install the controllers needed for Helm operations with flux : flux install \\ --namespace = flux-system \\ --network-policy = false \\ --components = source-controller,helm-controller Create a Helm release with kubectl : cat << EOF | kubectl apply -f - --- apiVersion: source.toolkit.fluxcd.io/v1beta1 kind: HelmRepository metadata: name: bitnami namespace: flux-system spec: interval: 30m url: https://charts.bitnami.com/bitnami --- apiVersion: helm.toolkit.fluxcd.io/v2beta1 kind: HelmRelease metadata: name: metrics-server namespace: kube-system spec: interval: 60m releaseName: metrics-server chart: spec: chart: metrics-server version: \"^5.x\" sourceRef: kind: HelmRepository name: bitnami namespace: flux-system values: apiService: create: true EOF Based on the above definition, Flux will upgrade the release automatically when Bitnami publishes a new version of the metrics-server chart. Flux v1 vs v2 questions \u00b6 What are the differences between v1 and v2? \u00b6 Flux v1 is a monolithic do-it-all operator; Flux v2 separates the functionalities into specialized controllers, collectively called the GitOps Toolkit. You can find a detailed comparison of Flux v1 and v2 features in the migration FAQ . How can I migrate from v1 to v2? \u00b6 The Flux community has created guides and example repositories to help you migrate to Flux v2: Migrate from Flux v1 Migrate from .flux.yaml and kustomize Migrate from Flux v1 automated container image updates How to manage multi-tenant clusters with Flux v2 Migrate from Helm Operator to Flux v2 How to structure your HelmReleases","title":"FAQ"},{"location":"faq/#frequently-asked-questions","text":"","title":"Frequently asked questions"},{"location":"faq/#kustomize-questions","text":"","title":"Kustomize questions"},{"location":"faq/#are-there-two-kustomization-types","text":"Yes, the kustomization.kustomize.toolkit.fluxcd.io is a Kubernetes custom resource while kustomization.kustomize.config.k8s.io is the type used to configure a Kustomize overlay . The kustomization.kustomize.toolkit.fluxcd.io object refers to a kustomization.yaml file path inside a Git repository or Bucket source.","title":"Are there two Kustomization types?"},{"location":"faq/#how-do-i-use-them-together","text":"Assuming an app repository with ./deploy/prod/kustomization.yaml : apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization resources : - deployment.yaml - service.yaml - ingress.yaml Define a source of type gitrepository.source.toolkit.fluxcd.io that pulls changes from the app repository every 5 minutes inside the cluster: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : my-app namespace : default spec : interval : 5m url : https://github.com/my-org/my-app ref : branch : main Then define a kustomization.kustomize.toolkit.fluxcd.io that uses the kustomization.yaml from ./deploy/prod to determine which resources to create, update or delete: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : my-app namespace : default spec : interval : 15m path : \"./deploy/prod\" prune : true sourceRef : kind : GitRepository name : my-app","title":"How do I use them together?"},{"location":"faq/#what-is-a-kustomization-reconciliation","text":"In the above example, we pull changes from Git every 5 minutes, and a new commit will trigger a reconciliation of all the Kustomization objects using that source. Depending on your configuration, a reconciliation can mean: generating a kustomization.yaml file in the specified path building the kustomize overlay decrypting secrets validating the manifests with client or server-side dry-run applying changes on the cluster health checking of deployed workloads garbage collection of resources removed from Git issuing events about the reconciliation result recoding metrics about the reconciliation process The 15 minutes reconciliation interval, is the interval at which you want to undo manual changes .e.g. kubectl set image deployment/my-app by reapplying the latest commit on the cluster. Note that a reconciliation will override all fields of a Kubernetes object, that diverge from Git. For example, you'll have to omit the spec.replicas field from your Deployments YAMLs if you are using a HorizontalPodAutoscaler that changes the replicas in-cluster.","title":"What is a Kustomization reconciliation?"},{"location":"faq/#can-i-use-repositories-with-plain-yamls","text":"Yes, you can specify the path where the Kubernetes manifests are, and kustomize-controller will generate a kustomization.yaml if one doesn't exist. Assuming an app repository with the following structure: \u251c\u2500\u2500 deploy \u2502 \u2514\u2500\u2500 prod \u2502 \u251c\u2500\u2500 .yamllint.yaml \u2502 \u251c\u2500\u2500 deployment.yaml \u2502 \u251c\u2500\u2500 service.yaml \u2502 \u2514\u2500\u2500 ingress.yaml \u2514\u2500\u2500 src Create a GitRepository definition and exclude all the files that are not Kubernetes manifests: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : my-app namespace : default spec : interval : 5m url : https://github.com/my-org/my-app ref : branch : main ignore : | # exclude all /* # include deploy dir !/deploy # exclude non-Kubernetes YAMLs /deploy/**/.yamllint.yaml Then create a Kustomization definition to reconcile the ./deploy/prod dir: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : my-app namespace : default spec : interval : 15m path : \"./deploy/prod\" prune : true sourceRef : kind : GitRepository name : my-app With the above configuration, source-controller will pull the Kubernetes manifests from the app repository and kustomize-controller will generate a kustomization.yaml including all the resources found with ./deploy/prod/**/*.yaml . The kustomize-controller creates kustomization.yaml files similar to: cd ./deploy/prod && kustomize create --autodetect --recursive","title":"Can I use repositories with plain YAMLs?"},{"location":"faq/#what-is-the-behavior-of-kustomize-used-by-flux","text":"We referred to the Kustomization CLI flags here, so that you can replicate the same behavior using the CLI. The behavior of Kustomize used by the controller is currently configured as following: --allow_id_changes is set to false, so it does not change any resource IDs. --enable_kyaml is disabled by default, so it currently used k8sdeps to process YAMLs. --enable_alpha_plugins is disabled by default, so it uses only the built-in plugins. --load_restrictor is set to LoadRestrictionsNone , so it allows loading files outside the dir containing kustomization.yaml . --reorder resources is done in the legacy mode, so the output will have namespaces and cluster roles/role bindings first, CRDs before CRs, and webhooks last. kustomization.yaml validation To validate changes before committing and/or merging, a validation utility script is available , it runs kustomize locally or in CI with the same set of flags as the controller and validates the output using kubeval .","title":"What is the behavior of Kustomize used by Flux"},{"location":"faq/#helm-questions","text":"","title":"Helm questions"},{"location":"faq/#how-to-debug-not-ready-errors","text":"Misconfiguring the HelmRelease.spec.chart , like a typo in the chart name, version or chart source URL would result in a \"HelmChart is not ready\" error displayed by: $ flux get helmreleases --all-namespaces NAMESPACE NAME READY MESSAGE default podinfo False HelmChart 'default/default-podinfo' is not ready In order to get to the root cause, first make sure the source e.g. the HelmRepository is configured properly and has access to the remote index.yaml : $ flux get sources helm --all-namespaces NAMESPACE NAME READY MESSAGE default podinfo False failed to fetch https://stefanprodan.github.io/podinfo2/index.yaml : 404 Not Found If the source is Ready , then the error must be caused by the chart, for example due to an invalid chart name or non-existing version: $ flux get sources chart --all-namespaces NAMESPACE NAME READY MESSAGE default default-podinfo False no chart version found for podinfo-9.0.0","title":"How to debug \"not ready\" errors?"},{"location":"faq/#can-i-use-flux-helmreleases-without-gitops","text":"Yes, you can install the Flux components directly on a cluster and manage Helm releases with kubectl . Install the controllers needed for Helm operations with flux : flux install \\ --namespace = flux-system \\ --network-policy = false \\ --components = source-controller,helm-controller Create a Helm release with kubectl : cat << EOF | kubectl apply -f - --- apiVersion: source.toolkit.fluxcd.io/v1beta1 kind: HelmRepository metadata: name: bitnami namespace: flux-system spec: interval: 30m url: https://charts.bitnami.com/bitnami --- apiVersion: helm.toolkit.fluxcd.io/v2beta1 kind: HelmRelease metadata: name: metrics-server namespace: kube-system spec: interval: 60m releaseName: metrics-server chart: spec: chart: metrics-server version: \"^5.x\" sourceRef: kind: HelmRepository name: bitnami namespace: flux-system values: apiService: create: true EOF Based on the above definition, Flux will upgrade the release automatically when Bitnami publishes a new version of the metrics-server chart.","title":"Can I use Flux HelmReleases without GitOps?"},{"location":"faq/#flux-v1-vs-v2-questions","text":"","title":"Flux v1 vs v2 questions"},{"location":"faq/#what-are-the-differences-between-v1-and-v2","text":"Flux v1 is a monolithic do-it-all operator; Flux v2 separates the functionalities into specialized controllers, collectively called the GitOps Toolkit. You can find a detailed comparison of Flux v1 and v2 features in the migration FAQ .","title":"What are the differences between v1 and v2?"},{"location":"faq/#how-can-i-migrate-from-v1-to-v2","text":"The Flux community has created guides and example repositories to help you migrate to Flux v2: Migrate from Flux v1 Migrate from .flux.yaml and kustomize Migrate from Flux v1 automated container image updates How to manage multi-tenant clusters with Flux v2 Migrate from Helm Operator to Flux v2 How to structure your HelmReleases","title":"How can I migrate from v1 to v2?"},{"location":"get-started/","text":"Get started with Flux v2 \u00b6 Basic knowledge This guide assumes you have some understanding of the core concepts and have read the introduction to Flux. The core concepts used in this guide are GitOps , Sources , Kustomization . In this tutorial, you will deploy an application to a kubernetes cluster with Flux and manage the cluster in a complete GitOps manner. You'll be using a dedicated Git repository e.g. fleet-infra to manage your Kubernetes clusters. Prerequisites \u00b6 In order to follow the guide, you will need a Kubernetes cluster version 1.16 or newer and kubectl version 1.18. For a quick local test, you can use Kubernetes kind . Any other Kubernetes setup will work as well though. Flux is installed in a GitOps way and its manifest will be pushed to the repository, so you will also need a GitHub account and a personal access token that can create repositories (check all permissions under repo ) to enable Flux do this. Export your GitHub personal access token and username: export GITHUB_TOKEN = <your-token> export GITHUB_USER = <your-username> Install the Flux CLI \u00b6 To install the latest flux release on MacOS and Linux using Homebrew run: brew install fluxcd/tap/flux Or install flux by downloading precompiled binaries using a Bash script: curl -s https://toolkit.fluxcd.io/install.sh | sudo bash The install script downloads the flux binary to /usr/local/bin . If using Arch Linux, install the latest stable version from AUR using either flux-bin (pre-built binary) or flux-go (locally built binary). Binaries for macOS , Windows and Linux AMD64/ARM are available for download on the release page . To configure your shell to load flux bash completions add to your profile: # ~/.bashrc or ~/.bash_profile . < ( flux completion bash ) zsh , fish , and powershell are also supported with their own sub-commands. Install Flux components \u00b6 Create the cluster using Kubernetes kind or set the kubectl context to an existing cluster: kind create cluster kubectl cluster-info Verify that your staging cluster satisfies the prerequisites with: $ flux check --pre \u25ba checking prerequisites \u2714 kubectl 1.18.3 >=1.18.0 \u2714 kubernetes 1.18.2 >=1.16.0 \u2714 prerequisites checks passed Run the bootstrap command: flux bootstrap github \\ --owner = $GITHUB_USER \\ --repository = fleet-infra \\ --branch = main \\ --path = ./clusters/my-cluster \\ --personal Multi-arch images The component images are published as multi-arch container images with support for Linux amd64 , arm64 and armv7 (e.g. 32bit Raspberry Pi) architectures. The bootstrap command creates a repository if one doesn't exist, commits the manifests for the Flux components to the default branch at the specified path, and installs the Flux components. Then it configures the target cluster to synchronize with the specified path inside the repository. If you wish to create the repository under a GitHub organization: flux bootstrap github \\ --owner = <organization> \\ --repository = <repo-name> \\ --branch = <organization default branch> \\ --team = <team1-slug> \\ --team = <team2-slug> \\ --path = ./clusters/my-cluster Example output: $ flux bootstrap github --owner = gitopsrun --team = devs --repository = fleet-infra --path = ./clusters/my-cluster \u25ba connecting to github.com \u2714 repository created \u2714 devs team access granted \u2714 repository cloned \u271a generating manifests \u2714 components manifests pushed \u25ba installing components in flux-system namespace deployment \"source-controller\" successfully rolled out deployment \"kustomize-controller\" successfully rolled out deployment \"helm-controller\" successfully rolled out deployment \"notification-controller\" successfully rolled out \u2714 install completed \u25ba configuring deploy key \u2714 deploy key configured \u25ba generating sync manifests \u2714 sync manifests pushed \u25ba applying sync manifests \u25ce waiting for cluster sync \u2714 bootstrap finished If you prefer GitLab, export GITLAB_TOKEN env var and use the command flux bootstrap gitlab . Idempotency It is safe to run the bootstrap command as many times as you want. If the Flux components are present on the cluster, the bootstrap command will perform an upgrade if needed. You can target a specific Flux version with flux bootstrap --version=<semver> . Clone the git repository \u00b6 We are going to drive app deployments in a GitOps manner, using the Git repository as the desired state for our cluster. Instead of applying the manifests directly to the cluster, Flux will apply it for us instead. Therefore, we need to clone the repository to our local machine: git clone https://github.com/ $GITHUB_USER /fleet-infra cd fleet-infra Add podinfo repository to Flux \u00b6 We will be using a public repository github.com/stefanprodan/podinfo , podinfo is a tiny web application made with Go. Create a GitRepository manifest pointing to podinfo repository's master branch: flux create source git podinfo \\ --url = https://github.com/stefanprodan/podinfo \\ --branch = master \\ --interval = 30s \\ --export > ./clusters/my-cluster/podinfo-source.yaml The above command generates the following manifest: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : flux-system spec : interval : 30s ref : branch : master url : https://github.com/stefanprodan/podinfo Commit and push it to the fleet-infra repository: git add -A && git commit -m \"Add podinfo GitRepository\" git push Deploy podinfo application \u00b6 We will create a Flux Kustomization manifest for podinfo. This configures Flux to build and apply the kustomize directory located in the podinfo repository. flux create kustomization podinfo \\ --source = podinfo \\ --path = \"./kustomize\" \\ --prune = true \\ --validation = client \\ --interval = 5m \\ --export > ./clusters/my-cluster/podinfo-kustomization.yaml The above command generates the following manifest: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : flux-system spec : interval : 5m0s path : ./kustomize prune : true sourceRef : kind : GitRepository name : podinfo validation : client Commit and push the Kustomization manifest to the repository: git add -A && git commit -m \"Add podinfo Kustomization\" git push The structure of your repository should look like this: fleet-infra \u2514\u2500\u2500 clusters/ \u2514\u2500\u2500 my-cluster/ \u251c\u2500\u2500 flux-system/ \u2502 \u251c\u2500\u2500 gotk-components.yaml \u2502 \u251c\u2500\u2500 gotk-sync.yaml \u2502 \u2514\u2500\u2500 kustomization.yaml \u251c\u2500\u2500 podinfo-kustomization.yaml \u2514\u2500\u2500 podinfo-source.yaml Watch Flux sync the application \u00b6 In about 30s the synchronization should start: $ watch flux get kustomizations NAME READY MESSAGE flux-system True Applied revision: main/fc07af652d3168be329539b30a4c3943a7d12dd8 podinfo True Applied revision: master/855f7724be13f6146f61a893851522837ad5b634 When the synchronization finishes you can check that podinfo has been deployed on your cluster: $ kubectl -n default get deployments,services NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/podinfo 2/2 2 2 108s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/podinfo ClusterIP 10.100.149.126 <none> 9898/TCP,9999/TCP 108s Tip From this moment forward, any changes made to the podinfo Kubernetes manifests in the master branch will be synchronised with your cluster. If a Kubernetes manifest is removed from the podinfo repository, Flux will remove it from your cluster. If you delete a Kustomization from the fleet-infra repository, Flux will remove all Kubernetes objects that were previously applied from that Kustomization . If you alter the podinfo deployment using kubectl edit , the changes will be reverted to match the state described in Git. When dealing with an incident, you can pause the reconciliation of a kustomization with flux suspend kustomization <name> . Once the debugging session is over, you can re-enable the reconciliation with flux resume kustomization <name> . Multi-cluster Setup \u00b6 To use Flux to manage more than one cluster or promote deployments from staging to production, take a look at the two approaches in the repositories listed below. https://github.com/fluxcd/flux2-kustomize-helm-example https://github.com/fluxcd/flux2-multi-tenancy","title":"Get Started"},{"location":"get-started/#get-started-with-flux-v2","text":"Basic knowledge This guide assumes you have some understanding of the core concepts and have read the introduction to Flux. The core concepts used in this guide are GitOps , Sources , Kustomization . In this tutorial, you will deploy an application to a kubernetes cluster with Flux and manage the cluster in a complete GitOps manner. You'll be using a dedicated Git repository e.g. fleet-infra to manage your Kubernetes clusters.","title":"Get started with Flux v2"},{"location":"get-started/#prerequisites","text":"In order to follow the guide, you will need a Kubernetes cluster version 1.16 or newer and kubectl version 1.18. For a quick local test, you can use Kubernetes kind . Any other Kubernetes setup will work as well though. Flux is installed in a GitOps way and its manifest will be pushed to the repository, so you will also need a GitHub account and a personal access token that can create repositories (check all permissions under repo ) to enable Flux do this. Export your GitHub personal access token and username: export GITHUB_TOKEN = <your-token> export GITHUB_USER = <your-username>","title":"Prerequisites"},{"location":"get-started/#install-the-flux-cli","text":"To install the latest flux release on MacOS and Linux using Homebrew run: brew install fluxcd/tap/flux Or install flux by downloading precompiled binaries using a Bash script: curl -s https://toolkit.fluxcd.io/install.sh | sudo bash The install script downloads the flux binary to /usr/local/bin . If using Arch Linux, install the latest stable version from AUR using either flux-bin (pre-built binary) or flux-go (locally built binary). Binaries for macOS , Windows and Linux AMD64/ARM are available for download on the release page . To configure your shell to load flux bash completions add to your profile: # ~/.bashrc or ~/.bash_profile . < ( flux completion bash ) zsh , fish , and powershell are also supported with their own sub-commands.","title":"Install the Flux CLI"},{"location":"get-started/#install-flux-components","text":"Create the cluster using Kubernetes kind or set the kubectl context to an existing cluster: kind create cluster kubectl cluster-info Verify that your staging cluster satisfies the prerequisites with: $ flux check --pre \u25ba checking prerequisites \u2714 kubectl 1.18.3 >=1.18.0 \u2714 kubernetes 1.18.2 >=1.16.0 \u2714 prerequisites checks passed Run the bootstrap command: flux bootstrap github \\ --owner = $GITHUB_USER \\ --repository = fleet-infra \\ --branch = main \\ --path = ./clusters/my-cluster \\ --personal Multi-arch images The component images are published as multi-arch container images with support for Linux amd64 , arm64 and armv7 (e.g. 32bit Raspberry Pi) architectures. The bootstrap command creates a repository if one doesn't exist, commits the manifests for the Flux components to the default branch at the specified path, and installs the Flux components. Then it configures the target cluster to synchronize with the specified path inside the repository. If you wish to create the repository under a GitHub organization: flux bootstrap github \\ --owner = <organization> \\ --repository = <repo-name> \\ --branch = <organization default branch> \\ --team = <team1-slug> \\ --team = <team2-slug> \\ --path = ./clusters/my-cluster Example output: $ flux bootstrap github --owner = gitopsrun --team = devs --repository = fleet-infra --path = ./clusters/my-cluster \u25ba connecting to github.com \u2714 repository created \u2714 devs team access granted \u2714 repository cloned \u271a generating manifests \u2714 components manifests pushed \u25ba installing components in flux-system namespace deployment \"source-controller\" successfully rolled out deployment \"kustomize-controller\" successfully rolled out deployment \"helm-controller\" successfully rolled out deployment \"notification-controller\" successfully rolled out \u2714 install completed \u25ba configuring deploy key \u2714 deploy key configured \u25ba generating sync manifests \u2714 sync manifests pushed \u25ba applying sync manifests \u25ce waiting for cluster sync \u2714 bootstrap finished If you prefer GitLab, export GITLAB_TOKEN env var and use the command flux bootstrap gitlab . Idempotency It is safe to run the bootstrap command as many times as you want. If the Flux components are present on the cluster, the bootstrap command will perform an upgrade if needed. You can target a specific Flux version with flux bootstrap --version=<semver> .","title":"Install Flux components"},{"location":"get-started/#clone-the-git-repository","text":"We are going to drive app deployments in a GitOps manner, using the Git repository as the desired state for our cluster. Instead of applying the manifests directly to the cluster, Flux will apply it for us instead. Therefore, we need to clone the repository to our local machine: git clone https://github.com/ $GITHUB_USER /fleet-infra cd fleet-infra","title":"Clone the git repository"},{"location":"get-started/#add-podinfo-repository-to-flux","text":"We will be using a public repository github.com/stefanprodan/podinfo , podinfo is a tiny web application made with Go. Create a GitRepository manifest pointing to podinfo repository's master branch: flux create source git podinfo \\ --url = https://github.com/stefanprodan/podinfo \\ --branch = master \\ --interval = 30s \\ --export > ./clusters/my-cluster/podinfo-source.yaml The above command generates the following manifest: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : flux-system spec : interval : 30s ref : branch : master url : https://github.com/stefanprodan/podinfo Commit and push it to the fleet-infra repository: git add -A && git commit -m \"Add podinfo GitRepository\" git push","title":"Add podinfo repository to Flux"},{"location":"get-started/#deploy-podinfo-application","text":"We will create a Flux Kustomization manifest for podinfo. This configures Flux to build and apply the kustomize directory located in the podinfo repository. flux create kustomization podinfo \\ --source = podinfo \\ --path = \"./kustomize\" \\ --prune = true \\ --validation = client \\ --interval = 5m \\ --export > ./clusters/my-cluster/podinfo-kustomization.yaml The above command generates the following manifest: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : flux-system spec : interval : 5m0s path : ./kustomize prune : true sourceRef : kind : GitRepository name : podinfo validation : client Commit and push the Kustomization manifest to the repository: git add -A && git commit -m \"Add podinfo Kustomization\" git push The structure of your repository should look like this: fleet-infra \u2514\u2500\u2500 clusters/ \u2514\u2500\u2500 my-cluster/ \u251c\u2500\u2500 flux-system/ \u2502 \u251c\u2500\u2500 gotk-components.yaml \u2502 \u251c\u2500\u2500 gotk-sync.yaml \u2502 \u2514\u2500\u2500 kustomization.yaml \u251c\u2500\u2500 podinfo-kustomization.yaml \u2514\u2500\u2500 podinfo-source.yaml","title":"Deploy podinfo application"},{"location":"get-started/#watch-flux-sync-the-application","text":"In about 30s the synchronization should start: $ watch flux get kustomizations NAME READY MESSAGE flux-system True Applied revision: main/fc07af652d3168be329539b30a4c3943a7d12dd8 podinfo True Applied revision: master/855f7724be13f6146f61a893851522837ad5b634 When the synchronization finishes you can check that podinfo has been deployed on your cluster: $ kubectl -n default get deployments,services NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/podinfo 2/2 2 2 108s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/podinfo ClusterIP 10.100.149.126 <none> 9898/TCP,9999/TCP 108s Tip From this moment forward, any changes made to the podinfo Kubernetes manifests in the master branch will be synchronised with your cluster. If a Kubernetes manifest is removed from the podinfo repository, Flux will remove it from your cluster. If you delete a Kustomization from the fleet-infra repository, Flux will remove all Kubernetes objects that were previously applied from that Kustomization . If you alter the podinfo deployment using kubectl edit , the changes will be reverted to match the state described in Git. When dealing with an incident, you can pause the reconciliation of a kustomization with flux suspend kustomization <name> . Once the debugging session is over, you can re-enable the reconciliation with flux resume kustomization <name> .","title":"Watch Flux sync the application"},{"location":"get-started/#multi-cluster-setup","text":"To use Flux to manage more than one cluster or promote deployments from staging to production, take a look at the two approaches in the repositories listed below. https://github.com/fluxcd/flux2-kustomize-helm-example https://github.com/fluxcd/flux2-multi-tenancy","title":"Multi-cluster Setup"},{"location":"guides/faq-migration/","text":"Flux v1 vs v2 questions \u00b6 What does Flux v2 mean for Flux? \u00b6 Flux v1 is a monolithic do-it-all operator; Flux v2 separates the functionalities into specialized controllers, collectively called the GitOps Toolkit. You can install and operate Flux v2 simply using the flux command. You can easily pick and choose the functionality you need and extend it to serve your own purposes. The timeline we are looking at right now is: Put Flux v1 into maintenance mode (no new features being added; bugfixes and CVEs patched only). Continue work on the Flux v2 roadmap . We will provide transition guides for specific user groups, e.g. users of Flux v1 in read-only mode, or of Helm Operator v1, etc. once the functionality is integrated into Flux v2 and it's deemed \"ready\". Once the use-cases of Flux v1 are covered, we will continue supporting Flux v1 for 6 months. This will be the transition period before it's considered unsupported. Why did you rewrite Flux? \u00b6 Flux v2 implements its functionality in individual controllers, which allowed us to address long-standing feature requests much more easily. By basing these controllers on modern Kubernetes tooling ( controller-runtime libraries), they can be dynamically configured with Kubernetes custom resources either by cluster admins or by other automated tools -- and you get greatly increased observability. This gave us the opportunity to build Flux v2 with the top Flux v1 feature requests in mind: Supporting multiple source Git repositories Operational insight through health checks, events and alerts Multi-tenancy capabilities, like applying each source repository with its own set of permissions On top of that, testing the individual components and understanding the codebase becomes a lot easier. What are significant new differences between Flux v1 and Flux v2? \u00b6 Reconciliation \u00b6 Flux v1 Flux v2 Limited to a single Git repository Multiple Git repositories Declarative config via arguments in the Flux deployment GitRepository custom resource, which produces an artifact which can be reconciled by other controllers Follow HEAD of Git branches Supports Git branches, pinning on commits and tags, follow SemVer tag ranges Suspending of reconciliation by downscaling Flux deployment Reconciliation can be paused per resource by suspending the GitRepository Credentials config via Arguments and/or Secret volume mounts in the Flux pod Credentials config per GitRepository resource: SSH private key, HTTP/S username/password/token, OpenPGP public keys kustomize support \u00b6 Flux v1 Flux v2 Declarative config through .flux.yaml files in the Git repository Declarative config through a Kustomization custom resource, consuming the artifact from the GitRepository Manifests are generated via shell exec and then reconciled by fluxd Generation, server-side validation, and reconciliation is handled by a specialised kustomize-controller Reconciliation using the service account of the Flux deployment Support for service account impersonation Garbage collection needs cluster role binding for Flux to query the Kubernetes discovery API Garbage collection needs no cluster role binding or access to Kubernetes discovery API Support for custom commands and generators executed by fluxd in a POSIX shell No support for custom commands Helm integration \u00b6 Flux v1 Flux v2 Declarative config in a single Helm custom resource Declarative config through HelmRepository , GitRepository , Bucket , HelmChart and HelmRelease custom resources Chart synchronisation embedded in the operator Extensive release configuration options, and a reconciliation interval per source Support for fixed SemVer versions from Helm repositories Support for SemVer ranges for HelmChart resources Git repository synchronisation on a global interval Planned support for charts from GitRepository sources Limited observability via the status object of the HelmRelease resource Better observability via the HelmRelease status object, Kubernetes events, and notifications Resource heavy, relatively slow Better performance Chart changes from Git sources are determined from Git metadata Chart changes must be accompanied by a version bump in Chart.yaml to produce a new artifact Notifications, webhooks, observability \u00b6 Flux v1 Flux v2 Emits \"custom Flux events\" to a webhook endpoint Emits Kubernetes events for included custom resources RPC endpoint can be configured to a 3rd party solution like FluxCloud to be forwarded as notifications to e.g. Slack Flux v2 components can be configured to POST the events to a notification-controller endpoint. Selective forwarding of POSTed events as notifications using Provider and Alert custom resources. Webhook receiver is a side-project Webhook receiver, handling a wide range of platforms, is included Unstructured logging Structured logging for all components Custom Prometheus metrics Generic / common controller-runtime Prometheus metrics Are there any breaking changes? \u00b6 In Flux v1 Kustomize support was implemented through .flux.yaml files in the Git repository. As indicated in the comparison table above, while this approach worked, we found it to be error-prone and hard to debug. The new Kustomization CR should make troubleshooting much easier. Unfortunately we needed to drop the support for custom commands as running arbitrary shell scripts in-cluster poses serious security concerns. Helm users: we redesigned the HelmRelease API and the automation will work quite differently, so upgrading to HelmRelease v2 will require a little work from you, but you will gain more flexibility, better observability and performance. Is the GitOps Toolkit related to the GitOps Engine? \u00b6 In an announcement in August 2019, the expectation was set that the Flux project would integrate the GitOps Engine, then being factored out of ArgoCD. Since the result would be backward-incompatible, it would require a major version bump: Flux v2. After experimentation and considerable thought, we (the maintainers) have found a path to Flux v2 that we think better serves our vision of GitOps: the GitOps Toolkit. In consequence, we do not now plan to integrate GitOps Engine into Flux. How can I get involved? \u00b6 There are a variety of ways and we look forward to having you on board building the future of GitOps together: Discuss the direction of Flux v2 with us Join us in #flux-dev on the CNCF Slack Check out our contributor docs Take a look at the roadmap for Flux v2","title":"FAQ"},{"location":"guides/faq-migration/#flux-v1-vs-v2-questions","text":"","title":"Flux v1 vs v2 questions"},{"location":"guides/faq-migration/#what-does-flux-v2-mean-for-flux","text":"Flux v1 is a monolithic do-it-all operator; Flux v2 separates the functionalities into specialized controllers, collectively called the GitOps Toolkit. You can install and operate Flux v2 simply using the flux command. You can easily pick and choose the functionality you need and extend it to serve your own purposes. The timeline we are looking at right now is: Put Flux v1 into maintenance mode (no new features being added; bugfixes and CVEs patched only). Continue work on the Flux v2 roadmap . We will provide transition guides for specific user groups, e.g. users of Flux v1 in read-only mode, or of Helm Operator v1, etc. once the functionality is integrated into Flux v2 and it's deemed \"ready\". Once the use-cases of Flux v1 are covered, we will continue supporting Flux v1 for 6 months. This will be the transition period before it's considered unsupported.","title":"What does Flux v2 mean for Flux?"},{"location":"guides/faq-migration/#why-did-you-rewrite-flux","text":"Flux v2 implements its functionality in individual controllers, which allowed us to address long-standing feature requests much more easily. By basing these controllers on modern Kubernetes tooling ( controller-runtime libraries), they can be dynamically configured with Kubernetes custom resources either by cluster admins or by other automated tools -- and you get greatly increased observability. This gave us the opportunity to build Flux v2 with the top Flux v1 feature requests in mind: Supporting multiple source Git repositories Operational insight through health checks, events and alerts Multi-tenancy capabilities, like applying each source repository with its own set of permissions On top of that, testing the individual components and understanding the codebase becomes a lot easier.","title":"Why did you rewrite Flux?"},{"location":"guides/faq-migration/#what-are-significant-new-differences-between-flux-v1-and-flux-v2","text":"","title":"What are significant new differences between Flux v1 and Flux v2?"},{"location":"guides/faq-migration/#reconciliation","text":"Flux v1 Flux v2 Limited to a single Git repository Multiple Git repositories Declarative config via arguments in the Flux deployment GitRepository custom resource, which produces an artifact which can be reconciled by other controllers Follow HEAD of Git branches Supports Git branches, pinning on commits and tags, follow SemVer tag ranges Suspending of reconciliation by downscaling Flux deployment Reconciliation can be paused per resource by suspending the GitRepository Credentials config via Arguments and/or Secret volume mounts in the Flux pod Credentials config per GitRepository resource: SSH private key, HTTP/S username/password/token, OpenPGP public keys","title":"Reconciliation"},{"location":"guides/faq-migration/#kustomize-support","text":"Flux v1 Flux v2 Declarative config through .flux.yaml files in the Git repository Declarative config through a Kustomization custom resource, consuming the artifact from the GitRepository Manifests are generated via shell exec and then reconciled by fluxd Generation, server-side validation, and reconciliation is handled by a specialised kustomize-controller Reconciliation using the service account of the Flux deployment Support for service account impersonation Garbage collection needs cluster role binding for Flux to query the Kubernetes discovery API Garbage collection needs no cluster role binding or access to Kubernetes discovery API Support for custom commands and generators executed by fluxd in a POSIX shell No support for custom commands","title":"kustomize support"},{"location":"guides/faq-migration/#helm-integration","text":"Flux v1 Flux v2 Declarative config in a single Helm custom resource Declarative config through HelmRepository , GitRepository , Bucket , HelmChart and HelmRelease custom resources Chart synchronisation embedded in the operator Extensive release configuration options, and a reconciliation interval per source Support for fixed SemVer versions from Helm repositories Support for SemVer ranges for HelmChart resources Git repository synchronisation on a global interval Planned support for charts from GitRepository sources Limited observability via the status object of the HelmRelease resource Better observability via the HelmRelease status object, Kubernetes events, and notifications Resource heavy, relatively slow Better performance Chart changes from Git sources are determined from Git metadata Chart changes must be accompanied by a version bump in Chart.yaml to produce a new artifact","title":"Helm integration"},{"location":"guides/faq-migration/#notifications-webhooks-observability","text":"Flux v1 Flux v2 Emits \"custom Flux events\" to a webhook endpoint Emits Kubernetes events for included custom resources RPC endpoint can be configured to a 3rd party solution like FluxCloud to be forwarded as notifications to e.g. Slack Flux v2 components can be configured to POST the events to a notification-controller endpoint. Selective forwarding of POSTed events as notifications using Provider and Alert custom resources. Webhook receiver is a side-project Webhook receiver, handling a wide range of platforms, is included Unstructured logging Structured logging for all components Custom Prometheus metrics Generic / common controller-runtime Prometheus metrics","title":"Notifications, webhooks, observability"},{"location":"guides/faq-migration/#are-there-any-breaking-changes","text":"In Flux v1 Kustomize support was implemented through .flux.yaml files in the Git repository. As indicated in the comparison table above, while this approach worked, we found it to be error-prone and hard to debug. The new Kustomization CR should make troubleshooting much easier. Unfortunately we needed to drop the support for custom commands as running arbitrary shell scripts in-cluster poses serious security concerns. Helm users: we redesigned the HelmRelease API and the automation will work quite differently, so upgrading to HelmRelease v2 will require a little work from you, but you will gain more flexibility, better observability and performance.","title":"Are there any breaking changes?"},{"location":"guides/faq-migration/#is-the-gitops-toolkit-related-to-the-gitops-engine","text":"In an announcement in August 2019, the expectation was set that the Flux project would integrate the GitOps Engine, then being factored out of ArgoCD. Since the result would be backward-incompatible, it would require a major version bump: Flux v2. After experimentation and considerable thought, we (the maintainers) have found a path to Flux v2 that we think better serves our vision of GitOps: the GitOps Toolkit. In consequence, we do not now plan to integrate GitOps Engine into Flux.","title":"Is the GitOps Toolkit related to the GitOps Engine?"},{"location":"guides/faq-migration/#how-can-i-get-involved","text":"There are a variety of ways and we look forward to having you on board building the future of GitOps together: Discuss the direction of Flux v2 with us Join us in #flux-dev on the CNCF Slack Check out our contributor docs Take a look at the roadmap for Flux v2","title":"How can I get involved?"},{"location":"guides/flux-v1-automation-migration/","text":"Migrating image update automation to Flux v2 \u00b6 \"Image Update Automation\" is a process in which Flux makes commits to your Git repository when it detects that there is a new image to be used in a workload (e.g., a Deployment). In Flux v2 this works quite differently to how it worked in Flux v1. This guide explains the differences and how to port your cluster configuration from v1 to v2. There is also a tutorial for using image update automation with a new cluster . Overview of changes between v1 and v2 \u00b6 In Flux v1, image update automation (from here, just \"automation\") was built into the Flux daemon, which scanned everything it found in the cluster and updated the Git repository it was syncing. In Flux v2, automation is controlled with custom resources, not annotations ordering images by build time is not supported (there is a section below explaining what to do instead) the fields to update in files are marked explicitly, rather than inferred from annotations. Automation is now controlled by custom resources \u00b6 Flux v2 breaks down the functions in Flux v1's daemon into controllers, with each having a specific area of concern. Automation is now done by two controllers: one which scans image repositories to find the latest images, and one which uses that information to commit changes to git repositories. These are in turn separate to the syncing controllers. This means that automation in Flux v2 is governed by custom resources. In Flux v1 the daemon scanned everything, and looked at annotations on the resources to determine what to update. Automation in v2 is more explicit than in v1 -- you have to mention exactly which images you want to be scanned, and which fields you want to be updated. A consequence of using custom resources is that with Flux v2 you can have an arbitrary number of automations, targeting different Git repositories if you wish, and updating different sets of images. If you run a multitenant cluster, the tenants can define automation in their own namespaces, for their own Git repositories. Selecting an image is more flexible \u00b6 The ways in which you choose to select an image have changed. In Flux v1, you generally supply a filter pattern, and the latest image is the image with the most recent build time out of those filtered. In Flux v2, you choose an ordering, and separately specify a filter for the tags to consider. These are dealt with in detail below. Selecting an image by build time is no longer supported. This is the implicit default in Flux v1. In Flux v2, you will need to tag images so that they sort in the order you would like -- see below for how to do this conveniently. Fields to update are explicitly marked \u00b6 Lastly, in Flux v2 the fields to update in files are marked explicitly. In Flux v1 they are inferred from the type of the resource, along with the annotations given. The approach in Flux v1 was limited to the types that had been programmed in, whereas Flux v2 can update any Kubernetes object (and some files that aren't Kubernetes objects, like kustomization.yaml ). Preparing for migration \u00b6 It is best to complete migration of your system to Flux v2 syncing first, using the Flux v1 migration guide . This will remove Flux v1 from the system, along with its image automation. You can then reintroduce automation with Flux v2 by following the instructions in this guide. It is safe to leave the annotations for Flux v1 in files while you reintroduce automation, because Flux v2 will ignore them. To migrate to Flux v2 automation, you will need to do three things: make sure you are running the automation controllers; then, declare the automation with an ImageUpdateAutomation object; and, migrate each manifest by translate Flux v1 annotations to Flux v2 ImageRepository and ImagePolicy objects, and putting update markers in the manifest file. Where to keep ImageRepository , ImagePolicy and ImageUpdateAutomation manifests \u00b6 This guide assumes you want to manage automation itself via Flux. In the following sections, manifests for the objects controlling automation are saved in files, committed to Git, and applied in the cluster with Flux. A Flux v2 installation will typically have a Git repository structured like this: <...>/flux-system/ gotk-components.yaml gotk-sync.yaml <...>/app/ # deployments etc. The <...> is the path to a particular cluster's definitions -- this may be simply . , or something like clusters/my-cluster . To get the files in the right place, set a variable for this path: $ CLUSTER_PATH = <...> # e.g., \".\" or \"clusters/my-cluster\", or ... $ AUTO_PATH = $CLUSTER_PATH /automation $ mkdir ./ $AUTO_PATH The file $CLUSTER_PATH/flux-system/gotk-components.yaml has definitions of all the Flux v2 controllers and custom resource definitions. The file gotk-sync.yaml defines a GitRepository and a Kustomization which will sync manifests under $CLUSTER_PATH/ . To these will be added definitions for automation objects. This guide puts manifest files for automation in $CLUSTER_PATH/automation/ , but there is no particular structure required by Flux. The automation objects do not have to be in the same namespace as the objects to be updated. Migration on a branch \u00b6 This guide assumes you will commit changes to the branch that is synced by Flux, as this is the simplest way to understand. It may be less disruptive to put migration changes on a branch, then merging when you have completed the migration. You would need to either change the GitRepository to point at the migration branch, or have separate GitRepository and Kustomization objects for the migrated parts of your Git repository. The main thing to avoid is syncing the same objects in two different places; e.g., avoid having Kustomizations that sync both the unmigrated and migrated application configuration. Installing the command-line tool flux \u00b6 The command-line tool flux will be used below; see these instructions for how to install it. Running the automation controllers \u00b6 The first thing to do is to deploy the automation controllers to your cluster. The best way to proceed will depend on the approach you took when following the Flux read-only migration guide . If you used flux bootstrap to create a new Git repository, then ported your cluster configuration to that repository, use After flux bootstrap ; If you used flux install to install the controllers directly, use After migrating Flux v1 in place ; If you used flux install and exported the configuration to a file, use After committing Flux v2 configuration to Git . After flux bootstrap \u00b6 When starting from scratch, you are likely to have used flux bootstrap . Rerun the command, and include the image automation controllers in your starting configuration with the flag --components-extra , as shown in the installation guide . This will commit changes to your Git repository and sync them in the cluster. flux check --components-extra = image-reflector-controller,image-automation-controller Now jump to the section Migrating each manifest to Flux v2 . After migrating Flux v1 in place \u00b6 If you followed the Flux v1 migration guide , you will already be running some Flux v2 controllers. The automation controllers are currently considered an optional extra to those, but are installed and run in much the same way. You may or may not have committed the Flux v2 configuration to your Git repository. If you did, go to the section After committing Flux v2 configuration to Git . If not , you will be installing directly to the cluster: $ flux install --components-extra = image-reflector-controller,image-automation-controller It is safe to repeat the installation command, or to run it after using flux bootstrap , so long as you repeat any arguments you supplied the first time. Now jump ahead to Migrating each manifest to Flux v2 . After committing a Flux v2 configuration to Git \u00b6 If you added the Flux v2 configuration to your git repository, assuming it's in the file $CLUSTER_PATH/flux-system/gotk-components.yaml as used in the guide, use flux install and write it back to that file: $ flux install \\ --components-extra = image-reflector-controller,image-automation-controller \\ --export > \" $CLUSTER_PATH /flux-system/gotk-components.yaml\" Commit changes to the $CLUSTER_PATH/flux-system/gotk-components.yaml file and sync the cluster: $ git add $CLUSTER_PATH /flux-system/gotk-components.yaml $ git commit -s -m \"Add image automation controllers to Flux config\" $ git push $ flux reconcile kustomization --with-source flux-system Controlling automation with an ImageUpdateAutomation object \u00b6 In Flux v1, automation was run by default. With Flux v2, you have to explicitly tell the controller which Git repository to update and how to do so. These are defined in an ImageUpdateAutomation object; but first, you need a GitRepository with write access, for the automation to use. If you followed the Flux v1 read-only migration guide , you will have a GitRepository defined in the namespace flux-system , for syncing to use. This GitRepository will have read access to the Git repository by default, and automation needs write access to push commits. To give it write access, you can replace the secret it refers to. How to do this will depend on what kind of authentication you used to install Flux v2. Replacing the Git credentials secret \u00b6 The secret with Git credentials will be named in the .spec.secretRef.name field of the GitRepository object. Say your GitRepository is in the namespace flux-system and named flux-system (these are the defaults if you used flux bootstrap ); you can retrieve the secret name and Git URL with: $ FLUX_NS = flux-system $ GIT_NAME = flux-system $ SECRET_NAME = $( kubectl -n $FLUX_NS get gitrepository $GIT_NAME -o jsonpath ={ .spec.secretRef.name } ) $ GIT_URL = $( kubectl -n $FLUX_NS get gitrepository $GIT_NAME -o jsonpath = '{.spec.url}' ) $ echo $SECRET_NAME $GIT_URL # make sure they have values If you're not sure which kind of credentials you're using, look at the secret: $ kubectl -n $FLUX_NS describe secret $SECRET_NAME An entry at .data.identity indicates that you are using an SSH key (the first section below); an entry at .data.username indicates you are using a username and password or token (the second section below). Replacing an SSH key secret \u00b6 When using an SSH (deploy) key, create a new key: $ flux create secret git -n $FLUX_NS $SECRET_NAME --url = $GIT_URL You will need to copy the public key that's printed out, and install that as a deploy key for your Git repo making sure to check the 'All write access' box (or otherwise give the key write permissions). Remove the old deploy key. Replacing a username/password secret \u00b6 When you're using a username and password to authenticate, you may be able to change the permissions associated with that account. If not, you will need to create a new access token (e.g., \"Personal Access Token\" in GitHub). In this case, once you have the new token you can replace the secret with the following: $ flux create secret git -n $FLUX_NS $SECRET_NAME \\ --username <username> --password <token> --url $GIT_URL Checking the new credentials \u00b6 To check if your replaced credentials still work, try syncing the GitRepository object: $ flux reconcile source git -n $FLUX_NS $GIT_NAME \u25ba annotating GitRepository flux-system in flux-system namespace \u2714 GitRepository annotated \u25ce waiting for GitRepository reconciliation \u2714 GitRepository reconciliation completed \u2714 fetched revision main/d537304e8f5f41f1584ca1e807df5b5752b2577e When this is successful, it tells you the new credentials have at least read access. Making an automation object \u00b6 To set automation running, you create an ImageUpdateAutomation object. Each object will update a Git repository, according to the image policies in the namespace. Here is an ImageUpdateAutomation manifest for the example (note: you will have to supply your own value for at least the host part of the email address): $ # the environment variables $AUTO_PATH and $GIT_NAME are set above $ FLUXBOT_EMAIL=fluxbot@example.com # supply your own host or address here $ flux create image update my-app-auto \\ --author-name FluxBot --author-email \"$FLUXBOT_EMAIL\" \\ --git-repo-ref $GIT_NAME --branch main \\ --interval 5m \\ --export > ./$AUTO_PATH/my-app-auto.yaml $ cat my-app-auto.yaml --- apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImageUpdateAutomation metadata : name : my-app-auto namespace : flux-system spec : checkout : branch : main gitRepositoryRef : name : flux-system commit : authorEmail : fluxbot@example.com authorName : FluxBot interval : 5m0s Commit and check that the automation object works \u00b6 Commit the manifeat file and push: $ git add ./ $AUTO_PATH /my-app-auto.yaml $ git commit -s -m \"Add image update automation\" $ git push # ... Then sync and check the object status: $ flux reconcile kustomization --with-source flux-system \u25ba annotating GitRepository flux-system in flux-system namespace \u2714 GitRepository annotated \u25ce waiting for GitRepository reconciliation \u2714 GitRepository reconciliation completed \u2714 fetched revision main/401dd3b550f82581c7d12bb79ade389089c6422f \u25ba annotating Kustomization flux-system in flux-system namespace \u2714 Kustomization annotated \u25ce waiting for Kustomization reconciliation \u2714 Kustomization reconciliation completed \u2714 reconciled revision main/401dd3b550f82581c7d12bb79ade389089c6422f $ flux get image update NAME READY MESSAGE LAST RUN SUSPENDED my-app-auto True no updates made 2021 -02-08T14:53:43Z False Read on to the next section to see how to change each manifest file to work with Flux v2. Migrating each manifest to Flux v2 \u00b6 In Flux v1, the annotation fluxcd.io/automated: \"true\" switches automation on for a manifest (a description of a Kubernetes object). For each manifest that has that annotation, you will need to create custom resources to scan for the latest image, and to replace the annotations with field markers. The following sections explain these steps, using this example Deployment manifest which is initially annotated to work with Flux v1: apiVersion : apps/v1 kind : Deployment metadata : name : my-app namespace : default annotations : fluxcd.io/automated : \"true\" fluxcd.io/tag.app : semver:^5.0 selector : matchLabels : app : podinfo spec : template : metadata : labels : app : podinfo spec : containers : - name : app image : ghcr.io/stefanprodan/podinfo:5.0.0 Warning A YAML file may have more than one manifest in it, separated with --- . Be careful to account for each manifest in a file. You may wish to try migrating the automation of just one file or manifest and follow it through to the end of the guide, before returning here to do the remainder. How to migrate annotations to image policies \u00b6 For each image repository that is the subject of automation you will need to create an ImageRepository object, so that the image repository is scanned for tags. The image repository in the example deployment is ghcr.io/stefanprodan/podinfo , which is the image reference minus its tag: $ cat $CLUSTER_PATH/app/my-app.yaml apiVersion : apps/v1 kind : Deployment metadata : name : my-app namespace : default annotations : fluxcd.io/automated : \"true\" fluxcd.io/tag.app : semver:^5.0 selector : matchLabels : app : podinfo spec : template : metadata : labels : app : podinfo spec : containers : - name : app image : ghcr.io/stefanprodan/podinfo:5.0.0 # <-- image reference The command-line tool flux will help create a manifest for you. Note that the output is redirected to a file under $AUTO_PATH , so it can be added to the Git repository and synced to the cluster. $ # the environment variable $AUTO_PATH was set earlier $ flux create image repository podinfo-image \\ --image ghcr.io/stefanprodan/podinfo \\ --interval 5m \\ --export > ./ $AUTO_PATH /podinfo-image.yaml $ cat ./ $AUTO_PATH /podinfo-image.yaml --- apiVersion: image.toolkit.fluxcd.io/v1alpha1 kind: ImageRepository metadata: name: podinfo-image namespace: flux-system spec: image: ghcr.io/stefanprodan/podinfo interval: 5m0s Hint If you are using the same image repository in several manifests, you only need one ImageRepository object for it. Using image registry credentials for scanning \u00b6 When your image repositories are private, you supply Kubernetes with \"image pull secrets\" with credentials for accessing the image registry (e.g., DockerHub). The image reflector controller needs the same kind of credentials to scan image repositories. There are several ways that image pull secrets can be made available for the image reflector controller. The image update tutorial describes how to create or arrange secrets for scanning to use. Also see later in the tutorial for instructions specific to some cloud platforms . Committing and checking the ImageRepository \u00b6 Add the ImageRepository manifest to the Git index and commit it: $ git add ./ $AUTO_PATH /podinfo-image.yaml $ git commit -s -m \"Add image repository object for podinfo\" $ git push # ... Now you can sync the new commit, and check that the object is working: $ flux reocncile kustomization --with-source flux-system \u25ba annotating GitRepository flux-system in flux-system namespace \u2714 GitRepository annotated \u25ce waiting for GitRepository reconciliation \u2714 GitRepository reconciliation completed \u2714 fetched revision main/fd2fe8a61d4537bcfa349e4d1dbc480ea699ba8a \u25ba annotating Kustomization flux-system in flux-system namespace \u2714 Kustomization annotated \u25ce waiting for Kustomization reconciliation \u2714 Kustomization reconciliation completed \u2714 reconciled revision main/fd2fe8a61d4537bcfa349e4d1dbc480ea699ba8a $ flux get image repository podinfo-image NAME READY MESSAGE LAST SCAN SUSPENDED podinfo-image True successful scan, found 16 tags 2021 -02-08T14:31:38Z False Replacing automation annotations \u00b6 For each field that's being updated by automation, you'll need an ImagePolicy object to describe how to select an image for the field value. In the example, the field .image in the container named \"app\" is the field being updated. In Flux v1, annotations describe how to select the image to update to, using a prefix. In the example, the prefix is semver: : annotations : fluxcd.io/automated : \"true\" fluxcd.io/tag.app : semver:^5.0 These are the prefixes supported in Flux v1, and what to use in Flux v2: Flux v1 prefix Meaning Flux v2 equivalent glob: Filter for tags matching the glob pattern, then select the newest by build time Use sortable tags regex: Filter for tags matching the regular expression, then select the newest by build time Use sortable tags semver: Filter for tags that represent versions, and select the highest version in the given range Use semver ordering How to use sortable image tags \u00b6 To give image tags a useful ordering, you can use a timestamp or serial number as part of each image's tag, then sort either alphabetically or numerically. This is a change from Flux v1, in which the build time was fetched from each image's config, and didn't need to be included in the image tag. Therefore, this is likely to require a change to your build process. The guide How to make sortable image tags explains how to change your build process to tag images with a timestamp. This will mean Flux v2 can sort the tags to find the most recently built image. Filtering the tags in an ImagePolicy \u00b6 The recommended format for image tags using a timestamp is: <branch>-<sha1>-<timestamp> The timestamp (or serial number) is the part of the tag that you want to order on. The SHA1 is there so you can trace an image back to the commit from which it was built. You don't need the branch for sorting, but you may want to include only builds from a specific branch. Say you want to filter for only images that are from main branch, and pick the most recent. Your ImagePolicy would look like this: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImagePolicy metadata : name : my-app-policy namespace : flux-system spec : imageRepositoryRef : name : podinfo-image filterTags : pattern : '^main-[a-f0-9]+-(?P<ts>[0-9]+)' extract : '$ts' policy : numerical : order : asc The .spec.pattern field gives a regular expression that a tag must match to be included. The .spec.extract field gives a replacement pattern that can refer back to capture groups in the filter pattern. The extracted values are sorted to find the selected image tag. In this case, the timestamp part of the tag will be extracted and sorted numerically in ascending order. See the reference docs for more examples. Once you have made sure you have image tags and an ImagePolicy that works, jump ahead to Checking the ImagePolicy works . How to use SemVer image tags \u00b6 The other kind of sorting is by SemVer , picking the highest version from among those included by the filter. A semver range will also filter for tags that fit in the range. For example, semver : range : ^5.0 includes only tags that have a major version of 5 , and selects whichever is the highest. This can be combined with a regular expression pattern, to filter on other parts of the tags. For example, you might put a target environment as well as the version in your image tags, like dev-v1.0.3 . Then you would use an ImagePolicy similar to this one: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImagePolicy metadata : name : my-app-policy namespace : flux-system spec : imageRepositoryRef : name : podinfo-image filterTags : pattern : '^dev-v(?P<version>.*)' extract : '$version' policy : semver : range : '^1.0' Continue on to the next sections to see an example, and how to check that your ImagePolicy works. An ImagePolicy for the example \u00b6 The example Deployment has annotations using semver: as a prefix, so the policy object also uses semver: $ # the environment variable $AUTO_PATH was set earlier $ flux create image policy my-app-policy \\ --image-ref podinfo-image \\ --semver '^5.0' \\ --export > ./ $AUTO_PATH /my-app-policy.yaml $ cat ./ $AUTO_PATH /my-app-policy.yaml --- apiVersion: image.toolkit.fluxcd.io/v1alpha1 kind: ImagePolicy metadata: name: my-app-policy namespace: flux-system spec: imageRepositoryRef: name: podinfo-image policy: semver: range: ^5.0 Checking that the ImagePolicy works \u00b6 Commit the manifest file, and push: $ git add ./ $AUTO_PATH /my-app-policy.yaml $ git commit -s -m \"Add image policy for my-app\" $ git push # ... Then you can reconcile and check that the image policy works: $ flux reconcile kustomization --with-source flux-system \u25ba annotating GitRepository flux-system in flux-system namespace \u2714 GitRepository annotated \u25ce waiting for GitRepository reconciliation \u2714 GitRepository reconciliation completed \u2714 fetched revision main/7dcf50222499be8c97e22cd37e26bbcda8f70b95 \u25ba annotating Kustomization flux-system in flux-system namespace \u2714 Kustomization annotated \u25ce waiting for Kustomization reconciliation \u2714 Kustomization reconciliation completed \u2714 reconciled revision main/7dcf50222499be8c97e22cd37e26bbcda8f70b95 $ flux get image policy flux-system NAME READY MESSAGE LATEST IMAGE my-app-policy True Latest image tag for 'ghcr.io/stefanprodan/podinfo' resolved to: 5 .1.4 ghcr.io/stefanprodan/podinfo:5.1.4 How to mark up files for update \u00b6 The last thing to do in each manifest is to mark the fields that you want to be updated. In Flux v1, the annotations in a manifest determines the fields to be updated. In the example, the annotations target the image used by the container app : apiVersion : apps/v1 kind : Deployment metadata : name : my-app namespace : default annotations : fluxcd.io/automated : \"true\" fluxcd.io/tag.app : semver:^5.0 # <-- `.app` here selector : matchLabels : app : podinfo spec : template : metadata : labels : app : podinfo spec : containers : - name : app # <-- targets `app` here image : ghcr.io/stefanprodan/podinfo:5.0.0 This works straight-forwardly for Deployment manifests, but when it comes to HelmRelease manifests, it gets complicated , and it doesn't work at all for many kinds of resources. For Flux v2, you mark the field you want to be updated directly, with the namespaced name of the image policy to apply. This is the example Deployment, marked up for Flux v2: apiVersion : apps/v1 kind : Deployment metadata : namespace : default name : my-app selector : matchLabels : app : podinfo spec : template : metadata : labels : app : podinfo spec : containers : - name : app image : ghcr.io/stefanprodan/podinfo:5.0.0 # {\"$imagepolicy\": \"flux-system:my-app-policy\"} The value flux-system:my-app-policy names the policy that selects the desired image. This works in the same way for DaemonSet and CronJob manifests. For HelmRelease manifests, put the marker alongside the part of the values that has the image tag. If the image tag is a separate field, you can put :tag on the end of the name, to replace the value with just the selected image's tag. The image automation guide has examples for HelmRelease and other custom resources. Committing the marker change and checking that automation works \u00b6 Referring to the image policy created earlier, you can see the example Deployment does not use the most recent image. When you commit the manifest file with the update marker added, you would expect automation to update the file. Commit the change that adds an update marker: $ git add app/my-app.yaml # the filename of the example $ git commit -s -m \"Add update marker to my-app manifest\" $ git push # ... Now to check that the automation makes a change: $ flux reconcile image update my-app-auto \u25ba annotating ImageUpdateAutomation my-app-auto in flux-system namespace \u2714 ImageUpdateAutomation annotated \u25ce waiting for ImageUpdateAutomation reconciliation \u2714 ImageUpdateAutomation reconciliation completed \u2714 committed and pushed a92a4b654f520c00cb6c46b2d5e4fb4861aa58fc Troubleshooting \u00b6 If a change was not pushed by the image automation, there's several things you can check: it's possible it made a change that is not reported in the latest status -- pull from the origin and check the commit log check that the name used in the marker corresponds to the namespace and name of an ImagePolicy check that the ImageUpdateAutomation is in the same namespace as the ImagePolicy objects named in markers check that the image policy and the image repository are both reported as Ready check that the credentials referenced by the GitRepository object have write permission, and create new credentials if necessary. As a fallback, you can scan the logs of the automation controller to see if it logged errors: $ kubectl logs -n flux-system deploy/image-automation-controller Once you are satisfied that it is working, you can migrate the rest of the manifests using the steps from \"Migrating each manifest to Flux v2\" above.","title":"Migrate from Flux v1 image update automation"},{"location":"guides/flux-v1-automation-migration/#migrating-image-update-automation-to-flux-v2","text":"\"Image Update Automation\" is a process in which Flux makes commits to your Git repository when it detects that there is a new image to be used in a workload (e.g., a Deployment). In Flux v2 this works quite differently to how it worked in Flux v1. This guide explains the differences and how to port your cluster configuration from v1 to v2. There is also a tutorial for using image update automation with a new cluster .","title":"Migrating image update automation to Flux v2"},{"location":"guides/flux-v1-automation-migration/#overview-of-changes-between-v1-and-v2","text":"In Flux v1, image update automation (from here, just \"automation\") was built into the Flux daemon, which scanned everything it found in the cluster and updated the Git repository it was syncing. In Flux v2, automation is controlled with custom resources, not annotations ordering images by build time is not supported (there is a section below explaining what to do instead) the fields to update in files are marked explicitly, rather than inferred from annotations.","title":"Overview of changes between v1 and v2"},{"location":"guides/flux-v1-automation-migration/#automation-is-now-controlled-by-custom-resources","text":"Flux v2 breaks down the functions in Flux v1's daemon into controllers, with each having a specific area of concern. Automation is now done by two controllers: one which scans image repositories to find the latest images, and one which uses that information to commit changes to git repositories. These are in turn separate to the syncing controllers. This means that automation in Flux v2 is governed by custom resources. In Flux v1 the daemon scanned everything, and looked at annotations on the resources to determine what to update. Automation in v2 is more explicit than in v1 -- you have to mention exactly which images you want to be scanned, and which fields you want to be updated. A consequence of using custom resources is that with Flux v2 you can have an arbitrary number of automations, targeting different Git repositories if you wish, and updating different sets of images. If you run a multitenant cluster, the tenants can define automation in their own namespaces, for their own Git repositories.","title":"Automation is now controlled by custom resources"},{"location":"guides/flux-v1-automation-migration/#selecting-an-image-is-more-flexible","text":"The ways in which you choose to select an image have changed. In Flux v1, you generally supply a filter pattern, and the latest image is the image with the most recent build time out of those filtered. In Flux v2, you choose an ordering, and separately specify a filter for the tags to consider. These are dealt with in detail below. Selecting an image by build time is no longer supported. This is the implicit default in Flux v1. In Flux v2, you will need to tag images so that they sort in the order you would like -- see below for how to do this conveniently.","title":"Selecting an image is more flexible"},{"location":"guides/flux-v1-automation-migration/#fields-to-update-are-explicitly-marked","text":"Lastly, in Flux v2 the fields to update in files are marked explicitly. In Flux v1 they are inferred from the type of the resource, along with the annotations given. The approach in Flux v1 was limited to the types that had been programmed in, whereas Flux v2 can update any Kubernetes object (and some files that aren't Kubernetes objects, like kustomization.yaml ).","title":"Fields to update are explicitly marked"},{"location":"guides/flux-v1-automation-migration/#preparing-for-migration","text":"It is best to complete migration of your system to Flux v2 syncing first, using the Flux v1 migration guide . This will remove Flux v1 from the system, along with its image automation. You can then reintroduce automation with Flux v2 by following the instructions in this guide. It is safe to leave the annotations for Flux v1 in files while you reintroduce automation, because Flux v2 will ignore them. To migrate to Flux v2 automation, you will need to do three things: make sure you are running the automation controllers; then, declare the automation with an ImageUpdateAutomation object; and, migrate each manifest by translate Flux v1 annotations to Flux v2 ImageRepository and ImagePolicy objects, and putting update markers in the manifest file.","title":"Preparing for migration"},{"location":"guides/flux-v1-automation-migration/#where-to-keep-imagerepository-imagepolicy-and-imageupdateautomation-manifests","text":"This guide assumes you want to manage automation itself via Flux. In the following sections, manifests for the objects controlling automation are saved in files, committed to Git, and applied in the cluster with Flux. A Flux v2 installation will typically have a Git repository structured like this: <...>/flux-system/ gotk-components.yaml gotk-sync.yaml <...>/app/ # deployments etc. The <...> is the path to a particular cluster's definitions -- this may be simply . , or something like clusters/my-cluster . To get the files in the right place, set a variable for this path: $ CLUSTER_PATH = <...> # e.g., \".\" or \"clusters/my-cluster\", or ... $ AUTO_PATH = $CLUSTER_PATH /automation $ mkdir ./ $AUTO_PATH The file $CLUSTER_PATH/flux-system/gotk-components.yaml has definitions of all the Flux v2 controllers and custom resource definitions. The file gotk-sync.yaml defines a GitRepository and a Kustomization which will sync manifests under $CLUSTER_PATH/ . To these will be added definitions for automation objects. This guide puts manifest files for automation in $CLUSTER_PATH/automation/ , but there is no particular structure required by Flux. The automation objects do not have to be in the same namespace as the objects to be updated.","title":"Where to keep ImageRepository, ImagePolicy and ImageUpdateAutomation manifests"},{"location":"guides/flux-v1-automation-migration/#migration-on-a-branch","text":"This guide assumes you will commit changes to the branch that is synced by Flux, as this is the simplest way to understand. It may be less disruptive to put migration changes on a branch, then merging when you have completed the migration. You would need to either change the GitRepository to point at the migration branch, or have separate GitRepository and Kustomization objects for the migrated parts of your Git repository. The main thing to avoid is syncing the same objects in two different places; e.g., avoid having Kustomizations that sync both the unmigrated and migrated application configuration.","title":"Migration on a branch"},{"location":"guides/flux-v1-automation-migration/#installing-the-command-line-tool-flux","text":"The command-line tool flux will be used below; see these instructions for how to install it.","title":"Installing the command-line tool flux"},{"location":"guides/flux-v1-automation-migration/#running-the-automation-controllers","text":"The first thing to do is to deploy the automation controllers to your cluster. The best way to proceed will depend on the approach you took when following the Flux read-only migration guide . If you used flux bootstrap to create a new Git repository, then ported your cluster configuration to that repository, use After flux bootstrap ; If you used flux install to install the controllers directly, use After migrating Flux v1 in place ; If you used flux install and exported the configuration to a file, use After committing Flux v2 configuration to Git .","title":"Running the automation controllers"},{"location":"guides/flux-v1-automation-migration/#after-flux-bootstrap","text":"When starting from scratch, you are likely to have used flux bootstrap . Rerun the command, and include the image automation controllers in your starting configuration with the flag --components-extra , as shown in the installation guide . This will commit changes to your Git repository and sync them in the cluster. flux check --components-extra = image-reflector-controller,image-automation-controller Now jump to the section Migrating each manifest to Flux v2 .","title":"After flux bootstrap"},{"location":"guides/flux-v1-automation-migration/#after-migrating-flux-v1-in-place","text":"If you followed the Flux v1 migration guide , you will already be running some Flux v2 controllers. The automation controllers are currently considered an optional extra to those, but are installed and run in much the same way. You may or may not have committed the Flux v2 configuration to your Git repository. If you did, go to the section After committing Flux v2 configuration to Git . If not , you will be installing directly to the cluster: $ flux install --components-extra = image-reflector-controller,image-automation-controller It is safe to repeat the installation command, or to run it after using flux bootstrap , so long as you repeat any arguments you supplied the first time. Now jump ahead to Migrating each manifest to Flux v2 .","title":"After migrating Flux v1 in place"},{"location":"guides/flux-v1-automation-migration/#after-committing-a-flux-v2-configuration-to-git","text":"If you added the Flux v2 configuration to your git repository, assuming it's in the file $CLUSTER_PATH/flux-system/gotk-components.yaml as used in the guide, use flux install and write it back to that file: $ flux install \\ --components-extra = image-reflector-controller,image-automation-controller \\ --export > \" $CLUSTER_PATH /flux-system/gotk-components.yaml\" Commit changes to the $CLUSTER_PATH/flux-system/gotk-components.yaml file and sync the cluster: $ git add $CLUSTER_PATH /flux-system/gotk-components.yaml $ git commit -s -m \"Add image automation controllers to Flux config\" $ git push $ flux reconcile kustomization --with-source flux-system","title":"After committing a Flux v2 configuration to Git"},{"location":"guides/flux-v1-automation-migration/#controlling-automation-with-an-imageupdateautomation-object","text":"In Flux v1, automation was run by default. With Flux v2, you have to explicitly tell the controller which Git repository to update and how to do so. These are defined in an ImageUpdateAutomation object; but first, you need a GitRepository with write access, for the automation to use. If you followed the Flux v1 read-only migration guide , you will have a GitRepository defined in the namespace flux-system , for syncing to use. This GitRepository will have read access to the Git repository by default, and automation needs write access to push commits. To give it write access, you can replace the secret it refers to. How to do this will depend on what kind of authentication you used to install Flux v2.","title":"Controlling automation with an ImageUpdateAutomation object"},{"location":"guides/flux-v1-automation-migration/#replacing-the-git-credentials-secret","text":"The secret with Git credentials will be named in the .spec.secretRef.name field of the GitRepository object. Say your GitRepository is in the namespace flux-system and named flux-system (these are the defaults if you used flux bootstrap ); you can retrieve the secret name and Git URL with: $ FLUX_NS = flux-system $ GIT_NAME = flux-system $ SECRET_NAME = $( kubectl -n $FLUX_NS get gitrepository $GIT_NAME -o jsonpath ={ .spec.secretRef.name } ) $ GIT_URL = $( kubectl -n $FLUX_NS get gitrepository $GIT_NAME -o jsonpath = '{.spec.url}' ) $ echo $SECRET_NAME $GIT_URL # make sure they have values If you're not sure which kind of credentials you're using, look at the secret: $ kubectl -n $FLUX_NS describe secret $SECRET_NAME An entry at .data.identity indicates that you are using an SSH key (the first section below); an entry at .data.username indicates you are using a username and password or token (the second section below).","title":"Replacing the Git credentials secret"},{"location":"guides/flux-v1-automation-migration/#replacing-an-ssh-key-secret","text":"When using an SSH (deploy) key, create a new key: $ flux create secret git -n $FLUX_NS $SECRET_NAME --url = $GIT_URL You will need to copy the public key that's printed out, and install that as a deploy key for your Git repo making sure to check the 'All write access' box (or otherwise give the key write permissions). Remove the old deploy key.","title":"Replacing an SSH key secret"},{"location":"guides/flux-v1-automation-migration/#replacing-a-usernamepassword-secret","text":"When you're using a username and password to authenticate, you may be able to change the permissions associated with that account. If not, you will need to create a new access token (e.g., \"Personal Access Token\" in GitHub). In this case, once you have the new token you can replace the secret with the following: $ flux create secret git -n $FLUX_NS $SECRET_NAME \\ --username <username> --password <token> --url $GIT_URL","title":"Replacing a username/password secret"},{"location":"guides/flux-v1-automation-migration/#checking-the-new-credentials","text":"To check if your replaced credentials still work, try syncing the GitRepository object: $ flux reconcile source git -n $FLUX_NS $GIT_NAME \u25ba annotating GitRepository flux-system in flux-system namespace \u2714 GitRepository annotated \u25ce waiting for GitRepository reconciliation \u2714 GitRepository reconciliation completed \u2714 fetched revision main/d537304e8f5f41f1584ca1e807df5b5752b2577e When this is successful, it tells you the new credentials have at least read access.","title":"Checking the new credentials"},{"location":"guides/flux-v1-automation-migration/#making-an-automation-object","text":"To set automation running, you create an ImageUpdateAutomation object. Each object will update a Git repository, according to the image policies in the namespace. Here is an ImageUpdateAutomation manifest for the example (note: you will have to supply your own value for at least the host part of the email address): $ # the environment variables $AUTO_PATH and $GIT_NAME are set above $ FLUXBOT_EMAIL=fluxbot@example.com # supply your own host or address here $ flux create image update my-app-auto \\ --author-name FluxBot --author-email \"$FLUXBOT_EMAIL\" \\ --git-repo-ref $GIT_NAME --branch main \\ --interval 5m \\ --export > ./$AUTO_PATH/my-app-auto.yaml $ cat my-app-auto.yaml --- apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImageUpdateAutomation metadata : name : my-app-auto namespace : flux-system spec : checkout : branch : main gitRepositoryRef : name : flux-system commit : authorEmail : fluxbot@example.com authorName : FluxBot interval : 5m0s","title":"Making an automation object"},{"location":"guides/flux-v1-automation-migration/#commit-and-check-that-the-automation-object-works","text":"Commit the manifeat file and push: $ git add ./ $AUTO_PATH /my-app-auto.yaml $ git commit -s -m \"Add image update automation\" $ git push # ... Then sync and check the object status: $ flux reconcile kustomization --with-source flux-system \u25ba annotating GitRepository flux-system in flux-system namespace \u2714 GitRepository annotated \u25ce waiting for GitRepository reconciliation \u2714 GitRepository reconciliation completed \u2714 fetched revision main/401dd3b550f82581c7d12bb79ade389089c6422f \u25ba annotating Kustomization flux-system in flux-system namespace \u2714 Kustomization annotated \u25ce waiting for Kustomization reconciliation \u2714 Kustomization reconciliation completed \u2714 reconciled revision main/401dd3b550f82581c7d12bb79ade389089c6422f $ flux get image update NAME READY MESSAGE LAST RUN SUSPENDED my-app-auto True no updates made 2021 -02-08T14:53:43Z False Read on to the next section to see how to change each manifest file to work with Flux v2.","title":"Commit and check that the automation object works"},{"location":"guides/flux-v1-automation-migration/#migrating-each-manifest-to-flux-v2","text":"In Flux v1, the annotation fluxcd.io/automated: \"true\" switches automation on for a manifest (a description of a Kubernetes object). For each manifest that has that annotation, you will need to create custom resources to scan for the latest image, and to replace the annotations with field markers. The following sections explain these steps, using this example Deployment manifest which is initially annotated to work with Flux v1: apiVersion : apps/v1 kind : Deployment metadata : name : my-app namespace : default annotations : fluxcd.io/automated : \"true\" fluxcd.io/tag.app : semver:^5.0 selector : matchLabels : app : podinfo spec : template : metadata : labels : app : podinfo spec : containers : - name : app image : ghcr.io/stefanprodan/podinfo:5.0.0 Warning A YAML file may have more than one manifest in it, separated with --- . Be careful to account for each manifest in a file. You may wish to try migrating the automation of just one file or manifest and follow it through to the end of the guide, before returning here to do the remainder.","title":"Migrating each manifest to Flux v2"},{"location":"guides/flux-v1-automation-migration/#how-to-migrate-annotations-to-image-policies","text":"For each image repository that is the subject of automation you will need to create an ImageRepository object, so that the image repository is scanned for tags. The image repository in the example deployment is ghcr.io/stefanprodan/podinfo , which is the image reference minus its tag: $ cat $CLUSTER_PATH/app/my-app.yaml apiVersion : apps/v1 kind : Deployment metadata : name : my-app namespace : default annotations : fluxcd.io/automated : \"true\" fluxcd.io/tag.app : semver:^5.0 selector : matchLabels : app : podinfo spec : template : metadata : labels : app : podinfo spec : containers : - name : app image : ghcr.io/stefanprodan/podinfo:5.0.0 # <-- image reference The command-line tool flux will help create a manifest for you. Note that the output is redirected to a file under $AUTO_PATH , so it can be added to the Git repository and synced to the cluster. $ # the environment variable $AUTO_PATH was set earlier $ flux create image repository podinfo-image \\ --image ghcr.io/stefanprodan/podinfo \\ --interval 5m \\ --export > ./ $AUTO_PATH /podinfo-image.yaml $ cat ./ $AUTO_PATH /podinfo-image.yaml --- apiVersion: image.toolkit.fluxcd.io/v1alpha1 kind: ImageRepository metadata: name: podinfo-image namespace: flux-system spec: image: ghcr.io/stefanprodan/podinfo interval: 5m0s Hint If you are using the same image repository in several manifests, you only need one ImageRepository object for it.","title":"How to migrate annotations to image policies"},{"location":"guides/flux-v1-automation-migration/#using-image-registry-credentials-for-scanning","text":"When your image repositories are private, you supply Kubernetes with \"image pull secrets\" with credentials for accessing the image registry (e.g., DockerHub). The image reflector controller needs the same kind of credentials to scan image repositories. There are several ways that image pull secrets can be made available for the image reflector controller. The image update tutorial describes how to create or arrange secrets for scanning to use. Also see later in the tutorial for instructions specific to some cloud platforms .","title":"Using image registry credentials for scanning"},{"location":"guides/flux-v1-automation-migration/#committing-and-checking-the-imagerepository","text":"Add the ImageRepository manifest to the Git index and commit it: $ git add ./ $AUTO_PATH /podinfo-image.yaml $ git commit -s -m \"Add image repository object for podinfo\" $ git push # ... Now you can sync the new commit, and check that the object is working: $ flux reocncile kustomization --with-source flux-system \u25ba annotating GitRepository flux-system in flux-system namespace \u2714 GitRepository annotated \u25ce waiting for GitRepository reconciliation \u2714 GitRepository reconciliation completed \u2714 fetched revision main/fd2fe8a61d4537bcfa349e4d1dbc480ea699ba8a \u25ba annotating Kustomization flux-system in flux-system namespace \u2714 Kustomization annotated \u25ce waiting for Kustomization reconciliation \u2714 Kustomization reconciliation completed \u2714 reconciled revision main/fd2fe8a61d4537bcfa349e4d1dbc480ea699ba8a $ flux get image repository podinfo-image NAME READY MESSAGE LAST SCAN SUSPENDED podinfo-image True successful scan, found 16 tags 2021 -02-08T14:31:38Z False","title":"Committing and checking the ImageRepository"},{"location":"guides/flux-v1-automation-migration/#replacing-automation-annotations","text":"For each field that's being updated by automation, you'll need an ImagePolicy object to describe how to select an image for the field value. In the example, the field .image in the container named \"app\" is the field being updated. In Flux v1, annotations describe how to select the image to update to, using a prefix. In the example, the prefix is semver: : annotations : fluxcd.io/automated : \"true\" fluxcd.io/tag.app : semver:^5.0 These are the prefixes supported in Flux v1, and what to use in Flux v2: Flux v1 prefix Meaning Flux v2 equivalent glob: Filter for tags matching the glob pattern, then select the newest by build time Use sortable tags regex: Filter for tags matching the regular expression, then select the newest by build time Use sortable tags semver: Filter for tags that represent versions, and select the highest version in the given range Use semver ordering","title":"Replacing automation annotations"},{"location":"guides/flux-v1-automation-migration/#how-to-use-sortable-image-tags","text":"To give image tags a useful ordering, you can use a timestamp or serial number as part of each image's tag, then sort either alphabetically or numerically. This is a change from Flux v1, in which the build time was fetched from each image's config, and didn't need to be included in the image tag. Therefore, this is likely to require a change to your build process. The guide How to make sortable image tags explains how to change your build process to tag images with a timestamp. This will mean Flux v2 can sort the tags to find the most recently built image.","title":"How to use sortable image tags"},{"location":"guides/flux-v1-automation-migration/#filtering-the-tags-in-an-imagepolicy","text":"The recommended format for image tags using a timestamp is: <branch>-<sha1>-<timestamp> The timestamp (or serial number) is the part of the tag that you want to order on. The SHA1 is there so you can trace an image back to the commit from which it was built. You don't need the branch for sorting, but you may want to include only builds from a specific branch. Say you want to filter for only images that are from main branch, and pick the most recent. Your ImagePolicy would look like this: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImagePolicy metadata : name : my-app-policy namespace : flux-system spec : imageRepositoryRef : name : podinfo-image filterTags : pattern : '^main-[a-f0-9]+-(?P<ts>[0-9]+)' extract : '$ts' policy : numerical : order : asc The .spec.pattern field gives a regular expression that a tag must match to be included. The .spec.extract field gives a replacement pattern that can refer back to capture groups in the filter pattern. The extracted values are sorted to find the selected image tag. In this case, the timestamp part of the tag will be extracted and sorted numerically in ascending order. See the reference docs for more examples. Once you have made sure you have image tags and an ImagePolicy that works, jump ahead to Checking the ImagePolicy works .","title":"Filtering the tags in an ImagePolicy"},{"location":"guides/flux-v1-automation-migration/#how-to-use-semver-image-tags","text":"The other kind of sorting is by SemVer , picking the highest version from among those included by the filter. A semver range will also filter for tags that fit in the range. For example, semver : range : ^5.0 includes only tags that have a major version of 5 , and selects whichever is the highest. This can be combined with a regular expression pattern, to filter on other parts of the tags. For example, you might put a target environment as well as the version in your image tags, like dev-v1.0.3 . Then you would use an ImagePolicy similar to this one: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImagePolicy metadata : name : my-app-policy namespace : flux-system spec : imageRepositoryRef : name : podinfo-image filterTags : pattern : '^dev-v(?P<version>.*)' extract : '$version' policy : semver : range : '^1.0' Continue on to the next sections to see an example, and how to check that your ImagePolicy works.","title":"How to use SemVer image tags"},{"location":"guides/flux-v1-automation-migration/#an-imagepolicy-for-the-example","text":"The example Deployment has annotations using semver: as a prefix, so the policy object also uses semver: $ # the environment variable $AUTO_PATH was set earlier $ flux create image policy my-app-policy \\ --image-ref podinfo-image \\ --semver '^5.0' \\ --export > ./ $AUTO_PATH /my-app-policy.yaml $ cat ./ $AUTO_PATH /my-app-policy.yaml --- apiVersion: image.toolkit.fluxcd.io/v1alpha1 kind: ImagePolicy metadata: name: my-app-policy namespace: flux-system spec: imageRepositoryRef: name: podinfo-image policy: semver: range: ^5.0","title":"An ImagePolicy for the example"},{"location":"guides/flux-v1-automation-migration/#checking-that-the-imagepolicy-works","text":"Commit the manifest file, and push: $ git add ./ $AUTO_PATH /my-app-policy.yaml $ git commit -s -m \"Add image policy for my-app\" $ git push # ... Then you can reconcile and check that the image policy works: $ flux reconcile kustomization --with-source flux-system \u25ba annotating GitRepository flux-system in flux-system namespace \u2714 GitRepository annotated \u25ce waiting for GitRepository reconciliation \u2714 GitRepository reconciliation completed \u2714 fetched revision main/7dcf50222499be8c97e22cd37e26bbcda8f70b95 \u25ba annotating Kustomization flux-system in flux-system namespace \u2714 Kustomization annotated \u25ce waiting for Kustomization reconciliation \u2714 Kustomization reconciliation completed \u2714 reconciled revision main/7dcf50222499be8c97e22cd37e26bbcda8f70b95 $ flux get image policy flux-system NAME READY MESSAGE LATEST IMAGE my-app-policy True Latest image tag for 'ghcr.io/stefanprodan/podinfo' resolved to: 5 .1.4 ghcr.io/stefanprodan/podinfo:5.1.4","title":"Checking that the ImagePolicy works"},{"location":"guides/flux-v1-automation-migration/#how-to-mark-up-files-for-update","text":"The last thing to do in each manifest is to mark the fields that you want to be updated. In Flux v1, the annotations in a manifest determines the fields to be updated. In the example, the annotations target the image used by the container app : apiVersion : apps/v1 kind : Deployment metadata : name : my-app namespace : default annotations : fluxcd.io/automated : \"true\" fluxcd.io/tag.app : semver:^5.0 # <-- `.app` here selector : matchLabels : app : podinfo spec : template : metadata : labels : app : podinfo spec : containers : - name : app # <-- targets `app` here image : ghcr.io/stefanprodan/podinfo:5.0.0 This works straight-forwardly for Deployment manifests, but when it comes to HelmRelease manifests, it gets complicated , and it doesn't work at all for many kinds of resources. For Flux v2, you mark the field you want to be updated directly, with the namespaced name of the image policy to apply. This is the example Deployment, marked up for Flux v2: apiVersion : apps/v1 kind : Deployment metadata : namespace : default name : my-app selector : matchLabels : app : podinfo spec : template : metadata : labels : app : podinfo spec : containers : - name : app image : ghcr.io/stefanprodan/podinfo:5.0.0 # {\"$imagepolicy\": \"flux-system:my-app-policy\"} The value flux-system:my-app-policy names the policy that selects the desired image. This works in the same way for DaemonSet and CronJob manifests. For HelmRelease manifests, put the marker alongside the part of the values that has the image tag. If the image tag is a separate field, you can put :tag on the end of the name, to replace the value with just the selected image's tag. The image automation guide has examples for HelmRelease and other custom resources.","title":"How to mark up files for update"},{"location":"guides/flux-v1-automation-migration/#committing-the-marker-change-and-checking-that-automation-works","text":"Referring to the image policy created earlier, you can see the example Deployment does not use the most recent image. When you commit the manifest file with the update marker added, you would expect automation to update the file. Commit the change that adds an update marker: $ git add app/my-app.yaml # the filename of the example $ git commit -s -m \"Add update marker to my-app manifest\" $ git push # ... Now to check that the automation makes a change: $ flux reconcile image update my-app-auto \u25ba annotating ImageUpdateAutomation my-app-auto in flux-system namespace \u2714 ImageUpdateAutomation annotated \u25ce waiting for ImageUpdateAutomation reconciliation \u2714 ImageUpdateAutomation reconciliation completed \u2714 committed and pushed a92a4b654f520c00cb6c46b2d5e4fb4861aa58fc","title":"Committing the marker change and checking that automation works"},{"location":"guides/flux-v1-automation-migration/#troubleshooting","text":"If a change was not pushed by the image automation, there's several things you can check: it's possible it made a change that is not reported in the latest status -- pull from the origin and check the commit log check that the name used in the marker corresponds to the namespace and name of an ImagePolicy check that the ImageUpdateAutomation is in the same namespace as the ImagePolicy objects named in markers check that the image policy and the image repository are both reported as Ready check that the credentials referenced by the GitRepository object have write permission, and create new credentials if necessary. As a fallback, you can scan the logs of the automation controller to see if it logged errors: $ kubectl logs -n flux-system deploy/image-automation-controller Once you are satisfied that it is working, you can migrate the rest of the manifests using the steps from \"Migrating each manifest to Flux v2\" above.","title":"Troubleshooting"},{"location":"guides/flux-v1-migration/","text":"Migrate from Flux v1 to v2 \u00b6 This guide walks you through migrating from Flux v1 to v2. Read the FAQ to find out what differences are between v1 and v2. Automated image updates The image automation feature is under development in Flux v2. Please consult the roadmap for more details. Feature parity \"Feature parity\" does not mean Flux v2 works exactly the same as v1 (or is backward-compatible); it means you can accomplish the same results, while accounting for the fact that it's a system with a substantially different design. This may at times mean that you have to make adjustments to the way your current cluster configuration is structured. If you are in this situation and need help, please refer to the support page . Prerequisites \u00b6 You will need a Kubernetes cluster version 1.16 or newer and kubectl version 1.18 or newer. Install Flux v2 CLI \u00b6 With Homebrew: brew install fluxcd/tap/flux With Bash: curl -s https://toolkit.fluxcd.io/install.sh | sudo bash # enable completions in ~/.bash_profile . < ( flux completion bash ) Command-line completion for zsh , fish , and powershell are also supported with their own sub-commands. Binaries for macOS, Windows and Linux AMD64/ARM are available for download on the release page . Verify that your cluster satisfies the prerequisites with: flux check --pre GitOps migration \u00b6 Flux v2 offers an installation procedure that is declarative first and disaster resilient. Using the flux bootstrap command you can install Flux on a Kubernetes cluster and configure it to manage itself from a Git repository. The Git repository created during bootstrap can be used to define the state of your fleet of Kubernetes clusters. For a detailed walk-through of the bootstrap procedure please see the installation guide . flux bootstrap target flux bootstrap should not be run against a Git branch or path that is already being synchronized by Flux v1, as this will make them fight over the resources. Instead, bootstrap to a new Git repository, branch or path , and continue with moving the manifests. After you've installed Flux v2 on your cluster using bootstrap, you can delete the Flux v1 from your clusters and move the manifests from the Flux v1 repository to the bootstrap one. In-place migration \u00b6 Warning For production use we recommend using the bootstrap procedure (see the Gitops migration section above), but if you wish to install Flux v2 in the same way as Flux v1 then follow along. Flux read-only mode \u00b6 Assuming you've installed Flux v1 to sync a directory with plain YAMLs from a private Git repo: # create namespace kubectl create ns flux # deploy Flux v1 fluxctl install \\ --git-url = git@github.com:org/app \\ --git-branch = main \\ --git-path = ./deploy \\ --git-readonly \\ --namespace = flux | kubectl apply -f - # print deploy key fluxctl identity --k8s-fwd-ns flux # trigger sync fluxctl sync --k8s-fwd-ns flux Uninstall Flux v1 Before you proceed, scale the Flux v1 deployment to zero or delete its namespace and RBAC. If there are YAML files in your deploy dir that are not meant to be applied on the cluster, you can exclude them by placing a .sourceignore in your repo root: $ cat .sourceignore # exclude all /* # include deploy dir !/deploy # exclude files from deploy dir /deploy/**/eksctl.yaml /deploy/**/charts Install Flux v2 in the flux-system namespace: $ flux install \\ --network-policy=true \\ --watch-all-namespaces=true \\ --namespace=flux-system \u271a generating manifests \u2714 manifests build completed \u25ba installing components in flux-system namespace \u2714 install completed \u25ce verifying installation \u2714 source-controller ready \u2714 kustomize-controller ready \u2714 helm-controller ready \u2714 notification-controller ready \u2714 install finished Register your Git repository and add the deploy key with read-only access: $ flux create source git app \\ --url=ssh://git@github.com/org/app \\ --branch=main \\ --interval=1m \u25ba generating deploy key pair ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCp2x9ghVmv1zD... Have you added the deploy key to your repository: y \u25ba collecting preferred public key from SSH server \u2714 collected public key from SSH server: github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A... \u25ba applying secret with keys \u2714 authentication configured \u271a generating GitRepository source \u25ba applying GitRepository source \u2714 GitRepository source created \u25ce waiting for GitRepository source reconciliation \u2714 GitRepository source reconciliation completed \u2714 fetched revision: main/5302d04c2ab8f0579500747efa0fe7abc72c8f9b Configure the reconciliation of the deploy dir on your cluster: $ flux create kustomization app \\ --source=app \\ --path=\"./deploy\" \\ --prune=true \\ --interval=10m \u271a generating Kustomization \u25ba applying Kustomization \u2714 Kustomization created \u25ce waiting for Kustomization reconciliation \u2714 Kustomization app is ready \u2714 applied revision main/5302d04c2ab8f0579500747efa0fe7abc72c8f9b If your repository contains secrets encrypted with Mozilla SOPS, please read this guide . Pull changes from Git and apply them immediately: flux reconcile kustomization app --with-source List all Kubernetes objects reconciled by app : kubectl get all --all-namespaces \\ -l = kustomize.toolkit.fluxcd.io/name = app \\ -l = kustomize.toolkit.fluxcd.io/namespace = flux-system Flux with Kustomize \u00b6 Assuming you've installed Flux v1 to sync a Kustomize overlay from an HTTPS Git repository: fluxctl install \\ --git-url = https://github.com/org/app \\ --git-branch = main \\ --manifest-generation \\ --namespace = flux | kubectl apply -f - With the following .flux.yaml in the root dir: version : 1 patchUpdated : generators : - command : kustomize build ./overlays/prod patchFile : flux-patch.yaml Uninstall Flux v1 Before you proceed, delete the Flux v1 namespace and remove the .flux.yaml from your repo. Install Flux v2 in the flux-system namespace: flux install Register the Git repository using a personal access token: flux create source git app \\ --url = https://github.com/org/app \\ --branch = main \\ --username = git \\ --password = token \\ --interval = 1m Configure the reconciliation of the prod overlay on your cluster: flux create kustomization app \\ --source = GitRepository/app \\ --path = \"./overlays/prod\" \\ --prune = true \\ --interval = 10m Check the status of the Kustomization reconciliation: $ flux get kustomizations app NAME REVISION SUSPENDED READY app main/5302d04c2ab8f0579500747efa0fe7abc72c8f9b False True Flux with Slack notifications \u00b6 Assuming you've configured Flux v1 to send notifications to Slack with FluxCloud. With Flux v2, create an alert provider for a Slack channel: flux create alert-provider slack \\ --type = slack \\ --channel = general \\ --address = https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK And configure notifications for the app reconciliation events: flux create alert app \\ --provider-ref = slack \\ --event-severity = info \\ --event-source = GitRepository/app \\ --event-source = Kustomization/app For more details, read the guides on how to configure notifications and webhooks . Flux debugging \u00b6 Check the status of Git operations: $ kubectl -n flux-system get gitrepositories NAME READY MESSAGE app True Fetched revision: main/5302d04c2ab8f0579500747efa0fe7abc72c8f9b test False SSH handshake failed: unable to authenticate, attempted methods [none publickey] Check the status of the cluster reconciliation with kubectl: $ kubectl -n flux-system get kustomizations NAME READY STATUS app True Applied revision: main/5302d04c2ab8f0579500747efa0fe7abc72c8f9 test False The Service 'backend' is invalid: spec.type: Unsupported value: 'Ingress' Suspend a reconciliation: $ flux suspend kustomization app \u25ba suspending kustomization app in flux-system namespace \u2714 kustomization suspended Check the status with kubectl: $ kubectl -n flux-system get kustomization app NAME READY STATUS app False Kustomization is suspended, skipping reconciliation Resume a reconciliation: $ flux resume kustomization app \u25ba resuming Kustomization app in flux-system namespace \u2714 Kustomization resumed \u25ce waiting for Kustomization reconciliation \u2714 Kustomization reconciliation completed \u2714 applied revision main/5302d04c2ab8f0579500747efa0fe7abc72c8f9b","title":"Migrate from Flux v1"},{"location":"guides/flux-v1-migration/#migrate-from-flux-v1-to-v2","text":"This guide walks you through migrating from Flux v1 to v2. Read the FAQ to find out what differences are between v1 and v2. Automated image updates The image automation feature is under development in Flux v2. Please consult the roadmap for more details. Feature parity \"Feature parity\" does not mean Flux v2 works exactly the same as v1 (or is backward-compatible); it means you can accomplish the same results, while accounting for the fact that it's a system with a substantially different design. This may at times mean that you have to make adjustments to the way your current cluster configuration is structured. If you are in this situation and need help, please refer to the support page .","title":"Migrate from Flux v1 to v2"},{"location":"guides/flux-v1-migration/#prerequisites","text":"You will need a Kubernetes cluster version 1.16 or newer and kubectl version 1.18 or newer.","title":"Prerequisites"},{"location":"guides/flux-v1-migration/#install-flux-v2-cli","text":"With Homebrew: brew install fluxcd/tap/flux With Bash: curl -s https://toolkit.fluxcd.io/install.sh | sudo bash # enable completions in ~/.bash_profile . < ( flux completion bash ) Command-line completion for zsh , fish , and powershell are also supported with their own sub-commands. Binaries for macOS, Windows and Linux AMD64/ARM are available for download on the release page . Verify that your cluster satisfies the prerequisites with: flux check --pre","title":"Install Flux v2 CLI"},{"location":"guides/flux-v1-migration/#gitops-migration","text":"Flux v2 offers an installation procedure that is declarative first and disaster resilient. Using the flux bootstrap command you can install Flux on a Kubernetes cluster and configure it to manage itself from a Git repository. The Git repository created during bootstrap can be used to define the state of your fleet of Kubernetes clusters. For a detailed walk-through of the bootstrap procedure please see the installation guide . flux bootstrap target flux bootstrap should not be run against a Git branch or path that is already being synchronized by Flux v1, as this will make them fight over the resources. Instead, bootstrap to a new Git repository, branch or path , and continue with moving the manifests. After you've installed Flux v2 on your cluster using bootstrap, you can delete the Flux v1 from your clusters and move the manifests from the Flux v1 repository to the bootstrap one.","title":"GitOps migration"},{"location":"guides/flux-v1-migration/#in-place-migration","text":"Warning For production use we recommend using the bootstrap procedure (see the Gitops migration section above), but if you wish to install Flux v2 in the same way as Flux v1 then follow along.","title":"In-place migration"},{"location":"guides/flux-v1-migration/#flux-read-only-mode","text":"Assuming you've installed Flux v1 to sync a directory with plain YAMLs from a private Git repo: # create namespace kubectl create ns flux # deploy Flux v1 fluxctl install \\ --git-url = git@github.com:org/app \\ --git-branch = main \\ --git-path = ./deploy \\ --git-readonly \\ --namespace = flux | kubectl apply -f - # print deploy key fluxctl identity --k8s-fwd-ns flux # trigger sync fluxctl sync --k8s-fwd-ns flux Uninstall Flux v1 Before you proceed, scale the Flux v1 deployment to zero or delete its namespace and RBAC. If there are YAML files in your deploy dir that are not meant to be applied on the cluster, you can exclude them by placing a .sourceignore in your repo root: $ cat .sourceignore # exclude all /* # include deploy dir !/deploy # exclude files from deploy dir /deploy/**/eksctl.yaml /deploy/**/charts Install Flux v2 in the flux-system namespace: $ flux install \\ --network-policy=true \\ --watch-all-namespaces=true \\ --namespace=flux-system \u271a generating manifests \u2714 manifests build completed \u25ba installing components in flux-system namespace \u2714 install completed \u25ce verifying installation \u2714 source-controller ready \u2714 kustomize-controller ready \u2714 helm-controller ready \u2714 notification-controller ready \u2714 install finished Register your Git repository and add the deploy key with read-only access: $ flux create source git app \\ --url=ssh://git@github.com/org/app \\ --branch=main \\ --interval=1m \u25ba generating deploy key pair ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCp2x9ghVmv1zD... Have you added the deploy key to your repository: y \u25ba collecting preferred public key from SSH server \u2714 collected public key from SSH server: github.com ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAq2A... \u25ba applying secret with keys \u2714 authentication configured \u271a generating GitRepository source \u25ba applying GitRepository source \u2714 GitRepository source created \u25ce waiting for GitRepository source reconciliation \u2714 GitRepository source reconciliation completed \u2714 fetched revision: main/5302d04c2ab8f0579500747efa0fe7abc72c8f9b Configure the reconciliation of the deploy dir on your cluster: $ flux create kustomization app \\ --source=app \\ --path=\"./deploy\" \\ --prune=true \\ --interval=10m \u271a generating Kustomization \u25ba applying Kustomization \u2714 Kustomization created \u25ce waiting for Kustomization reconciliation \u2714 Kustomization app is ready \u2714 applied revision main/5302d04c2ab8f0579500747efa0fe7abc72c8f9b If your repository contains secrets encrypted with Mozilla SOPS, please read this guide . Pull changes from Git and apply them immediately: flux reconcile kustomization app --with-source List all Kubernetes objects reconciled by app : kubectl get all --all-namespaces \\ -l = kustomize.toolkit.fluxcd.io/name = app \\ -l = kustomize.toolkit.fluxcd.io/namespace = flux-system","title":"Flux read-only mode"},{"location":"guides/flux-v1-migration/#flux-with-kustomize","text":"Assuming you've installed Flux v1 to sync a Kustomize overlay from an HTTPS Git repository: fluxctl install \\ --git-url = https://github.com/org/app \\ --git-branch = main \\ --manifest-generation \\ --namespace = flux | kubectl apply -f - With the following .flux.yaml in the root dir: version : 1 patchUpdated : generators : - command : kustomize build ./overlays/prod patchFile : flux-patch.yaml Uninstall Flux v1 Before you proceed, delete the Flux v1 namespace and remove the .flux.yaml from your repo. Install Flux v2 in the flux-system namespace: flux install Register the Git repository using a personal access token: flux create source git app \\ --url = https://github.com/org/app \\ --branch = main \\ --username = git \\ --password = token \\ --interval = 1m Configure the reconciliation of the prod overlay on your cluster: flux create kustomization app \\ --source = GitRepository/app \\ --path = \"./overlays/prod\" \\ --prune = true \\ --interval = 10m Check the status of the Kustomization reconciliation: $ flux get kustomizations app NAME REVISION SUSPENDED READY app main/5302d04c2ab8f0579500747efa0fe7abc72c8f9b False True","title":"Flux with Kustomize"},{"location":"guides/flux-v1-migration/#flux-with-slack-notifications","text":"Assuming you've configured Flux v1 to send notifications to Slack with FluxCloud. With Flux v2, create an alert provider for a Slack channel: flux create alert-provider slack \\ --type = slack \\ --channel = general \\ --address = https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK And configure notifications for the app reconciliation events: flux create alert app \\ --provider-ref = slack \\ --event-severity = info \\ --event-source = GitRepository/app \\ --event-source = Kustomization/app For more details, read the guides on how to configure notifications and webhooks .","title":"Flux with Slack notifications"},{"location":"guides/flux-v1-migration/#flux-debugging","text":"Check the status of Git operations: $ kubectl -n flux-system get gitrepositories NAME READY MESSAGE app True Fetched revision: main/5302d04c2ab8f0579500747efa0fe7abc72c8f9b test False SSH handshake failed: unable to authenticate, attempted methods [none publickey] Check the status of the cluster reconciliation with kubectl: $ kubectl -n flux-system get kustomizations NAME READY STATUS app True Applied revision: main/5302d04c2ab8f0579500747efa0fe7abc72c8f9 test False The Service 'backend' is invalid: spec.type: Unsupported value: 'Ingress' Suspend a reconciliation: $ flux suspend kustomization app \u25ba suspending kustomization app in flux-system namespace \u2714 kustomization suspended Check the status with kubectl: $ kubectl -n flux-system get kustomization app NAME READY STATUS app False Kustomization is suspended, skipping reconciliation Resume a reconciliation: $ flux resume kustomization app \u25ba resuming Kustomization app in flux-system namespace \u2714 Kustomization resumed \u25ce waiting for Kustomization reconciliation \u2714 Kustomization reconciliation completed \u2714 applied revision main/5302d04c2ab8f0579500747efa0fe7abc72c8f9b","title":"Flux debugging"},{"location":"guides/helm-operator-migration/","text":"Migrate to the Helm Controller \u00b6 This guide will learn you everything you need to know to be able to migrate from the Helm Operator to the Helm Controller . Overview of changes \u00b6 Support for Helm v2 dropped \u00b6 The Helm Operator offered support for both Helm v2 and v3, due to Kubernetes client incompatibility issues between the versions. This has blocked the Helm Operator from being able to upgrade to a newer v3 version since the release of 3.2.0 . In combination with the fact that Helm v2 reaches end of life after November 13, 2020 , support for Helm v2 has been dropped. Helm and Git repositories, and even Helm charts are now Custom Resources \u00b6 When working with the Helm Operator, you had to mount various files to either make it recognize new (private) Helm repositories or make it gain access to Helm and/or Git repositories. While this approach was declarative, it did not provide a great user experience and was at times hard to set up. By moving this configuration to HelmRepository , GitRepository , Bucket and HelmChart Custom Resources, they can now be declaratively described (including their credentials using references to Secret resources), and applied to the cluster. The reconciliation of these resources has been offloaded to a dedicated Source Controller , specialized in the acquisition of artifacts from external sources. The result of this all is an easier and more flexible configuration, with much better observability. Failures are traceable to the level of the resource that lead to a failure, and are easier to resolve. As polling intervals can now be configured per resource, you can customize your repository and/or chart configuration to a much finer grain. From a technical perspective, this also means less overhead, as the resources managed by the Source Controller can be shared between multiple HelmRelease resources, or even reused by other controllers like the Kustomize Controller . The HelmRelease Custom Resource group domain changed \u00b6 Due to the Helm Controller becoming part of the extensive set of controller components Flux now has, the Custom Resource group domain has changed from helm.fluxcd.io to helm.toolkit.fluxcd.io . Together with the new API version ( v2beta1 at time of writing), the full apiVersion you use in your YAML document becomes helm.toolkit.fluxcd.io/v2beta1 . The API specification changed (quite a lot), for the better \u00b6 While developing the Helm Controller, we were given the chance to rethink what a declarative API for driving automated Helm releases would look like. This has, in short, resulted in the following changes: Extensive configuration options per Helm action (install, upgrade, test, rollback); this includes things like timeouts, disabling hooks, and ignoring failures for tests. Strategy-based remediation on failures. This makes it possible, for example, to uninstall a release instead of rolling it back after a failed upgrade. The number of retries or keeping the last failed state when the retries are exhausted is now a configurable option. Better observability. The Status field in the HelmRelease provides a much better view of the current state of the release, including dedicated Ready , Released , TestSuccess , and Remediated conditions. For a comprehensive overview, see the API spec changes . Helm storage drift detection no longer relies on dry-runs \u00b6 The Helm Controller no longer uses dry-runs as a way to detect mutations to the Helm storage. Instead, it uses a simpler model of bookkeeping based on the observed state and revisions. This has resulted in much better performance, a lower memory and CPU footprint, and more reliable drift detection. No longer supports Helm downloader plugins \u00b6 We have reduced our usage of Helm packages to a bare minimum (that being: as much as we need to be able to work with chart repositories and charts), and are avoiding shell outs as much as we can. Given the latter, and the fact that Helm (downloader) plugins work based on shelling out to another command and/or binary, support for this had to be dropped. We are aware some of our users are using this functionality to be able to retrieve charts from S3 or GCS. The Source Controller already has support for S3 storage compatible buckets ( this includes GCS ), and we hope to extend this support in the foreseeable future to be on par with the plugins that offered support for these Helm repository types. Values from ConfigMap and Secret resources in other namespaces are no longer supported \u00b6 Support for values references to ConfigMap and Secret resources in other namespaces than the namespace of the HelmRelease has been dropped, as this allowed information from other namespaces to leak into the composed values for the Helm release. Values from external source references (URLs) are no longer supported \u00b6 We initially introduced this feature to support alternative (production focused) values.yaml files that sometimes come with charts. It was also used by users to use generic and/or dynamic values.yaml files in their HelmRelease resources. The former can now be achieved by defining a ValuesFile overwrite in the HelmChartTemplateSpec , which will make the Source Controller look for the referenced file in the chart, and overwrite the default values with the contents from that file. Support for the latter use has been dropped, as it goes against the principles of GitOps and declarative configuration. You can not reliably restore the cluster state from a Git repository if the configuration of a service relies on some URL being available. Getting similar behaviour is still possible using a workaround that makes use of a CronJob to download the contents of the external URL on an interval . You can now merge single values at a given path \u00b6 There was a long outstanding request for the Helm Operator to support merging single values at a given path. With the Helm Controller this now possible by defining a targetPath in the ValuesReference , which supports the same formatting as you would supply as an argument to the helm binary using --set [path]=[value] . In addition to this, the referred value can contain the same value formats (e.g. {a,b,c} for a list). You can read more about the available formats and limitations in the Helm documentation . Support added for depends-on relationships \u00b6 We have added support for depends-on relationships to install HelmRelease resources in a given order; for example, because a chart relies on the presence of a Custom Resource Definition installed by another HelmRelease resource. Entries defined in the spec.dependsOn list of the HelmRelease must be in a Ready state before the Helm Controller proceeds with installation and/or upgrade actions. Note that this does not account for upgrade ordering. Kubernetes only allows applying one resource ( HelmRelease in this case) at a time, so there is no way for the controller to know when a dependency HelmRelease may be updated. Also, circular dependencies between HelmRelease resources must be avoided, otherwise the interdependent HelmRelease resources will never be reconciled. You can now suspend a HelmRelease \u00b6 There is a new spec.suspend field, that if set to true causes the Helm Controller to skip reconciliation for the resource. This can be utilized to e.g. temporarily ignore chart changes, and prevent a Helm release from getting upgraded. Helm releases can target another cluster \u00b6 We have added support for making Helm releases to other clusters. If the spec.kubeConfig field in the HelmRelease is set, Helm actions will run against the default cluster specified in that KubeConfig instead of the local cluster that is responsible for the reconciliation of the HelmRelease . The Helm storage is stored on the remote cluster in a namespace that equals to the namespace of the HelmRelease , or the configured spec.storageNamespace . The release itself is made in a namespace that equals to the namespace of the HelmRelease , or the configured spec.targetNamespace . The namespaces are expected to exist, and can for example be created using the Kustomize Controller which has the same cross-cluster support. Other references to Kubernetes resources in the HelmRelease , like ValuesReference resources, are expected to exist on the reconciling cluster. Added support for notifications and webhooks \u00b6 Sending notifications and/or alerts to Slack, Microsoft Teams, Discord, or Rocker is now possible using the Notification Controller , Provider Custom Resources and Alert Custom Resources . It does not stop there, using Receiver Custom Resources you can trigger push based reconciliations from Harbor, GitHub, GitLab, BitBucket or your CI system by making use of the webhook endpoint the resource creates. Introduction of the flux CLI to create and/or generate Custom Resources \u00b6 With the new flux CLI it is now possible to create and/or generate the Custom Resources mentioned earlier. To generate the YAML for a HelmRepository and HelmRelease resource, you can for example run: $ flux create source helm podinfo \\ --url=https://stefanprodan.github.io/podinfo \\ --interval=10m \\ --export --- apiVersion: source.toolkit.fluxcd.io/v1beta1 kind: HelmRepository metadata: name: podinfo namespace: flux-system spec: interval: 10m0s url: https://stefanprodan.github.io/podinfo $ flux create helmrelease podinfo \\ --interval=10m \\ --source=HelmRepository/podinfo \\ --chart=podinfo \\ --chart-version=\">4.0.0\" \\ --export --- apiVersion: helm.toolkit.fluxcd.io/v2beta1 kind: HelmRelease metadata: name: podinfo namespace: flux-system spec: chart: spec: chart: podinfo sourceRef: kind: HelmRepository name: podinfo version: '>4.0.0' interval: 10m0s API spec changes \u00b6 The following is an overview of changes to the API spec, including behavioral changes compared to how the Helm Operator performs actions. For a full overview of the new API spec, consult the API spec documentation . Defining the Helm chart \u00b6 Helm repository \u00b6 For the Helm Operator, you used to configure a chart from a Helm repository as follows: --- apiVersion : helm.fluxcd.io/v1 kind : HelmRelease metadata : name : my-release namespace : default spec : chart : # The repository URL repository : https://charts.example.com # The name of the chart (without an alias) name : my-chart # The SemVer version of the chart version : 1.2.3 With the Helm Controller, you now create a HelmRepository resource in addition to the HelmRelease you would normally create (for all available fields, consult the Source API reference ): --- apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : my-repository namespace : default spec : # The interval at wich to check the upstream for updates interval : 10m # The repository URL, a valid URL contains at least a protocol and host url : https://chart.example.com If you make use of a private Helm repository, instead of configuring the credentials by mounting a repositories.yaml file, you can now configure the HTTP/S basic auth and/or TLS credentials by referring to a Secret in the same namespace as the HelmRepository : --- apiVersion : v1 kind : Secret metadata : name : my-repository-creds namespace : default data : # HTTP/S basic auth credentials username : <base64 encoded username> password : <base64 encoded password> # TLS credentials (certFile and keyFile, and/or caCert) certFile : <base64 encoded certificate> keyFile : <base64 encoded key> caCert : <base64 encoded CA certificate> --- apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : my-repository namespace : default spec : # ...omitted for brevity secretRef : name : my-repository-creds In the HelmRelease , you then use a reference to the HelmRepository resource in the spec.chart.spec (for all available fields, consult the Helm API reference ): --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # The interval at which to reconcile the Helm release interval : 10m chart : spec : # The name of the chart as made available by the HelmRepository # (without any aliases) chart : my-chart # A fixed SemVer, or any SemVer range # (i.e. >=4.0.0 <5.0.0) version : 1.2.3 # The reference to the HelmRepository sourceRef : kind : HelmRepository name : my-repository # Optional, defaults to the namespace of the HelmRelease namespace : default The spec.chart.spec values are used by the Helm Controller as a template to create a new HelmChart resource in the same namespace as the sourceRef , to be reconciled by the Source Controller. The Helm Controller watches HelmChart resources for (revision) changes, and performs an installation or upgrade when it notices a change. Git repository \u00b6 For the Helm Operator, you used to configure a chart from a Git repository as follows: --- apiVersion : helm.fluxcd.io/v1 kind : HelmRelease metadata : name : my-release namespace : default spec : chart : # The URL of the Git repository git : https://example.com/org/repo # The Git branch (or other Git reference) ref : master # The path of the chart relative to the repository root path : ./charts/my-chart With the Helm Controller, you create a GitRepository resource in addition to the HelmRelease you would normally create (for all available fields, consult the Source API reference : --- apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : my-repository namespace : default spec : # The interval at which to check the upstream for updates interval : 10m # The repository URL, can be a HTTP/S or SSH address url : https://example.com/org/repo # The Git reference to checkout and monitor for changes # (defaults to master) # For all available options, see: # https://toolkit.fluxcd.io/components/source/api/#source.toolkit.fluxcd.io/v1beta1.GitRepositoryRef ref : branch : master If you make use of a private Git repository, instead of configuring the credentials by mounting a private key and making changes to the known_hosts file, you can now configure the credentials for both HTTP/S and SSH by referring to a Secret in the same namespace as the GitRepository : --- apiVersion : v1 kind : Secret metadata : name : my-repository-creds namespace : default data : # HTTP/S basic auth credentials username : <base64 encoded username> password : <base64 encoded password> # SSH credentials identity : <base64 encoded private key> identity.pub : <base64 public key> known_hosts : <base64 encoded known_hosts> --- apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : my-repository namespace : default spec : # ...omitted for brevity secretRef : name : my-repository-creds In the HelmRelease , you then use a reference to the GitRepository resource in the spec.chart.spec (for all available fields, consult the Helm API reference ): --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # The interval at which to reconcile the Helm release interval : 10m chart : spec : # The path of the chart relative to the repository root chart : ./charts/my-chart # The reference to the GitRepository sourceRef : kind : GitRepository name : my-repository # Optional, defaults to the namespace of the HelmRelease namespace : default The spec.chart.spec values are used by the Helm Controller as a template to create a new HelmChart resource in the same namespace as the sourceRef , to be reconciled by the Source Controller. The Helm Controller watches HelmChart resources for (revision) changes, and performs an installation or upgrade when it notices a change. Defining values \u00b6 Inlined values \u00b6 Inlined values (defined in the spec.values of the HelmRelease ) still work as with the Helm operator. It represents a YAML map as you would put in a file and supply to helm with -f values.yaml , but inlined into the HelmRelease manifest: --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity values : foo : value1 bar : baz : value2 oof : - item1 - item2 Values from sources \u00b6 As described in the overview of changes , there have been multiple changes to the way you can refer to values from sources (like ConfigMap and Secret references), including the drop of support for external source (URL) references and added support for merging single values at a specific path . Values are still merged in the order given, with later values overwriting earlier. The values from sources always have a lower priority than the values inlined in the HelmRelease via the spec.values key. ConfigMap and Secret references \u00b6 ConfigMap and Secret references used to be defined as follows: --- apiVersion : helm.fluxcd.io/v1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity valuesFrom : - configMapKeyRef : name : my-config-values namespace : my-ns key : values.yaml optional : false - secretKeyRef : name : my-secret-values namespace : my-ns key : values.yaml optional : true In the new API spec the individual configMapKeyRef and secretKeyRef objects are bundled into a single ValuesReference which does no longer allow refering to resources in other namespaces : --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity valuesFrom : - kind : ConfigMap name : my-config-values valuesKey : values.yaml optional : false - kind : Secret name : my-secret-values valuesKey : values.yaml optional : true Another thing to take note of is that the behavior for values references marked as optional has changed. When set, a \"not found\" error for the values reference is ignored, but any valuesKey , targetPath or transient error will still result in a reconciliation failure. Chart file references \u00b6 With the Helm Operator it was possible to refer to an alternative values file (for e.g. production usage) in the directory of a chart from a Git repository: --- apiVersion : helm.fluxcd.io/v1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity valuesFrom : # Values file to merge in, # expected to be a relative path in the chart directory - chartFileRef : path : values-prod.yaml With the Helm Controller, this declaration has moved to the spec.chart.spec , and the feature is no longer limited to charts from a Git repository: --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity chart : spec : chart : my-chart version : 1.2.3 # Alternative values file to use as the default values, # expected to be a relative path in the sourceRef valuesFile : values-prod.yaml sourceRef : kind : HelmRepository name : my-repository When the valuesFile is defined, the chart will be (re)packaged with the values from the referenced file as the default values. Note that this behavior is different from the Helm Operator and requires a full set of alternative values, as the referenced values are no longer merged with the default values. External source references \u00b6 While the support for external source references has been dropped , it is possible to work around this limitation by creating a CronJob that periodically fetches the values from an external URL and saves them to a ConfigMap or Secret resource. First, create a ServiceAccount , Role and RoleBinding capable of updating a limited set of ConfigMap resources: --- apiVersion : v1 kind : ServiceAccount metadata : name : values-fetcher namespace : default --- apiVersion : rbac.authorization.k8s.io/v1 kind : Role metadata : name : configmap-updater namespace : default rules : - apiGroups : [ \"\" ] resources : [ \"configmaps\" ] # ResourceNames limits the access of the role to # a defined set of ConfigMap resources resourceNames : [ \"my-external-values\" ] verbs : [ \"patch\" , \"get\" ] --- apiVersion : rbac.authorization.k8s.io/v1 kind : RoleBinding metadata : name : update-values-configmaps namespace : default subjects : - kind : ServiceAccount name : values-fetcher namespace : default roleRef : kind : Role name : configmap-updater apiGroup : rbac.authorization.k8s.io As resourceNames scoping in the Role does not allow restricting create requests , we need to create empty placeholder(s) for the ConfigMap resource(s) that will hold the fetched values: --- apiVersion : v1 kind : ConfigMap metadata : name : my-external-values namespace : default data : {} Lastly, create a CronJob that uses the ServiceAccount defined above, fetches the external values on an interval, and applies them to the ConfigMap : --- apiVersion : batch/v1beta1 kind : CronJob metadata : name : fetch-external-values spec : concurrencyPolicy : Forbid schedule : \"*/5 * * * *\" successfulJobsHistoryLimit : 3 failedJobsHistoryLimit : 3 jobTemplate : spec : template : spec : serviceAccountName : values-fetcher containers : - name : kubectl image : bitnami/kubectl:1.19 volumeMounts : - mountPath : /tmp name : tmp-volume command : - sh - -c args : - >- curl -f -# https://example.com/path/to/values.yaml -o /tmp/values.yaml && kubectl create configmap my-external-values --from-file=/tmp/values.yaml -oyaml --dry-run=client | kubectl apply -f - volumes : - name : tmp-volume emptyDir : medium : Memory restartPolicy : OnFailure You can now refer to the my-external-values ConfigMap resource in your HelmRelease : --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity valuesFrom : - kind : ConfigMap name : my-external-values Defining release options \u00b6 With the Helm Operator the release options used to be configured in the spec of the HelmRelease and applied to both Helm install and upgrade actions. This has changed for the Helm Controller, where some defaults can be defined in the spec , but specific action configurations and overwrites for the defaults can be defined in the spec.install , spec.upgrade and spec.test sections of the HelmRelease . Defining a rollback / uninstall configuration \u00b6 With the Helm Operator, uninstalling a release after an installation failure was done automatically, and rolling back from a faulty upgrade and configuring options like retries was done as follows: --- apiVersion : helm.fluxcd.io/v1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity rollback : enable : true retries : true maxRetries : 5 disableHooks : false force : false recreate : false timeout : 300 The Helm Controller offers an extensive set of configuration options to remediate when a Helm release fails, using spec.install.remediate , spec.upgrade.remediate , spec.rollback and spec.uninstall . Some of the new features include the option to remediate with an uninstall after an upgrade failure, and the option to keep a failed release for debugging purposes when it has run out of retries. Automated uninstalls \u00b6 The configuration below mimics the uninstall behavior of the Helm Operator (for all available fields, consult the InstallRemediation and Uninstall API references): apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity install : # Remediation configuration for when the Helm install # (or sequent Helm test) action fails remediation : # Number of retries that should be attempted on failures before # bailing, a negative integer equals to unlimited retries retries : -1 # Configuration options for the Helm uninstall action uninstall : timeout : 5m disableHooks : false keepHistory : false Automated rollbacks \u00b6 The configuration below shows an automated rollback configuration that equals the configuration for the Helm Operator showed above (for all available fields, consult the UpgradeRemediation and Rollback API references): apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity upgrade : # Remediaton configuration for when an Helm upgrade action fails remediation : # Amount of retries to attempt after a failure, # setting this to 0 means no remedation will be # attempted retries : 5 # Configuration options for the Helm rollback action rollback : timeout : 5m disableWait : false disableHooks : false recreate : false force : false cleanupOnFail : false Migration strategy \u00b6 Due to the high number of changes to the API spec, there are no detailed instructions available to provide a simple migration path. But there is a simple procedure to follow , which combined with the detailed list of API spec changes should make the migration path relatively easy. Here are some things to know: The Helm Controller will ignore the old custom resources (and the Helm Operator will ignore the new resources). Deleting a resource while the corresponding controller is running will result in the Helm release also being deleted. Deleting a CustomResourceDefinition will also delete all custom resources of that kind. If both the Helm Controller and Helm Operator are running, and both a new and old custom resources define a release, they will fight over the release. The Helm Controller will always perform an upgrade the first time it encounters a new HelmRelease for an existing release; this is due to the changes to release mechanics and bookkeeping . The safest way to upgrade is to avoid deletions and fights by stopping the Helm Operator. Once the operator is not running, it is safe to deploy the Helm Controller (e.g., by following the Get Started guide , utilizing flux install , or using the manifests from the release page ), and start replacing the old resources with new resources. You can keep the old resources around during this process, since the Helm Controller will ignore them. Steps \u00b6 The recommended migration steps for a single HelmRelease are as follows: Ensure the Helm Operator is not running, as otherwise the Helm Controller and Helm Operator will fight over the release. Create a GitRepository or HelmRepository resource for the HelmRelease , including any Secret that may be required to access the source. Note that it is possible for multiple HelmRelease resources to share a GitRepository or HelmRepository resource. Create a new HelmRelease resource ( with the helm.toolkit.fluxcd.io group domain ), define the spec.releaseName (plus the spec.targetNamespace and spec.storageNamespace if applicable) to match that of the existing release, and rewrite the configuration to adhere to the API spec changes . Confirm the Helm Controller successfully upgrades the release. Example \u00b6 As a full example, this is an old resource: --- apiVersion : helm.fluxcd.io/v1 kind : HelmRelease metadata : name : podinfo namespace : default spec : chart : repository : https://stefanprodan.github.io/podinfo name : podinfo version : 5.0.3 values : replicaCount : 1 The custom resources for the Helm Controller would be: --- apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : podinfo namespace : default spec : interval : 10m url : https://stefanprodan.github.io/podinfo --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : default spec : interval : 5m releaseName : default-podinfo chart : spec : chart : podinfo version : 5.0.3 sourceRef : kind : HelmRepository name : podinfo interval : 10m values : replicaCount : 1 Migrating gradually \u00b6 Gradually migrating to the Helm Controller is possible by scaling down the Helm Operator while you move over resources, and scaling it up again once you have migrated some of the releases to the Helm Controller. While doing this, make sure that once you scale up the Helm Operator again, there are no old and new HelmRelease resources pointing towards the same release, as they will fight over the release. Deleting old resources \u00b6 Once you have migrated all your HelmRelease resources to the Helm Controller. You can remove all of the old resources by removing the old Custom Resource Definition. kubectl delete crd helm.fluxcd.io Frequently Asked Questions \u00b6 Are automated image updates supported? \u00b6 Not yet, but the feature is under active development. See the image update feature parity section on the roadmap for updates on this topic. How do I automatically apply my HelmRelease resources to the cluster? \u00b6 If you are currently a Flux v1 user, you can commit the HelmRelease resources to Git, and Flux will automatically apply them to the cluster like any other resource. It does however not support automated image updates for Helm Controller resources. If you are not a Flux v1 user or want to fully migrate to Flux v2, the Kustomize Controller will serve your needs. I am still running Helm v2, what is the right upgrade path for me? \u00b6 Migrate your Helm v2 releases to v3 using the Helm Operator's migration feature , or make use of the helm-2to3 plugin directly, before continuing following the migration steps . Is the Helm Controller ready for production? \u00b6 Probably, but with some side notes: It is still under active development, and while our focus has been to stabilize the API as much as we can during the first development phase, we do not guarantee there will not be any breaking changes before we reach General Availability. We are however committed to provide conversion webhooks for upcoming API versions. There may be (internal) behavioral changes in upcoming releases, but they should be aimed at further stabilizing the Helm Controller itself, solving edge case issues, providing better logging, observability, and/or other improvements. Can I use Helm Controller standalone? \u00b6 Helm Controller depends on Source Controller , you can install both controllers and manager Helm releases in a declarative way without GitOps. For more details please see this answer . I have another question \u00b6 Given the amount of changes, it is quite possible that this document did not provide you with a clear answer for you specific setup. If this applies to you, do not hestitate to ask for help in the GitHub Discussions or on the #flux CNCF Slack channel !","title":"Migrate from the Helm Operator"},{"location":"guides/helm-operator-migration/#migrate-to-the-helm-controller","text":"This guide will learn you everything you need to know to be able to migrate from the Helm Operator to the Helm Controller .","title":"Migrate to the Helm Controller"},{"location":"guides/helm-operator-migration/#overview-of-changes","text":"","title":"Overview of changes"},{"location":"guides/helm-operator-migration/#support-for-helm-v2-dropped","text":"The Helm Operator offered support for both Helm v2 and v3, due to Kubernetes client incompatibility issues between the versions. This has blocked the Helm Operator from being able to upgrade to a newer v3 version since the release of 3.2.0 . In combination with the fact that Helm v2 reaches end of life after November 13, 2020 , support for Helm v2 has been dropped.","title":"Support for Helm v2 dropped"},{"location":"guides/helm-operator-migration/#helm-and-git-repositories-and-even-helm-charts-are-now-custom-resources","text":"When working with the Helm Operator, you had to mount various files to either make it recognize new (private) Helm repositories or make it gain access to Helm and/or Git repositories. While this approach was declarative, it did not provide a great user experience and was at times hard to set up. By moving this configuration to HelmRepository , GitRepository , Bucket and HelmChart Custom Resources, they can now be declaratively described (including their credentials using references to Secret resources), and applied to the cluster. The reconciliation of these resources has been offloaded to a dedicated Source Controller , specialized in the acquisition of artifacts from external sources. The result of this all is an easier and more flexible configuration, with much better observability. Failures are traceable to the level of the resource that lead to a failure, and are easier to resolve. As polling intervals can now be configured per resource, you can customize your repository and/or chart configuration to a much finer grain. From a technical perspective, this also means less overhead, as the resources managed by the Source Controller can be shared between multiple HelmRelease resources, or even reused by other controllers like the Kustomize Controller .","title":"Helm and Git repositories, and even Helm charts are now Custom Resources"},{"location":"guides/helm-operator-migration/#the-helmrelease-custom-resource-group-domain-changed","text":"Due to the Helm Controller becoming part of the extensive set of controller components Flux now has, the Custom Resource group domain has changed from helm.fluxcd.io to helm.toolkit.fluxcd.io . Together with the new API version ( v2beta1 at time of writing), the full apiVersion you use in your YAML document becomes helm.toolkit.fluxcd.io/v2beta1 .","title":"The HelmRelease Custom Resource group domain changed"},{"location":"guides/helm-operator-migration/#the-api-specification-changed-quite-a-lot-for-the-better","text":"While developing the Helm Controller, we were given the chance to rethink what a declarative API for driving automated Helm releases would look like. This has, in short, resulted in the following changes: Extensive configuration options per Helm action (install, upgrade, test, rollback); this includes things like timeouts, disabling hooks, and ignoring failures for tests. Strategy-based remediation on failures. This makes it possible, for example, to uninstall a release instead of rolling it back after a failed upgrade. The number of retries or keeping the last failed state when the retries are exhausted is now a configurable option. Better observability. The Status field in the HelmRelease provides a much better view of the current state of the release, including dedicated Ready , Released , TestSuccess , and Remediated conditions. For a comprehensive overview, see the API spec changes .","title":"The API specification changed (quite a lot), for the better"},{"location":"guides/helm-operator-migration/#helm-storage-drift-detection-no-longer-relies-on-dry-runs","text":"The Helm Controller no longer uses dry-runs as a way to detect mutations to the Helm storage. Instead, it uses a simpler model of bookkeeping based on the observed state and revisions. This has resulted in much better performance, a lower memory and CPU footprint, and more reliable drift detection.","title":"Helm storage drift detection no longer relies on dry-runs"},{"location":"guides/helm-operator-migration/#no-longer-supports-helm-downloader-plugins","text":"We have reduced our usage of Helm packages to a bare minimum (that being: as much as we need to be able to work with chart repositories and charts), and are avoiding shell outs as much as we can. Given the latter, and the fact that Helm (downloader) plugins work based on shelling out to another command and/or binary, support for this had to be dropped. We are aware some of our users are using this functionality to be able to retrieve charts from S3 or GCS. The Source Controller already has support for S3 storage compatible buckets ( this includes GCS ), and we hope to extend this support in the foreseeable future to be on par with the plugins that offered support for these Helm repository types.","title":"No longer supports Helm downloader plugins"},{"location":"guides/helm-operator-migration/#values-from-configmap-and-secret-resources-in-other-namespaces-are-no-longer-supported","text":"Support for values references to ConfigMap and Secret resources in other namespaces than the namespace of the HelmRelease has been dropped, as this allowed information from other namespaces to leak into the composed values for the Helm release.","title":"Values from ConfigMap and Secret resources in other namespaces are no longer supported"},{"location":"guides/helm-operator-migration/#values-from-external-source-references-urls-are-no-longer-supported","text":"We initially introduced this feature to support alternative (production focused) values.yaml files that sometimes come with charts. It was also used by users to use generic and/or dynamic values.yaml files in their HelmRelease resources. The former can now be achieved by defining a ValuesFile overwrite in the HelmChartTemplateSpec , which will make the Source Controller look for the referenced file in the chart, and overwrite the default values with the contents from that file. Support for the latter use has been dropped, as it goes against the principles of GitOps and declarative configuration. You can not reliably restore the cluster state from a Git repository if the configuration of a service relies on some URL being available. Getting similar behaviour is still possible using a workaround that makes use of a CronJob to download the contents of the external URL on an interval .","title":"Values from external source references (URLs) are no longer supported"},{"location":"guides/helm-operator-migration/#you-can-now-merge-single-values-at-a-given-path","text":"There was a long outstanding request for the Helm Operator to support merging single values at a given path. With the Helm Controller this now possible by defining a targetPath in the ValuesReference , which supports the same formatting as you would supply as an argument to the helm binary using --set [path]=[value] . In addition to this, the referred value can contain the same value formats (e.g. {a,b,c} for a list). You can read more about the available formats and limitations in the Helm documentation .","title":"You can now merge single values at a given path"},{"location":"guides/helm-operator-migration/#support-added-for-depends-on-relationships","text":"We have added support for depends-on relationships to install HelmRelease resources in a given order; for example, because a chart relies on the presence of a Custom Resource Definition installed by another HelmRelease resource. Entries defined in the spec.dependsOn list of the HelmRelease must be in a Ready state before the Helm Controller proceeds with installation and/or upgrade actions. Note that this does not account for upgrade ordering. Kubernetes only allows applying one resource ( HelmRelease in this case) at a time, so there is no way for the controller to know when a dependency HelmRelease may be updated. Also, circular dependencies between HelmRelease resources must be avoided, otherwise the interdependent HelmRelease resources will never be reconciled.","title":"Support added for depends-on relationships"},{"location":"guides/helm-operator-migration/#you-can-now-suspend-a-helmrelease","text":"There is a new spec.suspend field, that if set to true causes the Helm Controller to skip reconciliation for the resource. This can be utilized to e.g. temporarily ignore chart changes, and prevent a Helm release from getting upgraded.","title":"You can now suspend a HelmRelease"},{"location":"guides/helm-operator-migration/#helm-releases-can-target-another-cluster","text":"We have added support for making Helm releases to other clusters. If the spec.kubeConfig field in the HelmRelease is set, Helm actions will run against the default cluster specified in that KubeConfig instead of the local cluster that is responsible for the reconciliation of the HelmRelease . The Helm storage is stored on the remote cluster in a namespace that equals to the namespace of the HelmRelease , or the configured spec.storageNamespace . The release itself is made in a namespace that equals to the namespace of the HelmRelease , or the configured spec.targetNamespace . The namespaces are expected to exist, and can for example be created using the Kustomize Controller which has the same cross-cluster support. Other references to Kubernetes resources in the HelmRelease , like ValuesReference resources, are expected to exist on the reconciling cluster.","title":"Helm releases can target another cluster"},{"location":"guides/helm-operator-migration/#added-support-for-notifications-and-webhooks","text":"Sending notifications and/or alerts to Slack, Microsoft Teams, Discord, or Rocker is now possible using the Notification Controller , Provider Custom Resources and Alert Custom Resources . It does not stop there, using Receiver Custom Resources you can trigger push based reconciliations from Harbor, GitHub, GitLab, BitBucket or your CI system by making use of the webhook endpoint the resource creates.","title":"Added support for notifications and webhooks"},{"location":"guides/helm-operator-migration/#introduction-of-the-flux-cli-to-create-andor-generate-custom-resources","text":"With the new flux CLI it is now possible to create and/or generate the Custom Resources mentioned earlier. To generate the YAML for a HelmRepository and HelmRelease resource, you can for example run: $ flux create source helm podinfo \\ --url=https://stefanprodan.github.io/podinfo \\ --interval=10m \\ --export --- apiVersion: source.toolkit.fluxcd.io/v1beta1 kind: HelmRepository metadata: name: podinfo namespace: flux-system spec: interval: 10m0s url: https://stefanprodan.github.io/podinfo $ flux create helmrelease podinfo \\ --interval=10m \\ --source=HelmRepository/podinfo \\ --chart=podinfo \\ --chart-version=\">4.0.0\" \\ --export --- apiVersion: helm.toolkit.fluxcd.io/v2beta1 kind: HelmRelease metadata: name: podinfo namespace: flux-system spec: chart: spec: chart: podinfo sourceRef: kind: HelmRepository name: podinfo version: '>4.0.0' interval: 10m0s","title":"Introduction of the flux CLI to create and/or generate Custom Resources"},{"location":"guides/helm-operator-migration/#api-spec-changes","text":"The following is an overview of changes to the API spec, including behavioral changes compared to how the Helm Operator performs actions. For a full overview of the new API spec, consult the API spec documentation .","title":"API spec changes"},{"location":"guides/helm-operator-migration/#defining-the-helm-chart","text":"","title":"Defining the Helm chart"},{"location":"guides/helm-operator-migration/#helm-repository","text":"For the Helm Operator, you used to configure a chart from a Helm repository as follows: --- apiVersion : helm.fluxcd.io/v1 kind : HelmRelease metadata : name : my-release namespace : default spec : chart : # The repository URL repository : https://charts.example.com # The name of the chart (without an alias) name : my-chart # The SemVer version of the chart version : 1.2.3 With the Helm Controller, you now create a HelmRepository resource in addition to the HelmRelease you would normally create (for all available fields, consult the Source API reference ): --- apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : my-repository namespace : default spec : # The interval at wich to check the upstream for updates interval : 10m # The repository URL, a valid URL contains at least a protocol and host url : https://chart.example.com If you make use of a private Helm repository, instead of configuring the credentials by mounting a repositories.yaml file, you can now configure the HTTP/S basic auth and/or TLS credentials by referring to a Secret in the same namespace as the HelmRepository : --- apiVersion : v1 kind : Secret metadata : name : my-repository-creds namespace : default data : # HTTP/S basic auth credentials username : <base64 encoded username> password : <base64 encoded password> # TLS credentials (certFile and keyFile, and/or caCert) certFile : <base64 encoded certificate> keyFile : <base64 encoded key> caCert : <base64 encoded CA certificate> --- apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : my-repository namespace : default spec : # ...omitted for brevity secretRef : name : my-repository-creds In the HelmRelease , you then use a reference to the HelmRepository resource in the spec.chart.spec (for all available fields, consult the Helm API reference ): --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # The interval at which to reconcile the Helm release interval : 10m chart : spec : # The name of the chart as made available by the HelmRepository # (without any aliases) chart : my-chart # A fixed SemVer, or any SemVer range # (i.e. >=4.0.0 <5.0.0) version : 1.2.3 # The reference to the HelmRepository sourceRef : kind : HelmRepository name : my-repository # Optional, defaults to the namespace of the HelmRelease namespace : default The spec.chart.spec values are used by the Helm Controller as a template to create a new HelmChart resource in the same namespace as the sourceRef , to be reconciled by the Source Controller. The Helm Controller watches HelmChart resources for (revision) changes, and performs an installation or upgrade when it notices a change.","title":"Helm repository"},{"location":"guides/helm-operator-migration/#git-repository","text":"For the Helm Operator, you used to configure a chart from a Git repository as follows: --- apiVersion : helm.fluxcd.io/v1 kind : HelmRelease metadata : name : my-release namespace : default spec : chart : # The URL of the Git repository git : https://example.com/org/repo # The Git branch (or other Git reference) ref : master # The path of the chart relative to the repository root path : ./charts/my-chart With the Helm Controller, you create a GitRepository resource in addition to the HelmRelease you would normally create (for all available fields, consult the Source API reference : --- apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : my-repository namespace : default spec : # The interval at which to check the upstream for updates interval : 10m # The repository URL, can be a HTTP/S or SSH address url : https://example.com/org/repo # The Git reference to checkout and monitor for changes # (defaults to master) # For all available options, see: # https://toolkit.fluxcd.io/components/source/api/#source.toolkit.fluxcd.io/v1beta1.GitRepositoryRef ref : branch : master If you make use of a private Git repository, instead of configuring the credentials by mounting a private key and making changes to the known_hosts file, you can now configure the credentials for both HTTP/S and SSH by referring to a Secret in the same namespace as the GitRepository : --- apiVersion : v1 kind : Secret metadata : name : my-repository-creds namespace : default data : # HTTP/S basic auth credentials username : <base64 encoded username> password : <base64 encoded password> # SSH credentials identity : <base64 encoded private key> identity.pub : <base64 public key> known_hosts : <base64 encoded known_hosts> --- apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : my-repository namespace : default spec : # ...omitted for brevity secretRef : name : my-repository-creds In the HelmRelease , you then use a reference to the GitRepository resource in the spec.chart.spec (for all available fields, consult the Helm API reference ): --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # The interval at which to reconcile the Helm release interval : 10m chart : spec : # The path of the chart relative to the repository root chart : ./charts/my-chart # The reference to the GitRepository sourceRef : kind : GitRepository name : my-repository # Optional, defaults to the namespace of the HelmRelease namespace : default The spec.chart.spec values are used by the Helm Controller as a template to create a new HelmChart resource in the same namespace as the sourceRef , to be reconciled by the Source Controller. The Helm Controller watches HelmChart resources for (revision) changes, and performs an installation or upgrade when it notices a change.","title":"Git repository"},{"location":"guides/helm-operator-migration/#defining-values","text":"","title":"Defining values"},{"location":"guides/helm-operator-migration/#inlined-values","text":"Inlined values (defined in the spec.values of the HelmRelease ) still work as with the Helm operator. It represents a YAML map as you would put in a file and supply to helm with -f values.yaml , but inlined into the HelmRelease manifest: --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity values : foo : value1 bar : baz : value2 oof : - item1 - item2","title":"Inlined values"},{"location":"guides/helm-operator-migration/#values-from-sources","text":"As described in the overview of changes , there have been multiple changes to the way you can refer to values from sources (like ConfigMap and Secret references), including the drop of support for external source (URL) references and added support for merging single values at a specific path . Values are still merged in the order given, with later values overwriting earlier. The values from sources always have a lower priority than the values inlined in the HelmRelease via the spec.values key.","title":"Values from sources"},{"location":"guides/helm-operator-migration/#configmap-and-secret-references","text":"ConfigMap and Secret references used to be defined as follows: --- apiVersion : helm.fluxcd.io/v1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity valuesFrom : - configMapKeyRef : name : my-config-values namespace : my-ns key : values.yaml optional : false - secretKeyRef : name : my-secret-values namespace : my-ns key : values.yaml optional : true In the new API spec the individual configMapKeyRef and secretKeyRef objects are bundled into a single ValuesReference which does no longer allow refering to resources in other namespaces : --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity valuesFrom : - kind : ConfigMap name : my-config-values valuesKey : values.yaml optional : false - kind : Secret name : my-secret-values valuesKey : values.yaml optional : true Another thing to take note of is that the behavior for values references marked as optional has changed. When set, a \"not found\" error for the values reference is ignored, but any valuesKey , targetPath or transient error will still result in a reconciliation failure.","title":"ConfigMap and Secret references"},{"location":"guides/helm-operator-migration/#chart-file-references","text":"With the Helm Operator it was possible to refer to an alternative values file (for e.g. production usage) in the directory of a chart from a Git repository: --- apiVersion : helm.fluxcd.io/v1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity valuesFrom : # Values file to merge in, # expected to be a relative path in the chart directory - chartFileRef : path : values-prod.yaml With the Helm Controller, this declaration has moved to the spec.chart.spec , and the feature is no longer limited to charts from a Git repository: --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity chart : spec : chart : my-chart version : 1.2.3 # Alternative values file to use as the default values, # expected to be a relative path in the sourceRef valuesFile : values-prod.yaml sourceRef : kind : HelmRepository name : my-repository When the valuesFile is defined, the chart will be (re)packaged with the values from the referenced file as the default values. Note that this behavior is different from the Helm Operator and requires a full set of alternative values, as the referenced values are no longer merged with the default values.","title":"Chart file references"},{"location":"guides/helm-operator-migration/#external-source-references","text":"While the support for external source references has been dropped , it is possible to work around this limitation by creating a CronJob that periodically fetches the values from an external URL and saves them to a ConfigMap or Secret resource. First, create a ServiceAccount , Role and RoleBinding capable of updating a limited set of ConfigMap resources: --- apiVersion : v1 kind : ServiceAccount metadata : name : values-fetcher namespace : default --- apiVersion : rbac.authorization.k8s.io/v1 kind : Role metadata : name : configmap-updater namespace : default rules : - apiGroups : [ \"\" ] resources : [ \"configmaps\" ] # ResourceNames limits the access of the role to # a defined set of ConfigMap resources resourceNames : [ \"my-external-values\" ] verbs : [ \"patch\" , \"get\" ] --- apiVersion : rbac.authorization.k8s.io/v1 kind : RoleBinding metadata : name : update-values-configmaps namespace : default subjects : - kind : ServiceAccount name : values-fetcher namespace : default roleRef : kind : Role name : configmap-updater apiGroup : rbac.authorization.k8s.io As resourceNames scoping in the Role does not allow restricting create requests , we need to create empty placeholder(s) for the ConfigMap resource(s) that will hold the fetched values: --- apiVersion : v1 kind : ConfigMap metadata : name : my-external-values namespace : default data : {} Lastly, create a CronJob that uses the ServiceAccount defined above, fetches the external values on an interval, and applies them to the ConfigMap : --- apiVersion : batch/v1beta1 kind : CronJob metadata : name : fetch-external-values spec : concurrencyPolicy : Forbid schedule : \"*/5 * * * *\" successfulJobsHistoryLimit : 3 failedJobsHistoryLimit : 3 jobTemplate : spec : template : spec : serviceAccountName : values-fetcher containers : - name : kubectl image : bitnami/kubectl:1.19 volumeMounts : - mountPath : /tmp name : tmp-volume command : - sh - -c args : - >- curl -f -# https://example.com/path/to/values.yaml -o /tmp/values.yaml && kubectl create configmap my-external-values --from-file=/tmp/values.yaml -oyaml --dry-run=client | kubectl apply -f - volumes : - name : tmp-volume emptyDir : medium : Memory restartPolicy : OnFailure You can now refer to the my-external-values ConfigMap resource in your HelmRelease : --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity valuesFrom : - kind : ConfigMap name : my-external-values","title":"External source references"},{"location":"guides/helm-operator-migration/#defining-release-options","text":"With the Helm Operator the release options used to be configured in the spec of the HelmRelease and applied to both Helm install and upgrade actions. This has changed for the Helm Controller, where some defaults can be defined in the spec , but specific action configurations and overwrites for the defaults can be defined in the spec.install , spec.upgrade and spec.test sections of the HelmRelease .","title":"Defining release options"},{"location":"guides/helm-operator-migration/#defining-a-rollback-uninstall-configuration","text":"With the Helm Operator, uninstalling a release after an installation failure was done automatically, and rolling back from a faulty upgrade and configuring options like retries was done as follows: --- apiVersion : helm.fluxcd.io/v1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity rollback : enable : true retries : true maxRetries : 5 disableHooks : false force : false recreate : false timeout : 300 The Helm Controller offers an extensive set of configuration options to remediate when a Helm release fails, using spec.install.remediate , spec.upgrade.remediate , spec.rollback and spec.uninstall . Some of the new features include the option to remediate with an uninstall after an upgrade failure, and the option to keep a failed release for debugging purposes when it has run out of retries.","title":"Defining a rollback / uninstall configuration"},{"location":"guides/helm-operator-migration/#automated-uninstalls","text":"The configuration below mimics the uninstall behavior of the Helm Operator (for all available fields, consult the InstallRemediation and Uninstall API references): apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity install : # Remediation configuration for when the Helm install # (or sequent Helm test) action fails remediation : # Number of retries that should be attempted on failures before # bailing, a negative integer equals to unlimited retries retries : -1 # Configuration options for the Helm uninstall action uninstall : timeout : 5m disableHooks : false keepHistory : false","title":"Automated uninstalls"},{"location":"guides/helm-operator-migration/#automated-rollbacks","text":"The configuration below shows an automated rollback configuration that equals the configuration for the Helm Operator showed above (for all available fields, consult the UpgradeRemediation and Rollback API references): apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : my-release namespace : default spec : # ...omitted for brevity upgrade : # Remediaton configuration for when an Helm upgrade action fails remediation : # Amount of retries to attempt after a failure, # setting this to 0 means no remedation will be # attempted retries : 5 # Configuration options for the Helm rollback action rollback : timeout : 5m disableWait : false disableHooks : false recreate : false force : false cleanupOnFail : false","title":"Automated rollbacks"},{"location":"guides/helm-operator-migration/#migration-strategy","text":"Due to the high number of changes to the API spec, there are no detailed instructions available to provide a simple migration path. But there is a simple procedure to follow , which combined with the detailed list of API spec changes should make the migration path relatively easy. Here are some things to know: The Helm Controller will ignore the old custom resources (and the Helm Operator will ignore the new resources). Deleting a resource while the corresponding controller is running will result in the Helm release also being deleted. Deleting a CustomResourceDefinition will also delete all custom resources of that kind. If both the Helm Controller and Helm Operator are running, and both a new and old custom resources define a release, they will fight over the release. The Helm Controller will always perform an upgrade the first time it encounters a new HelmRelease for an existing release; this is due to the changes to release mechanics and bookkeeping . The safest way to upgrade is to avoid deletions and fights by stopping the Helm Operator. Once the operator is not running, it is safe to deploy the Helm Controller (e.g., by following the Get Started guide , utilizing flux install , or using the manifests from the release page ), and start replacing the old resources with new resources. You can keep the old resources around during this process, since the Helm Controller will ignore them.","title":"Migration strategy"},{"location":"guides/helm-operator-migration/#steps","text":"The recommended migration steps for a single HelmRelease are as follows: Ensure the Helm Operator is not running, as otherwise the Helm Controller and Helm Operator will fight over the release. Create a GitRepository or HelmRepository resource for the HelmRelease , including any Secret that may be required to access the source. Note that it is possible for multiple HelmRelease resources to share a GitRepository or HelmRepository resource. Create a new HelmRelease resource ( with the helm.toolkit.fluxcd.io group domain ), define the spec.releaseName (plus the spec.targetNamespace and spec.storageNamespace if applicable) to match that of the existing release, and rewrite the configuration to adhere to the API spec changes . Confirm the Helm Controller successfully upgrades the release.","title":"Steps"},{"location":"guides/helm-operator-migration/#example","text":"As a full example, this is an old resource: --- apiVersion : helm.fluxcd.io/v1 kind : HelmRelease metadata : name : podinfo namespace : default spec : chart : repository : https://stefanprodan.github.io/podinfo name : podinfo version : 5.0.3 values : replicaCount : 1 The custom resources for the Helm Controller would be: --- apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : podinfo namespace : default spec : interval : 10m url : https://stefanprodan.github.io/podinfo --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : default spec : interval : 5m releaseName : default-podinfo chart : spec : chart : podinfo version : 5.0.3 sourceRef : kind : HelmRepository name : podinfo interval : 10m values : replicaCount : 1","title":"Example"},{"location":"guides/helm-operator-migration/#migrating-gradually","text":"Gradually migrating to the Helm Controller is possible by scaling down the Helm Operator while you move over resources, and scaling it up again once you have migrated some of the releases to the Helm Controller. While doing this, make sure that once you scale up the Helm Operator again, there are no old and new HelmRelease resources pointing towards the same release, as they will fight over the release.","title":"Migrating gradually"},{"location":"guides/helm-operator-migration/#deleting-old-resources","text":"Once you have migrated all your HelmRelease resources to the Helm Controller. You can remove all of the old resources by removing the old Custom Resource Definition. kubectl delete crd helm.fluxcd.io","title":"Deleting old resources"},{"location":"guides/helm-operator-migration/#frequently-asked-questions","text":"","title":"Frequently Asked Questions"},{"location":"guides/helm-operator-migration/#are-automated-image-updates-supported","text":"Not yet, but the feature is under active development. See the image update feature parity section on the roadmap for updates on this topic.","title":"Are automated image updates supported?"},{"location":"guides/helm-operator-migration/#how-do-i-automatically-apply-my-helmrelease-resources-to-the-cluster","text":"If you are currently a Flux v1 user, you can commit the HelmRelease resources to Git, and Flux will automatically apply them to the cluster like any other resource. It does however not support automated image updates for Helm Controller resources. If you are not a Flux v1 user or want to fully migrate to Flux v2, the Kustomize Controller will serve your needs.","title":"How do I automatically apply my HelmRelease resources to the cluster?"},{"location":"guides/helm-operator-migration/#i-am-still-running-helm-v2-what-is-the-right-upgrade-path-for-me","text":"Migrate your Helm v2 releases to v3 using the Helm Operator's migration feature , or make use of the helm-2to3 plugin directly, before continuing following the migration steps .","title":"I am still running Helm v2, what is the right upgrade path for me?"},{"location":"guides/helm-operator-migration/#is-the-helm-controller-ready-for-production","text":"Probably, but with some side notes: It is still under active development, and while our focus has been to stabilize the API as much as we can during the first development phase, we do not guarantee there will not be any breaking changes before we reach General Availability. We are however committed to provide conversion webhooks for upcoming API versions. There may be (internal) behavioral changes in upcoming releases, but they should be aimed at further stabilizing the Helm Controller itself, solving edge case issues, providing better logging, observability, and/or other improvements.","title":"Is the Helm Controller ready for production?"},{"location":"guides/helm-operator-migration/#can-i-use-helm-controller-standalone","text":"Helm Controller depends on Source Controller , you can install both controllers and manager Helm releases in a declarative way without GitOps. For more details please see this answer .","title":"Can I use Helm Controller standalone?"},{"location":"guides/helm-operator-migration/#i-have-another-question","text":"Given the amount of changes, it is quite possible that this document did not provide you with a clear answer for you specific setup. If this applies to you, do not hestitate to ask for help in the GitHub Discussions or on the #flux CNCF Slack channel !","title":"I have another question"},{"location":"guides/helmreleases/","text":"Manage Helm Releases \u00b6 The helm-controller allows you to declaratively manage Helm chart releases with Kubernetes manifests. It makes use of the artifacts produced by the source-controller from HelmRepository , GitRepository , Bucket and HelmChart resources. The helm-controller is part of the default toolkit installation. Prerequisites \u00b6 To follow this guide you'll need a Kubernetes cluster with the GitOps toolkit controllers installed on it. Please see the get started guide or the installation guide . Define a chart source \u00b6 To be able to release a Helm chart, the source that contains the chart (either a HelmRepository , GitRepository , or Bucket ) has to be known first to the source-controller, so that the HelmRelease can reference to it. Helm repository \u00b6 Helm repositories are the recommended source to retrieve Helm charts from, as they are lightweight in processing and make it possible to configure a semantic version selector for the chart version that should be released. They can be declared by creating a HelmRepository resource, the source-controller will fetch the Helm repository index for this resource on an interval and expose it as an artifact: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : podinfo namespace : flux-system spec : interval : 1m url : https://stefanprodan.github.io/podinfo The interval defines at which interval the Helm repository index is fetched, and should be at least 1m . Setting this to a higher value means newer chart versions will be detected at a slower pace, a push-based fetch can be introduced using webhook receivers The url can be any HTTP/S Helm repository URL. Authentication HTTP/S basic and TLS authentication can be configured for private Helm repositories. See the HelmRepository CRD docs for more details. Git repository \u00b6 Charts from Git repositories can be released by declaring a GitRepository , the source-controller will fetch the contents of the repository on an interval and expose it as an artifact. The source-controller can build and expose Helm charts as artifacts from the contents of the GitRepository artifact (more about this later on in the guide). There is one caveat you should be aware of: to make the source-controller produce a new chart artifact, the version in the Chart.yaml of the chart must be bumped. An example GitRepository : apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : flux-system spec : interval : 1m url : https://github.com/stefanprodan/podinfo ref : branch : master ignore : | # exclude all /* # include charts directory !/charts/ The interval defines at which interval the Git repository contents are fetched, and should be at least 1m . Setting this to a higher value means newer chart versions will be detected at a slower pace, a push-based fetch can be introduced using webhook receivers The url can be any HTTP/S or SSH address (the latter requiring authentication). The ref defines the checkout strategy, and is set to follow the master branch in the above example. For other strategies like tags or commits, see the GitRepository CRD docs . The ignore defines file and folder exclusion for the artifact produced, and follows the .gitignore pattern format . The above example only includes the charts directory of the repository and omits all other files. Authentication HTTP/S basic and SSH authentication can be configured for private Git repositories. See the GitRepository CRD docs for more details. Cloud Storage \u00b6 It is inadvisable while still possible to use a Bucket as a source for a HelmRelease , as the whole storage bucket will be downloaded by source controller at each sync. The bucket can easily become very large if there are frequent releases of multiple charts that are stored in the same bucket. A better option is to use Chartmuseum and run a cluster local Helm repository that can be used by source controller. Chartmuseum has support for multiple different cloud storage solutions such as S3, GCS, and Azure Blob Storage, meaning that you are not limited to only using storage providers that support the S3 protocol. You can deploy a Chartmuseum instance with a HelmRelease that exposes a Helm repository stored in a S3 bucket. Please refer to Chartmuseums how to run documentation for details about how to use other storage backends. apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : chartmuseum namespace : flux-system spec : url : https://chartmuseum.github.io/charts interval : 10m --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : chartmuseum namespace : flux-system spec : interval : 5m chart : spec : chart : chartmuseum version : \"2.14.2\" sourceRef : kind : HelmRepository name : chartmuseum namespace : flux-system interval : 1m values : env : open : AWS_SDK_LOAD_CONFIG : true STORAGE : amazon STORAGE_AMAZON_BUCKET : \"bucket-name\" STORAGE_AMAZON_PREFIX : \"\" STORAGE_AMAZON_REGION : \"region-name\" serviceAccount : create : true annotations : eks.amazonaws.com/role-arn : \"role-arn\" securityContext : enabled : true fsGroup : 65534 After Chartmuseum is up and running it should be possible to use the accompanying service as the url for the HelmRepository . apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : helm-charts namespace : flux-system spec : interval : 1m url : http://chartmuseum-chartmuseum:8080 Define a Helm release \u00b6 With the chart source created, define a new HelmRelease to release the Helm chart: apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : default spec : interval : 5m chart : spec : chart : <name|path> version : '4.0.x' sourceRef : kind : <HelmRepository|GitRepository|Bucket> name : podinfo namespace : flux-system interval : 1m values : replicaCount : 2 The chart.spec values are used by the helm-controller as a template to create a new HelmChart resource in the same namespace as the sourceRef . The source-controller will then lookup the chart in the artifact of the referenced source, and either fetch the chart for a HelmRepository , or build it from a GitRepository or Bucket . It will then make it available as a HelmChart artifact to be used by the helm-controller. The chart.spec.chart can either contain: The name of the chart as made available by the HelmRepository (without any aliases), for example: podinfo The relative path the chart can be found at in the GitRepository or Bucket , for example: ./charts/podinfo The relative path the chart package can be found at in the GitRepository or Bucket , for example: ./charts/podinfo-1.2.3.tgz The chart.spec.version can be a fixed semver, or any semver range (i.e. >=4.0.0 <5.0.0 ). It is only taken into account for HelmRelease resources that reference a HelmRepository source. Advanced configuration The HelmRelease offers an extensive set of configurable flags for finer grain control over how Helm actions are performed. See the HelmRelease CRD docs for more details. Refer to values in ConfigMap and Secret resources \u00b6 It is possible to define a list of ConfigMap and Secret resources from which to take values. The values are merged in the order given, with the later values overwriting earlier. These values always have a lower priority than the values inlined in the HelmRelease via the spec.values parameter. spec : valuesFrom : - kind : ConfigMap name : prod-env-values valuesKey : values-prod.yaml - kind : Secret name : prod-tls-values valuesKey : crt targetPath : tls.crt The definition of the listed keys is as follows: kind : Kind of the values referent ( ConfigMap or Secret ). name : Name of the values referent, in the same namespace as the HelmRelease . valuesKey (Optional) : The data key where the values.yaml or a specific value can be found. Defaults to values.yaml when omitted. targetPath (Optional) : The YAML dot notation path at which the value should be merged. When set, the valuesKey is expected to be a single flat value. Defaults to None when omitted, which results in the values getting merged at the root. Note The targetPath supports the same formatting as you would supply as an argument to the helm binary using --set [path]=[value] . In addition to this, the referred value can contain the same value formats (e.g. {a,b,c} for a list). You can read more about the available formats and limitations in the Helm documentation . TargetPath and JSON values When using TargetPath in combination with a JSON string, the limitations are the same as while using helm , and require you to escape the full JSON string (including = , [ , , , . ). Refer to values in ConfigMaps generated with Kustomize \u00b6 It is possible to use Kustomize ConfigMap generator to trigger a Helm release upgrade every time the encoded values change. First create a kustomizeconfig.yaml for Kustomize to be able to patch ConfigMaps referenced in HelmRelease manifests: nameReference : - kind : ConfigMap version : v1 fieldSpecs : - path : spec/valuesFrom/name kind : HelmRelease Create a HelmRelease definition that references a ConfigMap : apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : podinfo spec : interval : 5m releaseName : podinfo chart : spec : chart : podinfo sourceRef : kind : HelmRepository name : podinfo valuesFrom : - kind : ConfigMap name : podinfo-values Create a kustomization.yaml that generates the ConfigMap using our kustomize config: apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization namespace : podinfo resources : - namespace.yaml - repository.yaml - release.yaml configMapGenerator : - name : podinfo-values files : - values.yaml=my-values.yaml configurations : - kustomizeconfig.yaml When kustomize-controller reconciles the above manifests, it will generate a unique name of the ConfigMap every time my-values.yaml content is updated in Git: apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : podinfo spec : valuesFrom : - kind : ConfigMap name : podinfo-values-2mh2t8m94h Note Stale ConfigMaps , previously generated by Kustomize, will be removed from the cluster by kustomize-controller if pruning is enabled. Refer to values inside the chart \u00b6 It is possible to replace the values.yaml with a different file present inside the Helm chart. apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : mongodb namespace : mongodb spec : interval : 5m chart : spec : chart : mongodb sourceRef : kind : HelmRepository name : bitnami valuesFile : values-production.yaml values : replicaCount : 5 If the spec.chart.spec.valuesFile doesn't exists inside the chart, helm-controller will not be able to fetch the chart. To determine why the HelmChart fails to produce an artifact, you can inspect the status with: $ kubectl get helmcharts --all-namespaces NAME READY STATUS mongodb False failed to locate override values file: values-prod.yaml Configure notifications \u00b6 The default toolkit installation configures the helm-controller to broadcast events to the notification-controller . To receive the events as notifications, a Provider needs to be setup first as described in the notifications guide . Once you have set up the Provider , create a new Alert resource in the flux-system to start receiving notifications about the Helm release: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : generation : 2 name : helm-podinfo namespace : flux-system spec : providerRef : name : slack eventSeverity : info eventSources : - kind : HelmRepository name : podinfo - kind : HelmChart name : default-podinfo - kind : HelmRelease name : podinfo namespace : default Configure webhook receivers \u00b6 When using semver ranges for Helm releases, you may want to trigger an update as soon as a new chart version is published to your Helm repository. In order to notify source-controller about a chart update, you can setup webhook receivers . First generate a random string and create a secret with a token field: TOKEN = $( head -c 12 /dev/urandom | shasum | cut -d ' ' -f1 ) echo $TOKEN kubectl -n flux-system create secret generic webhook-token \\ --from-literal = token = $TOKEN When using Harbor as your Helm repository, you can define a receiver with: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : helm-podinfo namespace : flux-system spec : type : harbor secretRef : name : webhook-token resources : - kind : HelmRepository name : podinfo The notification-controller generates a unique URL using the provided token and the receiver name/namespace. Find the URL with: $ kubectl -n flux-system get receiver/helm-podinfo NAME READY STATUS helm-podinfo True Receiver initialised with URL: /hook/bed6d00b5555b1603e1f59b94d7fdbca58089cb5663633fb83f2815dc626d92b Log in to the Harbor interface, go to Projects, select a project, and select Webhooks. Fill the form with: Endpoint URL: compose the address using the receiver LB and the generated URL http://<LoadBalancerAddress>/<ReceiverURL> Auth Header: use the token string With the above settings, when you upload a chart, the following happens: Harbor sends the chart push event to the receiver address Notification controller validates the authenticity of the payload using the auth header Source controller is notified about the changes Source controller pulls the changes into the cluster and updates the HelmChart version Helm controller is notified about the version change and upgrades the release Note Besides Harbor, you can define receivers for GitHub , GitLab , Bitbucket and any other system that supports webhooks e.g. Jenkins, CircleCI, etc. See the Receiver CRD docs for more details.","title":"Manage Helm Releases"},{"location":"guides/helmreleases/#manage-helm-releases","text":"The helm-controller allows you to declaratively manage Helm chart releases with Kubernetes manifests. It makes use of the artifacts produced by the source-controller from HelmRepository , GitRepository , Bucket and HelmChart resources. The helm-controller is part of the default toolkit installation.","title":"Manage Helm Releases"},{"location":"guides/helmreleases/#prerequisites","text":"To follow this guide you'll need a Kubernetes cluster with the GitOps toolkit controllers installed on it. Please see the get started guide or the installation guide .","title":"Prerequisites"},{"location":"guides/helmreleases/#define-a-chart-source","text":"To be able to release a Helm chart, the source that contains the chart (either a HelmRepository , GitRepository , or Bucket ) has to be known first to the source-controller, so that the HelmRelease can reference to it.","title":"Define a chart source"},{"location":"guides/helmreleases/#helm-repository","text":"Helm repositories are the recommended source to retrieve Helm charts from, as they are lightweight in processing and make it possible to configure a semantic version selector for the chart version that should be released. They can be declared by creating a HelmRepository resource, the source-controller will fetch the Helm repository index for this resource on an interval and expose it as an artifact: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : podinfo namespace : flux-system spec : interval : 1m url : https://stefanprodan.github.io/podinfo The interval defines at which interval the Helm repository index is fetched, and should be at least 1m . Setting this to a higher value means newer chart versions will be detected at a slower pace, a push-based fetch can be introduced using webhook receivers The url can be any HTTP/S Helm repository URL. Authentication HTTP/S basic and TLS authentication can be configured for private Helm repositories. See the HelmRepository CRD docs for more details.","title":"Helm repository"},{"location":"guides/helmreleases/#git-repository","text":"Charts from Git repositories can be released by declaring a GitRepository , the source-controller will fetch the contents of the repository on an interval and expose it as an artifact. The source-controller can build and expose Helm charts as artifacts from the contents of the GitRepository artifact (more about this later on in the guide). There is one caveat you should be aware of: to make the source-controller produce a new chart artifact, the version in the Chart.yaml of the chart must be bumped. An example GitRepository : apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : podinfo namespace : flux-system spec : interval : 1m url : https://github.com/stefanprodan/podinfo ref : branch : master ignore : | # exclude all /* # include charts directory !/charts/ The interval defines at which interval the Git repository contents are fetched, and should be at least 1m . Setting this to a higher value means newer chart versions will be detected at a slower pace, a push-based fetch can be introduced using webhook receivers The url can be any HTTP/S or SSH address (the latter requiring authentication). The ref defines the checkout strategy, and is set to follow the master branch in the above example. For other strategies like tags or commits, see the GitRepository CRD docs . The ignore defines file and folder exclusion for the artifact produced, and follows the .gitignore pattern format . The above example only includes the charts directory of the repository and omits all other files. Authentication HTTP/S basic and SSH authentication can be configured for private Git repositories. See the GitRepository CRD docs for more details.","title":"Git repository"},{"location":"guides/helmreleases/#cloud-storage","text":"It is inadvisable while still possible to use a Bucket as a source for a HelmRelease , as the whole storage bucket will be downloaded by source controller at each sync. The bucket can easily become very large if there are frequent releases of multiple charts that are stored in the same bucket. A better option is to use Chartmuseum and run a cluster local Helm repository that can be used by source controller. Chartmuseum has support for multiple different cloud storage solutions such as S3, GCS, and Azure Blob Storage, meaning that you are not limited to only using storage providers that support the S3 protocol. You can deploy a Chartmuseum instance with a HelmRelease that exposes a Helm repository stored in a S3 bucket. Please refer to Chartmuseums how to run documentation for details about how to use other storage backends. apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : chartmuseum namespace : flux-system spec : url : https://chartmuseum.github.io/charts interval : 10m --- apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : chartmuseum namespace : flux-system spec : interval : 5m chart : spec : chart : chartmuseum version : \"2.14.2\" sourceRef : kind : HelmRepository name : chartmuseum namespace : flux-system interval : 1m values : env : open : AWS_SDK_LOAD_CONFIG : true STORAGE : amazon STORAGE_AMAZON_BUCKET : \"bucket-name\" STORAGE_AMAZON_PREFIX : \"\" STORAGE_AMAZON_REGION : \"region-name\" serviceAccount : create : true annotations : eks.amazonaws.com/role-arn : \"role-arn\" securityContext : enabled : true fsGroup : 65534 After Chartmuseum is up and running it should be possible to use the accompanying service as the url for the HelmRepository . apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : helm-charts namespace : flux-system spec : interval : 1m url : http://chartmuseum-chartmuseum:8080","title":"Cloud Storage"},{"location":"guides/helmreleases/#define-a-helm-release","text":"With the chart source created, define a new HelmRelease to release the Helm chart: apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : default spec : interval : 5m chart : spec : chart : <name|path> version : '4.0.x' sourceRef : kind : <HelmRepository|GitRepository|Bucket> name : podinfo namespace : flux-system interval : 1m values : replicaCount : 2 The chart.spec values are used by the helm-controller as a template to create a new HelmChart resource in the same namespace as the sourceRef . The source-controller will then lookup the chart in the artifact of the referenced source, and either fetch the chart for a HelmRepository , or build it from a GitRepository or Bucket . It will then make it available as a HelmChart artifact to be used by the helm-controller. The chart.spec.chart can either contain: The name of the chart as made available by the HelmRepository (without any aliases), for example: podinfo The relative path the chart can be found at in the GitRepository or Bucket , for example: ./charts/podinfo The relative path the chart package can be found at in the GitRepository or Bucket , for example: ./charts/podinfo-1.2.3.tgz The chart.spec.version can be a fixed semver, or any semver range (i.e. >=4.0.0 <5.0.0 ). It is only taken into account for HelmRelease resources that reference a HelmRepository source. Advanced configuration The HelmRelease offers an extensive set of configurable flags for finer grain control over how Helm actions are performed. See the HelmRelease CRD docs for more details.","title":"Define a Helm release"},{"location":"guides/helmreleases/#refer-to-values-in-configmap-and-secret-resources","text":"It is possible to define a list of ConfigMap and Secret resources from which to take values. The values are merged in the order given, with the later values overwriting earlier. These values always have a lower priority than the values inlined in the HelmRelease via the spec.values parameter. spec : valuesFrom : - kind : ConfigMap name : prod-env-values valuesKey : values-prod.yaml - kind : Secret name : prod-tls-values valuesKey : crt targetPath : tls.crt The definition of the listed keys is as follows: kind : Kind of the values referent ( ConfigMap or Secret ). name : Name of the values referent, in the same namespace as the HelmRelease . valuesKey (Optional) : The data key where the values.yaml or a specific value can be found. Defaults to values.yaml when omitted. targetPath (Optional) : The YAML dot notation path at which the value should be merged. When set, the valuesKey is expected to be a single flat value. Defaults to None when omitted, which results in the values getting merged at the root. Note The targetPath supports the same formatting as you would supply as an argument to the helm binary using --set [path]=[value] . In addition to this, the referred value can contain the same value formats (e.g. {a,b,c} for a list). You can read more about the available formats and limitations in the Helm documentation . TargetPath and JSON values When using TargetPath in combination with a JSON string, the limitations are the same as while using helm , and require you to escape the full JSON string (including = , [ , , , . ).","title":"Refer to values in ConfigMap and Secret resources"},{"location":"guides/helmreleases/#refer-to-values-in-configmaps-generated-with-kustomize","text":"It is possible to use Kustomize ConfigMap generator to trigger a Helm release upgrade every time the encoded values change. First create a kustomizeconfig.yaml for Kustomize to be able to patch ConfigMaps referenced in HelmRelease manifests: nameReference : - kind : ConfigMap version : v1 fieldSpecs : - path : spec/valuesFrom/name kind : HelmRelease Create a HelmRelease definition that references a ConfigMap : apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : podinfo spec : interval : 5m releaseName : podinfo chart : spec : chart : podinfo sourceRef : kind : HelmRepository name : podinfo valuesFrom : - kind : ConfigMap name : podinfo-values Create a kustomization.yaml that generates the ConfigMap using our kustomize config: apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization namespace : podinfo resources : - namespace.yaml - repository.yaml - release.yaml configMapGenerator : - name : podinfo-values files : - values.yaml=my-values.yaml configurations : - kustomizeconfig.yaml When kustomize-controller reconciles the above manifests, it will generate a unique name of the ConfigMap every time my-values.yaml content is updated in Git: apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : podinfo spec : valuesFrom : - kind : ConfigMap name : podinfo-values-2mh2t8m94h Note Stale ConfigMaps , previously generated by Kustomize, will be removed from the cluster by kustomize-controller if pruning is enabled.","title":"Refer to values in ConfigMaps generated with Kustomize"},{"location":"guides/helmreleases/#refer-to-values-inside-the-chart","text":"It is possible to replace the values.yaml with a different file present inside the Helm chart. apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : mongodb namespace : mongodb spec : interval : 5m chart : spec : chart : mongodb sourceRef : kind : HelmRepository name : bitnami valuesFile : values-production.yaml values : replicaCount : 5 If the spec.chart.spec.valuesFile doesn't exists inside the chart, helm-controller will not be able to fetch the chart. To determine why the HelmChart fails to produce an artifact, you can inspect the status with: $ kubectl get helmcharts --all-namespaces NAME READY STATUS mongodb False failed to locate override values file: values-prod.yaml","title":"Refer to values inside the chart"},{"location":"guides/helmreleases/#configure-notifications","text":"The default toolkit installation configures the helm-controller to broadcast events to the notification-controller . To receive the events as notifications, a Provider needs to be setup first as described in the notifications guide . Once you have set up the Provider , create a new Alert resource in the flux-system to start receiving notifications about the Helm release: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : generation : 2 name : helm-podinfo namespace : flux-system spec : providerRef : name : slack eventSeverity : info eventSources : - kind : HelmRepository name : podinfo - kind : HelmChart name : default-podinfo - kind : HelmRelease name : podinfo namespace : default","title":"Configure notifications"},{"location":"guides/helmreleases/#configure-webhook-receivers","text":"When using semver ranges for Helm releases, you may want to trigger an update as soon as a new chart version is published to your Helm repository. In order to notify source-controller about a chart update, you can setup webhook receivers . First generate a random string and create a secret with a token field: TOKEN = $( head -c 12 /dev/urandom | shasum | cut -d ' ' -f1 ) echo $TOKEN kubectl -n flux-system create secret generic webhook-token \\ --from-literal = token = $TOKEN When using Harbor as your Helm repository, you can define a receiver with: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : helm-podinfo namespace : flux-system spec : type : harbor secretRef : name : webhook-token resources : - kind : HelmRepository name : podinfo The notification-controller generates a unique URL using the provided token and the receiver name/namespace. Find the URL with: $ kubectl -n flux-system get receiver/helm-podinfo NAME READY STATUS helm-podinfo True Receiver initialised with URL: /hook/bed6d00b5555b1603e1f59b94d7fdbca58089cb5663633fb83f2815dc626d92b Log in to the Harbor interface, go to Projects, select a project, and select Webhooks. Fill the form with: Endpoint URL: compose the address using the receiver LB and the generated URL http://<LoadBalancerAddress>/<ReceiverURL> Auth Header: use the token string With the above settings, when you upload a chart, the following happens: Harbor sends the chart push event to the receiver address Notification controller validates the authenticity of the payload using the auth header Source controller is notified about the changes Source controller pulls the changes into the cluster and updates the HelmChart version Helm controller is notified about the version change and upgrades the release Note Besides Harbor, you can define receivers for GitHub , GitLab , Bitbucket and any other system that supports webhooks e.g. Jenkins, CircleCI, etc. See the Receiver CRD docs for more details.","title":"Configure webhook receivers"},{"location":"guides/image-update/","text":"Automate image updates to Git \u00b6 This guide walks you through configuring container image scanning and deployment rollouts with Flux. For a container image you can configure Flux to: scan the container registry and fetch the image tags select the latest tag based on the defined policy (semver, calver, regex) replace the tag in Kubernetes manifests (YAML format) checkout a branch, commit and push the changes to the remote Git repository apply the changes in-cluster and rollout the container image Alpha version Note that the image update feature is currently alpha, see the roadmap for more details. For production environments, this feature allows you to automatically deploy application patches (CVEs and bug fixes), and keep a record of all deployments in Git history. Production CI/CD workflow DEV: push a bug fix to the app repository DEV: bump the patch version and release e.g. v1.0.1 CI: build and push a container image tagged as registry.domain/org/app:v1.0.1 CD: pull the latest image metadata from the app registry (Flux image scanning) CD: update the image tag in the app manifest to v1.0.1 (Flux cluster to Git reconciliation) CD: deploy v1.0.1 to production clusters (Flux Git to cluster reconciliation) For staging environments, this features allow you to deploy the latest build of a branch, without having to manually edit the app deployment manifest in Git. Staging CI/CD workflow DEV: push code changes to the app repository main branch CI: build and push a container image tagged as ${GIT_BRANCH}-${GIT_SHA:0:7}-$(date +%s) CD: pull the latest image metadata from the app registry (Flux image scanning) CD: update the image tag in the app manifest to main-2d3fcbd-1611906956 (Flux cluster to Git reconciliation) CD: deploy main-2d3fcbd-1611906956 to staging clusters (Flux Git to cluster reconciliation) Prerequisites \u00b6 You will need a Kubernetes cluster version 1.16 or newer and kubectl version 1.18. For a quick local test, you can use Kubernetes kind . Any other Kubernetes setup will work as well. In order to follow the guide you'll need a GitHub account and a personal access token that can create repositories (check all permissions under repo ). Export your GitHub personal access token and username: export GITHUB_TOKEN = <your-token> export GITHUB_USER = <your-username> Install Flux \u00b6 Enable image automation components If you bootstrapped Flux before without the --components-extra= argument, you need to add --components-extra=image-reflector-controller,image-automation-controller to your bootstrapping routine as image automation components are not installed by default. Install Flux with the image automation components: flux bootstrap github \\ --components-extra = image-reflector-controller,image-automation-controller \\ --owner = $GITHUB_USER \\ --repository = flux-image-updates \\ --branch = main \\ --path = clusters/my-cluster \\ --token-auth \\ --personal The bootstrap command creates a repository if one doesn't exist, and commits the manifests for the Flux components to the default branch at the specified path. It then configures the target cluster to synchronize with the specified path inside the repository. GitLab and other Git platforms You can install Flux and bootstrap repositories hosted on GitLab, BitBucket, Azure DevOps and any other Git provider that support SSH or token-based authentication. When using SSH, make sure the deploy key is configured with write access. Please see the installation guide for more details. Deploy a demo app \u00b6 We'll be using a tiny webapp called podinfo to showcase the image update feature. Clone your repository with: git clone https://github.com/ $GITHUB_USER /flux-image-updates cd flux-image-updates Add the podinfo Kubernetes deployment file inside cluster/my-cluster : curl -sL https://raw.githubusercontent.com/stefanprodan/podinfo/5.0.0/kustomize/deployment.yaml \\ > ./clusters/my-cluster/podinfo-deployment.yaml Commit and push changes to main branch: git add -A && \\ git commit -m \"add podinfo deployment\" && \\ git push origin main Tell Flux to pull and apply the changes or wait one minute for Flux to detect the changes on its own: flux reconcile kustomization flux-system --with-source Print the podinfo image deployed on your cluster: $ kubectl get deployment/podinfo -oyaml | grep 'image:' image: ghcr.io/stefanprodan/podinfo:5.0.0 Configure image scanning \u00b6 Create an ImageRepository to tell Flux which container registry to scan for new tags: flux create image repository podinfo \\ --image = ghcr.io/stefanprodan/podinfo \\ --interval = 1m \\ --export > ./clusters/my-cluster/podinfo-registry.yaml The above command generates the following manifest: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImageRepository metadata : name : podinfo namespace : flux-system spec : image : ghcr.io/stefanprodan/podinfo interval : 1m0s For private images, you can create a Kubernetes secret in the same namespace as the ImageRepository with kubectl create secret docker-registry . Then you can configure Flux to use the credentials by referencing the Kubernetes secret in the ImageRepository : kind : ImageRepository spec : secretRef : name : regcred Storing secrets in Git Note that if you want to store the image pull secret in Git, you can encrypt the manifest with Mozilla SOPS or Sealed Secrets . Create an ImagePolicy to tell Flux which semver range to use when filtering tags: flux create image policy podinfo \\ --image-ref = podinfo \\ --select-semver = 5 .0.x \\ --export > ./clusters/my-cluster/podinfo-policy.yaml The above command generates the following manifest: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImagePolicy metadata : name : podinfo namespace : flux-system spec : imageRepositoryRef : name : podinfo policy : semver : range : 5.0.x semver ranges A semver range that includes stable releases can be defined with 1.0.x (patch versions only) or >=1.0.0 <2.0.0 (minor and patch versions). If you want to include pre-release e.g. 1.0.0-rc.1 , you can define a range like: ^1.x-0 or >1.0.0-rc <2.0.0-rc . Other policy examples For policies that make use of CalVer, build IDs or alphabetical sorting, have a look at the examples . Commit and push changes to main branch: git add -A && \\ git commit -m \"add podinfo image scan\" && \\ git push origin main Tell Flux to pull and apply changes: flux reconcile kustomization flux-system --with-source Wait for Flux to fetch the image tag list from GitHub container registry: $ flux get image repository podinfo NAME READY MESSAGE LAST SCAN podinfo True successful scan, found 13 tags 2020-12-13T17:51:48+02:00 Find which image tag matches the policy semver range with: $ flux get image policy podinfo NAME READY MESSAGE podinfo True Latest image tag for 'ghcr.io/stefanprodan/podinfo' resolved to: 5.0.3 Configure image updates \u00b6 Edit the podinfo-deploy.yaml and add a marker to tell Flux which policy to use when updating the container image: spec : containers : - name : podinfod image : ghcr.io/stefanprodan/podinfo:5.0.0 # {\"$imagepolicy\": \"flux-system:podinfo\"} Create an ImageUpdateAutomation to tell Flux which Git repository to write image updates to: flux create image update flux-system \\ --git-repo-ref = flux-system \\ --branch = main \\ --author-name = fluxcdbot \\ --author-email = fluxcdbot@users.noreply.github.com \\ --commit-template = \"[ci skip] update image\" \\ --export > ./clusters/my-cluster/flux-system-automation.yaml The above command generates the following manifest: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImageUpdateAutomation metadata : name : flux-system namespace : flux-system spec : checkout : branch : main gitRepositoryRef : name : flux-system commit : authorEmail : fluxcdbot@users.noreply.github.com authorName : fluxcdbot messageTemplate : '[ci skip] update image' interval : 1m0s update : strategy : Setters Commit and push changes to main branch: git add -A && \\ git commit -m \"add image updates automation\" && \\ git push origin main Note that the ImageUpdateAutomation runs all the policies found in its namespace at the specified interval. Tell Flux to pull and apply changes: flux reconcile kustomization flux-system --with-source In a couple of seconds, Flux will push a commit to your repository with the latest image tag that matches the podinfo policy: $ git pull && cat clusters/my-cluster/podinfo-deployment.yaml | grep \"image:\" image: ghcr.io/stefanprodan/podinfo:5.0.3 # {\"$imagepolicy\": \"flux-system:podinfo\"} Wait for Flux to apply the latest commit on the cluster and verify that podinfo was updated to 5.0.3 : $ watch \"kubectl get deployment/podinfo -oyaml | grep 'image:'\" image: ghcr.io/stefanprodan/podinfo:5.0.3 Configure image update for custom resources \u00b6 Besides Kubernetes native kinds (Deployment, StatefulSet, DaemonSet, CronJob), Flux can be used to patch image tags in any Kubernetes custom resource stored in Git. The image policy marker format is: {\"$imagepolicy\": \"<policy-namespace>:<policy-name>\"} {\"$imagepolicy\": \"<policy-namespace>:<policy-name>:tag\"} HelmRelease example: apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : default spec : values : image : repository : ghcr.io/stefanprodan/podinfo tag : 5.0.0 # {\"$imagepolicy\": \"flux-system:podinfo:tag\"} Tekton Task example: apiVersion : tekton.dev/v1beta1 kind : Task metadata : name : golang namespace : default spec : steps : - name : golang image : docker.io/golang:1.15.6 # {\"$imagepolicy\": \"flux-system:golang\"} Flux Kustomization example: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : default spec : images : - name : ghcr.io/stefanprodan/podinfo newName : ghcr.io/stefanprodan/podinfo newTag : 5.0.0 # {\"$imagepolicy\": \"flux-system:podinfo:tag\"} Kustomize config ( kustomization.yaml ) example: apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization resources : - deployment.yaml images : - name : ghcr.io/stefanprodan/podinfo newName : ghcr.io/stefanprodan/podinfo newTag : 5.0.0 # {\"$imagepolicy\": \"flux-system:podinfo:tag\"} Trigger image updates with webhooks \u00b6 You may want to trigger a deployment as soon as a new image tag is pushed to your container registry. In order to notify the image-reflector-controller about new images, you can setup webhook receivers . First generate a random string and create a secret with a token field: TOKEN = $( head -c 12 /dev/urandom | shasum | cut -d ' ' -f1 ) echo $TOKEN kubectl -n flux-system create secret generic webhook-token \\ --from-literal = token = $TOKEN Define a receiver for DockerHub: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : podinfo namespace : flux-system spec : type : dockerhub secretRef : name : webhook-token resources : - kind : ImageRepository name : podinfo The notification-controller generates a unique URL using the provided token and the receiver name/namespace. Find the URL with: $ kubectl -n flux-system get receiver/podinfo NAME READY STATUS podinfo True Receiver initialised with URL: /hook/bed6d00b5555b1603e1f59b94d7fdbca58089cb5663633fb83f2815dc626d92b Log in to DockerHub web interface, go to your image registry Settings and select Webhooks. Fill the form \"Webhook URL\" by composing the address using the receiver LB and the generated URL http://<LoadBalancerAddress>/<ReceiverURL> . Note Besides DockerHub, you can define receivers for Harbor , Quay , Nexus , GCR , and any other system that supports webhooks e.g. GitHub Actions, Jenkins, CircleCI, etc. See the Receiver CRD docs for more details. Incident management \u00b6 Suspend automation \u00b6 During an incident you may wish to stop Flux from pushing image updates to Git. You can suspend the image automation directly in-cluster: flux suspend image update flux-system Or by editing the ImageUpdateAutomation manifest in Git: kind : ImageUpdateAutomation metadata : name : flux-system namespace : flux-system spec : suspend : true Once the incident is resolved, you can resume automation with: flux resume image update flux-system If you wish to pause the automation for a particular image only, you can suspend/resume the image scanning: flux suspend image repository podinfo Revert image updates \u00b6 Assuming you've configured Flux to update an app to its latest stable version: flux create image policy podinfo \\ --image-ref = podinfo \\ --select-semver = \">=5.0.0\" If the latest version e.g. 5.0.1 causes an incident in production, you can tell Flux to revert the image tag to a previous version e.g. 5.0.0 with: flux create image policy podinfo \\ --image-ref = podinfo \\ --select-semver = 5 .0.0 Or by changing the semver range in Git: kind : ImagePolicy metadata : name : podinfo namespace : flux-system spec : policy : semver : range : 5.0.0 Based on the above configuration, Flux will patch the podinfo deployment manifest in Git and roll out 5.0.0 in-cluster. When a new version is available e.g. 5.0.2 , you can update the policy once more and tell Flux to consider only versions greater than 5.0.1 : flux create image policy podinfo \\ --image-ref = podinfo \\ --select-semver = \">5.0.1\" ImageRepository cloud providers authentication \u00b6 If relying on a cloud provider image repository, you might need to do some extra work in order to configure the ImageRepository resource credentials. Here are some common examples for the most popular cloud provider docker registries. Workarounds The examples below are intended as workaround solutions until native authentication mechanisms are implemented in Flux itself to support this in a more straightforward manner. AWS Elastic Container Registry \u00b6 The registry authentication credentials for ECR expire every 12 hours. Considering this limitation, one needs to ensure the credentials are being refreshed before expiration so that the controller can rely on them for authentication. The solution proposed is to create a cronjob that runs every 6 hours which would re-create the docker-registry secret using a new token. Edit and save the following snippet to a file ./clusters/my-cluster/ecr-sync.yaml , commit and push it to git. kind : Role apiVersion : rbac.authorization.k8s.io/v1 metadata : name : ecr-credentials-sync namespace : flux-system rules : - apiGroups : [ \"\" ] resources : - secrets verbs : - delete - create --- kind : RoleBinding apiVersion : rbac.authorization.k8s.io/v1 metadata : name : ecr-credentials-sync namespace : flux-system subjects : - kind : ServiceAccount name : ecr-credentials-sync roleRef : kind : Role name : ecr-credentials-sync apiGroup : \"\" --- apiVersion : v1 kind : ServiceAccount metadata : name : ecr-credentials-sync namespace : flux-system # Uncomment and edit if using IRSA # annotations: # eks.amazonaws.com/role-arn: <role arn> --- apiVersion : batch/v1beta1 kind : CronJob metadata : name : ecr-credentials-sync namespace : flux-system spec : suspend : false schedule : 0 */6 * * * failedJobsHistoryLimit : 1 successfulJobsHistoryLimit : 1 jobTemplate : spec : template : spec : serviceAccountName : ecr-credentials-sync restartPolicy : Never volumes : - name : token emptyDir : medium : Memory initContainers : - image : amazon/aws-cli name : get-token imagePullPolicy : IfNotPresent # You will need to set the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables if not using # IRSA. It is recommended to store the values in a Secret and load them in the container using envFrom. # envFrom: # - secretRef: # name: aws-credentials env : - name : REGION value : us-east-1 # change this if ECR repo is in a different region volumeMounts : - mountPath : /token name : token command : - /bin/sh - -ce - aws ecr get-login-password --region ${REGION} > /token/ecr-token containers : - image : bitnami/kubectl name : create-secret imagePullPolicy : IfNotPresent env : - name : SECRET_NAME value : ecr-credentials - name : ECR_REGISTRY value : <account id>.dkr.ecr.<region>.amazonaws.com # fill in the account id and region volumeMounts : - mountPath : /token name : token command : - /bin/bash - -ce - |- kubectl delete secret --ignore-not-found $SECRET_NAME kubectl create secret docker-registry $SECRET_NAME \\ --docker-server=\"$ECR_REGISTRY\" \\ --docker-username=AWS \\ --docker-password=\"$(</token/ecr-token)\" Using IAM Roles for Service Accounts (IRSA) If using IRSA, make sure the role attached to the service account has readonly access to ECR. The AWS managed policy arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly can be attached to the role. Since the cronjob will not create a job right away, after applying the manifest, you can manually create an init job using the following command: $ kubectl create job --from = cronjob/ecr-credentials-sync -n flux-system ecr-credentials-sync-init After the job runs, a secret named ecr-credentials should be created. Use this name in your ECR ImageRepository resource manifest as the value for .spec.secretRef.name . spec : secretRef : name : ecr-credentials GCP Container Registry \u00b6 Using access token [short-lived] \u00b6 Workload Identity Please ensure that you enable workload identity for your cluster, create a GCP service account that has access to the container registry and create an IAM policy binding between the GCP service account and the Kubernetes service account so that the pods created by the cronjob can access GCP APIs and get the token. Take a look at this guide The access token for GCR expires hourly. Considering this limitation, one needs to ensure the credentials are being refreshed before expiration so that the controller can rely on them for authentication. The solution proposed is to create a cronjob that runs every 45 minutes which would re-create the docker-registry secret using a new token. Edit and save the following snippet to a file ./clusters/my-cluster/gcr-sync.yaml , commit and push it to git. kind : Role apiVersion : rbac.authorization.k8s.io/v1 metadata : name : gcr-credentials-sync namespace : flux-system rules : - apiGroups : [ \"\" ] resources : - secrets verbs : - delete - create --- kind : RoleBinding apiVersion : rbac.authorization.k8s.io/v1 metadata : name : gcr-credentials-sync namespace : flux-system subjects : - kind : ServiceAccount name : gcr-credentials-sync roleRef : kind : Role name : gcr-credentials-sync apiGroup : \"\" --- apiVersion : v1 kind : ServiceAccount metadata : annotations : iam.gke.io/gcp-service-account : <name-of-service-account>@<project-id>.iam.gserviceaccount.com name : gcr-credentials-sync namespace : flux-system --- apiVersion : batch/v1beta1 kind : CronJob metadata : name : gcr-credentials-sync namespace : flux-system spec : suspend : false schedule : \"*/45 * * * *\" failedJobsHistoryLimit : 1 successfulJobsHistoryLimit : 1 jobTemplate : spec : template : spec : serviceAccountName : gcr-credentials-sync restartPolicy : Never containers : - image : google/cloud-sdk name : create-secret imagePullPolicy : IfNotPresent env : - name : SECRET_NAME value : gcr-credentials - name : GCR_REGISTRY value : <REGISTRY_NAME> # fill in the registry name e.g gcr.io, eu.gcr.io command : - /bin/bash - -ce - |- kubectl delete secret --ignore-not-found $SECRET_NAME kubectl create secret docker-registry $SECRET_NAME \\ --docker-server=\"$GCR_REGISTRY\" \\ --docker-username=oauth2accesstoken \\ --docker-password=\"$(gcloud auth print-access-token)\" Since the cronjob will not create a job right away, after applying the manifest, you can manually create an init job using the following command: $ kubectl create job --from = cronjob/gcr-credentials-sync -n flux-system gcr-credentials-sync-init After the job runs, a secret named gcr-credentials should be created. Use this name in your GCR ImageRepository resource manifest as the value for .spec.secretRef.name . spec : secretRef : name : gcr-credentials Using a JSON key [long-lived] \u00b6 Less secure option From Google documentation on authenticating container registry A user-managed key-pair that you can use as a credential for a service account. Because the credential is long-lived, it is the least secure option of all the available authentication methods. When possible, use an access token or another available authentication method to reduce the risk of unauthorized access to your artifacts. If you must use a service account key, ensure that you follow best practices for managing credentials. A Json key doesn't expire, so we don't need a cronjob, we just need to create the secret and reference it in the ImagePolicy. First, create a json key file by following this documentation . Grant the service account the role of Container Registry Service Agent so that it can access GCR and download the json file. Then create a secret, encrypt it using Mozilla SOPS or Sealed Secrets , commit and push the encypted file to git. kubectl create secret docker-registry <secret-name> \\ --docker-server=<GCR-REGISTRY> \\ # e.g gcr.io --docker-username=_json_key \\ --docker-password=\"$(cat <downloaded-json-file>)\" Azure Container Registry \u00b6 AKS clusters are not able to pull and run images from ACR by default. Read Integrating AKS /w ACR as a potential pre-requisite before integrating Flux ImageRepositories with ACR. Note that the resulting ImagePullSecret for Flux could also be specified by Pods within the same Namespace to pull and run ACR images as well. Generating Tokens for Managed Identities [short-lived] \u00b6 With AAD Pod-Identity , we can create Pods that have their own cloud credentials for accessing Azure services like ACR. Your cluster should have --enable-managed-identity configured. This software can be installed via Helm not managed by Azure. Use Flux's HelmRepository and HelmRelease object to manage the aad-pod-identity installation from a bootstrap repository. !!! As an alternative to Helm, the --enable-aad-pod-identity flag for the az aks create is currently in Preview. Follow the Azure guide for Creating an AKS cluster with AAD Pod Identity if you would like to enable this feature with the Azure CLI. Once we have AAD Pod Identity installed, we can create a Deployment that frequently refreshes an image pull secret into our desired Namespace. Create a directory in your control repository and save this kustomization.yaml : # kustomization.yaml apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization resources : - git@github.com/fluxcd/flux2//manifests/integrations/registry-credentials-sync/azure patchesStrategicMerge : - config-patches.yaml Save and configure the following patch -- note the instructional comments for configuring matching Azure resources: # config-patches.yaml --- apiVersion : v1 kind : ConfigMap metadata : name : credentials-sync data : ACR_NAME : my-registry KUBE_SECRET : my-registry # does not yet exist -- will be created in the same Namespace SYNC_PERIOD : \"3600\" # ACR tokens expire every 3 hours; refresh faster than that # Create an identity in Azure and assign it a role to pull from ACR (note: the identity's resourceGroup should match the desired ACR): # az identity create -n acr-sync # az role assignment create --role AcrPull --assignee-object-id \"$(az identity show -n acr-sync -o tsv --query principalId)\" # Fetch the clientID and resourceID to configure the AzureIdentity spec below: # az identity show -n acr-sync -otsv --query clientId # az identity show -n acr-sync -otsv --query resourceId --- apiVersion : aadpodidentity.k8s.io/v1 kind : AzureIdentity metadata : name : credentials-sync # name must match the stub-resource in az-identity.yaml namespace : flux-system spec : clientID : 4ceaa448-d7b9-4a80-8f32-497eaf3d3287 resourceID : /subscriptions/8c69185e-55f9-4d00-8e71-a1b1bb1386a1/resourcegroups/stealthybox/providers/Microsoft.ManagedIdentity/userAssignedIdentities/acr-sync type : 0 # user-managed identity Verify that kustomize build . works, then commit the directory to you control repo. Flux will apply the Deployment and it will use the AAD managed identity for that Pod to regularly fetch ACR tokens into your configured KUBE_SECRET name. Reference the KUBE_SECRET value from any ImageRepository objects for that ACR registry. This example uses the fluxcd/flux2 github archive as a remote base, but you may copy the ./manifests/integrations/registry-credentials-sync/azure folder into your own repository or use a git submodule to vendor it if preferred. Using Static Credentials [long-lived] \u00b6 !!! Using a static credential requires a Secrets management solution compatible with your GitOps workflow. Follow the official Azure documentation for Creating an Image Pull Secret for ACR . Instead of creating the Secret directly into your Kubernetes cluster, encrypt it using Mozilla SOPS or Sealed Secrets , then commit and push the encypted file to git. This Secret should be in the same Namespace as your flux ImageRepository object. Update the ImageRepository.spec.secretRef to point to it. It is also possible to create Repository Scoped Tokens . !!! Note that this feature is in preview and does have limitations.","title":"Automate image updates to Git"},{"location":"guides/image-update/#automate-image-updates-to-git","text":"This guide walks you through configuring container image scanning and deployment rollouts with Flux. For a container image you can configure Flux to: scan the container registry and fetch the image tags select the latest tag based on the defined policy (semver, calver, regex) replace the tag in Kubernetes manifests (YAML format) checkout a branch, commit and push the changes to the remote Git repository apply the changes in-cluster and rollout the container image Alpha version Note that the image update feature is currently alpha, see the roadmap for more details. For production environments, this feature allows you to automatically deploy application patches (CVEs and bug fixes), and keep a record of all deployments in Git history. Production CI/CD workflow DEV: push a bug fix to the app repository DEV: bump the patch version and release e.g. v1.0.1 CI: build and push a container image tagged as registry.domain/org/app:v1.0.1 CD: pull the latest image metadata from the app registry (Flux image scanning) CD: update the image tag in the app manifest to v1.0.1 (Flux cluster to Git reconciliation) CD: deploy v1.0.1 to production clusters (Flux Git to cluster reconciliation) For staging environments, this features allow you to deploy the latest build of a branch, without having to manually edit the app deployment manifest in Git. Staging CI/CD workflow DEV: push code changes to the app repository main branch CI: build and push a container image tagged as ${GIT_BRANCH}-${GIT_SHA:0:7}-$(date +%s) CD: pull the latest image metadata from the app registry (Flux image scanning) CD: update the image tag in the app manifest to main-2d3fcbd-1611906956 (Flux cluster to Git reconciliation) CD: deploy main-2d3fcbd-1611906956 to staging clusters (Flux Git to cluster reconciliation)","title":"Automate image updates to Git"},{"location":"guides/image-update/#prerequisites","text":"You will need a Kubernetes cluster version 1.16 or newer and kubectl version 1.18. For a quick local test, you can use Kubernetes kind . Any other Kubernetes setup will work as well. In order to follow the guide you'll need a GitHub account and a personal access token that can create repositories (check all permissions under repo ). Export your GitHub personal access token and username: export GITHUB_TOKEN = <your-token> export GITHUB_USER = <your-username>","title":"Prerequisites"},{"location":"guides/image-update/#install-flux","text":"Enable image automation components If you bootstrapped Flux before without the --components-extra= argument, you need to add --components-extra=image-reflector-controller,image-automation-controller to your bootstrapping routine as image automation components are not installed by default. Install Flux with the image automation components: flux bootstrap github \\ --components-extra = image-reflector-controller,image-automation-controller \\ --owner = $GITHUB_USER \\ --repository = flux-image-updates \\ --branch = main \\ --path = clusters/my-cluster \\ --token-auth \\ --personal The bootstrap command creates a repository if one doesn't exist, and commits the manifests for the Flux components to the default branch at the specified path. It then configures the target cluster to synchronize with the specified path inside the repository. GitLab and other Git platforms You can install Flux and bootstrap repositories hosted on GitLab, BitBucket, Azure DevOps and any other Git provider that support SSH or token-based authentication. When using SSH, make sure the deploy key is configured with write access. Please see the installation guide for more details.","title":"Install Flux"},{"location":"guides/image-update/#deploy-a-demo-app","text":"We'll be using a tiny webapp called podinfo to showcase the image update feature. Clone your repository with: git clone https://github.com/ $GITHUB_USER /flux-image-updates cd flux-image-updates Add the podinfo Kubernetes deployment file inside cluster/my-cluster : curl -sL https://raw.githubusercontent.com/stefanprodan/podinfo/5.0.0/kustomize/deployment.yaml \\ > ./clusters/my-cluster/podinfo-deployment.yaml Commit and push changes to main branch: git add -A && \\ git commit -m \"add podinfo deployment\" && \\ git push origin main Tell Flux to pull and apply the changes or wait one minute for Flux to detect the changes on its own: flux reconcile kustomization flux-system --with-source Print the podinfo image deployed on your cluster: $ kubectl get deployment/podinfo -oyaml | grep 'image:' image: ghcr.io/stefanprodan/podinfo:5.0.0","title":"Deploy a demo app"},{"location":"guides/image-update/#configure-image-scanning","text":"Create an ImageRepository to tell Flux which container registry to scan for new tags: flux create image repository podinfo \\ --image = ghcr.io/stefanprodan/podinfo \\ --interval = 1m \\ --export > ./clusters/my-cluster/podinfo-registry.yaml The above command generates the following manifest: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImageRepository metadata : name : podinfo namespace : flux-system spec : image : ghcr.io/stefanprodan/podinfo interval : 1m0s For private images, you can create a Kubernetes secret in the same namespace as the ImageRepository with kubectl create secret docker-registry . Then you can configure Flux to use the credentials by referencing the Kubernetes secret in the ImageRepository : kind : ImageRepository spec : secretRef : name : regcred Storing secrets in Git Note that if you want to store the image pull secret in Git, you can encrypt the manifest with Mozilla SOPS or Sealed Secrets . Create an ImagePolicy to tell Flux which semver range to use when filtering tags: flux create image policy podinfo \\ --image-ref = podinfo \\ --select-semver = 5 .0.x \\ --export > ./clusters/my-cluster/podinfo-policy.yaml The above command generates the following manifest: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImagePolicy metadata : name : podinfo namespace : flux-system spec : imageRepositoryRef : name : podinfo policy : semver : range : 5.0.x semver ranges A semver range that includes stable releases can be defined with 1.0.x (patch versions only) or >=1.0.0 <2.0.0 (minor and patch versions). If you want to include pre-release e.g. 1.0.0-rc.1 , you can define a range like: ^1.x-0 or >1.0.0-rc <2.0.0-rc . Other policy examples For policies that make use of CalVer, build IDs or alphabetical sorting, have a look at the examples . Commit and push changes to main branch: git add -A && \\ git commit -m \"add podinfo image scan\" && \\ git push origin main Tell Flux to pull and apply changes: flux reconcile kustomization flux-system --with-source Wait for Flux to fetch the image tag list from GitHub container registry: $ flux get image repository podinfo NAME READY MESSAGE LAST SCAN podinfo True successful scan, found 13 tags 2020-12-13T17:51:48+02:00 Find which image tag matches the policy semver range with: $ flux get image policy podinfo NAME READY MESSAGE podinfo True Latest image tag for 'ghcr.io/stefanprodan/podinfo' resolved to: 5.0.3","title":"Configure image scanning"},{"location":"guides/image-update/#configure-image-updates","text":"Edit the podinfo-deploy.yaml and add a marker to tell Flux which policy to use when updating the container image: spec : containers : - name : podinfod image : ghcr.io/stefanprodan/podinfo:5.0.0 # {\"$imagepolicy\": \"flux-system:podinfo\"} Create an ImageUpdateAutomation to tell Flux which Git repository to write image updates to: flux create image update flux-system \\ --git-repo-ref = flux-system \\ --branch = main \\ --author-name = fluxcdbot \\ --author-email = fluxcdbot@users.noreply.github.com \\ --commit-template = \"[ci skip] update image\" \\ --export > ./clusters/my-cluster/flux-system-automation.yaml The above command generates the following manifest: apiVersion : image.toolkit.fluxcd.io/v1alpha1 kind : ImageUpdateAutomation metadata : name : flux-system namespace : flux-system spec : checkout : branch : main gitRepositoryRef : name : flux-system commit : authorEmail : fluxcdbot@users.noreply.github.com authorName : fluxcdbot messageTemplate : '[ci skip] update image' interval : 1m0s update : strategy : Setters Commit and push changes to main branch: git add -A && \\ git commit -m \"add image updates automation\" && \\ git push origin main Note that the ImageUpdateAutomation runs all the policies found in its namespace at the specified interval. Tell Flux to pull and apply changes: flux reconcile kustomization flux-system --with-source In a couple of seconds, Flux will push a commit to your repository with the latest image tag that matches the podinfo policy: $ git pull && cat clusters/my-cluster/podinfo-deployment.yaml | grep \"image:\" image: ghcr.io/stefanprodan/podinfo:5.0.3 # {\"$imagepolicy\": \"flux-system:podinfo\"} Wait for Flux to apply the latest commit on the cluster and verify that podinfo was updated to 5.0.3 : $ watch \"kubectl get deployment/podinfo -oyaml | grep 'image:'\" image: ghcr.io/stefanprodan/podinfo:5.0.3","title":"Configure image updates"},{"location":"guides/image-update/#configure-image-update-for-custom-resources","text":"Besides Kubernetes native kinds (Deployment, StatefulSet, DaemonSet, CronJob), Flux can be used to patch image tags in any Kubernetes custom resource stored in Git. The image policy marker format is: {\"$imagepolicy\": \"<policy-namespace>:<policy-name>\"} {\"$imagepolicy\": \"<policy-namespace>:<policy-name>:tag\"} HelmRelease example: apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : podinfo namespace : default spec : values : image : repository : ghcr.io/stefanprodan/podinfo tag : 5.0.0 # {\"$imagepolicy\": \"flux-system:podinfo:tag\"} Tekton Task example: apiVersion : tekton.dev/v1beta1 kind : Task metadata : name : golang namespace : default spec : steps : - name : golang image : docker.io/golang:1.15.6 # {\"$imagepolicy\": \"flux-system:golang\"} Flux Kustomization example: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : default spec : images : - name : ghcr.io/stefanprodan/podinfo newName : ghcr.io/stefanprodan/podinfo newTag : 5.0.0 # {\"$imagepolicy\": \"flux-system:podinfo:tag\"} Kustomize config ( kustomization.yaml ) example: apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization resources : - deployment.yaml images : - name : ghcr.io/stefanprodan/podinfo newName : ghcr.io/stefanprodan/podinfo newTag : 5.0.0 # {\"$imagepolicy\": \"flux-system:podinfo:tag\"}","title":"Configure image update for custom resources"},{"location":"guides/image-update/#trigger-image-updates-with-webhooks","text":"You may want to trigger a deployment as soon as a new image tag is pushed to your container registry. In order to notify the image-reflector-controller about new images, you can setup webhook receivers . First generate a random string and create a secret with a token field: TOKEN = $( head -c 12 /dev/urandom | shasum | cut -d ' ' -f1 ) echo $TOKEN kubectl -n flux-system create secret generic webhook-token \\ --from-literal = token = $TOKEN Define a receiver for DockerHub: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : podinfo namespace : flux-system spec : type : dockerhub secretRef : name : webhook-token resources : - kind : ImageRepository name : podinfo The notification-controller generates a unique URL using the provided token and the receiver name/namespace. Find the URL with: $ kubectl -n flux-system get receiver/podinfo NAME READY STATUS podinfo True Receiver initialised with URL: /hook/bed6d00b5555b1603e1f59b94d7fdbca58089cb5663633fb83f2815dc626d92b Log in to DockerHub web interface, go to your image registry Settings and select Webhooks. Fill the form \"Webhook URL\" by composing the address using the receiver LB and the generated URL http://<LoadBalancerAddress>/<ReceiverURL> . Note Besides DockerHub, you can define receivers for Harbor , Quay , Nexus , GCR , and any other system that supports webhooks e.g. GitHub Actions, Jenkins, CircleCI, etc. See the Receiver CRD docs for more details.","title":"Trigger image updates with webhooks"},{"location":"guides/image-update/#incident-management","text":"","title":"Incident management"},{"location":"guides/image-update/#suspend-automation","text":"During an incident you may wish to stop Flux from pushing image updates to Git. You can suspend the image automation directly in-cluster: flux suspend image update flux-system Or by editing the ImageUpdateAutomation manifest in Git: kind : ImageUpdateAutomation metadata : name : flux-system namespace : flux-system spec : suspend : true Once the incident is resolved, you can resume automation with: flux resume image update flux-system If you wish to pause the automation for a particular image only, you can suspend/resume the image scanning: flux suspend image repository podinfo","title":"Suspend automation"},{"location":"guides/image-update/#revert-image-updates","text":"Assuming you've configured Flux to update an app to its latest stable version: flux create image policy podinfo \\ --image-ref = podinfo \\ --select-semver = \">=5.0.0\" If the latest version e.g. 5.0.1 causes an incident in production, you can tell Flux to revert the image tag to a previous version e.g. 5.0.0 with: flux create image policy podinfo \\ --image-ref = podinfo \\ --select-semver = 5 .0.0 Or by changing the semver range in Git: kind : ImagePolicy metadata : name : podinfo namespace : flux-system spec : policy : semver : range : 5.0.0 Based on the above configuration, Flux will patch the podinfo deployment manifest in Git and roll out 5.0.0 in-cluster. When a new version is available e.g. 5.0.2 , you can update the policy once more and tell Flux to consider only versions greater than 5.0.1 : flux create image policy podinfo \\ --image-ref = podinfo \\ --select-semver = \">5.0.1\"","title":"Revert image updates"},{"location":"guides/image-update/#imagerepository-cloud-providers-authentication","text":"If relying on a cloud provider image repository, you might need to do some extra work in order to configure the ImageRepository resource credentials. Here are some common examples for the most popular cloud provider docker registries. Workarounds The examples below are intended as workaround solutions until native authentication mechanisms are implemented in Flux itself to support this in a more straightforward manner.","title":"ImageRepository cloud providers authentication"},{"location":"guides/image-update/#aws-elastic-container-registry","text":"The registry authentication credentials for ECR expire every 12 hours. Considering this limitation, one needs to ensure the credentials are being refreshed before expiration so that the controller can rely on them for authentication. The solution proposed is to create a cronjob that runs every 6 hours which would re-create the docker-registry secret using a new token. Edit and save the following snippet to a file ./clusters/my-cluster/ecr-sync.yaml , commit and push it to git. kind : Role apiVersion : rbac.authorization.k8s.io/v1 metadata : name : ecr-credentials-sync namespace : flux-system rules : - apiGroups : [ \"\" ] resources : - secrets verbs : - delete - create --- kind : RoleBinding apiVersion : rbac.authorization.k8s.io/v1 metadata : name : ecr-credentials-sync namespace : flux-system subjects : - kind : ServiceAccount name : ecr-credentials-sync roleRef : kind : Role name : ecr-credentials-sync apiGroup : \"\" --- apiVersion : v1 kind : ServiceAccount metadata : name : ecr-credentials-sync namespace : flux-system # Uncomment and edit if using IRSA # annotations: # eks.amazonaws.com/role-arn: <role arn> --- apiVersion : batch/v1beta1 kind : CronJob metadata : name : ecr-credentials-sync namespace : flux-system spec : suspend : false schedule : 0 */6 * * * failedJobsHistoryLimit : 1 successfulJobsHistoryLimit : 1 jobTemplate : spec : template : spec : serviceAccountName : ecr-credentials-sync restartPolicy : Never volumes : - name : token emptyDir : medium : Memory initContainers : - image : amazon/aws-cli name : get-token imagePullPolicy : IfNotPresent # You will need to set the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables if not using # IRSA. It is recommended to store the values in a Secret and load them in the container using envFrom. # envFrom: # - secretRef: # name: aws-credentials env : - name : REGION value : us-east-1 # change this if ECR repo is in a different region volumeMounts : - mountPath : /token name : token command : - /bin/sh - -ce - aws ecr get-login-password --region ${REGION} > /token/ecr-token containers : - image : bitnami/kubectl name : create-secret imagePullPolicy : IfNotPresent env : - name : SECRET_NAME value : ecr-credentials - name : ECR_REGISTRY value : <account id>.dkr.ecr.<region>.amazonaws.com # fill in the account id and region volumeMounts : - mountPath : /token name : token command : - /bin/bash - -ce - |- kubectl delete secret --ignore-not-found $SECRET_NAME kubectl create secret docker-registry $SECRET_NAME \\ --docker-server=\"$ECR_REGISTRY\" \\ --docker-username=AWS \\ --docker-password=\"$(</token/ecr-token)\" Using IAM Roles for Service Accounts (IRSA) If using IRSA, make sure the role attached to the service account has readonly access to ECR. The AWS managed policy arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly can be attached to the role. Since the cronjob will not create a job right away, after applying the manifest, you can manually create an init job using the following command: $ kubectl create job --from = cronjob/ecr-credentials-sync -n flux-system ecr-credentials-sync-init After the job runs, a secret named ecr-credentials should be created. Use this name in your ECR ImageRepository resource manifest as the value for .spec.secretRef.name . spec : secretRef : name : ecr-credentials","title":"AWS Elastic Container Registry"},{"location":"guides/image-update/#gcp-container-registry","text":"","title":"GCP Container Registry"},{"location":"guides/image-update/#using-access-token-short-lived","text":"Workload Identity Please ensure that you enable workload identity for your cluster, create a GCP service account that has access to the container registry and create an IAM policy binding between the GCP service account and the Kubernetes service account so that the pods created by the cronjob can access GCP APIs and get the token. Take a look at this guide The access token for GCR expires hourly. Considering this limitation, one needs to ensure the credentials are being refreshed before expiration so that the controller can rely on them for authentication. The solution proposed is to create a cronjob that runs every 45 minutes which would re-create the docker-registry secret using a new token. Edit and save the following snippet to a file ./clusters/my-cluster/gcr-sync.yaml , commit and push it to git. kind : Role apiVersion : rbac.authorization.k8s.io/v1 metadata : name : gcr-credentials-sync namespace : flux-system rules : - apiGroups : [ \"\" ] resources : - secrets verbs : - delete - create --- kind : RoleBinding apiVersion : rbac.authorization.k8s.io/v1 metadata : name : gcr-credentials-sync namespace : flux-system subjects : - kind : ServiceAccount name : gcr-credentials-sync roleRef : kind : Role name : gcr-credentials-sync apiGroup : \"\" --- apiVersion : v1 kind : ServiceAccount metadata : annotations : iam.gke.io/gcp-service-account : <name-of-service-account>@<project-id>.iam.gserviceaccount.com name : gcr-credentials-sync namespace : flux-system --- apiVersion : batch/v1beta1 kind : CronJob metadata : name : gcr-credentials-sync namespace : flux-system spec : suspend : false schedule : \"*/45 * * * *\" failedJobsHistoryLimit : 1 successfulJobsHistoryLimit : 1 jobTemplate : spec : template : spec : serviceAccountName : gcr-credentials-sync restartPolicy : Never containers : - image : google/cloud-sdk name : create-secret imagePullPolicy : IfNotPresent env : - name : SECRET_NAME value : gcr-credentials - name : GCR_REGISTRY value : <REGISTRY_NAME> # fill in the registry name e.g gcr.io, eu.gcr.io command : - /bin/bash - -ce - |- kubectl delete secret --ignore-not-found $SECRET_NAME kubectl create secret docker-registry $SECRET_NAME \\ --docker-server=\"$GCR_REGISTRY\" \\ --docker-username=oauth2accesstoken \\ --docker-password=\"$(gcloud auth print-access-token)\" Since the cronjob will not create a job right away, after applying the manifest, you can manually create an init job using the following command: $ kubectl create job --from = cronjob/gcr-credentials-sync -n flux-system gcr-credentials-sync-init After the job runs, a secret named gcr-credentials should be created. Use this name in your GCR ImageRepository resource manifest as the value for .spec.secretRef.name . spec : secretRef : name : gcr-credentials","title":"Using access token [short-lived]"},{"location":"guides/image-update/#using-a-json-key-long-lived","text":"Less secure option From Google documentation on authenticating container registry A user-managed key-pair that you can use as a credential for a service account. Because the credential is long-lived, it is the least secure option of all the available authentication methods. When possible, use an access token or another available authentication method to reduce the risk of unauthorized access to your artifacts. If you must use a service account key, ensure that you follow best practices for managing credentials. A Json key doesn't expire, so we don't need a cronjob, we just need to create the secret and reference it in the ImagePolicy. First, create a json key file by following this documentation . Grant the service account the role of Container Registry Service Agent so that it can access GCR and download the json file. Then create a secret, encrypt it using Mozilla SOPS or Sealed Secrets , commit and push the encypted file to git. kubectl create secret docker-registry <secret-name> \\ --docker-server=<GCR-REGISTRY> \\ # e.g gcr.io --docker-username=_json_key \\ --docker-password=\"$(cat <downloaded-json-file>)\"","title":"Using a JSON key [long-lived]"},{"location":"guides/image-update/#azure-container-registry","text":"AKS clusters are not able to pull and run images from ACR by default. Read Integrating AKS /w ACR as a potential pre-requisite before integrating Flux ImageRepositories with ACR. Note that the resulting ImagePullSecret for Flux could also be specified by Pods within the same Namespace to pull and run ACR images as well.","title":"Azure Container Registry"},{"location":"guides/image-update/#generating-tokens-for-managed-identities-short-lived","text":"With AAD Pod-Identity , we can create Pods that have their own cloud credentials for accessing Azure services like ACR. Your cluster should have --enable-managed-identity configured. This software can be installed via Helm not managed by Azure. Use Flux's HelmRepository and HelmRelease object to manage the aad-pod-identity installation from a bootstrap repository. !!! As an alternative to Helm, the --enable-aad-pod-identity flag for the az aks create is currently in Preview. Follow the Azure guide for Creating an AKS cluster with AAD Pod Identity if you would like to enable this feature with the Azure CLI. Once we have AAD Pod Identity installed, we can create a Deployment that frequently refreshes an image pull secret into our desired Namespace. Create a directory in your control repository and save this kustomization.yaml : # kustomization.yaml apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization resources : - git@github.com/fluxcd/flux2//manifests/integrations/registry-credentials-sync/azure patchesStrategicMerge : - config-patches.yaml Save and configure the following patch -- note the instructional comments for configuring matching Azure resources: # config-patches.yaml --- apiVersion : v1 kind : ConfigMap metadata : name : credentials-sync data : ACR_NAME : my-registry KUBE_SECRET : my-registry # does not yet exist -- will be created in the same Namespace SYNC_PERIOD : \"3600\" # ACR tokens expire every 3 hours; refresh faster than that # Create an identity in Azure and assign it a role to pull from ACR (note: the identity's resourceGroup should match the desired ACR): # az identity create -n acr-sync # az role assignment create --role AcrPull --assignee-object-id \"$(az identity show -n acr-sync -o tsv --query principalId)\" # Fetch the clientID and resourceID to configure the AzureIdentity spec below: # az identity show -n acr-sync -otsv --query clientId # az identity show -n acr-sync -otsv --query resourceId --- apiVersion : aadpodidentity.k8s.io/v1 kind : AzureIdentity metadata : name : credentials-sync # name must match the stub-resource in az-identity.yaml namespace : flux-system spec : clientID : 4ceaa448-d7b9-4a80-8f32-497eaf3d3287 resourceID : /subscriptions/8c69185e-55f9-4d00-8e71-a1b1bb1386a1/resourcegroups/stealthybox/providers/Microsoft.ManagedIdentity/userAssignedIdentities/acr-sync type : 0 # user-managed identity Verify that kustomize build . works, then commit the directory to you control repo. Flux will apply the Deployment and it will use the AAD managed identity for that Pod to regularly fetch ACR tokens into your configured KUBE_SECRET name. Reference the KUBE_SECRET value from any ImageRepository objects for that ACR registry. This example uses the fluxcd/flux2 github archive as a remote base, but you may copy the ./manifests/integrations/registry-credentials-sync/azure folder into your own repository or use a git submodule to vendor it if preferred.","title":"Generating Tokens for Managed Identities [short-lived]"},{"location":"guides/image-update/#using-static-credentials-long-lived","text":"!!! Using a static credential requires a Secrets management solution compatible with your GitOps workflow. Follow the official Azure documentation for Creating an Image Pull Secret for ACR . Instead of creating the Secret directly into your Kubernetes cluster, encrypt it using Mozilla SOPS or Sealed Secrets , then commit and push the encypted file to git. This Secret should be in the same Namespace as your flux ImageRepository object. Update the ImageRepository.spec.secretRef to point to it. It is also possible to create Repository Scoped Tokens . !!! Note that this feature is in preview and does have limitations.","title":"Using Static Credentials [long-lived]"},{"location":"guides/installation/","text":"Installation \u00b6 This guide walks you through setting up Flux v2 (hereafter: \"Flux\") to manage one or more Kubernetes clusters. Prerequisites \u00b6 You will need a Kubernetes cluster version 1.16 or newer and kubectl version 1.18 or newer. Install the Flux CLI \u00b6 With Homebrew: brew install fluxcd/tap/flux With Bash: curl -s https://toolkit.fluxcd.io/install.sh | sudo bash # enable completions in ~/.bash_profile . < ( flux completion bash ) Command-line completion for zsh , fish , and powershell are also supported with their own sub-commands. Binaries for macOS, Windows and Linux AMD64/ARM are available for download on the release page . Verify that your cluster satisfies the prerequisites with: flux check --pre Bootstrap \u00b6 Using the flux bootstrap command you can install Flux on a Kubernetes cluster and configure it to manage itself from a Git repository. The bootstrap creates a Git repository if one doesn't exist and commits the Flux components manifests to the main branch. Then it configures the target cluster to synchronize with that repository by setting up SSH deploy keys. If the Flux components are present on the cluster, the bootstrap command will perform an upgrade if needed. The bootstrap is idempotent, it's safe to run the command as many times as you want. You can choose what components to install and for which cluster with: flux bootstrap <GIT-PROVIDER> \\ --components = source-controller,kustomize-controller,helm-controller,notification-controller \\ --components-extra = image-reflector-controller,image-automation-controller \\ --path = clusters/my-cluster Multi-arch images The component images are published as multi-arch container images with support for Linux amd64 , arm64 and armv7 (e.g. 32bit Raspberry Pi) architectures. If you wish to install a specific version, use the Flux release tag e.g. --version=v0.9.0 . If you wish to deploy the Flux components onto tainted Kubernetes nodes , you can specify the toleration keys with --toleration-keys=node.kubernetes.io/dedicated-to-flux . With --path you can configure the directory which will be used to reconcile the target cluster. To control multiple clusters from the same Git repository, you have to set a unique path per cluster e.g. clusters/staging and clusters/production : ./clusters/ \u251c\u2500\u2500 staging # <- path=clusters/staging \u2502 \u2514\u2500\u2500 flux-system # <- namespace dir generated by bootstrap \u2502 \u251c\u2500\u2500 gotk-components.yaml \u2502 \u251c\u2500\u2500 gotk-sync.yaml \u2502 \u2514\u2500\u2500 kustomization.yaml \u2514\u2500\u2500 production-cluster # <- path=clusters/production \u2514\u2500\u2500 flux-system After running bootstrap you can place Kubernetes YAMLs inside a dir under path e.g. clusters/staging/my-app , and Flux will reconcile them on your cluster. Change the default branch If you wish to change the branch to something else than main, create the repository manually, push a branch to origin and then use flux bootstrap <GIT-PROVIDER> --branch=your-branch . For examples on how you can structure your Git repository see: flux2-kustomize-helm-example flux2-multi-tenancy GitHub and GitHub Enterprise \u00b6 Generate a personal access token that can create repositories by checking all permissions under repo . Export your GitHub personal access token as an environment variable: export GITHUB_TOKEN = <your-token> Run the bootstrap for a repository on your personal GitHub account: flux bootstrap github \\ --owner = my-github-username \\ --repository = my-repository \\ --path = clusters/my-cluster \\ --personal Deploy key The bootstrap command creates an SSH key which it stores as a secret in the Kubernetes cluster. The key is also used to create a deploy key in the GitHub repository. The new deploy key will be linked to the personal access token used to authenticate. Removing the personal access token will also remove the deploy key. Run the bootstrap for a repository owned by a GitHub organization: flux bootstrap github \\ --owner = my-github-organization \\ --repository = my-repository \\ --team = team1-slug \\ --team = team2-slug \\ --path = clusters/my-cluster When you specify a list of teams, those teams will be granted maintainer access to the repository. To run the bootstrap for a repository hosted on GitHub Enterprise, you have to specify your GitHub hostname: flux bootstrap github \\ --hostname = my-github-enterprise.com \\ --ssh-hostname = my-github-enterprise.com \\ --owner = my-github-organization \\ --repository = my-repository \\ --branch = main \\ --path = clusters/my-cluster If your GitHub Enterprise has SSH access disabled, you can use HTTPS and token authentication with: flux bootstrap github \\ --token-auth \\ --hostname = my-github-enterprise.com \\ --owner = my-github-organization \\ --repository = my-repository \\ --branch = main \\ --path = clusters/my-cluster GitLab and GitLab Enterprise \u00b6 Generate a personal access token that grants complete read/write access to the GitLab API. Export your GitLab personal access token as an environment variable: export GITLAB_TOKEN = <your-token> Run the bootstrap for a repository on your personal GitLab account: flux bootstrap gitlab \\ --owner = my-gitlab-username \\ --repository = my-repository \\ --branch = master \\ --path = clusters/my-cluster \\ --token-auth \\ --personal To run the bootstrap for a repository using deploy keys for authentication, you have to specify the SSH hostname: flux bootstrap gitlab \\ --ssh-hostname = gitlab.com \\ --owner = my-gitlab-username \\ --repository = my-repository \\ --branch = master \\ --path = clusters/my-cluster Authentication When providing the --ssh-hostname , a read-only (SSH) deploy key will be added to your repository, otherwise your GitLab personal token will be used to authenticate against the HTTPS endpoint instead. Run the bootstrap for a repository owned by a GitLab (sub)group: flux bootstrap gitlab \\ --owner = my-gitlab-group/my-gitlab-subgroup \\ --repository = my-repository \\ --branch = master \\ --path = clusters/my-cluster To run the bootstrap for a repository hosted on GitLab on-prem or enterprise, you have to specify your GitLab hostname: flux bootstrap gitlab \\ --hostname = my-gitlab.com \\ --token-auth \\ --owner = my-gitlab-group \\ --repository = my-repository \\ --branch = master \\ --path = clusters/my-cluster Air-gapped Environments \u00b6 To bootstrap Flux on air-gapped environments without access to github.com and ghcr.io, first you'll need to download the flux binary, and the container images from a computer with access to internet. List all container images: $ flux install --export | grep ghcr.io image: ghcr.io/fluxcd/helm-controller:v0.8.0 image: ghcr.io/fluxcd/kustomize-controller:v0.9.0 image: ghcr.io/fluxcd/notification-controller:v0.9.0 image: ghcr.io/fluxcd/source-controller:v0.9.0 Pull the images locally and push them to your container registry: docker pull ghcr.io/fluxcd/source-controller:v0.9.0 docker tag ghcr.io/fluxcd/source-controller:v0.9.0 registry.internal/fluxcd/source-controller:v0.9.0 docker push registry.internal/fluxcd/source-controller:v0.9.0 Copy flux binary to a computer with access to your air-gapped cluster, and create the pull secret in the flux-system namespace: kubectl create ns flux-system kubectl -n flux-system create secret generic regcred \\ --from-file = .dockerconfigjson = /.docker/config.json \\ --type = kubernetes.io/dockerconfigjson Finally, bootstrap Flux using the images from your private registry: flux bootstrap <GIT-PROVIDER> \\ --registry = registry.internal/fluxcd \\ --image-pull-secret = regcred \\ --hostname = my-git-server.internal Note that when running flux bootstrap without specifying a --version , the CLI will use the manifests embedded in its binary instead of downloading them from GitHub. You can determine which version you'll be installing, with flux --version . Generic Git Server \u00b6 For other Git providers such as Bitbucket, Gogs, Gitea, Azure DevOps, etc you can manually setup the repository and deploy key. Create a Git repository and clone it locally: git clone ssh://<host>/<org>/my-repository cd my-repository Create a directory inside the repository: mkdir -p ./clusters/my-cluster/flux-system Generate the Flux manifests with: flux install \\ --export > ./clusters/my-cluster/flux-system/gotk-components.yaml Commit and push the manifest to the master branch: git add -A && git commit -m \"add components\" && git push Apply the manifests on your cluster: kubectl apply -f ./clusters/my-cluster/flux-system/gotk-components.yaml Verify that the controllers have started: flux check Create a GitRepository object on your cluster by specifying the SSH address of your repo: flux create source git flux-system \\ --url = ssh://git@<host>/<org>/<repository> \\ --ssh-key-algorithm = ecdsa \\ --ssh-ecdsa-curve = p521 \\ --branch = master \\ --interval = 1m You will be prompted to add a deploy key to your repository. If you don't specify the SSH algorithm, then flux will generate an RSA 2048 bits key. Azure DevOps Azure DevOps requires a non-default Git implementation ( libgit2 ) to be enabled, so that the Git v2 protocol is supported. Note that this implementation does not support shallow cloning, and it is therefore advised to only resort to this option if a connection fails with the default configuration. If you are using Azure DevOps you need to specify a different Git implementation than the default: flux create source git flux-system \\ --git-implementation = libgit2 \\ --url = ssh://git@ssh.dev.azure.com/v3/<org>/<project>/<repository> \\ --branch = master \\ --interval = 1m Note that unlike git , Flux does not support the \"shorter\" scp-like syntax for the SSH protocol (e.g. ssh.dev.azure.com:v3 ). Use the RFC 3986 compatible syntax instead: ssh.dev.azure.com/v3 . If you wish to use Git over HTTPS, then generated a personal access token and supply it as the password: flux create source git flux-system \\ --git-implementation = libgit2 \\ --url = https://dev.azure.com/<org>/<project>/_git/<repository> \\ --branch = master \\ --username = git \\ --password = token \\ --interval = 1m Please consult the Azure DevOps documentation on how to generate personal access tokens for Git repositories. If your Git server supports basic auth, you can set the URL to HTTPS and specify the credentials with: flux create source git flux-system \\ --url = https://<host>/<org>/my-repository \\ --username = my-username \\ --password = my-password \\ --branch = master \\ --interval = 1m Create a Kustomization object on your cluster: flux create kustomization flux-system \\ --source = flux-system \\ --path = \"./clusters/my-cluster\" \\ --prune = true \\ --interval = 10m Export both objects, generate a kustomization.yaml , commit and push the manifests to Git: flux export source git flux-system \\ > ./clusters/my-cluster/flux-system/gotk-sync.yaml flux export kustomization flux-system \\ >> ./clusters/my-cluster/flux-system/gotk-sync.yaml cd ./clusters/my-cluster/flux-system && kustomize create --autodetect git add -A && git commit -m \"add sync manifests\" && git push To upgrade the Flux components to a newer version, download the latest flux binary, run the install command and commit the changes: flux install \\ --export > ./clusters/my-cluster/flux-system/gotk-components.yaml git add -A && git commit -m \"update flux\" && git push The source-controller will pull the changes on the cluster, then the kustomize-controller will perform a rolling update of all Flux components including itself. Bootstrap with Terraform \u00b6 The bootstrap procedure can be implemented with Terraform using the Flux provider published on registry.terraform.io . The provider consists of two data sources ( flux_install and flux_sync ) for generating the Kubernetes manifests that can be used to install or upgrade Flux: data \"flux_install\" \"main\" { target_path = \"clusters/my-cluster\" network_policy = false version = \"latest\" } data \"flux_sync\" \"main\" { target_path = \"clusters/my-cluster\" url = \"https://github.com/${var.github_owner}/${var.repository_name}\" branch = \"main\" } For more details on how to use the Terraform provider please see fluxcd/terraform-provider-flux . Customize Flux manifests \u00b6 You can customize the Flux components in the Git repository where you've run bootstrap with Kustomize patches. First clone the repository locally and generate a kustomization.yaml file with: cd ./clusters/production && kustomize create --autodetect Assuming you want to add custom annotations and labels to the Flux controllers in clusters/production . Create a Kustomize patch and set the metadata for source-controller and kustomize-controller pods: apiVersion : apps/v1 kind : Deployment metadata : name : source-controller namespace : flux-system spec : template : metadata : annotations : custom : annotation labels : custom : label --- apiVersion : apps/v1 kind : Deployment metadata : name : kustomize-controller namespace : flux-system spec : template : metadata : annotations : custom : annotation labels : custom : label Save the above file as flux-system-patch.yaml inside the clusters/production dir. Edit clusters/production/kustomization.yaml and add the patch: apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization resources : - flux-system patchesStrategicMerge : - flux-system-patch.yaml Push the changes to main branch: git add -A && git commit -m \"add production metadata\" && git push Flux will detect the change and will update itself on the production cluster. Dev install \u00b6 For testing purposes you can install Flux without storing its manifests in a Git repository: flux install Or using kubectl: kubectl apply -f https://github.com/fluxcd/flux2/releases/latest/download/install.yaml Then you can register Git repositories and reconcile them on your cluster: flux create source git podinfo \\ --url = https://github.com/stefanprodan/podinfo \\ --tag-semver = \">=4.0.0\" \\ --interval = 1m flux create kustomization podinfo-default \\ --source = podinfo \\ --path = \"./kustomize\" \\ --prune = true \\ --validation = client \\ --interval = 10m \\ --health-check = \"Deployment/podinfo.default\" \\ --health-check-timeout = 2m You can register Helm repositories and create Helm releases: flux create source helm bitnami \\ --interval = 1h \\ --url = https://charts.bitnami.com/bitnami flux create helmrelease nginx \\ --interval = 1h \\ --release-name = nginx-ingress-controller \\ --target-namespace = kube-system \\ --source = HelmRepository/bitnami \\ --chart = nginx-ingress-controller \\ --chart-version = \"5.x.x\" Upgrade \u00b6 Patch versions It is safe and advised to use the latest PATCH version when upgrading to a new MINOR version. Update Flux CLI to the latest release with brew upgrade fluxcd/tap/flux or by downloading the binary from GitHub . Verify that you are running the latest version with: flux --version Bootstrap upgrade \u00b6 If you've used the bootstrap procedure to deploy Flux, then rerun the bootstrap command for each cluster using the same arguments as before: flux bootstrap github \\ --owner = my-github-username \\ --repository = my-repository \\ --branch = main \\ --path = clusters/my-cluster \\ --personal The above command will clone the repository, it will update the components manifest in <path>/flux-system/gotk-components.yaml and it will push the changes to the remote branch. Tell Flux to pull the manifests from Git and upgrade itself with: flux reconcile source git flux-system Verify that the controllers have been upgrade with: flux check Automated upgrades You can automate the components manifest update with GitHub Actions and open a PR when there is a new Flux version available. For more details please see Flux GitHub Action docs . Terraform upgrade \u00b6 Update the Flux provider to the latest release and run terraform apply . Tell Flux to upgrade itself in-cluster or wait for it to pull the latest commit from Git: kubectl annotate --overwrite gitrepository/flux-system reconcile.fluxcd.io/requestedAt = \" $( date +%s ) \" In-cluster upgrade \u00b6 If you've installed Flux directly on the cluster, then rerun the install command: flux install The above command will apply the new manifests on your cluster. You can verify that the controllers have been upgraded to the latest version with flux check . If you've installed Flux directly on the cluster with kubectl, then rerun the command using the latest manifests from the main branch: kustomize build https://github.com/fluxcd/flux2/manifests/install?ref = main | kubectl apply -f- Uninstall \u00b6 You can uninstall Flux with: flux uninstall --namespace = flux-system The above command performs the following operations: deletes Flux components (deployments and services) deletes Flux network policies deletes Flux RBAC (service accounts, cluster roles and cluster role bindings) removes the Kubernetes finalizers from Flux custom resources deletes Flux custom resource definitions and custom resources deletes the namespace where Flux was installed If you've installed Flux in a namespace that you wish to preserve, you can skip the namespace deletion with: flux uninstall --namespace = infra --keep-namespace Hint Note that the uninstall command will not remove any Kubernetes objects or Helm releases that were reconciled on the cluster by Flux.","title":"Installation"},{"location":"guides/installation/#installation","text":"This guide walks you through setting up Flux v2 (hereafter: \"Flux\") to manage one or more Kubernetes clusters.","title":"Installation"},{"location":"guides/installation/#prerequisites","text":"You will need a Kubernetes cluster version 1.16 or newer and kubectl version 1.18 or newer.","title":"Prerequisites"},{"location":"guides/installation/#install-the-flux-cli","text":"With Homebrew: brew install fluxcd/tap/flux With Bash: curl -s https://toolkit.fluxcd.io/install.sh | sudo bash # enable completions in ~/.bash_profile . < ( flux completion bash ) Command-line completion for zsh , fish , and powershell are also supported with their own sub-commands. Binaries for macOS, Windows and Linux AMD64/ARM are available for download on the release page . Verify that your cluster satisfies the prerequisites with: flux check --pre","title":"Install the Flux CLI"},{"location":"guides/installation/#bootstrap","text":"Using the flux bootstrap command you can install Flux on a Kubernetes cluster and configure it to manage itself from a Git repository. The bootstrap creates a Git repository if one doesn't exist and commits the Flux components manifests to the main branch. Then it configures the target cluster to synchronize with that repository by setting up SSH deploy keys. If the Flux components are present on the cluster, the bootstrap command will perform an upgrade if needed. The bootstrap is idempotent, it's safe to run the command as many times as you want. You can choose what components to install and for which cluster with: flux bootstrap <GIT-PROVIDER> \\ --components = source-controller,kustomize-controller,helm-controller,notification-controller \\ --components-extra = image-reflector-controller,image-automation-controller \\ --path = clusters/my-cluster Multi-arch images The component images are published as multi-arch container images with support for Linux amd64 , arm64 and armv7 (e.g. 32bit Raspberry Pi) architectures. If you wish to install a specific version, use the Flux release tag e.g. --version=v0.9.0 . If you wish to deploy the Flux components onto tainted Kubernetes nodes , you can specify the toleration keys with --toleration-keys=node.kubernetes.io/dedicated-to-flux . With --path you can configure the directory which will be used to reconcile the target cluster. To control multiple clusters from the same Git repository, you have to set a unique path per cluster e.g. clusters/staging and clusters/production : ./clusters/ \u251c\u2500\u2500 staging # <- path=clusters/staging \u2502 \u2514\u2500\u2500 flux-system # <- namespace dir generated by bootstrap \u2502 \u251c\u2500\u2500 gotk-components.yaml \u2502 \u251c\u2500\u2500 gotk-sync.yaml \u2502 \u2514\u2500\u2500 kustomization.yaml \u2514\u2500\u2500 production-cluster # <- path=clusters/production \u2514\u2500\u2500 flux-system After running bootstrap you can place Kubernetes YAMLs inside a dir under path e.g. clusters/staging/my-app , and Flux will reconcile them on your cluster. Change the default branch If you wish to change the branch to something else than main, create the repository manually, push a branch to origin and then use flux bootstrap <GIT-PROVIDER> --branch=your-branch . For examples on how you can structure your Git repository see: flux2-kustomize-helm-example flux2-multi-tenancy","title":"Bootstrap"},{"location":"guides/installation/#github-and-github-enterprise","text":"Generate a personal access token that can create repositories by checking all permissions under repo . Export your GitHub personal access token as an environment variable: export GITHUB_TOKEN = <your-token> Run the bootstrap for a repository on your personal GitHub account: flux bootstrap github \\ --owner = my-github-username \\ --repository = my-repository \\ --path = clusters/my-cluster \\ --personal Deploy key The bootstrap command creates an SSH key which it stores as a secret in the Kubernetes cluster. The key is also used to create a deploy key in the GitHub repository. The new deploy key will be linked to the personal access token used to authenticate. Removing the personal access token will also remove the deploy key. Run the bootstrap for a repository owned by a GitHub organization: flux bootstrap github \\ --owner = my-github-organization \\ --repository = my-repository \\ --team = team1-slug \\ --team = team2-slug \\ --path = clusters/my-cluster When you specify a list of teams, those teams will be granted maintainer access to the repository. To run the bootstrap for a repository hosted on GitHub Enterprise, you have to specify your GitHub hostname: flux bootstrap github \\ --hostname = my-github-enterprise.com \\ --ssh-hostname = my-github-enterprise.com \\ --owner = my-github-organization \\ --repository = my-repository \\ --branch = main \\ --path = clusters/my-cluster If your GitHub Enterprise has SSH access disabled, you can use HTTPS and token authentication with: flux bootstrap github \\ --token-auth \\ --hostname = my-github-enterprise.com \\ --owner = my-github-organization \\ --repository = my-repository \\ --branch = main \\ --path = clusters/my-cluster","title":"GitHub and GitHub Enterprise"},{"location":"guides/installation/#gitlab-and-gitlab-enterprise","text":"Generate a personal access token that grants complete read/write access to the GitLab API. Export your GitLab personal access token as an environment variable: export GITLAB_TOKEN = <your-token> Run the bootstrap for a repository on your personal GitLab account: flux bootstrap gitlab \\ --owner = my-gitlab-username \\ --repository = my-repository \\ --branch = master \\ --path = clusters/my-cluster \\ --token-auth \\ --personal To run the bootstrap for a repository using deploy keys for authentication, you have to specify the SSH hostname: flux bootstrap gitlab \\ --ssh-hostname = gitlab.com \\ --owner = my-gitlab-username \\ --repository = my-repository \\ --branch = master \\ --path = clusters/my-cluster Authentication When providing the --ssh-hostname , a read-only (SSH) deploy key will be added to your repository, otherwise your GitLab personal token will be used to authenticate against the HTTPS endpoint instead. Run the bootstrap for a repository owned by a GitLab (sub)group: flux bootstrap gitlab \\ --owner = my-gitlab-group/my-gitlab-subgroup \\ --repository = my-repository \\ --branch = master \\ --path = clusters/my-cluster To run the bootstrap for a repository hosted on GitLab on-prem or enterprise, you have to specify your GitLab hostname: flux bootstrap gitlab \\ --hostname = my-gitlab.com \\ --token-auth \\ --owner = my-gitlab-group \\ --repository = my-repository \\ --branch = master \\ --path = clusters/my-cluster","title":"GitLab and GitLab Enterprise"},{"location":"guides/installation/#air-gapped-environments","text":"To bootstrap Flux on air-gapped environments without access to github.com and ghcr.io, first you'll need to download the flux binary, and the container images from a computer with access to internet. List all container images: $ flux install --export | grep ghcr.io image: ghcr.io/fluxcd/helm-controller:v0.8.0 image: ghcr.io/fluxcd/kustomize-controller:v0.9.0 image: ghcr.io/fluxcd/notification-controller:v0.9.0 image: ghcr.io/fluxcd/source-controller:v0.9.0 Pull the images locally and push them to your container registry: docker pull ghcr.io/fluxcd/source-controller:v0.9.0 docker tag ghcr.io/fluxcd/source-controller:v0.9.0 registry.internal/fluxcd/source-controller:v0.9.0 docker push registry.internal/fluxcd/source-controller:v0.9.0 Copy flux binary to a computer with access to your air-gapped cluster, and create the pull secret in the flux-system namespace: kubectl create ns flux-system kubectl -n flux-system create secret generic regcred \\ --from-file = .dockerconfigjson = /.docker/config.json \\ --type = kubernetes.io/dockerconfigjson Finally, bootstrap Flux using the images from your private registry: flux bootstrap <GIT-PROVIDER> \\ --registry = registry.internal/fluxcd \\ --image-pull-secret = regcred \\ --hostname = my-git-server.internal Note that when running flux bootstrap without specifying a --version , the CLI will use the manifests embedded in its binary instead of downloading them from GitHub. You can determine which version you'll be installing, with flux --version .","title":"Air-gapped Environments"},{"location":"guides/installation/#generic-git-server","text":"For other Git providers such as Bitbucket, Gogs, Gitea, Azure DevOps, etc you can manually setup the repository and deploy key. Create a Git repository and clone it locally: git clone ssh://<host>/<org>/my-repository cd my-repository Create a directory inside the repository: mkdir -p ./clusters/my-cluster/flux-system Generate the Flux manifests with: flux install \\ --export > ./clusters/my-cluster/flux-system/gotk-components.yaml Commit and push the manifest to the master branch: git add -A && git commit -m \"add components\" && git push Apply the manifests on your cluster: kubectl apply -f ./clusters/my-cluster/flux-system/gotk-components.yaml Verify that the controllers have started: flux check Create a GitRepository object on your cluster by specifying the SSH address of your repo: flux create source git flux-system \\ --url = ssh://git@<host>/<org>/<repository> \\ --ssh-key-algorithm = ecdsa \\ --ssh-ecdsa-curve = p521 \\ --branch = master \\ --interval = 1m You will be prompted to add a deploy key to your repository. If you don't specify the SSH algorithm, then flux will generate an RSA 2048 bits key. Azure DevOps Azure DevOps requires a non-default Git implementation ( libgit2 ) to be enabled, so that the Git v2 protocol is supported. Note that this implementation does not support shallow cloning, and it is therefore advised to only resort to this option if a connection fails with the default configuration. If you are using Azure DevOps you need to specify a different Git implementation than the default: flux create source git flux-system \\ --git-implementation = libgit2 \\ --url = ssh://git@ssh.dev.azure.com/v3/<org>/<project>/<repository> \\ --branch = master \\ --interval = 1m Note that unlike git , Flux does not support the \"shorter\" scp-like syntax for the SSH protocol (e.g. ssh.dev.azure.com:v3 ). Use the RFC 3986 compatible syntax instead: ssh.dev.azure.com/v3 . If you wish to use Git over HTTPS, then generated a personal access token and supply it as the password: flux create source git flux-system \\ --git-implementation = libgit2 \\ --url = https://dev.azure.com/<org>/<project>/_git/<repository> \\ --branch = master \\ --username = git \\ --password = token \\ --interval = 1m Please consult the Azure DevOps documentation on how to generate personal access tokens for Git repositories. If your Git server supports basic auth, you can set the URL to HTTPS and specify the credentials with: flux create source git flux-system \\ --url = https://<host>/<org>/my-repository \\ --username = my-username \\ --password = my-password \\ --branch = master \\ --interval = 1m Create a Kustomization object on your cluster: flux create kustomization flux-system \\ --source = flux-system \\ --path = \"./clusters/my-cluster\" \\ --prune = true \\ --interval = 10m Export both objects, generate a kustomization.yaml , commit and push the manifests to Git: flux export source git flux-system \\ > ./clusters/my-cluster/flux-system/gotk-sync.yaml flux export kustomization flux-system \\ >> ./clusters/my-cluster/flux-system/gotk-sync.yaml cd ./clusters/my-cluster/flux-system && kustomize create --autodetect git add -A && git commit -m \"add sync manifests\" && git push To upgrade the Flux components to a newer version, download the latest flux binary, run the install command and commit the changes: flux install \\ --export > ./clusters/my-cluster/flux-system/gotk-components.yaml git add -A && git commit -m \"update flux\" && git push The source-controller will pull the changes on the cluster, then the kustomize-controller will perform a rolling update of all Flux components including itself.","title":"Generic Git Server"},{"location":"guides/installation/#bootstrap-with-terraform","text":"The bootstrap procedure can be implemented with Terraform using the Flux provider published on registry.terraform.io . The provider consists of two data sources ( flux_install and flux_sync ) for generating the Kubernetes manifests that can be used to install or upgrade Flux: data \"flux_install\" \"main\" { target_path = \"clusters/my-cluster\" network_policy = false version = \"latest\" } data \"flux_sync\" \"main\" { target_path = \"clusters/my-cluster\" url = \"https://github.com/${var.github_owner}/${var.repository_name}\" branch = \"main\" } For more details on how to use the Terraform provider please see fluxcd/terraform-provider-flux .","title":"Bootstrap with Terraform"},{"location":"guides/installation/#customize-flux-manifests","text":"You can customize the Flux components in the Git repository where you've run bootstrap with Kustomize patches. First clone the repository locally and generate a kustomization.yaml file with: cd ./clusters/production && kustomize create --autodetect Assuming you want to add custom annotations and labels to the Flux controllers in clusters/production . Create a Kustomize patch and set the metadata for source-controller and kustomize-controller pods: apiVersion : apps/v1 kind : Deployment metadata : name : source-controller namespace : flux-system spec : template : metadata : annotations : custom : annotation labels : custom : label --- apiVersion : apps/v1 kind : Deployment metadata : name : kustomize-controller namespace : flux-system spec : template : metadata : annotations : custom : annotation labels : custom : label Save the above file as flux-system-patch.yaml inside the clusters/production dir. Edit clusters/production/kustomization.yaml and add the patch: apiVersion : kustomize.config.k8s.io/v1beta1 kind : Kustomization resources : - flux-system patchesStrategicMerge : - flux-system-patch.yaml Push the changes to main branch: git add -A && git commit -m \"add production metadata\" && git push Flux will detect the change and will update itself on the production cluster.","title":"Customize Flux manifests"},{"location":"guides/installation/#dev-install","text":"For testing purposes you can install Flux without storing its manifests in a Git repository: flux install Or using kubectl: kubectl apply -f https://github.com/fluxcd/flux2/releases/latest/download/install.yaml Then you can register Git repositories and reconcile them on your cluster: flux create source git podinfo \\ --url = https://github.com/stefanprodan/podinfo \\ --tag-semver = \">=4.0.0\" \\ --interval = 1m flux create kustomization podinfo-default \\ --source = podinfo \\ --path = \"./kustomize\" \\ --prune = true \\ --validation = client \\ --interval = 10m \\ --health-check = \"Deployment/podinfo.default\" \\ --health-check-timeout = 2m You can register Helm repositories and create Helm releases: flux create source helm bitnami \\ --interval = 1h \\ --url = https://charts.bitnami.com/bitnami flux create helmrelease nginx \\ --interval = 1h \\ --release-name = nginx-ingress-controller \\ --target-namespace = kube-system \\ --source = HelmRepository/bitnami \\ --chart = nginx-ingress-controller \\ --chart-version = \"5.x.x\"","title":"Dev install"},{"location":"guides/installation/#upgrade","text":"Patch versions It is safe and advised to use the latest PATCH version when upgrading to a new MINOR version. Update Flux CLI to the latest release with brew upgrade fluxcd/tap/flux or by downloading the binary from GitHub . Verify that you are running the latest version with: flux --version","title":"Upgrade"},{"location":"guides/installation/#bootstrap-upgrade","text":"If you've used the bootstrap procedure to deploy Flux, then rerun the bootstrap command for each cluster using the same arguments as before: flux bootstrap github \\ --owner = my-github-username \\ --repository = my-repository \\ --branch = main \\ --path = clusters/my-cluster \\ --personal The above command will clone the repository, it will update the components manifest in <path>/flux-system/gotk-components.yaml and it will push the changes to the remote branch. Tell Flux to pull the manifests from Git and upgrade itself with: flux reconcile source git flux-system Verify that the controllers have been upgrade with: flux check Automated upgrades You can automate the components manifest update with GitHub Actions and open a PR when there is a new Flux version available. For more details please see Flux GitHub Action docs .","title":"Bootstrap upgrade"},{"location":"guides/installation/#terraform-upgrade","text":"Update the Flux provider to the latest release and run terraform apply . Tell Flux to upgrade itself in-cluster or wait for it to pull the latest commit from Git: kubectl annotate --overwrite gitrepository/flux-system reconcile.fluxcd.io/requestedAt = \" $( date +%s ) \"","title":"Terraform upgrade"},{"location":"guides/installation/#in-cluster-upgrade","text":"If you've installed Flux directly on the cluster, then rerun the install command: flux install The above command will apply the new manifests on your cluster. You can verify that the controllers have been upgraded to the latest version with flux check . If you've installed Flux directly on the cluster with kubectl, then rerun the command using the latest manifests from the main branch: kustomize build https://github.com/fluxcd/flux2/manifests/install?ref = main | kubectl apply -f-","title":"In-cluster upgrade"},{"location":"guides/installation/#uninstall","text":"You can uninstall Flux with: flux uninstall --namespace = flux-system The above command performs the following operations: deletes Flux components (deployments and services) deletes Flux network policies deletes Flux RBAC (service accounts, cluster roles and cluster role bindings) removes the Kubernetes finalizers from Flux custom resources deletes Flux custom resource definitions and custom resources deletes the namespace where Flux was installed If you've installed Flux in a namespace that you wish to preserve, you can skip the namespace deletion with: flux uninstall --namespace = infra --keep-namespace Hint Note that the uninstall command will not remove any Kubernetes objects or Helm releases that were reconciled on the cluster by Flux.","title":"Uninstall"},{"location":"guides/monitoring/","text":"Monitoring \u00b6 This guide walks you through configuring monitoring for the Flux control plane. Flux comes with a monitoring stack composed of: Prometheus server - collects metrics from the toolkit controllers and stores them for 2h Grafana dashboards - displays the control plane resource usage and reconciliation stats Install the monitoring stack \u00b6 To install the monitoring stack with flux , first register the toolkit Git repository on your cluster: flux create source git monitoring \\ --interval = 30m \\ --url = https://github.com/fluxcd/flux2 \\ --branch = main Then apply the manifests/monitoring kustomization: flux create kustomization monitoring \\ --interval = 1h \\ --prune = true \\ --source = monitoring \\ --path = \"./manifests/monitoring\" \\ --health-check = \"Deployment/prometheus.flux-system\" \\ --health-check = \"Deployment/grafana.flux-system\" You can access Grafana using port forwarding: kubectl -n flux-system port-forward svc/grafana 3000 :3000 Grafana dashboards \u00b6 Control plane dashboard http://localhost:3000/d/gitops-toolkit-control-plane : Cluster reconciliation dashboard http://localhost:3000/d/gitops-toolkit-cluster : If you wish to use your own Prometheus and Grafana instances, then you can import the dashboards from GitHub . Hint Note that the toolkit controllers expose the /metrics endpoint on port 8080 . When using Prometheus Operator you should create a PodMonitor object for each controller to configure scraping. apiVersion : monitoring.coreos.com/v1 kind : PodMonitor metadata : name : source-controller namespace : flux-system spec : namespaceSelector : matchNames : - flux-system selector : matchLabels : app : source-controller podMetricsEndpoints : - port : http-prom Metrics \u00b6 For each toolkit.fluxcd.io kind, the controllers expose a gauge metric to track the Ready condition status, and a histogram with the reconciliation duration in seconds. Ready status metrics: gotk_reconcile_condition { kind, name, namespace, type = \"Ready\" , status = \"True\" } gotk_reconcile_condition { kind, name, namespace, type = \"Ready\" , status = \"False\" } gotk_reconcile_condition { kind, name, namespace, type = \"Ready\" , status = \"Unknown\" } gotk_reconcile_condition { kind, name, namespace, type = \"Ready\" , status = \"Deleted\" } Time spent reconciling: gotk_reconcile_duration_seconds_bucket{kind, name, namespace, le} gotk_reconcile_duration_seconds_sum{kind, name, namespace} gotk_reconcile_duration_seconds_count{kind, name, namespace} Alert manager example: groups : - name : GitOpsToolkit rules : - alert : ReconciliationFailure expr : max(gotk_reconcile_condition{status=\"False\",type=\"Ready\"}) by (namespace, name, kind) + on(namespace, name, kind) (max(gotk_reconcile_condition{status=\"Deleted\"}) by (namespace, name, kind)) * 2 == 1 for : 10m labels : severity : page annotations : summary : '{{ $labels.kind }} {{ $labels.namespace }}/{{ $labels.name }} reconciliation has been failing for more than ten minutes.'","title":"Monitoring with Prometheus"},{"location":"guides/monitoring/#monitoring","text":"This guide walks you through configuring monitoring for the Flux control plane. Flux comes with a monitoring stack composed of: Prometheus server - collects metrics from the toolkit controllers and stores them for 2h Grafana dashboards - displays the control plane resource usage and reconciliation stats","title":"Monitoring"},{"location":"guides/monitoring/#install-the-monitoring-stack","text":"To install the monitoring stack with flux , first register the toolkit Git repository on your cluster: flux create source git monitoring \\ --interval = 30m \\ --url = https://github.com/fluxcd/flux2 \\ --branch = main Then apply the manifests/monitoring kustomization: flux create kustomization monitoring \\ --interval = 1h \\ --prune = true \\ --source = monitoring \\ --path = \"./manifests/monitoring\" \\ --health-check = \"Deployment/prometheus.flux-system\" \\ --health-check = \"Deployment/grafana.flux-system\" You can access Grafana using port forwarding: kubectl -n flux-system port-forward svc/grafana 3000 :3000","title":"Install the monitoring stack"},{"location":"guides/monitoring/#grafana-dashboards","text":"Control plane dashboard http://localhost:3000/d/gitops-toolkit-control-plane : Cluster reconciliation dashboard http://localhost:3000/d/gitops-toolkit-cluster : If you wish to use your own Prometheus and Grafana instances, then you can import the dashboards from GitHub . Hint Note that the toolkit controllers expose the /metrics endpoint on port 8080 . When using Prometheus Operator you should create a PodMonitor object for each controller to configure scraping. apiVersion : monitoring.coreos.com/v1 kind : PodMonitor metadata : name : source-controller namespace : flux-system spec : namespaceSelector : matchNames : - flux-system selector : matchLabels : app : source-controller podMetricsEndpoints : - port : http-prom","title":"Grafana dashboards"},{"location":"guides/monitoring/#metrics","text":"For each toolkit.fluxcd.io kind, the controllers expose a gauge metric to track the Ready condition status, and a histogram with the reconciliation duration in seconds. Ready status metrics: gotk_reconcile_condition { kind, name, namespace, type = \"Ready\" , status = \"True\" } gotk_reconcile_condition { kind, name, namespace, type = \"Ready\" , status = \"False\" } gotk_reconcile_condition { kind, name, namespace, type = \"Ready\" , status = \"Unknown\" } gotk_reconcile_condition { kind, name, namespace, type = \"Ready\" , status = \"Deleted\" } Time spent reconciling: gotk_reconcile_duration_seconds_bucket{kind, name, namespace, le} gotk_reconcile_duration_seconds_sum{kind, name, namespace} gotk_reconcile_duration_seconds_count{kind, name, namespace} Alert manager example: groups : - name : GitOpsToolkit rules : - alert : ReconciliationFailure expr : max(gotk_reconcile_condition{status=\"False\",type=\"Ready\"}) by (namespace, name, kind) + on(namespace, name, kind) (max(gotk_reconcile_condition{status=\"Deleted\"}) by (namespace, name, kind)) * 2 == 1 for : 10m labels : severity : page annotations : summary : '{{ $labels.kind }} {{ $labels.namespace }}/{{ $labels.name }} reconciliation has been failing for more than ten minutes.'","title":"Metrics"},{"location":"guides/mozilla-sops/","text":"Manage Kubernetes secrets with Mozilla SOPS \u00b6 In order to store secrets safely in a public or private Git repository, you can use Mozilla's SOPS CLI to encrypt Kubernetes secrets with OpenPGP, AWS KMS, GCP KMS and Azure Key Vault. Prerequisites \u00b6 To follow this guide you'll need a Kubernetes cluster with the GitOps toolkit controllers installed on it. Please see the get started guide or the installation guide . Install gnupg and sops : brew install gnupg sops Generate a GPG key \u00b6 Generate a GPG key with OpenPGP without specifying a passphrase: $ gpg --full-generate-key Real name: stefanprodan Email address: stefanprodan@users.noreply.github.com Comment: You selected this USER-ID: \"stefanprodan <stefanprodan@users.noreply.github.com>\" Retrieve the GPG key ID (second row of the sec column): $ gpg --list-secret-keys stefanprodan@users.noreply.github.com sec rsa3072 2020-09-06 [SC] 1F3D1CED2F865F5E59CA564553241F147E7C5FA4 Export the public and private keypair from your local GPG keyring and create a Kubernetes secret named sops-gpg in the flux-system namespace: gpg --export-secret-keys \\ --armor 1F3D1CED2F865F5E59CA564553241F147E7C5FA4 | kubectl create secret generic sops-gpg \\ --namespace = flux-system \\ --from-file = sops.asc = /dev/stdin Encrypt secrets \u00b6 Generate a Kubernetes secret manifest with kubectl: kubectl -n default create secret generic basic-auth \\ --from-literal = user = admin \\ --from-literal = password = change-me \\ --dry-run = client \\ -o yaml > basic-auth.yaml Encrypt the secret with sops using your GPG key: sops --encrypt \\ --pgp = 1F3D1CED2F865F5E59CA564553241F147E7C5FA4 \\ --encrypted-regex '^(data|stringData)$' \\ --in-place basic-auth.yaml Hint Note that you should encrypt only the data section. Encrypting the Kubernetes secret metadata, kind or apiVersion is not supported by kustomize-controller. You can now commit the encrypted secret to your Git repository. Hint Note that you shouldn't apply the encrypted secrets onto the cluster with kubectl. SOPS encrypted secrets are designed to be consumed by kustomize-controller. Configure secrets decryption \u00b6 Registry the Git repository on your cluster: flux create source git my-secrets \\ --url = https://github.com/my-org/my-secrets Create a kustomization for reconciling the secrets on the cluster: flux create kustomization my-secrets \\ --source = my-secrets \\ --prune = true \\ --interval = 10m \\ --decryption-provider = sops \\ --decryption-secret = sops-gpg Note that the sops-gpg can contain more than one key, sops will try to decrypt the secrets by iterating over all the private keys until it finds one that works. Using various cloud providers \u00b6 When using AWS/GCP KMS, you don't have to include the gpg secretRef under spec.provider (you can skip the --decryption-secret flag when running flux create kustomization ), instead you'll have to bind an IAM Role with access to the KMS keys to the kustomize-controller service account of the flux-system namespace for kustomize-controller to be able to fetch keys from KMS. AWS \u00b6 IAM Role example: { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Action\" : [ \"kms:Encrypt\" , \"kms:Decrypt\" , \"kms:ReEncrypt*\" , \"kms:GenerateDataKey*\" , \"kms:DescribeKey\" ], \"Effect\" : \"Allow\" , \"Resource\" : \"arn:aws:kms:eu-west-1:XXXXX209540:key/4f581f5b-7f78-45e9-a543-83a7022e8105\" } ] } Azure \u00b6 When using Azure Key Vault you need to authenticate the kustomize controller either by passing Service Principal credentials as environment variables or with add-pod-identity . Google Cloud \u00b6 Please ensure that the GKE cluster has Workload Identity enabled. Create a service account with the role Cloud KMS CryptoKey Encrypter/Decrypter . Create an IAM policy binding between the GCP service account to the kustomize-controller service account of the flux-system . Annotate the kustomize-controller service account in the flux-system with the GCP service account. kubectl annotate serviceaccount kustomize-controller \\ --namespace flux-system \\ iam.gke.io/gcp-service-account = <name-of-serviceaccount>@project-id.iam.gserviceaccount.com GitOps workflow \u00b6 A cluster admin should create the Kubernetes secret with the PGP keys on each cluster and add the GitRepository/Kustomization manifests to the fleet repository. Git repository manifest: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : my-secrets namespace : flux-system spec : interval : 1m url : https://github.com/my-org/my-secrets Kustomization manifest: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : my-secrets namespace : flux-system spec : interval : 10m0s sourceRef : kind : GitRepository name : my-secrets path : ./ prune : true decryption : provider : sops secretRef : name : sops-gpg Hint You can generate the above manifests using flux create <kind> --export > manifest.yaml . Assuming a team member wants to deploy an application that needs to connect to a database using a username and password, they'll be doing the following: create a Kubernetes Secret manifest locally with the db credentials e.g. db-auth.yaml encrypt the secret data field with sops create a Kubernetes Deployment manifest for the app e.g. app-deployment.yaml add the Secret to the Deployment manifest as a volume mount or env var commit the manifests db-auth.yaml and app-deployment.yaml to a Git repository that's being synced by the GitOps toolkit controllers Once the manifests have been pushed to the Git repository, the following happens: source-controller pulls the changes from Git kustomize-controller loads the GPG keys from the sops-pgp secret kustomize-controller decrypts the Kubernetes secrets with sops and applies them on the cluster kubelet creates the pods and mounts the secret as a volume or env variable inside the app container","title":"Mozilla SOPS"},{"location":"guides/mozilla-sops/#manage-kubernetes-secrets-with-mozilla-sops","text":"In order to store secrets safely in a public or private Git repository, you can use Mozilla's SOPS CLI to encrypt Kubernetes secrets with OpenPGP, AWS KMS, GCP KMS and Azure Key Vault.","title":"Manage Kubernetes secrets with Mozilla SOPS"},{"location":"guides/mozilla-sops/#prerequisites","text":"To follow this guide you'll need a Kubernetes cluster with the GitOps toolkit controllers installed on it. Please see the get started guide or the installation guide . Install gnupg and sops : brew install gnupg sops","title":"Prerequisites"},{"location":"guides/mozilla-sops/#generate-a-gpg-key","text":"Generate a GPG key with OpenPGP without specifying a passphrase: $ gpg --full-generate-key Real name: stefanprodan Email address: stefanprodan@users.noreply.github.com Comment: You selected this USER-ID: \"stefanprodan <stefanprodan@users.noreply.github.com>\" Retrieve the GPG key ID (second row of the sec column): $ gpg --list-secret-keys stefanprodan@users.noreply.github.com sec rsa3072 2020-09-06 [SC] 1F3D1CED2F865F5E59CA564553241F147E7C5FA4 Export the public and private keypair from your local GPG keyring and create a Kubernetes secret named sops-gpg in the flux-system namespace: gpg --export-secret-keys \\ --armor 1F3D1CED2F865F5E59CA564553241F147E7C5FA4 | kubectl create secret generic sops-gpg \\ --namespace = flux-system \\ --from-file = sops.asc = /dev/stdin","title":"Generate a GPG key"},{"location":"guides/mozilla-sops/#encrypt-secrets","text":"Generate a Kubernetes secret manifest with kubectl: kubectl -n default create secret generic basic-auth \\ --from-literal = user = admin \\ --from-literal = password = change-me \\ --dry-run = client \\ -o yaml > basic-auth.yaml Encrypt the secret with sops using your GPG key: sops --encrypt \\ --pgp = 1F3D1CED2F865F5E59CA564553241F147E7C5FA4 \\ --encrypted-regex '^(data|stringData)$' \\ --in-place basic-auth.yaml Hint Note that you should encrypt only the data section. Encrypting the Kubernetes secret metadata, kind or apiVersion is not supported by kustomize-controller. You can now commit the encrypted secret to your Git repository. Hint Note that you shouldn't apply the encrypted secrets onto the cluster with kubectl. SOPS encrypted secrets are designed to be consumed by kustomize-controller.","title":"Encrypt secrets"},{"location":"guides/mozilla-sops/#configure-secrets-decryption","text":"Registry the Git repository on your cluster: flux create source git my-secrets \\ --url = https://github.com/my-org/my-secrets Create a kustomization for reconciling the secrets on the cluster: flux create kustomization my-secrets \\ --source = my-secrets \\ --prune = true \\ --interval = 10m \\ --decryption-provider = sops \\ --decryption-secret = sops-gpg Note that the sops-gpg can contain more than one key, sops will try to decrypt the secrets by iterating over all the private keys until it finds one that works.","title":"Configure secrets decryption"},{"location":"guides/mozilla-sops/#using-various-cloud-providers","text":"When using AWS/GCP KMS, you don't have to include the gpg secretRef under spec.provider (you can skip the --decryption-secret flag when running flux create kustomization ), instead you'll have to bind an IAM Role with access to the KMS keys to the kustomize-controller service account of the flux-system namespace for kustomize-controller to be able to fetch keys from KMS.","title":"Using various cloud providers"},{"location":"guides/mozilla-sops/#aws","text":"IAM Role example: { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Action\" : [ \"kms:Encrypt\" , \"kms:Decrypt\" , \"kms:ReEncrypt*\" , \"kms:GenerateDataKey*\" , \"kms:DescribeKey\" ], \"Effect\" : \"Allow\" , \"Resource\" : \"arn:aws:kms:eu-west-1:XXXXX209540:key/4f581f5b-7f78-45e9-a543-83a7022e8105\" } ] }","title":"AWS"},{"location":"guides/mozilla-sops/#azure","text":"When using Azure Key Vault you need to authenticate the kustomize controller either by passing Service Principal credentials as environment variables or with add-pod-identity .","title":"Azure"},{"location":"guides/mozilla-sops/#google-cloud","text":"Please ensure that the GKE cluster has Workload Identity enabled. Create a service account with the role Cloud KMS CryptoKey Encrypter/Decrypter . Create an IAM policy binding between the GCP service account to the kustomize-controller service account of the flux-system . Annotate the kustomize-controller service account in the flux-system with the GCP service account. kubectl annotate serviceaccount kustomize-controller \\ --namespace flux-system \\ iam.gke.io/gcp-service-account = <name-of-serviceaccount>@project-id.iam.gserviceaccount.com","title":"Google Cloud"},{"location":"guides/mozilla-sops/#gitops-workflow","text":"A cluster admin should create the Kubernetes secret with the PGP keys on each cluster and add the GitRepository/Kustomization manifests to the fleet repository. Git repository manifest: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : my-secrets namespace : flux-system spec : interval : 1m url : https://github.com/my-org/my-secrets Kustomization manifest: apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : my-secrets namespace : flux-system spec : interval : 10m0s sourceRef : kind : GitRepository name : my-secrets path : ./ prune : true decryption : provider : sops secretRef : name : sops-gpg Hint You can generate the above manifests using flux create <kind> --export > manifest.yaml . Assuming a team member wants to deploy an application that needs to connect to a database using a username and password, they'll be doing the following: create a Kubernetes Secret manifest locally with the db credentials e.g. db-auth.yaml encrypt the secret data field with sops create a Kubernetes Deployment manifest for the app e.g. app-deployment.yaml add the Secret to the Deployment manifest as a volume mount or env var commit the manifests db-auth.yaml and app-deployment.yaml to a Git repository that's being synced by the GitOps toolkit controllers Once the manifests have been pushed to the Git repository, the following happens: source-controller pulls the changes from Git kustomize-controller loads the GPG keys from the sops-pgp secret kustomize-controller decrypts the Kubernetes secrets with sops and applies them on the cluster kubelet creates the pods and mounts the secret as a volume or env variable inside the app container","title":"GitOps workflow"},{"location":"guides/notifications/","text":"Setup Notifications \u00b6 When operating a cluster, different teams may wish to receive notifications about the status of their GitOps pipelines. For example, the on-call team would receive alerts about reconciliation failures in the cluster, while the dev team may wish to be alerted when a new version of an app was deployed and if the deployment is healthy. Prerequisites \u00b6 To follow this guide you'll need a Kubernetes cluster with the GitOps toolkit controllers installed on it. Please see the get started guide or the installation guide . The GitOps toolkit controllers emit Kubernetes events whenever a resource status changes. You can use the notification-controller to forward these events to Slack, Microsoft Teams, Discord or Rocket chart. The notification controller is part of the default toolkit installation. Define a provider \u00b6 First create a secret with your Slack incoming webhook: kubectl -n flux-system create secret generic slack-url \\ --from-literal = address = https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK Note that the secret must contain an address field, it can be a Slack, Microsoft Teams, Discord or Rocket webhook URL. Create a notification provider for Slack by referencing the above secret: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Provider metadata : name : slack namespace : flux-system spec : type : slack channel : general secretRef : name : slack-url The provider type can be slack , msteams , discord , rocket , github , gitlab or generic . When type generic is specified, the notification controller will post the incoming event in JSON format to the webhook address. This way you can create custom handlers that can store the events in Elasticsearch, CloudWatch, Stackdriver, etc. Define an alert \u00b6 Create an alert definition for all repositories and kustomizations: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : name : on-call-webapp namespace : flux-system spec : providerRef : name : slack eventSeverity : info eventSources : - kind : GitRepository name : '*' - kind : Kustomization name : '*' Apply the above files or commit them to the fleet-infra repository. To verify that the alert has been acknowledge by the notification controller do: $ kubectl -n flux-system get alerts NAME READY STATUS AGE on-call-webapp True Initialized 1m Multiple alerts can be used to send notifications to different channels or Slack organizations. The event severity can be set to info or error . When the severity is set to error , the kustomize controller will alert on any error encountered during the reconciliation process. This includes kustomize build and validation errors, apply errors and health check failures. When the verbosity is set to info , the controller will alert if: a Kubernetes object was created, updated or deleted heath checks are passing a dependency is delaying the execution an error occurs Git commit status \u00b6 The GitHub, GitLab, Bitbucket, and Azure DevOps providers are slightly different to the other providers. Instead of a stateless stream of events, the git notification providers will link the event with accompanying git commit which triggered the event. The linking is done by updating the commit status of a specific commit. GitHub GitLab Bitbucket Azure DevOps In GitHub the commit status set by notification-controller will result in a green checkmark or red cross next to the commit hash. Clicking the icon will show more detailed information about the status. Receiving an event in the form of a commit status rather than a message in a chat conversation has the benefit that it closes the deployment loop giving quick and visible feedback if a commit has reconciled and if it succeeded. This means that a deployment will work in a similar manner that people are used to with \"traditional\" push based CD pipelines. Additionally the status can be fetched from the git providers API for a specific commit. Allowing for custom automation tools that can automatically promote, commit to a new directory, after receiving a successful commit status. This can all be done without requiring any access to the Kubernetes cluster. As stated before the provider works by referencing the same git repository as the Kustomization controller does. When a new commit is pushed to the repository, source-controller will sync the commit, triggering the kustomize-controller to reconcile the new commit. After this is done the kustomize-controller sends an event to the notification-controller with the result and the commit hash it reconciled. Then notification-controller can update the correct commit and repository when receiving the event. Limitations The git notification providers require that a commit hash present in the meta data of the event. There for the the providers will only work with Kustomization as an event source, as it is the only resource which includes this data. First follow the get started guide if you do not have a Kubernetes cluster with Flux installed in it. You will need a authentication token to communicate with the API. The authentication method depends on the git provider used, refer to the Provider CRD for details about how to get the correct token. The guide will use GitHub, but the other providers will work in a very similar manner. The token will need to have write access to the repository it is going to update the commit status in. Store the generated token in a Secret with the following data format in the cluster. apiVersion : v1 kind : Secret metadata : name : github namespace : flux-system data : token : <token> When sending notification events the kustomization-controller will include the commit hash related to the event. Note that the commit hash in the event does not come from the git repository the Kustomization resource comes from but rather the kustomization source ref. This mean that commit status notifications will not work if the manifests comes from a repository which the API token is not allowed to write to. Copy the manifest content in the \" kustomize \" directory into the directory \"./clusters/my-cluster/podinfo\" in your fleet-infra repository. Make sure that you also add the namespace podinfo. apiVersion : v1 kind : Namespace metadata : name : podinfo Then create a Kustomization to deploy podinfo. apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : flux-system spec : interval : 5m targetNamespace : podinfo path : ./clusters/my-cluster/podinfo prune : true sourceRef : kind : GitRepository name : flux-system healthChecks : - apiVersion : apps/v1 kind : Deployment name : podinfo namespace : podinfo timeout : 1m Creating a git provider is very similar to creating other types of providers. The only caveat being that the provider address needs to point to the same git repository as the event source originates from. apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Provider metadata : name : flux-system namespace : flux-system spec : type : github address : https://github.com/<username>/fleet-infra secretRef : name : github --- apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : name : podinfo namespace : flux-system spec : providerRef : name : flux-system eventSeverity : info eventSources : - kind : Kustomization name : podinfo namespace : flux-system By now the fleet-infra repository should have a similar directory structure. fleet-infra \u2514\u2500\u2500 clusters/ \u2514\u2500\u2500 my-cluster/ \u251c\u2500\u2500 flux-system/ \u2502 \u251c\u2500\u2500 gotk-components.yaml \u2502 \u251c\u2500\u2500 gotk-sync.yaml \u2502 \u2514\u2500\u2500 kustomization.yaml \u251c\u2500\u2500 podinfo/ \u2502 \u251c\u2500\u2500 namespace.yaml \u2502 \u251c\u2500\u2500 deployment.yaml \u2502 \u251c\u2500\u2500 hpa.yaml \u2502 \u251c\u2500\u2500 service.yaml \u2502 \u2514\u2500\u2500 kustomization.yaml \u251c\u2500\u2500 podinfo-kustomization.yaml \u2514\u2500\u2500 podinfo-notification.yaml If podinfo is deployed and the health checks pass you should get a successful status in your forked podinfo repository. If everything is setup correctly there should now be a green check-mark next to the latest commit. Clicking the check-mark should show a detailed view. GitHub GitLab Generate error A deployment failure can be forced by setting an invalid image tag in the podinfo deployment. apiVersion : apps/v1 kind : Deployment spec : template : spec : containers : - name : podinfod image : ghcr.io/stefanprodan/podinfo:fake After the commit has been reconciled it should return a failed commit status. This is where the health check in the Kustomization comes into play together with the timeout. The health check is used to asses the health of the Kustomization. A failed commit status will not be sent until the health check timeout. Setting a lower timeout will give feedback faster, but may sometimes not allow enough time for a new application to deploy. GitHub GitLab Status changes \u00b6 The provider will continuously receive events as they happen, and multiple events may be received for the same commit hash. The git providers are configured to only update the status if the status has changed. This is to avoid spamming the commit status history with the same status over and over again. There is an aspect of state fullness that needs to be considered, compared to the other notification providers, as the events are stored by the git provider. This means that the status of a commit can change over time. Initially a deployment may be healthy, resulting in a successful status. Down the line the application, and the health check, may start failing due to the amount of traffic it receives or external dependencies no longer being available. The change in the health check would cause the status to go from successful to failed. It is important to keep this in mind when building any automation tools that deals with the status, and consider the fact that receiving a successful status once does not mean it will always be successful.","title":"Setup Notifications"},{"location":"guides/notifications/#setup-notifications","text":"When operating a cluster, different teams may wish to receive notifications about the status of their GitOps pipelines. For example, the on-call team would receive alerts about reconciliation failures in the cluster, while the dev team may wish to be alerted when a new version of an app was deployed and if the deployment is healthy.","title":"Setup Notifications"},{"location":"guides/notifications/#prerequisites","text":"To follow this guide you'll need a Kubernetes cluster with the GitOps toolkit controllers installed on it. Please see the get started guide or the installation guide . The GitOps toolkit controllers emit Kubernetes events whenever a resource status changes. You can use the notification-controller to forward these events to Slack, Microsoft Teams, Discord or Rocket chart. The notification controller is part of the default toolkit installation.","title":"Prerequisites"},{"location":"guides/notifications/#define-a-provider","text":"First create a secret with your Slack incoming webhook: kubectl -n flux-system create secret generic slack-url \\ --from-literal = address = https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK Note that the secret must contain an address field, it can be a Slack, Microsoft Teams, Discord or Rocket webhook URL. Create a notification provider for Slack by referencing the above secret: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Provider metadata : name : slack namespace : flux-system spec : type : slack channel : general secretRef : name : slack-url The provider type can be slack , msteams , discord , rocket , github , gitlab or generic . When type generic is specified, the notification controller will post the incoming event in JSON format to the webhook address. This way you can create custom handlers that can store the events in Elasticsearch, CloudWatch, Stackdriver, etc.","title":"Define a provider"},{"location":"guides/notifications/#define-an-alert","text":"Create an alert definition for all repositories and kustomizations: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : name : on-call-webapp namespace : flux-system spec : providerRef : name : slack eventSeverity : info eventSources : - kind : GitRepository name : '*' - kind : Kustomization name : '*' Apply the above files or commit them to the fleet-infra repository. To verify that the alert has been acknowledge by the notification controller do: $ kubectl -n flux-system get alerts NAME READY STATUS AGE on-call-webapp True Initialized 1m Multiple alerts can be used to send notifications to different channels or Slack organizations. The event severity can be set to info or error . When the severity is set to error , the kustomize controller will alert on any error encountered during the reconciliation process. This includes kustomize build and validation errors, apply errors and health check failures. When the verbosity is set to info , the controller will alert if: a Kubernetes object was created, updated or deleted heath checks are passing a dependency is delaying the execution an error occurs","title":"Define an alert"},{"location":"guides/notifications/#git-commit-status","text":"The GitHub, GitLab, Bitbucket, and Azure DevOps providers are slightly different to the other providers. Instead of a stateless stream of events, the git notification providers will link the event with accompanying git commit which triggered the event. The linking is done by updating the commit status of a specific commit. GitHub GitLab Bitbucket Azure DevOps In GitHub the commit status set by notification-controller will result in a green checkmark or red cross next to the commit hash. Clicking the icon will show more detailed information about the status. Receiving an event in the form of a commit status rather than a message in a chat conversation has the benefit that it closes the deployment loop giving quick and visible feedback if a commit has reconciled and if it succeeded. This means that a deployment will work in a similar manner that people are used to with \"traditional\" push based CD pipelines. Additionally the status can be fetched from the git providers API for a specific commit. Allowing for custom automation tools that can automatically promote, commit to a new directory, after receiving a successful commit status. This can all be done without requiring any access to the Kubernetes cluster. As stated before the provider works by referencing the same git repository as the Kustomization controller does. When a new commit is pushed to the repository, source-controller will sync the commit, triggering the kustomize-controller to reconcile the new commit. After this is done the kustomize-controller sends an event to the notification-controller with the result and the commit hash it reconciled. Then notification-controller can update the correct commit and repository when receiving the event. Limitations The git notification providers require that a commit hash present in the meta data of the event. There for the the providers will only work with Kustomization as an event source, as it is the only resource which includes this data. First follow the get started guide if you do not have a Kubernetes cluster with Flux installed in it. You will need a authentication token to communicate with the API. The authentication method depends on the git provider used, refer to the Provider CRD for details about how to get the correct token. The guide will use GitHub, but the other providers will work in a very similar manner. The token will need to have write access to the repository it is going to update the commit status in. Store the generated token in a Secret with the following data format in the cluster. apiVersion : v1 kind : Secret metadata : name : github namespace : flux-system data : token : <token> When sending notification events the kustomization-controller will include the commit hash related to the event. Note that the commit hash in the event does not come from the git repository the Kustomization resource comes from but rather the kustomization source ref. This mean that commit status notifications will not work if the manifests comes from a repository which the API token is not allowed to write to. Copy the manifest content in the \" kustomize \" directory into the directory \"./clusters/my-cluster/podinfo\" in your fleet-infra repository. Make sure that you also add the namespace podinfo. apiVersion : v1 kind : Namespace metadata : name : podinfo Then create a Kustomization to deploy podinfo. apiVersion : kustomize.toolkit.fluxcd.io/v1beta1 kind : Kustomization metadata : name : podinfo namespace : flux-system spec : interval : 5m targetNamespace : podinfo path : ./clusters/my-cluster/podinfo prune : true sourceRef : kind : GitRepository name : flux-system healthChecks : - apiVersion : apps/v1 kind : Deployment name : podinfo namespace : podinfo timeout : 1m Creating a git provider is very similar to creating other types of providers. The only caveat being that the provider address needs to point to the same git repository as the event source originates from. apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Provider metadata : name : flux-system namespace : flux-system spec : type : github address : https://github.com/<username>/fleet-infra secretRef : name : github --- apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Alert metadata : name : podinfo namespace : flux-system spec : providerRef : name : flux-system eventSeverity : info eventSources : - kind : Kustomization name : podinfo namespace : flux-system By now the fleet-infra repository should have a similar directory structure. fleet-infra \u2514\u2500\u2500 clusters/ \u2514\u2500\u2500 my-cluster/ \u251c\u2500\u2500 flux-system/ \u2502 \u251c\u2500\u2500 gotk-components.yaml \u2502 \u251c\u2500\u2500 gotk-sync.yaml \u2502 \u2514\u2500\u2500 kustomization.yaml \u251c\u2500\u2500 podinfo/ \u2502 \u251c\u2500\u2500 namespace.yaml \u2502 \u251c\u2500\u2500 deployment.yaml \u2502 \u251c\u2500\u2500 hpa.yaml \u2502 \u251c\u2500\u2500 service.yaml \u2502 \u2514\u2500\u2500 kustomization.yaml \u251c\u2500\u2500 podinfo-kustomization.yaml \u2514\u2500\u2500 podinfo-notification.yaml If podinfo is deployed and the health checks pass you should get a successful status in your forked podinfo repository. If everything is setup correctly there should now be a green check-mark next to the latest commit. Clicking the check-mark should show a detailed view. GitHub GitLab Generate error A deployment failure can be forced by setting an invalid image tag in the podinfo deployment. apiVersion : apps/v1 kind : Deployment spec : template : spec : containers : - name : podinfod image : ghcr.io/stefanprodan/podinfo:fake After the commit has been reconciled it should return a failed commit status. This is where the health check in the Kustomization comes into play together with the timeout. The health check is used to asses the health of the Kustomization. A failed commit status will not be sent until the health check timeout. Setting a lower timeout will give feedback faster, but may sometimes not allow enough time for a new application to deploy. GitHub GitLab","title":"Git commit status"},{"location":"guides/notifications/#status-changes","text":"The provider will continuously receive events as they happen, and multiple events may be received for the same commit hash. The git providers are configured to only update the status if the status has changed. This is to avoid spamming the commit status history with the same status over and over again. There is an aspect of state fullness that needs to be considered, compared to the other notification providers, as the events are stored by the git provider. This means that the status of a commit can change over time. Initially a deployment may be healthy, resulting in a successful status. Down the line the application, and the health check, may start failing due to the amount of traffic it receives or external dependencies no longer being available. The change in the health check would cause the status to go from successful to failed. It is important to keep this in mind when building any automation tools that deals with the status, and consider the fact that receiving a successful status once does not mean it will always be successful.","title":"Status changes"},{"location":"guides/sealed-secrets/","text":"Sealed Secrets \u00b6 In order to store secrets safely in a public or private Git repository, you can use Bitnami's sealed-secrets controller and encrypt your Kubernetes Secrets into SealedSecrets. The sealed secrets can be decrypted only by the controller running in your cluster and nobody else can obtain the original secret, even if they have access to the Git repository. Prerequisites \u00b6 To follow this guide you'll need a Kubernetes cluster with the GitOps toolkit controllers installed on it. Please see the get started guide or the installation guide . The sealed-secrets controller comes with a companion CLI tool called kubeseal. With kubeseal you can create SealedSecret custom resources in YAML format and store those in your Git repository. Install the kubeseal CLI: brew install kubeseal For Linux or Windows you can download the kubeseal binary from GitHub . Deploy sealed-secrets with a HelmRelease \u00b6 You'll be using helm-controller APIs to install the sealed-secrets controller from its Helm chart . First you have to register the Helm repository where the sealed-secrets chart is published: flux create source helm sealed-secrets \\ --interval = 1h \\ --url = https://bitnami-labs.github.io/sealed-secrets With interval we configure source-controller to download the Helm repository index every hour. If a newer version of sealed-secrets is published, source-controller will signal helm-controller that a new chart is available. Create a Helm release that installs the latest version of sealed-secrets controller: flux create helmrelease sealed-secrets \\ --interval = 1h \\ --release-name = sealed-secrets \\ --target-namespace = flux-system \\ --source = HelmRepository/sealed-secrets \\ --chart = sealed-secrets \\ --chart-version = \"1.13.x\" With chart version 1.13.x we configure helm-controller to automatically upgrade the release when a new chart patch version is fetched by source-controller. At startup, the sealed-secrets controller generates a 4096-bit RSA key pair and persists the private and public keys as Kubernetes secrets in the flux-system namespace. You can retrieve the public key with: kubeseal --fetch-cert \\ --controller-name = sealed-secrets \\ --controller-namespace = flux-system \\ > pub-sealed-secrets.pem The public key can be safely stored in Git, and can be used to encrypt secrets without direct access to the Kubernetes cluster. Encrypt secrets \u00b6 Generate a Kubernetes secret manifest with kubectl: kubectl -n default create secret generic basic-auth \\ --from-literal = user = admin \\ --from-literal = password = change-me \\ --dry-run = client \\ -o yaml > basic-auth.yaml Encrypt the secret with kubeseal: kubeseal --format = yaml --cert = pub-sealed-secrets.pem \\ < basic-auth.yaml > basic-auth-sealed.yaml Delete the plain secret and apply the sealed one: rm basic-auth.yaml kubectl apply -f basic-auth-sealed.yaml Verify that the sealed-secrets controller has created the basic-auth Kubernetes Secret: $ kubectl -n default get secrets basic-auth NAME TYPE DATA AGE basic-auth Opaque 2 1m43s GitOps workflow \u00b6 A cluster admin should add the stable HelmRepository manifest and the sealed-secrets HelmRelease to the fleet repository. Helm repository manifest: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : stable namespace : flux-system spec : interval : 1h0m0s url : https://charts.helm.sh/stable Helm release manifest: apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : sealed-secrets namespace : flux-system spec : chart : spec : chart : sealed-secrets sourceRef : kind : HelmRepository name : stable version : \"1.13.x\" interval : 1h0m0s releaseName : sealed-secrets targetNamespace : flux-system Hint You can generate the above manifests using flux create <kind> --export > manifest.yaml . Once the sealed-secrets controller is installed, the admin fetches the public key and shares it with the teams that operate on the fleet clusters via Git. When a team member wants to create a Kubernetes Secret on a cluster, they uses kubeseal and the public key corresponding to that cluster to generate a SealedSecret. Assuming a team member wants to deploy an application that needs to connect to a database using a username and password, they'll be doing the following: create a Kubernetes Secret manifest locally with the db credentials e.g. db-auth.yaml encrypt the secret with kubeseal as db-auth-sealed.yaml delete the original secret file db-auth.yaml create a Kubernetes Deployment manifest for the app e.g. app-deployment.yaml add the Secret to the Deployment manifest as a volume mount or env var using the original name db-auth commit the manifests db-auth-sealed.yaml and app-deployment.yaml to a Git repository that's being synced by the GitOps toolkit controllers Once the manifests have been pushed to the Git repository, the following happens: source-controller pulls the changes from Git kustomize-controller applies the SealedSecret and the Deployment manifests sealed-secrets controller decrypts the SealedSecret and creates a Kubernetes Secret kubelet creates the pods and mounts the secret as a volume or env variable inside the app container","title":"Sealed Secrets"},{"location":"guides/sealed-secrets/#sealed-secrets","text":"In order to store secrets safely in a public or private Git repository, you can use Bitnami's sealed-secrets controller and encrypt your Kubernetes Secrets into SealedSecrets. The sealed secrets can be decrypted only by the controller running in your cluster and nobody else can obtain the original secret, even if they have access to the Git repository.","title":"Sealed Secrets"},{"location":"guides/sealed-secrets/#prerequisites","text":"To follow this guide you'll need a Kubernetes cluster with the GitOps toolkit controllers installed on it. Please see the get started guide or the installation guide . The sealed-secrets controller comes with a companion CLI tool called kubeseal. With kubeseal you can create SealedSecret custom resources in YAML format and store those in your Git repository. Install the kubeseal CLI: brew install kubeseal For Linux or Windows you can download the kubeseal binary from GitHub .","title":"Prerequisites"},{"location":"guides/sealed-secrets/#deploy-sealed-secrets-with-a-helmrelease","text":"You'll be using helm-controller APIs to install the sealed-secrets controller from its Helm chart . First you have to register the Helm repository where the sealed-secrets chart is published: flux create source helm sealed-secrets \\ --interval = 1h \\ --url = https://bitnami-labs.github.io/sealed-secrets With interval we configure source-controller to download the Helm repository index every hour. If a newer version of sealed-secrets is published, source-controller will signal helm-controller that a new chart is available. Create a Helm release that installs the latest version of sealed-secrets controller: flux create helmrelease sealed-secrets \\ --interval = 1h \\ --release-name = sealed-secrets \\ --target-namespace = flux-system \\ --source = HelmRepository/sealed-secrets \\ --chart = sealed-secrets \\ --chart-version = \"1.13.x\" With chart version 1.13.x we configure helm-controller to automatically upgrade the release when a new chart patch version is fetched by source-controller. At startup, the sealed-secrets controller generates a 4096-bit RSA key pair and persists the private and public keys as Kubernetes secrets in the flux-system namespace. You can retrieve the public key with: kubeseal --fetch-cert \\ --controller-name = sealed-secrets \\ --controller-namespace = flux-system \\ > pub-sealed-secrets.pem The public key can be safely stored in Git, and can be used to encrypt secrets without direct access to the Kubernetes cluster.","title":"Deploy sealed-secrets with a HelmRelease"},{"location":"guides/sealed-secrets/#encrypt-secrets","text":"Generate a Kubernetes secret manifest with kubectl: kubectl -n default create secret generic basic-auth \\ --from-literal = user = admin \\ --from-literal = password = change-me \\ --dry-run = client \\ -o yaml > basic-auth.yaml Encrypt the secret with kubeseal: kubeseal --format = yaml --cert = pub-sealed-secrets.pem \\ < basic-auth.yaml > basic-auth-sealed.yaml Delete the plain secret and apply the sealed one: rm basic-auth.yaml kubectl apply -f basic-auth-sealed.yaml Verify that the sealed-secrets controller has created the basic-auth Kubernetes Secret: $ kubectl -n default get secrets basic-auth NAME TYPE DATA AGE basic-auth Opaque 2 1m43s","title":"Encrypt secrets"},{"location":"guides/sealed-secrets/#gitops-workflow","text":"A cluster admin should add the stable HelmRepository manifest and the sealed-secrets HelmRelease to the fleet repository. Helm repository manifest: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : HelmRepository metadata : name : stable namespace : flux-system spec : interval : 1h0m0s url : https://charts.helm.sh/stable Helm release manifest: apiVersion : helm.toolkit.fluxcd.io/v2beta1 kind : HelmRelease metadata : name : sealed-secrets namespace : flux-system spec : chart : spec : chart : sealed-secrets sourceRef : kind : HelmRepository name : stable version : \"1.13.x\" interval : 1h0m0s releaseName : sealed-secrets targetNamespace : flux-system Hint You can generate the above manifests using flux create <kind> --export > manifest.yaml . Once the sealed-secrets controller is installed, the admin fetches the public key and shares it with the teams that operate on the fleet clusters via Git. When a team member wants to create a Kubernetes Secret on a cluster, they uses kubeseal and the public key corresponding to that cluster to generate a SealedSecret. Assuming a team member wants to deploy an application that needs to connect to a database using a username and password, they'll be doing the following: create a Kubernetes Secret manifest locally with the db credentials e.g. db-auth.yaml encrypt the secret with kubeseal as db-auth-sealed.yaml delete the original secret file db-auth.yaml create a Kubernetes Deployment manifest for the app e.g. app-deployment.yaml add the Secret to the Deployment manifest as a volume mount or env var using the original name db-auth commit the manifests db-auth-sealed.yaml and app-deployment.yaml to a Git repository that's being synced by the GitOps toolkit controllers Once the manifests have been pushed to the Git repository, the following happens: source-controller pulls the changes from Git kustomize-controller applies the SealedSecret and the Deployment manifests sealed-secrets controller decrypts the SealedSecret and creates a Kubernetes Secret kubelet creates the pods and mounts the secret as a volume or env variable inside the app container","title":"GitOps workflow"},{"location":"guides/sortable-image-tags/","text":"How to make sortable image tags to use with automation \u00b6 Flux v2 does not support selecting the lastest image by build time. Obtaining the build time needs the container config for each image, and fetching that is subject to strict rate limiting by image registries (e.g., by DockerHub ). This guide explains how to construct image tags so that the most recent image has the tag that comes last in alphabetical or numerical order. The technique suggested is to put a timestamp or serial number in each image tag. Formats and alternatives \u00b6 The important properties for sorting are that the parts of the timestamp go from most significant to least (e.g., the year down to the second). For numbers it is best to use numerical order, since this will work with values of different width (e.g., '12' sorts after '2'). Image tags are often shown in user interfaces, so readability matters. Here is an example of a readable timestamp that will sort well: $ # date and time (remember ':' is not allowed in a tag) $ date +%F.%H%M%S 2021 -01-28.133158 You can use a timestamp that sorts as a number, like Unix time : $ # seconds since Jan 1 1970 $ date +%s 1611840548 Alternatively, you can use a serial number as part of the tag. Some CI platforms will provide a build number in an environment variable, but that may not be reliable to use as a serial number -- check the platform documentation. A commit count can be a reasonable stand-in for a serial number, if you build an image per commit and you don't rewrite the branch in question: $ # commits in branch $ git --rev-list --count HEAD 1504 Beware: this will not give a useful number if you have a shallow clone. Other things to include in the image tag \u00b6 It is also handy to quickly trace an image to the branch and commit of its source code. Including the branch also means you can filter for images from a particular branch. A useful tag format is <branch>-<sha1>-<timestamp> The branch and tag will usually be made available in a CI platform as environment variables. See CircleCI's built-in variables CIRCLE_BRANCH and CIRCLE_SHA1 GitHub Actions' GITHUB_REF and GITHUB_SHA Travis CI's TRAVIS_BRANCH and TRAVIS_COMMIT . Example of a build process with timestamp tagging \u00b6 Here is an example of a GitHub Actions job that creates a \"build ID\" with the git branch, SHA1, and a timestamp, and uses it as a tag when building an image: jobs : build-push : env : IMAGE : org/my-app runs-on : ubuntu-latest steps : - name : Generate build ID id : prep run : | branch=${GITHUB_REF##*/} sha=${GITHUB_SHA::8} ts=$(date +%s) echo \"::set-output name=BUILD_ID::${branch}-${sha}-${ts}\" # These are prerequisites for the docker build step - name : Set up QEMU uses : docker/setup-qemu-action@v1 - name : Set up Docker Buildx uses : docker/setup-buildx-action@v1 - name : Login to DockerHub uses : docker/login-action@v1 with : username : ${{ secrets.DOCKERHUB_USERNAME }} password : ${{ secrets.DOCKERHUB_TOKEN }} - name : Build and publish container image with tag uses : docker/build-push-action@v2 with : push : true context : . file : ./Dockerfile tags : | ${{ env.IMAGE }}:${{ steps.prep.outputs.BUILD_ID }} Using in an ImagePolicy object \u00b6 When creating an ImagePolicy object, you will need to extract just the timestamp part of the tag, using the tagFilter field. You can filter for a particular branch to restrict images to only those built from that branch. Here is an example that filters for only images built from main branch, and selects the most recent according the timestamp (created with date +%s ): apiVersion: image.toolkit.fluxcd.io/v1alpha1 kind: ImagePolicy metadata: name: image-repo-policy namespace: flux-system spec: imageRepositoryRef: name: image-repo filterTags: pattern: '^main-[a-f0-9]+-(?P<ts>[0-9]+)' extract: '$ts' policy: numerical: order: asc If you don't care about the branch, that part can be a wildcard in the pattern: apiVersion: image.toolkit.fluxcd.io/v1alpha1 kind: ImagePolicy metadata: name: image-repo-policy namespace: flux-system spec: imageRepositoryRef: name: image-repo filterTags: pattern: '^.+-[a-f0-9]+-(?P<ts>[0-9]+)' extract: '$ts' policy: numerical: order: asc","title":"Sortable image tags to use with automation"},{"location":"guides/sortable-image-tags/#how-to-make-sortable-image-tags-to-use-with-automation","text":"Flux v2 does not support selecting the lastest image by build time. Obtaining the build time needs the container config for each image, and fetching that is subject to strict rate limiting by image registries (e.g., by DockerHub ). This guide explains how to construct image tags so that the most recent image has the tag that comes last in alphabetical or numerical order. The technique suggested is to put a timestamp or serial number in each image tag.","title":"How to make sortable image tags to use with automation"},{"location":"guides/sortable-image-tags/#formats-and-alternatives","text":"The important properties for sorting are that the parts of the timestamp go from most significant to least (e.g., the year down to the second). For numbers it is best to use numerical order, since this will work with values of different width (e.g., '12' sorts after '2'). Image tags are often shown in user interfaces, so readability matters. Here is an example of a readable timestamp that will sort well: $ # date and time (remember ':' is not allowed in a tag) $ date +%F.%H%M%S 2021 -01-28.133158 You can use a timestamp that sorts as a number, like Unix time : $ # seconds since Jan 1 1970 $ date +%s 1611840548 Alternatively, you can use a serial number as part of the tag. Some CI platforms will provide a build number in an environment variable, but that may not be reliable to use as a serial number -- check the platform documentation. A commit count can be a reasonable stand-in for a serial number, if you build an image per commit and you don't rewrite the branch in question: $ # commits in branch $ git --rev-list --count HEAD 1504 Beware: this will not give a useful number if you have a shallow clone.","title":"Formats and alternatives"},{"location":"guides/sortable-image-tags/#other-things-to-include-in-the-image-tag","text":"It is also handy to quickly trace an image to the branch and commit of its source code. Including the branch also means you can filter for images from a particular branch. A useful tag format is <branch>-<sha1>-<timestamp> The branch and tag will usually be made available in a CI platform as environment variables. See CircleCI's built-in variables CIRCLE_BRANCH and CIRCLE_SHA1 GitHub Actions' GITHUB_REF and GITHUB_SHA Travis CI's TRAVIS_BRANCH and TRAVIS_COMMIT .","title":"Other things to include in the image tag"},{"location":"guides/sortable-image-tags/#example-of-a-build-process-with-timestamp-tagging","text":"Here is an example of a GitHub Actions job that creates a \"build ID\" with the git branch, SHA1, and a timestamp, and uses it as a tag when building an image: jobs : build-push : env : IMAGE : org/my-app runs-on : ubuntu-latest steps : - name : Generate build ID id : prep run : | branch=${GITHUB_REF##*/} sha=${GITHUB_SHA::8} ts=$(date +%s) echo \"::set-output name=BUILD_ID::${branch}-${sha}-${ts}\" # These are prerequisites for the docker build step - name : Set up QEMU uses : docker/setup-qemu-action@v1 - name : Set up Docker Buildx uses : docker/setup-buildx-action@v1 - name : Login to DockerHub uses : docker/login-action@v1 with : username : ${{ secrets.DOCKERHUB_USERNAME }} password : ${{ secrets.DOCKERHUB_TOKEN }} - name : Build and publish container image with tag uses : docker/build-push-action@v2 with : push : true context : . file : ./Dockerfile tags : | ${{ env.IMAGE }}:${{ steps.prep.outputs.BUILD_ID }}","title":"Example of a build process with timestamp tagging"},{"location":"guides/sortable-image-tags/#using-in-an-imagepolicy-object","text":"When creating an ImagePolicy object, you will need to extract just the timestamp part of the tag, using the tagFilter field. You can filter for a particular branch to restrict images to only those built from that branch. Here is an example that filters for only images built from main branch, and selects the most recent according the timestamp (created with date +%s ): apiVersion: image.toolkit.fluxcd.io/v1alpha1 kind: ImagePolicy metadata: name: image-repo-policy namespace: flux-system spec: imageRepositoryRef: name: image-repo filterTags: pattern: '^main-[a-f0-9]+-(?P<ts>[0-9]+)' extract: '$ts' policy: numerical: order: asc If you don't care about the branch, that part can be a wildcard in the pattern: apiVersion: image.toolkit.fluxcd.io/v1alpha1 kind: ImagePolicy metadata: name: image-repo-policy namespace: flux-system spec: imageRepositoryRef: name: image-repo filterTags: pattern: '^.+-[a-f0-9]+-(?P<ts>[0-9]+)' extract: '$ts' policy: numerical: order: asc","title":"Using in an ImagePolicy object"},{"location":"guides/webhook-receivers/","text":"Setup Webhook Receivers \u00b6 The GitOps toolkit controllers are by design pull-based . In order to notify the controllers about changes in Git or Helm repositories, you can setup webhooks and trigger a cluster reconciliation every time a source changes. Using webhook receivers, you can build push-based GitOps pipelines that react to external events. Prerequisites \u00b6 To follow this guide you'll need a Kubernetes cluster with the GitOps toolkit controllers installed on it. Please see the get started guide or the installation guide . The notification controller can handle events coming from external systems (GitHub, GitLab, Bitbucket, Harbor, Jenkins, etc) and notify the GitOps toolkit controllers about source changes. The notification controller is part of the default toolkit installation. Expose the webhook receiver \u00b6 In order to receive Git push or Helm chart upload events, you'll have to expose the webhook receiver endpoint outside of your Kubernetes cluster on a public address. The notification controller handles webhook requests on port 9292 . This port can be used to create a Kubernetes LoadBalancer Service or Ingress. Create a LoadBalancer service: apiVersion : v1 kind : Service metadata : name : receiver namespace : flux-system spec : type : LoadBalancer selector : app : notification-controller ports : - name : http port : 80 protocol : TCP targetPort : 9292 Wait for Kubernetes to assign a public address with: watch kubectl -n flux-system get svc/receiver Define a Git repository \u00b6 Create a Git source pointing to a GitHub repository that you have control over: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : webapp namespace : flux-system spec : interval : 60m url : https://github.com/<GH-ORG>/<GH-REPO> ref : branch : master Authentication SSH or token based authentication can be configured for private repositories. See the GitRepository CRD docs for more details. Define a Git repository receiver \u00b6 First generate a random string and create a secret with a token field: TOKEN = $( head -c 12 /dev/urandom | shasum | cut -d ' ' -f1 ) echo $TOKEN kubectl -n flux-system create secret generic webhook-token \\ --from-literal = token = $TOKEN Create a receiver for GitHub and specify the GitRepository object: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : webapp namespace : flux-system spec : type : github events : - \"ping\" - \"push\" secretRef : name : webhook-token resources : - kind : GitRepository name : webapp Note Besides GitHub, you can define receivers for GitLab , Bitbucket , Harbor and any other system that supports webhooks e.g. Jenkins, CircleCI, etc. See the Receiver CRD docs for more details. The notification controller generates a unique URL using the provided token and the receiver name/namespace. Find the URL with: $ kubectl -n flux-system get receiver/webapp NAME READY STATUS webapp True Receiver initialised with URL: /hook/bed6d00b5555b1603e1f59b94d7fdbca58089cb5663633fb83f2815dc626d92b On GitHub, navigate to your repository and click on the \"Add webhook\" button under \"Settings/Webhooks\". Fill the form with: Payload URL : compose the address using the receiver LB and the generated URL http://<LoadBalancerAddress>/<ReceiverURL> Secret : use the token string With the above settings, when you push a commit to the repository, the following happens: GitHub sends the Git push event to the receiver address Notification controller validates the authenticity of the payload using HMAC Source controller is notified about the changes Source controller pulls the changes into the cluster and updates the GitRepository revision Kustomize controller is notified about the revision change Kustomize controller reconciles all the Kustomizations that reference the GitRepository object","title":"Setup Webhook Receivers"},{"location":"guides/webhook-receivers/#setup-webhook-receivers","text":"The GitOps toolkit controllers are by design pull-based . In order to notify the controllers about changes in Git or Helm repositories, you can setup webhooks and trigger a cluster reconciliation every time a source changes. Using webhook receivers, you can build push-based GitOps pipelines that react to external events.","title":"Setup Webhook Receivers"},{"location":"guides/webhook-receivers/#prerequisites","text":"To follow this guide you'll need a Kubernetes cluster with the GitOps toolkit controllers installed on it. Please see the get started guide or the installation guide . The notification controller can handle events coming from external systems (GitHub, GitLab, Bitbucket, Harbor, Jenkins, etc) and notify the GitOps toolkit controllers about source changes. The notification controller is part of the default toolkit installation.","title":"Prerequisites"},{"location":"guides/webhook-receivers/#expose-the-webhook-receiver","text":"In order to receive Git push or Helm chart upload events, you'll have to expose the webhook receiver endpoint outside of your Kubernetes cluster on a public address. The notification controller handles webhook requests on port 9292 . This port can be used to create a Kubernetes LoadBalancer Service or Ingress. Create a LoadBalancer service: apiVersion : v1 kind : Service metadata : name : receiver namespace : flux-system spec : type : LoadBalancer selector : app : notification-controller ports : - name : http port : 80 protocol : TCP targetPort : 9292 Wait for Kubernetes to assign a public address with: watch kubectl -n flux-system get svc/receiver","title":"Expose the webhook receiver"},{"location":"guides/webhook-receivers/#define-a-git-repository","text":"Create a Git source pointing to a GitHub repository that you have control over: apiVersion : source.toolkit.fluxcd.io/v1beta1 kind : GitRepository metadata : name : webapp namespace : flux-system spec : interval : 60m url : https://github.com/<GH-ORG>/<GH-REPO> ref : branch : master Authentication SSH or token based authentication can be configured for private repositories. See the GitRepository CRD docs for more details.","title":"Define a Git repository"},{"location":"guides/webhook-receivers/#define-a-git-repository-receiver","text":"First generate a random string and create a secret with a token field: TOKEN = $( head -c 12 /dev/urandom | shasum | cut -d ' ' -f1 ) echo $TOKEN kubectl -n flux-system create secret generic webhook-token \\ --from-literal = token = $TOKEN Create a receiver for GitHub and specify the GitRepository object: apiVersion : notification.toolkit.fluxcd.io/v1beta1 kind : Receiver metadata : name : webapp namespace : flux-system spec : type : github events : - \"ping\" - \"push\" secretRef : name : webhook-token resources : - kind : GitRepository name : webapp Note Besides GitHub, you can define receivers for GitLab , Bitbucket , Harbor and any other system that supports webhooks e.g. Jenkins, CircleCI, etc. See the Receiver CRD docs for more details. The notification controller generates a unique URL using the provided token and the receiver name/namespace. Find the URL with: $ kubectl -n flux-system get receiver/webapp NAME READY STATUS webapp True Receiver initialised with URL: /hook/bed6d00b5555b1603e1f59b94d7fdbca58089cb5663633fb83f2815dc626d92b On GitHub, navigate to your repository and click on the \"Add webhook\" button under \"Settings/Webhooks\". Fill the form with: Payload URL : compose the address using the receiver LB and the generated URL http://<LoadBalancerAddress>/<ReceiverURL> Secret : use the token string With the above settings, when you push a commit to the repository, the following happens: GitHub sends the Git push event to the receiver address Notification controller validates the authenticity of the payload using HMAC Source controller is notified about the changes Source controller pulls the changes into the cluster and updates the GitRepository revision Kustomize controller is notified about the revision change Kustomize controller reconciles all the Kustomizations that reference the GitRepository object","title":"Define a Git repository receiver"},{"location":"internal/release/","text":"Flux release procedure \u00b6 The Flux Go modules and the GitOps Toolkit controllers are released by following the semver conventions. Repositories subject to semver releases: fluxcd/pkg modules: apis/meta , runtime , various utilities dependencies: k8s.io/* , sigs.k8s.io/controller-runtime fluxcd/source-controller modules: api dependencies: github.com/fluxcd/pkg/* fluxcd/kustomize-controller modules: api dependencies: github.com/fluxcd/source-controller/api , github.com/fluxcd/pkg/* fluxcd/helm-controller modules: api dependencies: github.com/fluxcd/source-controller/api , github.com/fluxcd/pkg/* fluxcd/image-reflector-controller modules: api dependencies: github.com/fluxcd/pkg/* fluxcd/image-automation-controller modules: api dependencies: github.com/fluxcd/source-controller/api , github.com/fluxcd/image-reflector-controller/api , github.com/fluxcd/pkg/* fluxcd/notification-controller modules: api dependencies: github.com/fluxcd/source-controller/api , github.com/fluxcd/pkg/* fluxcd/flux2 modules: manifestgen dependencies: github.com/fluxcd/source-controller/api , github.com/fluxcd/kustomize-controller/api , github.com/fluxcd/helm-controller/api , github.com/fluxcd/image-reflector-controller/api , github.com/fluxcd/image-automation-controller/api , github.com/fluxcd/notification-controller/api , github.com/fluxcd/pkg/* fluxcd/terraform-provider-flux dependencies: github.com/fluxcd/flux2/pkg/manifestgen Release procedure \u00b6 Go packages \u00b6 The Go packages in fluxcd/pkg are dedicated modules, each module has its own set of dependencies and release cycle. Release procedure for a package: Checkout the main branch and pull changes from remote. Run make release-<package name> VER=<next semver> . Controllers \u00b6 A toolkit controller has a dedicated module for its API, the API module has its own set of dependencies. Release procedure for a controller and its API: Checkout the main branch and pull changes from remote. Create a api/<next semver> tag and push it to remote. Create a new branch from main i.e. release-<next semver> . This will function as your release preparation branch. Update the github.com/fluxcd/<NAME>-controller/api version in go.mod Add an entry to the CHANGELOG.md for the new release and change the newTag value in config/manager/kustomization.yaml to that of the semver release you are going to make. Commit and push your changes. Create a PR for your release branch and get it merged into main . Create a <next semver> tag for the merge commit in main and push it to remote. Confirm CI builds and releases the newly tagged version. Flux \u00b6 Release procedure for Flux: Checkout the main branch and pull changes from remote. Create a <next semver> tag form main and push it to remote. Confirm CI builds and releases the newly tagged version. Upgrade Kubernetes modules \u00b6 Flux has the following Kubernetes dependencies: k8s.io/api k8s.io/apiextensions-apiserver k8s.io/apimachinery k8s.io/cli-runtime k8s.io/client-go sigs.k8s.io/controller-runtime Note that all k8s.io/* packages must the have the same version in go.mod e.g.: k8s.io/api v0.20.2 k8s.io/apiextensions-apiserver v0.20.2 k8s.io/apimachinery v0.20.2 k8s.io/cli-runtime v0.20.2 k8s.io/client-go v0.20.2 The specialised reconcilers depend on: kustomize-controller: sigs.k8s.io/kustomize/api image-automation-controller: sigs.k8s.io/kustomize/kyaml helm-controller: helm.sh/helm/v3 Note that the k8s.io/* version must be compatible with both kustomize/api and helm/v3 . If there is a breaking change in client-go we have to wait for Kustomize and Helm to upgrade first. Upgrade procedure: fluxcd/pkg : Update the k8s.io/* version in pkg/apis/meta/go.mod Release the apis/meta package Update apis/meta version in pkg/runtime/go.mod Update the k8s.io/* version in pkg/runtime/go.mod Update sigs.k8s.io/controller-runtime version in pkg/runtime/go.mod Release the runtime package fluxcd/source-controller : Update the github.com/fluxcd/pkg/apis/meta version in source-controller/api/go.mod and source-controller/go.mod Update the k8s.io/* version in source-controller/api/go.mod and source-controller/go.mod Update the sigs.k8s.io/controller-runtime version in source-controller/api/go.mod and source-controller/go.mod Update the github.com/fluxcd/pkg/runtime version in source-controller/go.mod Release the api package fluxcd/<kustomize|helm|notification|image-automation>-controller : Update the github.com/fluxcd/source-controller/api version in controller/api/go.mod and controller/go.mod Update the github.com/fluxcd/pkg/apis/meta version in controller/api/go.mod and controller/go.mod Update the k8s.io/* version in controller/api/go.mod and controller/go.mod Update the github.com/fluxcd/pkg/runtime version in controller/go.mod Release the api package fluxcd/flux2 : Update the github.com/fluxcd/*-controller/api version in flux2/go.mod (automated with GitHub Actions ) Update the github.com/fluxcd/pkg/* version in flux2/go.mod Update the k8s.io/* and github.com/fluxcd/pkg/runtime version in flux2/go.mod fluxcd/terraform-provider-flux : Update the github.com/fluxcd/flux2 version in terraform-provider-flux/go.mod (automated with GitHub Actions )","title":"Flux release procedure"},{"location":"internal/release/#flux-release-procedure","text":"The Flux Go modules and the GitOps Toolkit controllers are released by following the semver conventions. Repositories subject to semver releases: fluxcd/pkg modules: apis/meta , runtime , various utilities dependencies: k8s.io/* , sigs.k8s.io/controller-runtime fluxcd/source-controller modules: api dependencies: github.com/fluxcd/pkg/* fluxcd/kustomize-controller modules: api dependencies: github.com/fluxcd/source-controller/api , github.com/fluxcd/pkg/* fluxcd/helm-controller modules: api dependencies: github.com/fluxcd/source-controller/api , github.com/fluxcd/pkg/* fluxcd/image-reflector-controller modules: api dependencies: github.com/fluxcd/pkg/* fluxcd/image-automation-controller modules: api dependencies: github.com/fluxcd/source-controller/api , github.com/fluxcd/image-reflector-controller/api , github.com/fluxcd/pkg/* fluxcd/notification-controller modules: api dependencies: github.com/fluxcd/source-controller/api , github.com/fluxcd/pkg/* fluxcd/flux2 modules: manifestgen dependencies: github.com/fluxcd/source-controller/api , github.com/fluxcd/kustomize-controller/api , github.com/fluxcd/helm-controller/api , github.com/fluxcd/image-reflector-controller/api , github.com/fluxcd/image-automation-controller/api , github.com/fluxcd/notification-controller/api , github.com/fluxcd/pkg/* fluxcd/terraform-provider-flux dependencies: github.com/fluxcd/flux2/pkg/manifestgen","title":"Flux release procedure"},{"location":"internal/release/#release-procedure","text":"","title":"Release procedure"},{"location":"internal/release/#go-packages","text":"The Go packages in fluxcd/pkg are dedicated modules, each module has its own set of dependencies and release cycle. Release procedure for a package: Checkout the main branch and pull changes from remote. Run make release-<package name> VER=<next semver> .","title":"Go packages"},{"location":"internal/release/#controllers","text":"A toolkit controller has a dedicated module for its API, the API module has its own set of dependencies. Release procedure for a controller and its API: Checkout the main branch and pull changes from remote. Create a api/<next semver> tag and push it to remote. Create a new branch from main i.e. release-<next semver> . This will function as your release preparation branch. Update the github.com/fluxcd/<NAME>-controller/api version in go.mod Add an entry to the CHANGELOG.md for the new release and change the newTag value in config/manager/kustomization.yaml to that of the semver release you are going to make. Commit and push your changes. Create a PR for your release branch and get it merged into main . Create a <next semver> tag for the merge commit in main and push it to remote. Confirm CI builds and releases the newly tagged version.","title":"Controllers"},{"location":"internal/release/#flux","text":"Release procedure for Flux: Checkout the main branch and pull changes from remote. Create a <next semver> tag form main and push it to remote. Confirm CI builds and releases the newly tagged version.","title":"Flux"},{"location":"internal/release/#upgrade-kubernetes-modules","text":"Flux has the following Kubernetes dependencies: k8s.io/api k8s.io/apiextensions-apiserver k8s.io/apimachinery k8s.io/cli-runtime k8s.io/client-go sigs.k8s.io/controller-runtime Note that all k8s.io/* packages must the have the same version in go.mod e.g.: k8s.io/api v0.20.2 k8s.io/apiextensions-apiserver v0.20.2 k8s.io/apimachinery v0.20.2 k8s.io/cli-runtime v0.20.2 k8s.io/client-go v0.20.2 The specialised reconcilers depend on: kustomize-controller: sigs.k8s.io/kustomize/api image-automation-controller: sigs.k8s.io/kustomize/kyaml helm-controller: helm.sh/helm/v3 Note that the k8s.io/* version must be compatible with both kustomize/api and helm/v3 . If there is a breaking change in client-go we have to wait for Kustomize and Helm to upgrade first. Upgrade procedure: fluxcd/pkg : Update the k8s.io/* version in pkg/apis/meta/go.mod Release the apis/meta package Update apis/meta version in pkg/runtime/go.mod Update the k8s.io/* version in pkg/runtime/go.mod Update sigs.k8s.io/controller-runtime version in pkg/runtime/go.mod Release the runtime package fluxcd/source-controller : Update the github.com/fluxcd/pkg/apis/meta version in source-controller/api/go.mod and source-controller/go.mod Update the k8s.io/* version in source-controller/api/go.mod and source-controller/go.mod Update the sigs.k8s.io/controller-runtime version in source-controller/api/go.mod and source-controller/go.mod Update the github.com/fluxcd/pkg/runtime version in source-controller/go.mod Release the api package fluxcd/<kustomize|helm|notification|image-automation>-controller : Update the github.com/fluxcd/source-controller/api version in controller/api/go.mod and controller/go.mod Update the github.com/fluxcd/pkg/apis/meta version in controller/api/go.mod and controller/go.mod Update the k8s.io/* version in controller/api/go.mod and controller/go.mod Update the github.com/fluxcd/pkg/runtime version in controller/go.mod Release the api package fluxcd/flux2 : Update the github.com/fluxcd/*-controller/api version in flux2/go.mod (automated with GitHub Actions ) Update the github.com/fluxcd/pkg/* version in flux2/go.mod Update the k8s.io/* and github.com/fluxcd/pkg/runtime version in flux2/go.mod fluxcd/terraform-provider-flux : Update the github.com/fluxcd/flux2 version in terraform-provider-flux/go.mod (automated with GitHub Actions )","title":"Upgrade Kubernetes modules"},{"location":"proposals/go-git-providers/","text":"go-git-providers \u00b6 Abstract \u00b6 This proposal aims to create a library with the import path github.com/fluxcd/go-git-providers ' (import name: gitprovider ), which provides an abstraction layer for talking to Git providers like GitHub, GitLab and Bitbucket. This would become a new repository, specifically targeted at being a general-purpose Git provider client for multiple providers and domains. Goals \u00b6 Support multiple Git provider backends (e.g. GitHub, GitLab, Bitbucket, etc.) using the same interface Support talking to multiple domains at once, including custom domains (e.g. talking to \"gitlab.com\" and \"version.aalto.fi\" from the same client) Support both no authentication (for public repos), basic auth, and OAuth2 for authentication Manipulating the following resources: Organizations : GET , LIST (both all accessible top-level orgs and sub-orgs) For a given Organization : Teams : GET and LIST Repositories : GET , LIST and POST Team Access : LIST , POST and DELETE Credentials : LIST , POST and DELETE Support sub-organizations (or \"sub-groups\" in GitLab) if possible Support reconciling an object for idempotent operations Pagination is automatically handled for LIST requests Transparently can manage teams (collections of users, sub-groups in Gitlab) with varying access to repos Follow library best practices in order to be easy to vendor (e.g. use major vX versioning & go.mod) Non-goals \u00b6 Support for features not mentioned above Design decisions \u00b6 A context.Context should be passed to every request as the first argument There should be two interfaces per resource, if applicable: one collection-specific interface, with a plural name (e.g. OrganizationsClient ), that has methods like Get() and List() one instance-specific interface, with a singular name (e.g. OrganizationClient ), that operates on that instance, e.g. allowing access to child resources, e.g. Teams() Every Create() signature shall have a {Resource}CreateOptions struct as the last argument. Delete() and similar methods may use the same pattern if needed All *Options structs shall be passed by value (i.e. non-nillable) and contain only nillable, optional fields All optional fields in the type structs shall be nillable It should be possible to create a fake API client for testing, implementing the same interfaces All type structs shall have a Validate() method, and optionally a Default() one All type structs shall expose their internal representation (from the underlying library) through the InternalGetter interface with a method GetInternal() interface{} Typed errors shall be returned, wrapped using Go 1.14's new features Go-style enums are used when there are only a few supported values for a field Every field is documented using Godoc comment, including +required or +optional to clearly signify its importance Support serializing the types to JSON (if needed for e.g. debugging) by adding tags Implementation \u00b6 Provider package \u00b6 The provider package, e.g. at github.com/fluxcd/go-git-providers/github , will have constructor methods so a client can be created, e.g. as follows: // Create a client for github.com without any authentication c := github . NewClient () // Create a client for an enterprise GitHub account, without any authentication c = github . NewClient ( github . WithBaseURL ( \"enterprise.github.com\" )) // Create a client for github.com using a personal oauth2 token c = github . NewClient ( github . WithOAuth2 ( \"<token-here>\" )) Client \u00b6 The definition of a Client is as follows: // Client is an interface that allows talking to a Git provider type Client interface { // The Client allows accessing all known resources ResourceClient // SupportedDomain returns the supported domain // This field is set at client creation time, and can't be changed SupportedDomain () string // ProviderID returns the provider ID (e.g. \"github\", \"gitlab\") for this client // This field is set at client creation time, and can't be changed ProviderID () ProviderID // Raw returns the Go client used under the hood for accessing the Git provider Raw () interface {} } As one can see, the Client is scoped for a single backing domain. ProviderID is a typed string, and every implementation package defines their own constant, e.g. const ProviderName = gitprovider.ProviderID(\"github\") . The ResourceClient actually allows talking to resources of the API, both for single objects, and collections: // ResourceClient allows access to resource-specific clients type ResourceClient interface { // Organization gets the OrganizationClient for the specific top-level organization // ErrNotTopLevelOrganization will be returned if the organization is not top-level when using Organization ( o OrganizationRef ) OrganizationClient // Organizations returns the OrganizationsClient handling sets of organizations Organizations () OrganizationsClient // Repository gets the RepositoryClient for the specified RepositoryRef Repository ( r RepositoryRef ) RepositoryClient // Repositories returns the RepositoriesClient handling sets of organizations Repositories () RepositoriesClient } In order to reference organizations and repositories, there are the OrganizationRef and RepositoryRef interfaces: // OrganizationRef references an organization in a Git provider type OrganizationRef interface { // String returns the HTTPS URL fmt . Stringer // GetDomain returns the URL-domain for the Git provider backend, e.g. gitlab.com or version.aalto.fi GetDomain () string // GetOrganization returns the top-level organization, i.e. \"weaveworks\" or \"kubernetes-sigs\" GetOrganization () string // GetSubOrganizations returns the names of sub-organizations (or sub-groups), // e.g. [\"engineering\", \"frontend\"] would be returned for gitlab.com/weaveworks/engineering/frontend GetSubOrganizations () [] string } // RepositoryRef references a repository hosted by a Git provider type RepositoryRef interface { // RepositoryRef requires an OrganizationRef to fully-qualify a repo reference OrganizationRef // GetRepository returns the name of the repository GetRepository () string } Along with these, there is OrganizationInfo and RepositoryInfo which implement the above mentioned interfaces in a straightforward way. If you want to create an OrganizationRef or RepositoryRef , you can either use NewOrganizationInfo() or NewRepositoryInfo() , filling in all parts of the reference, or use the ParseRepositoryURL(r string) (RepositoryRef, error) or ParseOrganizationURL(o string) (OrganizationRef, error) methods. As mentioned above, only one target domain is supported by the Client . This means e.g. that if the Client is configured for GitHub, and you feed it a GitLab URL to parse, ErrDomainUnsupported will be returned. This brings us to a higher-level client abstraction, MultiClient . MultiClient \u00b6 In order to automatically support multiple domains and providers using the same interface, MultiClient is introduced. The user would use the MultiClient as follows: // Create a client to github.com without authentication gh := github . NewClient () // Create a client to gitlab.com, authenticating with basic auth gl := gitlab . NewClient ( gitlab . WithBasicAuth ( \"<username>\" , \"<password\" )) // Create a client to the GitLab instance at version.aalto.fi, with a given OAuth2 token aalto := gitlab . NewClient ( gitlab . WithBaseURL ( \"version.aalto.fi\" ), gitlab . WithOAuth2Token ( \"<your-token>\" )) // Create a MultiClient which supports talking to any of these backends client := gitprovider . NewMultiClient ( gh , gl , aalto ) The interface definition of MultiClient is similar to that one of Client , both embedding ResourceClient , but it also allows access to domain-specific underlying Client 's: // MultiClient allows talking to multiple Git providers at once type MultiClient interface { // The MultiClient allows accessing all known resources, automatically choosing the right underlying // Client based on the resource's domain ResourceClient // SupportedDomains returns a list of known domains SupportedDomains () [] string // ClientForDomain returns the Client used for a specific domain ClientForDomain ( domain string ) ( Client , bool ) } OrganizationsClient \u00b6 The OrganizationsClient provides access to a set of organizations, as follows: // OrganizationsClient operates on organizations the user has access to type OrganizationsClient interface { // Get a specific organization the user has access to // This might also refer to a sub-organization // ErrNotFound is returned if the resource does not exist Get ( ctx context . Context , o OrganizationRef ) ( * Organization , error ) // List all top-level organizations the specific user has access to // List should return all available organizations, using multiple paginated requests if needed List ( ctx context . Context ) ([] Organization , error ) // Children returns the immediate child-organizations for the specific OrganizationRef o. // The OrganizationRef may point to any sub-organization that exists // This is not supported in GitHub // Children should return all available organizations, using multiple paginated requests if needed Children ( ctx context . Context , o OrganizationRef ) ([] Organization , error ) // Possibly add Create/Update/Delete methods later } The Organization struct is fairly straightforward for now: // Organization represents an (top-level- or sub-) organization type Organization struct { // OrganizationInfo provides the required fields // (Domain, Organization and SubOrganizations) required for being an OrganizationRef OrganizationInfo `json:\",inline\"` // InternalHolder implements the InternalGetter interface // +optional InternalHolder `json:\",inline\"` // Name is the human-friendly name of this organization, e.g. \"Weaveworks\" or \"Kubernetes SIGs\" // +required Name string `json:\"name\"` // Description returns a description for the organization // No default value at POST-time // +optional Description * string `json:\"description\"` } The OrganizationInfo struct is a straightforward struct just implementing the OrganizationRef interface with basic fields & getters. InternalHolder is implementing the InternalGetter interface as follows, and is embedded into all main structs: // InternalGetter allows access to the underlying object type InternalGetter interface { // GetInternal returns the underlying struct that's used GetInternal () interface {} } // InternalHolder can be embedded into other structs to implement the InternalGetter interface type InternalHolder struct { // Internal contains the underlying object. // +optional Internal interface {} `json:\"-\"` } OrganizationClient \u00b6 OrganizationClient allows access to a specific organization's underlying resources as follows: // OrganizationClient operates on a given/specific organization type OrganizationClient interface { // Teams gives access to the TeamsClient for this specific organization Teams () OrganizationTeamsClient } Organization Teams \u00b6 Teams belonging to a certain organization can at this moment be fetched on an individual basis, or listed. // OrganizationTeamsClient handles teams organization-wide type OrganizationTeamsClient interface { // Get a team within the specific organization // teamName may include slashes, to point to e.g. \"sub-teams\" i.e. subgroups in Gitlab // teamName must not be an empty string // ErrNotFound is returned if the resource does not exist Get ( ctx context . Context , teamName string ) ( * Team , error ) // List all teams (recursively, in terms of subgroups) within the specific organization // List should return all available organizations, using multiple paginated requests if needed List ( ctx context . Context ) ([] Team , error ) // Possibly add Create/Update/Delete methods later } The Team struct is defined as follows: // Team is a representation for a team of users inside of an organization type Team struct { // Team embeds OrganizationInfo which makes it automatically comply with OrganizationRef OrganizationInfo `json:\",inline\"` // Team embeds InternalHolder for accessing the underlying object // +optional InternalHolder `json:\",inline\"` // Name describes the name of the team. The team name may contain slashes // +required Name string `json:\"name\"` // Members points to a set of user names (logins) of the members of this team // +required Members [] string `json:\"members\"` } In GitLab, teams could be modelled as users in a sub-group. Those users can later be added as a single unit to access a given repository. RepositoriesClient \u00b6 RepositoriesClient provides access to a set of repositories for the user. // RepositoriesClient operates on repositories the user has access to type RepositoriesClient interface { // Get returns the repository at the given path // ErrNotFound is returned if the resource does not exist Get ( ctx context . Context , r RepositoryRef ) ( * Repository , error ) // List all repositories in the given organization // List should return all available organizations, using multiple paginated requests if needed List ( ctx context . Context , o OrganizationRef ) ([] Repository , error ) // Create creates a repository at the given organization path, with the given URL-encoded name and options // ErrAlreadyExists will be returned if the resource already exists Create ( ctx context . Context , r * Repository , opts RepositoryCreateOptions ) ( * Repository , error ) // Reconcile makes sure r is the actual state in the backing Git provider. If r doesn't exist // under the hood, it is created. If r is already the actual state, this is a no-op. If r isn't // the actual state, the resource will either be updated or deleted/recreated. Reconcile ( ctx context . Context , r * Repository ) error } RepositoryCreateOptions has options like AutoInit *bool , LicenseTemplate *string and so forth to allow an one-time initialization step. The Repository struct is defined as follows: // Repository represents a Git repository provided by a Git provider type Repository struct { // RepositoryInfo provides the required fields // (Domain, Organization, SubOrganizations and RepositoryName) // required for being an RepositoryRef RepositoryInfo `json:\",inline\"` // InternalHolder implements the InternalGetter interface // +optional InternalHolder `json:\",inline\"` // Description returns a description for the repository // No default value at POST-time // +optional Description * string `json:\"description\"` // Visibility returns the desired visibility for the repository // Default value at POST-time: RepoVisibilityPrivate // +optional Visibility * RepoVisibility } // GetCloneURL gets the clone URL for the specified transport type func ( r * Repository ) GetCloneURL ( transport TransportType ) string { return GetCloneURL ( r , transport ) } As can be seen, there is also a GetCloneURL function for the repository which allows resolving the URL from which to clone the repo, for a given transport method ( ssh and https are supported TransportType s) RepositoryClient \u00b6 RepositoryClient allows access to a given repository's underlying resources, like follows: // RepositoryClient operates on a given/specific repository type RepositoryClient interface { // TeamAccess gives access to what teams have access to this specific repository TeamAccess () RepositoryTeamAccessClient // Credentials gives access to manipulating credentials for accessing this specific repository Credentials () RepositoryCredentialsClient } Repository Teams \u00b6 RepositoryTeamAccessClient allows adding & removing teams from the list of authorized persons to access a repository. // RepositoryTeamAccessClient operates on the teams list for a specific repository type RepositoryTeamAccessClient interface { // Create adds a given team to the repo's team access control list // ErrAlreadyExists will be returned if the resource already exists // The embedded RepositoryInfo of ta does not need to be populated, but if it is, // it must equal to the RepositoryRef given to the RepositoryClient. Create ( ctx context . Context , ta * TeamAccess , opts RepositoryAddTeamOptions ) error // Lists the team access control list for this repo List ( ctx context . Context ) ([] TeamAccess , error ) // Reconcile makes sure ta is the actual state in the backing Git provider. If ta doesn't exist // under the hood, it is created. If ta is already the actual state, this is a no-op. If ta isn't // the actual state, the resource will either be updated or deleted/recreated. // The embedded RepositoryInfo of ta does not need to be populated, but if it is, // it must equal to the RepositoryRef given to the RepositoryClient. Reconcile ( ctx context . Context , ta * TeamAccess ) error // Delete removes the given team from the repo's team access control list // ErrNotFound is returned if the resource does not exist Delete ( ctx context . Context , teamName string ) error } The TeamAccess struct looks as follows: // TeamAccess describes a binding between a repository and a team type TeamAccess struct { // TeamAccess embeds RepositoryInfo which makes it automatically comply with RepositoryRef // +optional RepositoryInfo `json:\",inline\"` // TeamAccess embeds InternalHolder for accessing the underlying object // +optional InternalHolder `json:\",inline\"` // Name describes the name of the team. The team name may contain slashes // +required Name string `json:\"name\"` // Permission describes the permission level for which the team is allowed to operate // Default: read // Available options: See the TeamRepositoryPermission enum // +optional Permission * TeamRepositoryPermission } Repository Credentials \u00b6 RepositoryCredentialsClient allows adding & removing credentials (e.g. deploy keys) from accessing a specific repository. // RepositoryCredentialsClient operates on the access credential list for a specific repository type RepositoryCredentialsClient interface { // Create a credential with the given human-readable name, the given bytes and optional options // ErrAlreadyExists will be returned if the resource already exists Create ( ctx context . Context , c RepositoryCredential , opts CredentialCreateOptions ) error // Lists all credentials for the given credential type List ( ctx context . Context , t RepositoryCredentialType ) ([] RepositoryCredential , error ) // Reconcile makes sure c is the actual state in the backing Git provider. If c doesn't exist // under the hood, it is created. If c is already the actual state, this is a no-op. If c isn't // the actual state, the resource will either be updated or deleted/recreated. Reconcile ( ctx context . Context , c RepositoryCredential ) error // Deletes a credential from the repo. name corresponds to GetName() of the credential // ErrNotFound is returned if the resource does not exist Delete ( ctx context . Context , t RepositoryCredentialType , name string ) error } In order to support multiple different types of credentials, RepositoryCredential is an interface: // RepositoryCredential is a credential that allows access (either read-only or read-write) to the repo type RepositoryCredential interface { // GetType returns the type of the credential GetType () RepositoryCredentialType // GetName returns a name (or title/description) of the credential GetName () string // GetData returns the key that will be authorized to access the repo, this can e.g. be a SSH public key GetData () [] byte // IsReadOnly returns whether this credential is authorized to write to the repository or not IsReadOnly () bool } The default implementation of RepositoryCredential is DeployKey : // DeployKey represents a short-lived credential (e.g. an SSH public key) used for accessing a repository type DeployKey struct { // DeployKey embeds InternalHolder for accessing the underlying object // +optional InternalHolder `json:\",inline\"` // Title is the human-friendly interpretation of what the key is for (and does) // +required Title string `json:\"title\"` // Key specifies the public part of the deploy (e.g. SSH) key // +required Key [] byte `json:\"key\"` // ReadOnly specifies whether this DeployKey can write to the repository or not // Default value at POST-time: true // +optional ReadOnly * bool `json:\"readOnly\"` }","title":"go-git-providers"},{"location":"proposals/go-git-providers/#go-git-providers","text":"","title":"go-git-providers"},{"location":"proposals/go-git-providers/#abstract","text":"This proposal aims to create a library with the import path github.com/fluxcd/go-git-providers ' (import name: gitprovider ), which provides an abstraction layer for talking to Git providers like GitHub, GitLab and Bitbucket. This would become a new repository, specifically targeted at being a general-purpose Git provider client for multiple providers and domains.","title":"Abstract"},{"location":"proposals/go-git-providers/#goals","text":"Support multiple Git provider backends (e.g. GitHub, GitLab, Bitbucket, etc.) using the same interface Support talking to multiple domains at once, including custom domains (e.g. talking to \"gitlab.com\" and \"version.aalto.fi\" from the same client) Support both no authentication (for public repos), basic auth, and OAuth2 for authentication Manipulating the following resources: Organizations : GET , LIST (both all accessible top-level orgs and sub-orgs) For a given Organization : Teams : GET and LIST Repositories : GET , LIST and POST Team Access : LIST , POST and DELETE Credentials : LIST , POST and DELETE Support sub-organizations (or \"sub-groups\" in GitLab) if possible Support reconciling an object for idempotent operations Pagination is automatically handled for LIST requests Transparently can manage teams (collections of users, sub-groups in Gitlab) with varying access to repos Follow library best practices in order to be easy to vendor (e.g. use major vX versioning & go.mod)","title":"Goals"},{"location":"proposals/go-git-providers/#non-goals","text":"Support for features not mentioned above","title":"Non-goals"},{"location":"proposals/go-git-providers/#design-decisions","text":"A context.Context should be passed to every request as the first argument There should be two interfaces per resource, if applicable: one collection-specific interface, with a plural name (e.g. OrganizationsClient ), that has methods like Get() and List() one instance-specific interface, with a singular name (e.g. OrganizationClient ), that operates on that instance, e.g. allowing access to child resources, e.g. Teams() Every Create() signature shall have a {Resource}CreateOptions struct as the last argument. Delete() and similar methods may use the same pattern if needed All *Options structs shall be passed by value (i.e. non-nillable) and contain only nillable, optional fields All optional fields in the type structs shall be nillable It should be possible to create a fake API client for testing, implementing the same interfaces All type structs shall have a Validate() method, and optionally a Default() one All type structs shall expose their internal representation (from the underlying library) through the InternalGetter interface with a method GetInternal() interface{} Typed errors shall be returned, wrapped using Go 1.14's new features Go-style enums are used when there are only a few supported values for a field Every field is documented using Godoc comment, including +required or +optional to clearly signify its importance Support serializing the types to JSON (if needed for e.g. debugging) by adding tags","title":"Design decisions"},{"location":"proposals/go-git-providers/#implementation","text":"","title":"Implementation"},{"location":"proposals/go-git-providers/#provider-package","text":"The provider package, e.g. at github.com/fluxcd/go-git-providers/github , will have constructor methods so a client can be created, e.g. as follows: // Create a client for github.com without any authentication c := github . NewClient () // Create a client for an enterprise GitHub account, without any authentication c = github . NewClient ( github . WithBaseURL ( \"enterprise.github.com\" )) // Create a client for github.com using a personal oauth2 token c = github . NewClient ( github . WithOAuth2 ( \"<token-here>\" ))","title":"Provider package"},{"location":"proposals/go-git-providers/#client","text":"The definition of a Client is as follows: // Client is an interface that allows talking to a Git provider type Client interface { // The Client allows accessing all known resources ResourceClient // SupportedDomain returns the supported domain // This field is set at client creation time, and can't be changed SupportedDomain () string // ProviderID returns the provider ID (e.g. \"github\", \"gitlab\") for this client // This field is set at client creation time, and can't be changed ProviderID () ProviderID // Raw returns the Go client used under the hood for accessing the Git provider Raw () interface {} } As one can see, the Client is scoped for a single backing domain. ProviderID is a typed string, and every implementation package defines their own constant, e.g. const ProviderName = gitprovider.ProviderID(\"github\") . The ResourceClient actually allows talking to resources of the API, both for single objects, and collections: // ResourceClient allows access to resource-specific clients type ResourceClient interface { // Organization gets the OrganizationClient for the specific top-level organization // ErrNotTopLevelOrganization will be returned if the organization is not top-level when using Organization ( o OrganizationRef ) OrganizationClient // Organizations returns the OrganizationsClient handling sets of organizations Organizations () OrganizationsClient // Repository gets the RepositoryClient for the specified RepositoryRef Repository ( r RepositoryRef ) RepositoryClient // Repositories returns the RepositoriesClient handling sets of organizations Repositories () RepositoriesClient } In order to reference organizations and repositories, there are the OrganizationRef and RepositoryRef interfaces: // OrganizationRef references an organization in a Git provider type OrganizationRef interface { // String returns the HTTPS URL fmt . Stringer // GetDomain returns the URL-domain for the Git provider backend, e.g. gitlab.com or version.aalto.fi GetDomain () string // GetOrganization returns the top-level organization, i.e. \"weaveworks\" or \"kubernetes-sigs\" GetOrganization () string // GetSubOrganizations returns the names of sub-organizations (or sub-groups), // e.g. [\"engineering\", \"frontend\"] would be returned for gitlab.com/weaveworks/engineering/frontend GetSubOrganizations () [] string } // RepositoryRef references a repository hosted by a Git provider type RepositoryRef interface { // RepositoryRef requires an OrganizationRef to fully-qualify a repo reference OrganizationRef // GetRepository returns the name of the repository GetRepository () string } Along with these, there is OrganizationInfo and RepositoryInfo which implement the above mentioned interfaces in a straightforward way. If you want to create an OrganizationRef or RepositoryRef , you can either use NewOrganizationInfo() or NewRepositoryInfo() , filling in all parts of the reference, or use the ParseRepositoryURL(r string) (RepositoryRef, error) or ParseOrganizationURL(o string) (OrganizationRef, error) methods. As mentioned above, only one target domain is supported by the Client . This means e.g. that if the Client is configured for GitHub, and you feed it a GitLab URL to parse, ErrDomainUnsupported will be returned. This brings us to a higher-level client abstraction, MultiClient .","title":"Client"},{"location":"proposals/go-git-providers/#multiclient","text":"In order to automatically support multiple domains and providers using the same interface, MultiClient is introduced. The user would use the MultiClient as follows: // Create a client to github.com without authentication gh := github . NewClient () // Create a client to gitlab.com, authenticating with basic auth gl := gitlab . NewClient ( gitlab . WithBasicAuth ( \"<username>\" , \"<password\" )) // Create a client to the GitLab instance at version.aalto.fi, with a given OAuth2 token aalto := gitlab . NewClient ( gitlab . WithBaseURL ( \"version.aalto.fi\" ), gitlab . WithOAuth2Token ( \"<your-token>\" )) // Create a MultiClient which supports talking to any of these backends client := gitprovider . NewMultiClient ( gh , gl , aalto ) The interface definition of MultiClient is similar to that one of Client , both embedding ResourceClient , but it also allows access to domain-specific underlying Client 's: // MultiClient allows talking to multiple Git providers at once type MultiClient interface { // The MultiClient allows accessing all known resources, automatically choosing the right underlying // Client based on the resource's domain ResourceClient // SupportedDomains returns a list of known domains SupportedDomains () [] string // ClientForDomain returns the Client used for a specific domain ClientForDomain ( domain string ) ( Client , bool ) }","title":"MultiClient"},{"location":"proposals/go-git-providers/#organizationsclient","text":"The OrganizationsClient provides access to a set of organizations, as follows: // OrganizationsClient operates on organizations the user has access to type OrganizationsClient interface { // Get a specific organization the user has access to // This might also refer to a sub-organization // ErrNotFound is returned if the resource does not exist Get ( ctx context . Context , o OrganizationRef ) ( * Organization , error ) // List all top-level organizations the specific user has access to // List should return all available organizations, using multiple paginated requests if needed List ( ctx context . Context ) ([] Organization , error ) // Children returns the immediate child-organizations for the specific OrganizationRef o. // The OrganizationRef may point to any sub-organization that exists // This is not supported in GitHub // Children should return all available organizations, using multiple paginated requests if needed Children ( ctx context . Context , o OrganizationRef ) ([] Organization , error ) // Possibly add Create/Update/Delete methods later } The Organization struct is fairly straightforward for now: // Organization represents an (top-level- or sub-) organization type Organization struct { // OrganizationInfo provides the required fields // (Domain, Organization and SubOrganizations) required for being an OrganizationRef OrganizationInfo `json:\",inline\"` // InternalHolder implements the InternalGetter interface // +optional InternalHolder `json:\",inline\"` // Name is the human-friendly name of this organization, e.g. \"Weaveworks\" or \"Kubernetes SIGs\" // +required Name string `json:\"name\"` // Description returns a description for the organization // No default value at POST-time // +optional Description * string `json:\"description\"` } The OrganizationInfo struct is a straightforward struct just implementing the OrganizationRef interface with basic fields & getters. InternalHolder is implementing the InternalGetter interface as follows, and is embedded into all main structs: // InternalGetter allows access to the underlying object type InternalGetter interface { // GetInternal returns the underlying struct that's used GetInternal () interface {} } // InternalHolder can be embedded into other structs to implement the InternalGetter interface type InternalHolder struct { // Internal contains the underlying object. // +optional Internal interface {} `json:\"-\"` }","title":"OrganizationsClient"},{"location":"proposals/go-git-providers/#organizationclient","text":"OrganizationClient allows access to a specific organization's underlying resources as follows: // OrganizationClient operates on a given/specific organization type OrganizationClient interface { // Teams gives access to the TeamsClient for this specific organization Teams () OrganizationTeamsClient }","title":"OrganizationClient"},{"location":"proposals/go-git-providers/#organization-teams","text":"Teams belonging to a certain organization can at this moment be fetched on an individual basis, or listed. // OrganizationTeamsClient handles teams organization-wide type OrganizationTeamsClient interface { // Get a team within the specific organization // teamName may include slashes, to point to e.g. \"sub-teams\" i.e. subgroups in Gitlab // teamName must not be an empty string // ErrNotFound is returned if the resource does not exist Get ( ctx context . Context , teamName string ) ( * Team , error ) // List all teams (recursively, in terms of subgroups) within the specific organization // List should return all available organizations, using multiple paginated requests if needed List ( ctx context . Context ) ([] Team , error ) // Possibly add Create/Update/Delete methods later } The Team struct is defined as follows: // Team is a representation for a team of users inside of an organization type Team struct { // Team embeds OrganizationInfo which makes it automatically comply with OrganizationRef OrganizationInfo `json:\",inline\"` // Team embeds InternalHolder for accessing the underlying object // +optional InternalHolder `json:\",inline\"` // Name describes the name of the team. The team name may contain slashes // +required Name string `json:\"name\"` // Members points to a set of user names (logins) of the members of this team // +required Members [] string `json:\"members\"` } In GitLab, teams could be modelled as users in a sub-group. Those users can later be added as a single unit to access a given repository.","title":"Organization Teams"},{"location":"proposals/go-git-providers/#repositoriesclient","text":"RepositoriesClient provides access to a set of repositories for the user. // RepositoriesClient operates on repositories the user has access to type RepositoriesClient interface { // Get returns the repository at the given path // ErrNotFound is returned if the resource does not exist Get ( ctx context . Context , r RepositoryRef ) ( * Repository , error ) // List all repositories in the given organization // List should return all available organizations, using multiple paginated requests if needed List ( ctx context . Context , o OrganizationRef ) ([] Repository , error ) // Create creates a repository at the given organization path, with the given URL-encoded name and options // ErrAlreadyExists will be returned if the resource already exists Create ( ctx context . Context , r * Repository , opts RepositoryCreateOptions ) ( * Repository , error ) // Reconcile makes sure r is the actual state in the backing Git provider. If r doesn't exist // under the hood, it is created. If r is already the actual state, this is a no-op. If r isn't // the actual state, the resource will either be updated or deleted/recreated. Reconcile ( ctx context . Context , r * Repository ) error } RepositoryCreateOptions has options like AutoInit *bool , LicenseTemplate *string and so forth to allow an one-time initialization step. The Repository struct is defined as follows: // Repository represents a Git repository provided by a Git provider type Repository struct { // RepositoryInfo provides the required fields // (Domain, Organization, SubOrganizations and RepositoryName) // required for being an RepositoryRef RepositoryInfo `json:\",inline\"` // InternalHolder implements the InternalGetter interface // +optional InternalHolder `json:\",inline\"` // Description returns a description for the repository // No default value at POST-time // +optional Description * string `json:\"description\"` // Visibility returns the desired visibility for the repository // Default value at POST-time: RepoVisibilityPrivate // +optional Visibility * RepoVisibility } // GetCloneURL gets the clone URL for the specified transport type func ( r * Repository ) GetCloneURL ( transport TransportType ) string { return GetCloneURL ( r , transport ) } As can be seen, there is also a GetCloneURL function for the repository which allows resolving the URL from which to clone the repo, for a given transport method ( ssh and https are supported TransportType s)","title":"RepositoriesClient"},{"location":"proposals/go-git-providers/#repositoryclient","text":"RepositoryClient allows access to a given repository's underlying resources, like follows: // RepositoryClient operates on a given/specific repository type RepositoryClient interface { // TeamAccess gives access to what teams have access to this specific repository TeamAccess () RepositoryTeamAccessClient // Credentials gives access to manipulating credentials for accessing this specific repository Credentials () RepositoryCredentialsClient }","title":"RepositoryClient"},{"location":"proposals/go-git-providers/#repository-teams","text":"RepositoryTeamAccessClient allows adding & removing teams from the list of authorized persons to access a repository. // RepositoryTeamAccessClient operates on the teams list for a specific repository type RepositoryTeamAccessClient interface { // Create adds a given team to the repo's team access control list // ErrAlreadyExists will be returned if the resource already exists // The embedded RepositoryInfo of ta does not need to be populated, but if it is, // it must equal to the RepositoryRef given to the RepositoryClient. Create ( ctx context . Context , ta * TeamAccess , opts RepositoryAddTeamOptions ) error // Lists the team access control list for this repo List ( ctx context . Context ) ([] TeamAccess , error ) // Reconcile makes sure ta is the actual state in the backing Git provider. If ta doesn't exist // under the hood, it is created. If ta is already the actual state, this is a no-op. If ta isn't // the actual state, the resource will either be updated or deleted/recreated. // The embedded RepositoryInfo of ta does not need to be populated, but if it is, // it must equal to the RepositoryRef given to the RepositoryClient. Reconcile ( ctx context . Context , ta * TeamAccess ) error // Delete removes the given team from the repo's team access control list // ErrNotFound is returned if the resource does not exist Delete ( ctx context . Context , teamName string ) error } The TeamAccess struct looks as follows: // TeamAccess describes a binding between a repository and a team type TeamAccess struct { // TeamAccess embeds RepositoryInfo which makes it automatically comply with RepositoryRef // +optional RepositoryInfo `json:\",inline\"` // TeamAccess embeds InternalHolder for accessing the underlying object // +optional InternalHolder `json:\",inline\"` // Name describes the name of the team. The team name may contain slashes // +required Name string `json:\"name\"` // Permission describes the permission level for which the team is allowed to operate // Default: read // Available options: See the TeamRepositoryPermission enum // +optional Permission * TeamRepositoryPermission }","title":"Repository Teams"},{"location":"proposals/go-git-providers/#repository-credentials","text":"RepositoryCredentialsClient allows adding & removing credentials (e.g. deploy keys) from accessing a specific repository. // RepositoryCredentialsClient operates on the access credential list for a specific repository type RepositoryCredentialsClient interface { // Create a credential with the given human-readable name, the given bytes and optional options // ErrAlreadyExists will be returned if the resource already exists Create ( ctx context . Context , c RepositoryCredential , opts CredentialCreateOptions ) error // Lists all credentials for the given credential type List ( ctx context . Context , t RepositoryCredentialType ) ([] RepositoryCredential , error ) // Reconcile makes sure c is the actual state in the backing Git provider. If c doesn't exist // under the hood, it is created. If c is already the actual state, this is a no-op. If c isn't // the actual state, the resource will either be updated or deleted/recreated. Reconcile ( ctx context . Context , c RepositoryCredential ) error // Deletes a credential from the repo. name corresponds to GetName() of the credential // ErrNotFound is returned if the resource does not exist Delete ( ctx context . Context , t RepositoryCredentialType , name string ) error } In order to support multiple different types of credentials, RepositoryCredential is an interface: // RepositoryCredential is a credential that allows access (either read-only or read-write) to the repo type RepositoryCredential interface { // GetType returns the type of the credential GetType () RepositoryCredentialType // GetName returns a name (or title/description) of the credential GetName () string // GetData returns the key that will be authorized to access the repo, this can e.g. be a SSH public key GetData () [] byte // IsReadOnly returns whether this credential is authorized to write to the repository or not IsReadOnly () bool } The default implementation of RepositoryCredential is DeployKey : // DeployKey represents a short-lived credential (e.g. an SSH public key) used for accessing a repository type DeployKey struct { // DeployKey embeds InternalHolder for accessing the underlying object // +optional InternalHolder `json:\",inline\"` // Title is the human-friendly interpretation of what the key is for (and does) // +required Title string `json:\"title\"` // Key specifies the public part of the deploy (e.g. SSH) key // +required Key [] byte `json:\"key\"` // ReadOnly specifies whether this DeployKey can write to the repository or not // Default value at POST-time: true // +optional ReadOnly * bool `json:\"readOnly\"` }","title":"Repository Credentials"},{"location":"roadmap/","text":"Roadmap \u00b6 Production readiness The Flux custom resource definitions which are at v1beta1 and v2beta1 and their controllers are considered stable and production ready. Going forward, breaking changes to the beta CRDs will be accompanied by a conversion mechanism. The following components (included by default in flux bootstrap ) are considered production ready: source-controller kustomize-controller notification-controller helm-controller The following GitOps Toolkit APIs are considered production ready: source.toolkit.fluxcd.io/v1beta1 kustomize.toolkit.fluxcd.io/v1beta1 notification.toolkit.fluxcd.io/v1beta1 helm.toolkit.fluxcd.io/v2beta1 The road to Flux v2 GA \u00b6 In our planning discussions we have identified these possible areas of work, this list is subject to change while we gather feedback: Stabilize the image automation APIs Review the spec of ImageRepository , ImagePolicy and ImageUpdateAutomation Promote the image automation APIs to v1beta1 Include the image automation controllers in the default components list Improve the documentation Gather feedback on the migration guides and address more use-cases Incident management and troubleshooting guides Cloud specific guides (AWS, Azure, Google Cloud, more?) Consolidate the docs under fluxcd.io website The road to Flux v1 feature parity \u00b6 In our planning discussions we identified three areas of work: Feature parity with Flux v1 in read-only mode Feature parity with the image-update functionality in Flux v1 Feature parity with Helm Operator v1 Flux read-only feature parity \u00b6 100% Flux v2 read-only is ready to try. See the Getting Started how-to, and the Migration guide . This would be the first stepping stone: we want Flux v2 to be on-par with today's Flux in read-only mode and FluxCloud notifications. Goals Offer a migration guide for those that are using Flux in read-only mode to synchronize plain manifests Offer a migration guide for those that are using Flux in read-only mode to synchronize Kustomize overlays Offer a dedicated component for forwarding events to external messaging platforms Non-Goals Migrate users that are using Flux to run custom scripts with flux.yaml Automate the migration of flux.yaml kustomize users Tasks Design the events API Implement events in source and kustomize controllers Make the kustomize-controller apply/gc events on-par with Flux v1 apply events Design the notifications and events filtering API Implement a notification controller for Slack, MS Teams, Discord, Rocket Implement Prometheus metrics in source and kustomize controllers Review the git source and kustomize APIs Support bash-style variable substitution as an alternative to flux.yaml envsubst/sed usage Create a migration guide for flux.yaml kustomize users Include support for SOPS Flux image update feature parity \u00b6 100% Image automation is available as a prerelease. See this guide for how to install and use it. Goals Offer components that can replace Flux v1 image update feature Non-Goals Maintain backwards compatibility with Flux v1 annotations Order by timestamps found inside image layers Tasks Design the image scanning and automation API Implement an image scanning controller Public image repo support Credentials from Secret fluxcd/image-reflector-controller#35 Design the automation component Implement the image scan/patch/push workflow Integrate the new components in the Flux CLI fluxcd/flux2#538 Write a guide for how to use image automation ( guide here ) ACR/ECR/GCR integration ( guide here ) Write a migration guide from Flux v1 annotations ( guide here ) Helm v3 feature parity \u00b6 100% Helm support in Flux v2 is ready to try. See the Helm controller guide , and the Helm controller migration guide . Goals Offer a migration guide for those that are using Helm Operator with Helm v3 and charts from Helm and Git repositories Non-Goals Migrate users that are using Helm v2 Tasks Implement a Helm controller for Helm v3 covering all the current release options Discuss and design Helm releases based on source API: Providing values from sources Conditional remediation on failed Helm actions Support for Helm charts from Git Review the Helm release, chart and repository APIs Implement events in Helm controller Implement Prometheus metrics in Helm controller Implement support for values from Secret and ConfigMap resources Implement conditional remediation on (failed) Helm actions Implement support for Helm charts from Git Implement support for referring to an alternative chart values file Stabilize API Create a migration guide for Helm Operator users","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"Production readiness The Flux custom resource definitions which are at v1beta1 and v2beta1 and their controllers are considered stable and production ready. Going forward, breaking changes to the beta CRDs will be accompanied by a conversion mechanism. The following components (included by default in flux bootstrap ) are considered production ready: source-controller kustomize-controller notification-controller helm-controller The following GitOps Toolkit APIs are considered production ready: source.toolkit.fluxcd.io/v1beta1 kustomize.toolkit.fluxcd.io/v1beta1 notification.toolkit.fluxcd.io/v1beta1 helm.toolkit.fluxcd.io/v2beta1","title":"Roadmap"},{"location":"roadmap/#the-road-to-flux-v2-ga","text":"In our planning discussions we have identified these possible areas of work, this list is subject to change while we gather feedback: Stabilize the image automation APIs Review the spec of ImageRepository , ImagePolicy and ImageUpdateAutomation Promote the image automation APIs to v1beta1 Include the image automation controllers in the default components list Improve the documentation Gather feedback on the migration guides and address more use-cases Incident management and troubleshooting guides Cloud specific guides (AWS, Azure, Google Cloud, more?) Consolidate the docs under fluxcd.io website","title":"The road to Flux v2 GA"},{"location":"roadmap/#the-road-to-flux-v1-feature-parity","text":"In our planning discussions we identified three areas of work: Feature parity with Flux v1 in read-only mode Feature parity with the image-update functionality in Flux v1 Feature parity with Helm Operator v1","title":"The road to Flux v1 feature parity"},{"location":"roadmap/#flux-read-only-feature-parity","text":"100% Flux v2 read-only is ready to try. See the Getting Started how-to, and the Migration guide . This would be the first stepping stone: we want Flux v2 to be on-par with today's Flux in read-only mode and FluxCloud notifications. Goals Offer a migration guide for those that are using Flux in read-only mode to synchronize plain manifests Offer a migration guide for those that are using Flux in read-only mode to synchronize Kustomize overlays Offer a dedicated component for forwarding events to external messaging platforms Non-Goals Migrate users that are using Flux to run custom scripts with flux.yaml Automate the migration of flux.yaml kustomize users Tasks Design the events API Implement events in source and kustomize controllers Make the kustomize-controller apply/gc events on-par with Flux v1 apply events Design the notifications and events filtering API Implement a notification controller for Slack, MS Teams, Discord, Rocket Implement Prometheus metrics in source and kustomize controllers Review the git source and kustomize APIs Support bash-style variable substitution as an alternative to flux.yaml envsubst/sed usage Create a migration guide for flux.yaml kustomize users Include support for SOPS","title":"Flux read-only feature parity"},{"location":"roadmap/#flux-image-update-feature-parity","text":"100% Image automation is available as a prerelease. See this guide for how to install and use it. Goals Offer components that can replace Flux v1 image update feature Non-Goals Maintain backwards compatibility with Flux v1 annotations Order by timestamps found inside image layers Tasks Design the image scanning and automation API Implement an image scanning controller Public image repo support Credentials from Secret fluxcd/image-reflector-controller#35 Design the automation component Implement the image scan/patch/push workflow Integrate the new components in the Flux CLI fluxcd/flux2#538 Write a guide for how to use image automation ( guide here ) ACR/ECR/GCR integration ( guide here ) Write a migration guide from Flux v1 annotations ( guide here )","title":"Flux image update feature parity"},{"location":"roadmap/#helm-v3-feature-parity","text":"100% Helm support in Flux v2 is ready to try. See the Helm controller guide , and the Helm controller migration guide . Goals Offer a migration guide for those that are using Helm Operator with Helm v3 and charts from Helm and Git repositories Non-Goals Migrate users that are using Helm v2 Tasks Implement a Helm controller for Helm v3 covering all the current release options Discuss and design Helm releases based on source API: Providing values from sources Conditional remediation on failed Helm actions Support for Helm charts from Git Review the Helm release, chart and repository APIs Implement events in Helm controller Implement Prometheus metrics in Helm controller Implement support for values from Secret and ConfigMap resources Implement conditional remediation on (failed) Helm actions Implement support for Helm charts from Git Implement support for referring to an alternative chart values file Stabilize API Create a migration guide for Helm Operator users","title":"Helm v3 feature parity"}]}